{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Grad(m_lambda,W,train_X):\n",
    "    grad = m_lambda * W + (np.dot(train_X.transpose(), np.dot(train_X, W)))\n",
    "    return grad\n",
    "\n",
    "\n",
    "def Draw(loops,train_loss,validation_loss):\n",
    "    # the first 100loops\n",
    "    print('Drawing...')\n",
    "    plt.plot(np.arange(0,200,1), train_loss[0:200], label='Train Loss')\n",
    "    plt.plot(np.arange(0,200,1), validation_loss[0:200], label='Validation Loss')\n",
    "    plt.xlabel('loops')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('The First 200 loops')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # the last 10000 loops\n",
    "    plt.plot(np.arange(201, loops-1, 1), train_loss[201:loops-1], label='Train Loss')\n",
    "    plt.plot(np.arange(201, loops-1, 1), validation_loss[201:loops-1], label='Validation Loss')\n",
    "    plt.xlabel('loops')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('The rest loops')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('Draw Completed')\n",
    "\n",
    "\n",
    "def BGD(parameters):\n",
    "    tic1=time.time()\n",
    "    epsilon = parameters['epsilon']\n",
    "    max_loop=parameters['max_loops']\n",
    "    m_lambda=parameters['lambda']\n",
    "    N=parameters['learning_rate']\n",
    "    train_X=parameters['train_X']\n",
    "    train_Y=parameters['train_Y']\n",
    "    val_X=parameters['val_X']\n",
    "    val_Y=parameters['val_Y']\n",
    "    W=parameters['Weights']\n",
    "    count = 0\n",
    "    error = np.zeros((col, 1))\n",
    "    finish = 0\n",
    "    Tensor = np.dot(-train_X.transpose(), train_Y)  # It never change during our process, so I put it in a tensor to\n",
    "                                                    # decrease computation cost\n",
    "    TL=[]\n",
    "    VL=[]\n",
    "    while count <= max_loop:\n",
    "        count += 1\n",
    "        W = W - N * (Grad(m_lambda,W,train_X) + Tensor)\n",
    "        if (np.linalg.norm(W - error) < epsilon):\n",
    "            finish = 1\n",
    "            break\n",
    "        else:\n",
    "            error = W\n",
    "            Loss_Train=0.5*m_lambda*W.transpose().dot(W)+0.5*(train_Y-train_X.dot(W)).transpose().dot((train_Y-train_X.dot(W)))\n",
    "            Loss_Validation=0.5*m_lambda*W.transpose().dot(W)+0.5*(val_Y-val_X.dot(W)).transpose().dot((val_Y-val_X.dot(W)))\n",
    "            TL.append(Loss_Train[0]/train_X.shape[0])\n",
    "            VL.append(Loss_Validation[0]/val_X.shape[0])\n",
    "            print('Loop {}'.format(count),'Loss_Train: ',Loss_Train/train_X.shape[0],'Loss_Validation: ', Loss_Validation/val_X.shape[0])\n",
    "            # print(count)  #You can choose whether to print Count/W\n",
    "            # print(W)\n",
    "    print('BGD Completed Successfully. Time Used:{}s'.format(time.time()-tic1))\n",
    "    return count,TL,VL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1 Loss_Train:  [[ 280.1450163]] Loss_Validation:  [[ 300.07944075]]\n",
      "Loop 2 Loss_Train:  [[ 229.38039819]] Loss_Validation:  [[ 244.79294922]]\n",
      "Loop 3 Loss_Train:  [[ 189.43877374]] Loss_Validation:  [[ 201.21351158]]\n",
      "Loop 4 Loss_Train:  [[ 157.99342772]] Loss_Validation:  [[ 166.83648034]]\n",
      "Loop 5 Loss_Train:  [[ 133.21856653]] Loss_Validation:  [[ 139.69480336]]\n",
      "Loop 6 Loss_Train:  [[ 113.68141721]] Loss_Validation:  [[ 118.24344262]]\n",
      "Loop 7 Loss_Train:  [[ 98.25757426]] Loss_Validation:  [[ 101.26866558]]\n",
      "Loop 8 Loss_Train:  [[ 86.06458488]] Loss_Validation:  [[ 87.81685404]]\n",
      "Loop 9 Loss_Train:  [[ 76.40984266]] Loss_Validation:  [[ 77.13862824]]\n",
      "Loop 10 Loss_Train:  [[ 68.74970676]] Loss_Validation:  [[ 68.64498946]]\n",
      "Loop 11 Loss_Train:  [[ 62.65742774]] Loss_Validation:  [[ 61.87289401]]\n",
      "Loop 12 Loss_Train:  [[ 57.79798263]] Loss_Validation:  [[ 56.45822873]]\n",
      "Loop 13 Loss_Train:  [[ 53.90833052]] Loss_Validation:  [[ 52.11459542]]\n",
      "Loop 14 Loss_Train:  [[ 50.7819208]] Loss_Validation:  [[ 48.61665398]]\n",
      "Loop 15 Loss_Train:  [[ 48.25653792]] Loss_Validation:  [[ 45.78704392]]\n",
      "Loop 16 Loss_Train:  [[ 46.20476372]] Loss_Validation:  [[ 43.48611429]]\n",
      "Loop 17 Loss_Train:  [[ 44.52649352]] Loss_Validation:  [[ 41.60385819]]\n",
      "Loop 18 Loss_Train:  [[ 43.14306356]] Loss_Validation:  [[ 40.05357786]]\n",
      "Loop 19 Loss_Train:  [[ 41.99264262]] Loss_Validation:  [[ 38.76690842]]\n",
      "Loop 20 Loss_Train:  [[ 41.02661556]] Loss_Validation:  [[ 37.68990818]]\n",
      "Loop 21 Loss_Train:  [[ 40.20674513]] Loss_Validation:  [[ 36.77998651]]\n",
      "Loop 22 Loss_Train:  [[ 39.50294449]] Loss_Validation:  [[ 36.00348939]]\n",
      "Loop 23 Loss_Train:  [[ 38.89152884]] Loss_Validation:  [[ 35.33380136]]\n",
      "Loop 24 Loss_Train:  [[ 38.35384303]] Loss_Validation:  [[ 34.74985323]]\n",
      "Loop 25 Loss_Train:  [[ 37.87518427]] Loss_Validation:  [[ 34.23494836]]\n",
      "Loop 26 Loss_Train:  [[ 37.44395633]] Loss_Validation:  [[ 33.77583933]]\n",
      "Loop 27 Loss_Train:  [[ 37.0510054]] Loss_Validation:  [[ 33.36200136]]\n",
      "Loop 28 Loss_Train:  [[ 36.68909865]] Loss_Validation:  [[ 32.98506022]]\n",
      "Loop 29 Loss_Train:  [[ 36.35251455]] Loss_Validation:  [[ 32.6383418]]\n",
      "Loop 30 Loss_Train:  [[ 36.03672125]] Loss_Validation:  [[ 32.31651717]]\n",
      "Loop 31 Loss_Train:  [[ 35.73812368]] Loss_Validation:  [[ 32.01532275]]\n",
      "Loop 32 Loss_Train:  [[ 35.45386498]] Loss_Validation:  [[ 31.73133966]]\n",
      "Loop 33 Loss_Train:  [[ 35.18167031]] Loss_Validation:  [[ 31.46181955]]\n",
      "Loop 34 Loss_Train:  [[ 34.91972409]] Loss_Validation:  [[ 31.20454706]]\n",
      "Loop 35 Loss_Train:  [[ 34.66657341]] Loss_Validation:  [[ 30.9577311]]\n",
      "Loop 36 Loss_Train:  [[ 34.42105207]] Loss_Validation:  [[ 30.71991889]]\n",
      "Loop 37 Loss_Train:  [[ 34.18222074]] Loss_Validation:  [[ 30.48992785]]\n",
      "Loop 38 Loss_Train:  [[ 33.94931987]] Loss_Validation:  [[ 30.26679163]]\n",
      "Loop 39 Loss_Train:  [[ 33.72173256]] Loss_Validation:  [[ 30.04971733]]\n",
      "Loop 40 Loss_Train:  [[ 33.49895527]] Loss_Validation:  [[ 29.83805145]]\n",
      "Loop 41 Loss_Train:  [[ 33.28057476]] Loss_Validation:  [[ 29.63125284]]\n",
      "Loop 42 Loss_Train:  [[ 33.0662498]] Loss_Validation:  [[ 29.42887112]]\n",
      "Loop 43 Loss_Train:  [[ 32.85569676]] Loss_Validation:  [[ 29.23052949]]\n",
      "Loop 44 Loss_Train:  [[ 32.64867821]] Loss_Validation:  [[ 29.03591093]]\n",
      "Loop 45 Loss_Train:  [[ 32.44499386]] Loss_Validation:  [[ 28.84474722]]\n",
      "Loop 46 Loss_Train:  [[ 32.2444734]] Loss_Validation:  [[ 28.65681003]]\n",
      "Loop 47 Loss_Train:  [[ 32.04697076]] Loss_Validation:  [[ 28.47190384]]\n",
      "Loop 48 Loss_Train:  [[ 31.85235961]] Loss_Validation:  [[ 28.28986018]]\n",
      "Loop 49 Loss_Train:  [[ 31.66052969]] Loss_Validation:  [[ 28.11053293]]\n",
      "Loop 50 Loss_Train:  [[ 31.47138398]] Loss_Validation:  [[ 27.93379462]]\n",
      "Loop 51 Loss_Train:  [[ 31.28483632]] Loss_Validation:  [[ 27.75953331]]\n",
      "Loop 52 Loss_Train:  [[ 31.10080955]] Loss_Validation:  [[ 27.58765008]]\n",
      "Loop 53 Loss_Train:  [[ 30.91923405]] Loss_Validation:  [[ 27.41805702]]\n",
      "Loop 54 Loss_Train:  [[ 30.74004648]] Loss_Validation:  [[ 27.25067547]]\n",
      "Loop 55 Loss_Train:  [[ 30.56318881]] Loss_Validation:  [[ 27.08543469]]\n",
      "Loop 56 Loss_Train:  [[ 30.38860752]] Loss_Validation:  [[ 26.92227068]]\n",
      "Loop 57 Loss_Train:  [[ 30.21625294]] Loss_Validation:  [[ 26.7611252]]\n",
      "Loop 58 Loss_Train:  [[ 30.0460787]] Loss_Validation:  [[ 26.601945]]\n",
      "Loop 59 Loss_Train:  [[ 29.87804129]] Loss_Validation:  [[ 26.44468114]]\n",
      "Loop 60 Loss_Train:  [[ 29.71209971]] Loss_Validation:  [[ 26.28928841]]\n",
      "Loop 61 Loss_Train:  [[ 29.54821513]] Loss_Validation:  [[ 26.13572489]]\n",
      "Loop 62 Loss_Train:  [[ 29.38635066]] Loss_Validation:  [[ 25.98395149]]\n",
      "Loop 63 Loss_Train:  [[ 29.22647111]] Loss_Validation:  [[ 25.83393164]]\n",
      "Loop 64 Loss_Train:  [[ 29.0685428]] Loss_Validation:  [[ 25.68563101]]\n",
      "Loop 65 Loss_Train:  [[ 28.91253346]] Loss_Validation:  [[ 25.53901722]]\n",
      "Loop 66 Loss_Train:  [[ 28.75841202]] Loss_Validation:  [[ 25.39405964]]\n",
      "Loop 67 Loss_Train:  [[ 28.60614854]] Loss_Validation:  [[ 25.25072921]]\n",
      "Loop 68 Loss_Train:  [[ 28.45571411]] Loss_Validation:  [[ 25.10899828]]\n",
      "Loop 69 Loss_Train:  [[ 28.30708073]] Loss_Validation:  [[ 24.96884043]]\n",
      "Loop 70 Loss_Train:  [[ 28.16022128]] Loss_Validation:  [[ 24.83023042]]\n",
      "Loop 71 Loss_Train:  [[ 28.01510942]] Loss_Validation:  [[ 24.69314399]]\n",
      "Loop 72 Loss_Train:  [[ 27.87171955]] Loss_Validation:  [[ 24.55755784]]\n",
      "Loop 73 Loss_Train:  [[ 27.73002674]] Loss_Validation:  [[ 24.42344953]]\n",
      "Loop 74 Loss_Train:  [[ 27.59000672]] Loss_Validation:  [[ 24.29079737]]\n",
      "Loop 75 Loss_Train:  [[ 27.45163578]] Loss_Validation:  [[ 24.15958041]]\n",
      "Loop 76 Loss_Train:  [[ 27.31489079]] Loss_Validation:  [[ 24.02977834]]\n",
      "Loop 77 Loss_Train:  [[ 27.17974915]] Loss_Validation:  [[ 23.90137145]]\n",
      "Loop 78 Loss_Train:  [[ 27.04618874]] Loss_Validation:  [[ 23.77434061]]\n",
      "Loop 79 Loss_Train:  [[ 26.91418792]] Loss_Validation:  [[ 23.6486672]]\n",
      "Loop 80 Loss_Train:  [[ 26.78372549]] Loss_Validation:  [[ 23.52433306]]\n",
      "Loop 81 Loss_Train:  [[ 26.65478067]] Loss_Validation:  [[ 23.40132053]]\n",
      "Loop 82 Loss_Train:  [[ 26.52733311]] Loss_Validation:  [[ 23.27961233]]\n",
      "Loop 83 Loss_Train:  [[ 26.4013628]] Loss_Validation:  [[ 23.15919159]]\n",
      "Loop 84 Loss_Train:  [[ 26.27685014]] Loss_Validation:  [[ 23.04004182]]\n",
      "Loop 85 Loss_Train:  [[ 26.15377587]] Loss_Validation:  [[ 22.92214688]]\n",
      "Loop 86 Loss_Train:  [[ 26.03212106]] Loss_Validation:  [[ 22.80549097]]\n",
      "Loop 87 Loss_Train:  [[ 25.91186711]] Loss_Validation:  [[ 22.69005857]]\n",
      "Loop 88 Loss_Train:  [[ 25.79299576]] Loss_Validation:  [[ 22.57583451]]\n",
      "Loop 89 Loss_Train:  [[ 25.67548903]] Loss_Validation:  [[ 22.46280388]]\n",
      "Loop 90 Loss_Train:  [[ 25.55932923]] Loss_Validation:  [[ 22.35095204]]\n",
      "Loop 91 Loss_Train:  [[ 25.44449897]] Loss_Validation:  [[ 22.24026463]]\n",
      "Loop 92 Loss_Train:  [[ 25.33098113]] Loss_Validation:  [[ 22.13072752]]\n",
      "Loop 93 Loss_Train:  [[ 25.21875887]] Loss_Validation:  [[ 22.02232684]]\n",
      "Loop 94 Loss_Train:  [[ 25.1078156]] Loss_Validation:  [[ 21.91504892]]\n",
      "Loop 95 Loss_Train:  [[ 24.99813498]] Loss_Validation:  [[ 21.80888037]]\n",
      "Loop 96 Loss_Train:  [[ 24.88970092]] Loss_Validation:  [[ 21.70380795]]\n",
      "Loop 97 Loss_Train:  [[ 24.78249757]] Loss_Validation:  [[ 21.59981868]]\n",
      "Loop 98 Loss_Train:  [[ 24.67650933]] Loss_Validation:  [[ 21.49689975]]\n",
      "Loop 99 Loss_Train:  [[ 24.57172081]] Loss_Validation:  [[ 21.39503856]]\n",
      "Loop 100 Loss_Train:  [[ 24.46811685]] Loss_Validation:  [[ 21.2942227]]\n",
      "Loop 101 Loss_Train:  [[ 24.36568251]] Loss_Validation:  [[ 21.19443995]]\n",
      "Loop 102 Loss_Train:  [[ 24.26440307]] Loss_Validation:  [[ 21.09567825]]\n",
      "Loop 103 Loss_Train:  [[ 24.16426401]] Loss_Validation:  [[ 20.99792573]]\n",
      "Loop 104 Loss_Train:  [[ 24.06525103]] Loss_Validation:  [[ 20.90117069]]\n",
      "Loop 105 Loss_Train:  [[ 23.96735]] Loss_Validation:  [[ 20.80540159]]\n",
      "Loop 106 Loss_Train:  [[ 23.87054703]] Loss_Validation:  [[ 20.71060706]]\n",
      "Loop 107 Loss_Train:  [[ 23.7748284]] Loss_Validation:  [[ 20.61677588]]\n",
      "Loop 108 Loss_Train:  [[ 23.68018057]] Loss_Validation:  [[ 20.523897]]\n",
      "Loop 109 Loss_Train:  [[ 23.58659022]] Loss_Validation:  [[ 20.4319595]]\n",
      "Loop 110 Loss_Train:  [[ 23.49404418]] Loss_Validation:  [[ 20.34095263]]\n",
      "Loop 111 Loss_Train:  [[ 23.40252948]] Loss_Validation:  [[ 20.25086577]]\n",
      "Loop 112 Loss_Train:  [[ 23.31203332]] Loss_Validation:  [[ 20.16168845]]\n",
      "Loop 113 Loss_Train:  [[ 23.22254307]] Loss_Validation:  [[ 20.07341034]]\n",
      "Loop 114 Loss_Train:  [[ 23.13404629]] Loss_Validation:  [[ 19.98602126]]\n",
      "Loop 115 Loss_Train:  [[ 23.04653069]] Loss_Validation:  [[ 19.89951113]]\n",
      "Loop 116 Loss_Train:  [[ 22.95998414]] Loss_Validation:  [[ 19.81387003]]\n",
      "Loop 117 Loss_Train:  [[ 22.8743947]] Loss_Validation:  [[ 19.72908817]]\n",
      "Loop 118 Loss_Train:  [[ 22.78975056]] Loss_Validation:  [[ 19.64515587]]\n",
      "Loop 119 Loss_Train:  [[ 22.7060401]] Loss_Validation:  [[ 19.5620636]]\n",
      "Loop 120 Loss_Train:  [[ 22.62325182]] Loss_Validation:  [[ 19.47980193]]\n",
      "Loop 121 Loss_Train:  [[ 22.5413744]] Loss_Validation:  [[ 19.39836156]]\n",
      "Loop 122 Loss_Train:  [[ 22.46039667]] Loss_Validation:  [[ 19.31773331]]\n",
      "Loop 123 Loss_Train:  [[ 22.38030758]] Loss_Validation:  [[ 19.23790812]]\n",
      "Loop 124 Loss_Train:  [[ 22.30109626]] Loss_Validation:  [[ 19.15887705]]\n",
      "Loop 125 Loss_Train:  [[ 22.22275197]] Loss_Validation:  [[ 19.08063125]]\n",
      "Loop 126 Loss_Train:  [[ 22.14526411]] Loss_Validation:  [[ 19.003162]]\n",
      "Loop 127 Loss_Train:  [[ 22.06862223]] Loss_Validation:  [[ 18.92646069]]\n",
      "Loop 128 Loss_Train:  [[ 21.99281599]] Loss_Validation:  [[ 18.85051883]]\n",
      "Loop 129 Loss_Train:  [[ 21.91783523]] Loss_Validation:  [[ 18.775328]]\n",
      "Loop 130 Loss_Train:  [[ 21.84366989]] Loss_Validation:  [[ 18.70087991]]\n",
      "Loop 131 Loss_Train:  [[ 21.77031005]] Loss_Validation:  [[ 18.62716638]]\n",
      "Loop 132 Loss_Train:  [[ 21.69774592]] Loss_Validation:  [[ 18.55417932]]\n",
      "Loop 133 Loss_Train:  [[ 21.62596784]] Loss_Validation:  [[ 18.48191074]]\n",
      "Loop 134 Loss_Train:  [[ 21.55496629]] Loss_Validation:  [[ 18.41035276]]\n",
      "Loop 135 Loss_Train:  [[ 21.48473184]] Loss_Validation:  [[ 18.33949757]]\n",
      "Loop 136 Loss_Train:  [[ 21.41525522]] Loss_Validation:  [[ 18.26933748]]\n",
      "Loop 137 Loss_Train:  [[ 21.34652726]] Loss_Validation:  [[ 18.1998649]]\n",
      "Loop 138 Loss_Train:  [[ 21.27853891]] Loss_Validation:  [[ 18.13107232]]\n",
      "Loop 139 Loss_Train:  [[ 21.21128125]] Loss_Validation:  [[ 18.06295231]]\n",
      "Loop 140 Loss_Train:  [[ 21.14474546]] Loss_Validation:  [[ 17.99549756]]\n",
      "Loop 141 Loss_Train:  [[ 21.07892284]] Loss_Validation:  [[ 17.92870083]]\n",
      "Loop 142 Loss_Train:  [[ 21.01380482]] Loss_Validation:  [[ 17.86255497]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 143 Loss_Train:  [[ 20.94938291]] Loss_Validation:  [[ 17.79705292]]\n",
      "Loop 144 Loss_Train:  [[ 20.88564875]] Loss_Validation:  [[ 17.7321877]]\n",
      "Loop 145 Loss_Train:  [[ 20.82259409]] Loss_Validation:  [[ 17.66795242]]\n",
      "Loop 146 Loss_Train:  [[ 20.76021077]] Loss_Validation:  [[ 17.60434027]]\n",
      "Loop 147 Loss_Train:  [[ 20.69849076]] Loss_Validation:  [[ 17.54134453]]\n",
      "Loop 148 Loss_Train:  [[ 20.63742611]] Loss_Validation:  [[ 17.47895856]]\n",
      "Loop 149 Loss_Train:  [[ 20.57700898]] Loss_Validation:  [[ 17.41717577]]\n",
      "Loop 150 Loss_Train:  [[ 20.51723164]] Loss_Validation:  [[ 17.3559897]]\n",
      "Loop 151 Loss_Train:  [[ 20.45808645]] Loss_Validation:  [[ 17.29539393]]\n",
      "Loop 152 Loss_Train:  [[ 20.39956588]] Loss_Validation:  [[ 17.23538213]]\n",
      "Loop 153 Loss_Train:  [[ 20.34166247]] Loss_Validation:  [[ 17.17594804]]\n",
      "Loop 154 Loss_Train:  [[ 20.28436888]] Loss_Validation:  [[ 17.11708548]]\n",
      "Loop 155 Loss_Train:  [[ 20.22767786]] Loss_Validation:  [[ 17.05878833]]\n",
      "Loop 156 Loss_Train:  [[ 20.17158225]] Loss_Validation:  [[ 17.00105058]]\n",
      "Loop 157 Loss_Train:  [[ 20.11607498]] Loss_Validation:  [[ 16.94386624]]\n",
      "Loop 158 Loss_Train:  [[ 20.06114908]] Loss_Validation:  [[ 16.88722942]]\n",
      "Loop 159 Loss_Train:  [[ 20.00679765]] Loss_Validation:  [[ 16.83113431]]\n",
      "Loop 160 Loss_Train:  [[ 19.95301389]] Loss_Validation:  [[ 16.77557513]]\n",
      "Loop 161 Loss_Train:  [[ 19.8997911]] Loss_Validation:  [[ 16.72054622]]\n",
      "Loop 162 Loss_Train:  [[ 19.84712263]] Loss_Validation:  [[ 16.66604194]]\n",
      "Loop 163 Loss_Train:  [[ 19.79500196]] Loss_Validation:  [[ 16.61205675]]\n",
      "Loop 164 Loss_Train:  [[ 19.74342262]] Loss_Validation:  [[ 16.55858515]]\n",
      "Loop 165 Loss_Train:  [[ 19.69237822]] Loss_Validation:  [[ 16.50562171]]\n",
      "Loop 166 Loss_Train:  [[ 19.64186248]] Loss_Validation:  [[ 16.45316108]]\n",
      "Loop 167 Loss_Train:  [[ 19.59186917]] Loss_Validation:  [[ 16.40119795]]\n",
      "Loop 168 Loss_Train:  [[ 19.54239216]] Loss_Validation:  [[ 16.3497271]]\n",
      "Loop 169 Loss_Train:  [[ 19.49342539]] Loss_Validation:  [[ 16.29874333]]\n",
      "Loop 170 Loss_Train:  [[ 19.44496288]] Loss_Validation:  [[ 16.24824155]]\n",
      "Loop 171 Loss_Train:  [[ 19.3969987]] Loss_Validation:  [[ 16.19821668]]\n",
      "Loop 172 Loss_Train:  [[ 19.34952705]] Loss_Validation:  [[ 16.14866374]]\n",
      "Loop 173 Loss_Train:  [[ 19.30254214]] Loss_Validation:  [[ 16.09957779]]\n",
      "Loop 174 Loss_Train:  [[ 19.2560383]] Loss_Validation:  [[ 16.05095393]]\n",
      "Loop 175 Loss_Train:  [[ 19.21000992]] Loss_Validation:  [[ 16.00278735]]\n",
      "Loop 176 Loss_Train:  [[ 19.16445144]] Loss_Validation:  [[ 15.95507328]]\n",
      "Loop 177 Loss_Train:  [[ 19.11935739]] Loss_Validation:  [[ 15.907807]]\n",
      "Loop 178 Loss_Train:  [[ 19.07472238]] Loss_Validation:  [[ 15.86098385]]\n",
      "Loop 179 Loss_Train:  [[ 19.03054105]] Loss_Validation:  [[ 15.81459922]]\n",
      "Loop 180 Loss_Train:  [[ 18.98680815]] Loss_Validation:  [[ 15.76864856]]\n",
      "Loop 181 Loss_Train:  [[ 18.94351846]] Loss_Validation:  [[ 15.72312737]]\n",
      "Loop 182 Loss_Train:  [[ 18.90066685]] Loss_Validation:  [[ 15.6780312]]\n",
      "Loop 183 Loss_Train:  [[ 18.85824824]] Loss_Validation:  [[ 15.63335565]]\n",
      "Loop 184 Loss_Train:  [[ 18.81625763]] Loss_Validation:  [[ 15.58909636]]\n",
      "Loop 185 Loss_Train:  [[ 18.77469007]] Loss_Validation:  [[ 15.54524905]]\n",
      "Loop 186 Loss_Train:  [[ 18.73354066]] Loss_Validation:  [[ 15.50180946]]\n",
      "Loop 187 Loss_Train:  [[ 18.69280459]] Loss_Validation:  [[ 15.45877338]]\n",
      "Loop 188 Loss_Train:  [[ 18.65247709]] Loss_Validation:  [[ 15.41613668]]\n",
      "Loop 189 Loss_Train:  [[ 18.61255346]] Loss_Validation:  [[ 15.37389523]]\n",
      "Loop 190 Loss_Train:  [[ 18.57302905]] Loss_Validation:  [[ 15.33204498]]\n",
      "Loop 191 Loss_Train:  [[ 18.53389926]] Loss_Validation:  [[ 15.29058192]]\n",
      "Loop 192 Loss_Train:  [[ 18.49515958]] Loss_Validation:  [[ 15.24950208]]\n",
      "Loop 193 Loss_Train:  [[ 18.45680552]] Loss_Validation:  [[ 15.20880153]]\n",
      "Loop 194 Loss_Train:  [[ 18.41883267]] Loss_Validation:  [[ 15.1684764]]\n",
      "Loop 195 Loss_Train:  [[ 18.38123665]] Loss_Validation:  [[ 15.12852285]]\n",
      "Loop 196 Loss_Train:  [[ 18.34401317]] Loss_Validation:  [[ 15.08893709]]\n",
      "Loop 197 Loss_Train:  [[ 18.30715796]] Loss_Validation:  [[ 15.04971537]]\n",
      "Loop 198 Loss_Train:  [[ 18.27066682]] Loss_Validation:  [[ 15.01085399]]\n",
      "Loop 199 Loss_Train:  [[ 18.2345356]] Loss_Validation:  [[ 14.97234927]]\n",
      "Loop 200 Loss_Train:  [[ 18.1987602]] Loss_Validation:  [[ 14.9341976]]\n",
      "Loop 201 Loss_Train:  [[ 18.16333657]] Loss_Validation:  [[ 14.8963954]]\n",
      "Loop 202 Loss_Train:  [[ 18.12826071]] Loss_Validation:  [[ 14.85893911]]\n",
      "Loop 203 Loss_Train:  [[ 18.09352866]] Loss_Validation:  [[ 14.82182524]]\n",
      "Loop 204 Loss_Train:  [[ 18.05913653]] Loss_Validation:  [[ 14.78505032]]\n",
      "Loop 205 Loss_Train:  [[ 18.02508046]] Loss_Validation:  [[ 14.74861092]]\n",
      "Loop 206 Loss_Train:  [[ 17.99135666]] Loss_Validation:  [[ 14.71250367]]\n",
      "Loop 207 Loss_Train:  [[ 17.95796135]] Loss_Validation:  [[ 14.67672521]]\n",
      "Loop 208 Loss_Train:  [[ 17.92489082]] Loss_Validation:  [[ 14.64127222]]\n",
      "Loop 209 Loss_Train:  [[ 17.89214141]] Loss_Validation:  [[ 14.60614144]]\n",
      "Loop 210 Loss_Train:  [[ 17.8597095]] Loss_Validation:  [[ 14.57132963]]\n",
      "Loop 211 Loss_Train:  [[ 17.82759151]] Loss_Validation:  [[ 14.53683357]]\n",
      "Loop 212 Loss_Train:  [[ 17.7957839]] Loss_Validation:  [[ 14.50265011]]\n",
      "Loop 213 Loss_Train:  [[ 17.76428318]] Loss_Validation:  [[ 14.46877611]]\n",
      "Loop 214 Loss_Train:  [[ 17.73308591]] Loss_Validation:  [[ 14.43520848]]\n",
      "Loop 215 Loss_Train:  [[ 17.70218868]] Loss_Validation:  [[ 14.40194415]]\n",
      "Loop 216 Loss_Train:  [[ 17.67158812]] Loss_Validation:  [[ 14.36898009]]\n",
      "Loop 217 Loss_Train:  [[ 17.64128092]] Loss_Validation:  [[ 14.3363133]]\n",
      "Loop 218 Loss_Train:  [[ 17.61126379]] Loss_Validation:  [[ 14.30394083]]\n",
      "Loop 219 Loss_Train:  [[ 17.58153349]] Loss_Validation:  [[ 14.27185974]]\n",
      "Loop 220 Loss_Train:  [[ 17.55208681]] Loss_Validation:  [[ 14.24006714]]\n",
      "Loop 221 Loss_Train:  [[ 17.52292059]] Loss_Validation:  [[ 14.20856016]]\n",
      "Loop 222 Loss_Train:  [[ 17.4940317]] Loss_Validation:  [[ 14.17733596]]\n",
      "Loop 223 Loss_Train:  [[ 17.46541707]] Loss_Validation:  [[ 14.14639174]]\n",
      "Loop 224 Loss_Train:  [[ 17.43707363]] Loss_Validation:  [[ 14.11572473]]\n",
      "Loop 225 Loss_Train:  [[ 17.40899838]] Loss_Validation:  [[ 14.08533218]]\n",
      "Loop 226 Loss_Train:  [[ 17.38118833]] Loss_Validation:  [[ 14.05521138]]\n",
      "Loop 227 Loss_Train:  [[ 17.35364056]] Loss_Validation:  [[ 14.02535966]]\n",
      "Loop 228 Loss_Train:  [[ 17.32635215]] Loss_Validation:  [[ 13.99577435]]\n",
      "Loop 229 Loss_Train:  [[ 17.29932023]] Loss_Validation:  [[ 13.96645283]]\n",
      "Loop 230 Loss_Train:  [[ 17.27254197]] Loss_Validation:  [[ 13.9373925]]\n",
      "Loop 231 Loss_Train:  [[ 17.24601456]] Loss_Validation:  [[ 13.9085908]]\n",
      "Loop 232 Loss_Train:  [[ 17.21973525]] Loss_Validation:  [[ 13.88004519]]\n",
      "Loop 233 Loss_Train:  [[ 17.1937013]] Loss_Validation:  [[ 13.85175315]]\n",
      "Loop 234 Loss_Train:  [[ 17.16791]] Loss_Validation:  [[ 13.8237122]]\n",
      "Loop 235 Loss_Train:  [[ 17.1423587]] Loss_Validation:  [[ 13.79591988]]\n",
      "Loop 236 Loss_Train:  [[ 17.11704474]] Loss_Validation:  [[ 13.76837375]]\n",
      "Loop 237 Loss_Train:  [[ 17.09196553]] Loss_Validation:  [[ 13.74107143]]\n",
      "Loop 238 Loss_Train:  [[ 17.0671185]] Loss_Validation:  [[ 13.71401051]]\n",
      "Loop 239 Loss_Train:  [[ 17.0425011]] Loss_Validation:  [[ 13.68718866]]\n",
      "Loop 240 Loss_Train:  [[ 17.01811083]] Loss_Validation:  [[ 13.66060353]]\n",
      "Loop 241 Loss_Train:  [[ 16.99394519]] Loss_Validation:  [[ 13.63425284]]\n",
      "Loop 242 Loss_Train:  [[ 16.97000174]] Loss_Validation:  [[ 13.60813429]]\n",
      "Loop 243 Loss_Train:  [[ 16.94627805]] Loss_Validation:  [[ 13.58224564]]\n",
      "Loop 244 Loss_Train:  [[ 16.92277174]] Loss_Validation:  [[ 13.55658466]]\n",
      "Loop 245 Loss_Train:  [[ 16.89948043]] Loss_Validation:  [[ 13.53114913]]\n",
      "Loop 246 Loss_Train:  [[ 16.8764018]] Loss_Validation:  [[ 13.50593689]]\n",
      "Loop 247 Loss_Train:  [[ 16.85353352]] Loss_Validation:  [[ 13.48094576]]\n",
      "Loop 248 Loss_Train:  [[ 16.83087332]] Loss_Validation:  [[ 13.45617361]]\n",
      "Loop 249 Loss_Train:  [[ 16.80841895]] Loss_Validation:  [[ 13.43161834]]\n",
      "Loop 250 Loss_Train:  [[ 16.78616817]] Loss_Validation:  [[ 13.40727784]]\n",
      "Loop 251 Loss_Train:  [[ 16.76411879]] Loss_Validation:  [[ 13.38315006]]\n",
      "Loop 252 Loss_Train:  [[ 16.74226863]] Loss_Validation:  [[ 13.35923294]]\n",
      "Loop 253 Loss_Train:  [[ 16.72061554]] Loss_Validation:  [[ 13.33552446]]\n",
      "Loop 254 Loss_Train:  [[ 16.6991574]] Loss_Validation:  [[ 13.31202261]]\n",
      "Loop 255 Loss_Train:  [[ 16.67789212]] Loss_Validation:  [[ 13.28872543]]\n",
      "Loop 256 Loss_Train:  [[ 16.6568176]] Loss_Validation:  [[ 13.26563094]]\n",
      "Loop 257 Loss_Train:  [[ 16.63593182]] Loss_Validation:  [[ 13.2427372]]\n",
      "Loop 258 Loss_Train:  [[ 16.61523273]] Loss_Validation:  [[ 13.22004231]]\n",
      "Loop 259 Loss_Train:  [[ 16.59471835]] Loss_Validation:  [[ 13.19754435]]\n",
      "Loop 260 Loss_Train:  [[ 16.57438669]] Loss_Validation:  [[ 13.17524144]]\n",
      "Loop 261 Loss_Train:  [[ 16.5542358]] Loss_Validation:  [[ 13.15313174]]\n",
      "Loop 262 Loss_Train:  [[ 16.53426375]] Loss_Validation:  [[ 13.1312134]]\n",
      "Loop 263 Loss_Train:  [[ 16.51446862]] Loss_Validation:  [[ 13.1094846]]\n",
      "Loop 264 Loss_Train:  [[ 16.49484854]] Loss_Validation:  [[ 13.08794354]]\n",
      "Loop 265 Loss_Train:  [[ 16.47540165]] Loss_Validation:  [[ 13.06658843]]\n",
      "Loop 266 Loss_Train:  [[ 16.45612609]] Loss_Validation:  [[ 13.04541752]]\n",
      "Loop 267 Loss_Train:  [[ 16.43702004]] Loss_Validation:  [[ 13.02442907]]\n",
      "Loop 268 Loss_Train:  [[ 16.41808172]] Loss_Validation:  [[ 13.00362133]]\n",
      "Loop 269 Loss_Train:  [[ 16.39930934]] Loss_Validation:  [[ 12.98299261]]\n",
      "Loop 270 Loss_Train:  [[ 16.38070114]] Loss_Validation:  [[ 12.96254121]]\n",
      "Loop 271 Loss_Train:  [[ 16.36225538]] Loss_Validation:  [[ 12.94226546]]\n",
      "Loop 272 Loss_Train:  [[ 16.34397036]] Loss_Validation:  [[ 12.92216372]]\n",
      "Loop 273 Loss_Train:  [[ 16.32584437]] Loss_Validation:  [[ 12.90223432]]\n",
      "Loop 274 Loss_Train:  [[ 16.30787574]] Loss_Validation:  [[ 12.88247567]]\n",
      "Loop 275 Loss_Train:  [[ 16.29006282]] Loss_Validation:  [[ 12.86288615]]\n",
      "Loop 276 Loss_Train:  [[ 16.27240395]] Loss_Validation:  [[ 12.84346418]]\n",
      "Loop 277 Loss_Train:  [[ 16.25489753]] Loss_Validation:  [[ 12.82420818]]\n",
      "Loop 278 Loss_Train:  [[ 16.23754195]] Loss_Validation:  [[ 12.80511661]]\n",
      "Loop 279 Loss_Train:  [[ 16.22033564]] Loss_Validation:  [[ 12.78618791]]\n",
      "Loop 280 Loss_Train:  [[ 16.20327703]] Loss_Validation:  [[ 12.76742058]]\n",
      "Loop 281 Loss_Train:  [[ 16.18636457]] Loss_Validation:  [[ 12.7488131]]\n",
      "Loop 282 Loss_Train:  [[ 16.16959674]] Loss_Validation:  [[ 12.73036398]]\n",
      "Loop 283 Loss_Train:  [[ 16.15297203]] Loss_Validation:  [[ 12.71207175]]\n",
      "Loop 284 Loss_Train:  [[ 16.13648895]] Loss_Validation:  [[ 12.69393494]]\n",
      "Loop 285 Loss_Train:  [[ 16.12014602]] Loss_Validation:  [[ 12.67595212]]\n",
      "Loop 286 Loss_Train:  [[ 16.10394179]] Loss_Validation:  [[ 12.65812184]]\n",
      "Loop 287 Loss_Train:  [[ 16.08787481]] Loss_Validation:  [[ 12.6404427]]\n",
      "Loop 288 Loss_Train:  [[ 16.07194366]] Loss_Validation:  [[ 12.62291329]]\n",
      "Loop 289 Loss_Train:  [[ 16.05614693]] Loss_Validation:  [[ 12.60553223]]\n",
      "Loop 290 Loss_Train:  [[ 16.04048324]] Loss_Validation:  [[ 12.58829815]]\n",
      "Loop 291 Loss_Train:  [[ 16.0249512]] Loss_Validation:  [[ 12.57120968]]\n",
      "Loop 292 Loss_Train:  [[ 16.00954946]] Loss_Validation:  [[ 12.55426548]]\n",
      "Loop 293 Loss_Train:  [[ 15.99427667]] Loss_Validation:  [[ 12.53746422]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 294 Loss_Train:  [[ 15.9791315]] Loss_Validation:  [[ 12.52080458]]\n",
      "Loop 295 Loss_Train:  [[ 15.96411264]] Loss_Validation:  [[ 12.50428526]]\n",
      "Loop 296 Loss_Train:  [[ 15.94921879]] Loss_Validation:  [[ 12.48790497]]\n",
      "Loop 297 Loss_Train:  [[ 15.93444867]] Loss_Validation:  [[ 12.47166244]]\n",
      "Loop 298 Loss_Train:  [[ 15.91980101]] Loss_Validation:  [[ 12.45555639]]\n",
      "Loop 299 Loss_Train:  [[ 15.90527455]] Loss_Validation:  [[ 12.43958558]]\n",
      "Loop 300 Loss_Train:  [[ 15.89086805]] Loss_Validation:  [[ 12.42374876]]\n",
      "Loop 301 Loss_Train:  [[ 15.8765803]] Loss_Validation:  [[ 12.40804472]]\n",
      "Loop 302 Loss_Train:  [[ 15.86241006]] Loss_Validation:  [[ 12.39247223]]\n",
      "Loop 303 Loss_Train:  [[ 15.84835616]] Loss_Validation:  [[ 12.3770301]]\n",
      "Loop 304 Loss_Train:  [[ 15.8344174]] Loss_Validation:  [[ 12.36171714]]\n",
      "Loop 305 Loss_Train:  [[ 15.8205926]] Loss_Validation:  [[ 12.34653217]]\n",
      "Loop 306 Loss_Train:  [[ 15.80688062]] Loss_Validation:  [[ 12.33147403]]\n",
      "Loop 307 Loss_Train:  [[ 15.79328031]] Loss_Validation:  [[ 12.31654155]]\n",
      "Loop 308 Loss_Train:  [[ 15.77979054]] Loss_Validation:  [[ 12.30173361]]\n",
      "Loop 309 Loss_Train:  [[ 15.76641018]] Loss_Validation:  [[ 12.28704906]]\n",
      "Loop 310 Loss_Train:  [[ 15.75313814]] Loss_Validation:  [[ 12.2724868]]\n",
      "Loop 311 Loss_Train:  [[ 15.73997331]] Loss_Validation:  [[ 12.25804571]]\n",
      "Loop 312 Loss_Train:  [[ 15.72691462]] Loss_Validation:  [[ 12.2437247]]\n",
      "Loop 313 Loss_Train:  [[ 15.71396099]] Loss_Validation:  [[ 12.22952267]]\n",
      "Loop 314 Loss_Train:  [[ 15.70111138]] Loss_Validation:  [[ 12.21543857]]\n",
      "Loop 315 Loss_Train:  [[ 15.68836472]] Loss_Validation:  [[ 12.20147132]]\n",
      "Loop 316 Loss_Train:  [[ 15.67572]] Loss_Validation:  [[ 12.18761986]]\n",
      "Loop 317 Loss_Train:  [[ 15.66317618]] Loss_Validation:  [[ 12.17388317]]\n",
      "Loop 318 Loss_Train:  [[ 15.65073227]] Loss_Validation:  [[ 12.1602602]]\n",
      "Loop 319 Loss_Train:  [[ 15.63838725]] Loss_Validation:  [[ 12.14674993]]\n",
      "Loop 320 Loss_Train:  [[ 15.62614014]] Loss_Validation:  [[ 12.13335136]]\n",
      "Loop 321 Loss_Train:  [[ 15.61398996]] Loss_Validation:  [[ 12.12006347]]\n",
      "Loop 322 Loss_Train:  [[ 15.60193575]] Loss_Validation:  [[ 12.10688529]]\n",
      "Loop 323 Loss_Train:  [[ 15.58997656]] Loss_Validation:  [[ 12.09381582]]\n",
      "Loop 324 Loss_Train:  [[ 15.57811143]] Loss_Validation:  [[ 12.08085409]]\n",
      "Loop 325 Loss_Train:  [[ 15.56633944]] Loss_Validation:  [[ 12.06799915]]\n",
      "Loop 326 Loss_Train:  [[ 15.55465965]] Loss_Validation:  [[ 12.05525003]]\n",
      "Loop 327 Loss_Train:  [[ 15.54307117]] Loss_Validation:  [[ 12.0426058]]\n",
      "Loop 328 Loss_Train:  [[ 15.53157307]] Loss_Validation:  [[ 12.03006553]]\n",
      "Loop 329 Loss_Train:  [[ 15.52016448]] Loss_Validation:  [[ 12.01762828]]\n",
      "Loop 330 Loss_Train:  [[ 15.5088445]] Loss_Validation:  [[ 12.00529314]]\n",
      "Loop 331 Loss_Train:  [[ 15.49761227]] Loss_Validation:  [[ 11.99305921]]\n",
      "Loop 332 Loss_Train:  [[ 15.48646692]] Loss_Validation:  [[ 11.98092559]]\n",
      "Loop 333 Loss_Train:  [[ 15.4754076]] Loss_Validation:  [[ 11.96889138]]\n",
      "Loop 334 Loss_Train:  [[ 15.46443346]] Loss_Validation:  [[ 11.95695572]]\n",
      "Loop 335 Loss_Train:  [[ 15.45354367]] Loss_Validation:  [[ 11.94511772]]\n",
      "Loop 336 Loss_Train:  [[ 15.44273739]] Loss_Validation:  [[ 11.93337653]]\n",
      "Loop 337 Loss_Train:  [[ 15.43201382]] Loss_Validation:  [[ 11.92173128]]\n",
      "Loop 338 Loss_Train:  [[ 15.42137215]] Loss_Validation:  [[ 11.91018114]]\n",
      "Loop 339 Loss_Train:  [[ 15.41081157]] Loss_Validation:  [[ 11.89872527]]\n",
      "Loop 340 Loss_Train:  [[ 15.4003313]] Loss_Validation:  [[ 11.88736283]]\n",
      "Loop 341 Loss_Train:  [[ 15.38993056]] Loss_Validation:  [[ 11.87609301]]\n",
      "Loop 342 Loss_Train:  [[ 15.37960857]] Loss_Validation:  [[ 11.864915]]\n",
      "Loop 343 Loss_Train:  [[ 15.36936456]] Loss_Validation:  [[ 11.85382798]]\n",
      "Loop 344 Loss_Train:  [[ 15.35919779]] Loss_Validation:  [[ 11.84283115]]\n",
      "Loop 345 Loss_Train:  [[ 15.3491075]] Loss_Validation:  [[ 11.83192374]]\n",
      "Loop 346 Loss_Train:  [[ 15.33909296]] Loss_Validation:  [[ 11.82110496]]\n",
      "Loop 347 Loss_Train:  [[ 15.32915343]] Loss_Validation:  [[ 11.81037403]]\n",
      "Loop 348 Loss_Train:  [[ 15.31928819]] Loss_Validation:  [[ 11.79973019]]\n",
      "Loop 349 Loss_Train:  [[ 15.30949652]] Loss_Validation:  [[ 11.78917267]]\n",
      "Loop 350 Loss_Train:  [[ 15.29977772]] Loss_Validation:  [[ 11.77870073]]\n",
      "Loop 351 Loss_Train:  [[ 15.29013109]] Loss_Validation:  [[ 11.76831362]]\n",
      "Loop 352 Loss_Train:  [[ 15.28055593]] Loss_Validation:  [[ 11.7580106]]\n",
      "Loop 353 Loss_Train:  [[ 15.27105156]] Loss_Validation:  [[ 11.74779094]]\n",
      "Loop 354 Loss_Train:  [[ 15.26161731]] Loss_Validation:  [[ 11.73765392]]\n",
      "Loop 355 Loss_Train:  [[ 15.25225249]] Loss_Validation:  [[ 11.72759882]]\n",
      "Loop 356 Loss_Train:  [[ 15.24295646]] Loss_Validation:  [[ 11.71762494]]\n",
      "Loop 357 Loss_Train:  [[ 15.23372855]] Loss_Validation:  [[ 11.70773157]]\n",
      "Loop 358 Loss_Train:  [[ 15.22456811]] Loss_Validation:  [[ 11.697918]]\n",
      "Loop 359 Loss_Train:  [[ 15.21547451]] Loss_Validation:  [[ 11.68818357]]\n",
      "Loop 360 Loss_Train:  [[ 15.2064471]] Loss_Validation:  [[ 11.67852757]]\n",
      "Loop 361 Loss_Train:  [[ 15.19748527]] Loss_Validation:  [[ 11.66894935]]\n",
      "Loop 362 Loss_Train:  [[ 15.18858839]] Loss_Validation:  [[ 11.65944822]]\n",
      "Loop 363 Loss_Train:  [[ 15.17975584]] Loss_Validation:  [[ 11.65002352]]\n",
      "Loop 364 Loss_Train:  [[ 15.17098703]] Loss_Validation:  [[ 11.64067459]]\n",
      "Loop 365 Loss_Train:  [[ 15.16228134]] Loss_Validation:  [[ 11.6314008]]\n",
      "Loop 366 Loss_Train:  [[ 15.15363819]] Loss_Validation:  [[ 11.62220148]]\n",
      "Loop 367 Loss_Train:  [[ 15.14505698]] Loss_Validation:  [[ 11.61307601]]\n",
      "Loop 368 Loss_Train:  [[ 15.13653714]] Loss_Validation:  [[ 11.60402375]]\n",
      "Loop 369 Loss_Train:  [[ 15.12807808]] Loss_Validation:  [[ 11.59504408]]\n",
      "Loop 370 Loss_Train:  [[ 15.11967924]] Loss_Validation:  [[ 11.58613637]]\n",
      "Loop 371 Loss_Train:  [[ 15.11134006]] Loss_Validation:  [[ 11.57730001]]\n",
      "Loop 372 Loss_Train:  [[ 15.10305997]] Loss_Validation:  [[ 11.5685344]]\n",
      "Loop 373 Loss_Train:  [[ 15.09483844]] Loss_Validation:  [[ 11.55983892]]\n",
      "Loop 374 Loss_Train:  [[ 15.0866749]] Loss_Validation:  [[ 11.55121299]]\n",
      "Loop 375 Loss_Train:  [[ 15.07856883]] Loss_Validation:  [[ 11.54265601]]\n",
      "Loop 376 Loss_Train:  [[ 15.07051968]] Loss_Validation:  [[ 11.5341674]]\n",
      "Loop 377 Loss_Train:  [[ 15.06252693]] Loss_Validation:  [[ 11.52574657]]\n",
      "Loop 378 Loss_Train:  [[ 15.05459006]] Loss_Validation:  [[ 11.51739296]]\n",
      "Loop 379 Loss_Train:  [[ 15.04670855]] Loss_Validation:  [[ 11.50910598]]\n",
      "Loop 380 Loss_Train:  [[ 15.03888189]] Loss_Validation:  [[ 11.50088509]]\n",
      "Loop 381 Loss_Train:  [[ 15.03110957]] Loss_Validation:  [[ 11.49272972]]\n",
      "Loop 382 Loss_Train:  [[ 15.02339109]] Loss_Validation:  [[ 11.48463931]]\n",
      "Loop 383 Loss_Train:  [[ 15.01572596]] Loss_Validation:  [[ 11.47661332]]\n",
      "Loop 384 Loss_Train:  [[ 15.00811369]] Loss_Validation:  [[ 11.46865121]]\n",
      "Loop 385 Loss_Train:  [[ 15.00055378]] Loss_Validation:  [[ 11.46075244]]\n",
      "Loop 386 Loss_Train:  [[ 14.99304577]] Loss_Validation:  [[ 11.45291647]]\n",
      "Loop 387 Loss_Train:  [[ 14.98558917]] Loss_Validation:  [[ 11.44514278]]\n",
      "Loop 388 Loss_Train:  [[ 14.97818353]] Loss_Validation:  [[ 11.43743085]]\n",
      "Loop 389 Loss_Train:  [[ 14.97082836]] Loss_Validation:  [[ 11.42978015]]\n",
      "Loop 390 Loss_Train:  [[ 14.96352321]] Loss_Validation:  [[ 11.42219017]]\n",
      "Loop 391 Loss_Train:  [[ 14.95626763]] Loss_Validation:  [[ 11.41466042]]\n",
      "Loop 392 Loss_Train:  [[ 14.94906117]] Loss_Validation:  [[ 11.40719037]]\n",
      "Loop 393 Loss_Train:  [[ 14.94190338]] Loss_Validation:  [[ 11.39977954]]\n",
      "Loop 394 Loss_Train:  [[ 14.93479382]] Loss_Validation:  [[ 11.39242742]]\n",
      "Loop 395 Loss_Train:  [[ 14.92773205]] Loss_Validation:  [[ 11.38513354]]\n",
      "Loop 396 Loss_Train:  [[ 14.92071765]] Loss_Validation:  [[ 11.3778974]]\n",
      "Loop 397 Loss_Train:  [[ 14.91375017]] Loss_Validation:  [[ 11.37071852]]\n",
      "Loop 398 Loss_Train:  [[ 14.90682921]] Loss_Validation:  [[ 11.36359644]]\n",
      "Loop 399 Loss_Train:  [[ 14.89995435]] Loss_Validation:  [[ 11.35653066]]\n",
      "Loop 400 Loss_Train:  [[ 14.89312516]] Loss_Validation:  [[ 11.34952074]]\n",
      "Loop 401 Loss_Train:  [[ 14.88634124]] Loss_Validation:  [[ 11.3425662]]\n",
      "Loop 402 Loss_Train:  [[ 14.87960219]] Loss_Validation:  [[ 11.33566659]]\n",
      "Loop 403 Loss_Train:  [[ 14.8729076]] Loss_Validation:  [[ 11.32882145]]\n",
      "Loop 404 Loss_Train:  [[ 14.86625708]] Loss_Validation:  [[ 11.32203033]]\n",
      "Loop 405 Loss_Train:  [[ 14.85965022]] Loss_Validation:  [[ 11.31529279]]\n",
      "Loop 406 Loss_Train:  [[ 14.85308666]] Loss_Validation:  [[ 11.30860838]]\n",
      "Loop 407 Loss_Train:  [[ 14.84656599]] Loss_Validation:  [[ 11.30197667]]\n",
      "Loop 408 Loss_Train:  [[ 14.84008784]] Loss_Validation:  [[ 11.29539722]]\n",
      "Loop 409 Loss_Train:  [[ 14.83365183]] Loss_Validation:  [[ 11.2888696]]\n",
      "Loop 410 Loss_Train:  [[ 14.82725759]] Loss_Validation:  [[ 11.28239339]]\n",
      "Loop 411 Loss_Train:  [[ 14.82090475]] Loss_Validation:  [[ 11.27596816]]\n",
      "Loop 412 Loss_Train:  [[ 14.81459294]] Loss_Validation:  [[ 11.26959349]]\n",
      "Loop 413 Loss_Train:  [[ 14.80832181]] Loss_Validation:  [[ 11.26326898]]\n",
      "Loop 414 Loss_Train:  [[ 14.80209099]] Loss_Validation:  [[ 11.25699421]]\n",
      "Loop 415 Loss_Train:  [[ 14.79590013]] Loss_Validation:  [[ 11.25076877]]\n",
      "Loop 416 Loss_Train:  [[ 14.78974888]] Loss_Validation:  [[ 11.24459225]]\n",
      "Loop 417 Loss_Train:  [[ 14.78363689]] Loss_Validation:  [[ 11.23846427]]\n",
      "Loop 418 Loss_Train:  [[ 14.77756382]] Loss_Validation:  [[ 11.23238443]]\n",
      "Loop 419 Loss_Train:  [[ 14.77152933]] Loss_Validation:  [[ 11.22635233]]\n",
      "Loop 420 Loss_Train:  [[ 14.76553308]] Loss_Validation:  [[ 11.22036758]]\n",
      "Loop 421 Loss_Train:  [[ 14.75957475]] Loss_Validation:  [[ 11.21442979]]\n",
      "Loop 422 Loss_Train:  [[ 14.75365399]] Loss_Validation:  [[ 11.2085386]]\n",
      "Loop 423 Loss_Train:  [[ 14.74777048]] Loss_Validation:  [[ 11.20269361]]\n",
      "Loop 424 Loss_Train:  [[ 14.74192391]] Loss_Validation:  [[ 11.19689446]]\n",
      "Loop 425 Loss_Train:  [[ 14.73611395]] Loss_Validation:  [[ 11.19114077]]\n",
      "Loop 426 Loss_Train:  [[ 14.73034028]] Loss_Validation:  [[ 11.18543217]]\n",
      "Loop 427 Loss_Train:  [[ 14.7246026]] Loss_Validation:  [[ 11.1797683]]\n",
      "Loop 428 Loss_Train:  [[ 14.71890058]] Loss_Validation:  [[ 11.1741488]]\n",
      "Loop 429 Loss_Train:  [[ 14.71323393]] Loss_Validation:  [[ 11.1685733]]\n",
      "Loop 430 Loss_Train:  [[ 14.70760234]] Loss_Validation:  [[ 11.16304147]]\n",
      "Loop 431 Loss_Train:  [[ 14.70200551]] Loss_Validation:  [[ 11.15755293]]\n",
      "Loop 432 Loss_Train:  [[ 14.69644315]] Loss_Validation:  [[ 11.15210735]]\n",
      "Loop 433 Loss_Train:  [[ 14.69091495]] Loss_Validation:  [[ 11.14670438]]\n",
      "Loop 434 Loss_Train:  [[ 14.68542063]] Loss_Validation:  [[ 11.14134367]]\n",
      "Loop 435 Loss_Train:  [[ 14.67995989]] Loss_Validation:  [[ 11.13602489]]\n",
      "Loop 436 Loss_Train:  [[ 14.67453246]] Loss_Validation:  [[ 11.1307477]]\n",
      "Loop 437 Loss_Train:  [[ 14.66913805]] Loss_Validation:  [[ 11.12551176]]\n",
      "Loop 438 Loss_Train:  [[ 14.66377637]] Loss_Validation:  [[ 11.12031676]]\n",
      "Loop 439 Loss_Train:  [[ 14.65844716]] Loss_Validation:  [[ 11.11516235]]\n",
      "Loop 440 Loss_Train:  [[ 14.65315013]] Loss_Validation:  [[ 11.11004821]]\n",
      "Loop 441 Loss_Train:  [[ 14.64788502]] Loss_Validation:  [[ 11.10497403]]\n",
      "Loop 442 Loss_Train:  [[ 14.64265155]] Loss_Validation:  [[ 11.09993949]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 443 Loss_Train:  [[ 14.63744946]] Loss_Validation:  [[ 11.09494426]]\n",
      "Loop 444 Loss_Train:  [[ 14.63227849]] Loss_Validation:  [[ 11.08998804]]\n",
      "Loop 445 Loss_Train:  [[ 14.62713837]] Loss_Validation:  [[ 11.08507051]]\n",
      "Loop 446 Loss_Train:  [[ 14.62202885]] Loss_Validation:  [[ 11.08019137]]\n",
      "Loop 447 Loss_Train:  [[ 14.61694967]] Loss_Validation:  [[ 11.07535031]]\n",
      "Loop 448 Loss_Train:  [[ 14.61190058]] Loss_Validation:  [[ 11.07054704]]\n",
      "Loop 449 Loss_Train:  [[ 14.60688132]] Loss_Validation:  [[ 11.06578124]]\n",
      "Loop 450 Loss_Train:  [[ 14.60189165]] Loss_Validation:  [[ 11.06105263]]\n",
      "Loop 451 Loss_Train:  [[ 14.59693132]] Loss_Validation:  [[ 11.05636091]]\n",
      "Loop 452 Loss_Train:  [[ 14.59200009]] Loss_Validation:  [[ 11.05170578]]\n",
      "Loop 453 Loss_Train:  [[ 14.58709772]] Loss_Validation:  [[ 11.04708697]]\n",
      "Loop 454 Loss_Train:  [[ 14.58222396]] Loss_Validation:  [[ 11.04250418]]\n",
      "Loop 455 Loss_Train:  [[ 14.57737859]] Loss_Validation:  [[ 11.03795713]]\n",
      "Loop 456 Loss_Train:  [[ 14.57256137]] Loss_Validation:  [[ 11.03344553]]\n",
      "Loop 457 Loss_Train:  [[ 14.56777206]] Loss_Validation:  [[ 11.02896912]]\n",
      "Loop 458 Loss_Train:  [[ 14.56301044]] Loss_Validation:  [[ 11.0245276]]\n",
      "Loop 459 Loss_Train:  [[ 14.55827628]] Loss_Validation:  [[ 11.02012072]]\n",
      "Loop 460 Loss_Train:  [[ 14.55356935]] Loss_Validation:  [[ 11.01574818]]\n",
      "Loop 461 Loss_Train:  [[ 14.54888944]] Loss_Validation:  [[ 11.01140974]]\n",
      "Loop 462 Loss_Train:  [[ 14.54423632]] Loss_Validation:  [[ 11.00710512]]\n",
      "Loop 463 Loss_Train:  [[ 14.53960977]] Loss_Validation:  [[ 11.00283405]]\n",
      "Loop 464 Loss_Train:  [[ 14.53500958]] Loss_Validation:  [[ 10.99859627]]\n",
      "Loop 465 Loss_Train:  [[ 14.53043553]] Loss_Validation:  [[ 10.99439153]]\n",
      "Loop 466 Loss_Train:  [[ 14.52588741]] Loss_Validation:  [[ 10.99021956]]\n",
      "Loop 467 Loss_Train:  [[ 14.52136502]] Loss_Validation:  [[ 10.9860801]]\n",
      "Loop 468 Loss_Train:  [[ 14.51686813]] Loss_Validation:  [[ 10.98197292]]\n",
      "Loop 469 Loss_Train:  [[ 14.51239656]] Loss_Validation:  [[ 10.97789775]]\n",
      "Loop 470 Loss_Train:  [[ 14.50795009]] Loss_Validation:  [[ 10.97385434]]\n",
      "Loop 471 Loss_Train:  [[ 14.50352851]] Loss_Validation:  [[ 10.96984246]]\n",
      "Loop 472 Loss_Train:  [[ 14.49913164]] Loss_Validation:  [[ 10.96586184]]\n",
      "Loop 473 Loss_Train:  [[ 14.49475928]] Loss_Validation:  [[ 10.96191226]]\n",
      "Loop 474 Loss_Train:  [[ 14.49041122]] Loss_Validation:  [[ 10.95799347]]\n",
      "Loop 475 Loss_Train:  [[ 14.48608727]] Loss_Validation:  [[ 10.95410523]]\n",
      "Loop 476 Loss_Train:  [[ 14.48178725]] Loss_Validation:  [[ 10.95024731]]\n",
      "Loop 477 Loss_Train:  [[ 14.47751095]] Loss_Validation:  [[ 10.94641947]]\n",
      "Loop 478 Loss_Train:  [[ 14.4732582]] Loss_Validation:  [[ 10.94262148]]\n",
      "Loop 479 Loss_Train:  [[ 14.4690288]] Loss_Validation:  [[ 10.93885311]]\n",
      "Loop 480 Loss_Train:  [[ 14.46482257]] Loss_Validation:  [[ 10.93511412]]\n",
      "Loop 481 Loss_Train:  [[ 14.46063933]] Loss_Validation:  [[ 10.93140431]]\n",
      "Loop 482 Loss_Train:  [[ 14.45647889]] Loss_Validation:  [[ 10.92772343]]\n",
      "Loop 483 Loss_Train:  [[ 14.45234107]] Loss_Validation:  [[ 10.92407127]]\n",
      "Loop 484 Loss_Train:  [[ 14.44822571]] Loss_Validation:  [[ 10.92044761]]\n",
      "Loop 485 Loss_Train:  [[ 14.44413261]] Loss_Validation:  [[ 10.91685222]]\n",
      "Loop 486 Loss_Train:  [[ 14.44006161]] Loss_Validation:  [[ 10.9132849]]\n",
      "Loop 487 Loss_Train:  [[ 14.43601254]] Loss_Validation:  [[ 10.90974542]]\n",
      "Loop 488 Loss_Train:  [[ 14.43198521]] Loss_Validation:  [[ 10.90623358]]\n",
      "Loop 489 Loss_Train:  [[ 14.42797947]] Loss_Validation:  [[ 10.90274916]]\n",
      "Loop 490 Loss_Train:  [[ 14.42399514]] Loss_Validation:  [[ 10.89929195]]\n",
      "Loop 491 Loss_Train:  [[ 14.42003206]] Loss_Validation:  [[ 10.89586174]]\n",
      "Loop 492 Loss_Train:  [[ 14.41609006]] Loss_Validation:  [[ 10.89245833]]\n",
      "Loop 493 Loss_Train:  [[ 14.41216898]] Loss_Validation:  [[ 10.88908152]]\n",
      "Loop 494 Loss_Train:  [[ 14.40826866]] Loss_Validation:  [[ 10.8857311]]\n",
      "Loop 495 Loss_Train:  [[ 14.40438893]] Loss_Validation:  [[ 10.88240687]]\n",
      "Loop 496 Loss_Train:  [[ 14.40052965]] Loss_Validation:  [[ 10.87910863]]\n",
      "Loop 497 Loss_Train:  [[ 14.39669064]] Loss_Validation:  [[ 10.87583619]]\n",
      "Loop 498 Loss_Train:  [[ 14.39287176]] Loss_Validation:  [[ 10.87258934]]\n",
      "Loop 499 Loss_Train:  [[ 14.38907285]] Loss_Validation:  [[ 10.8693679]]\n",
      "Loop 500 Loss_Train:  [[ 14.38529376]] Loss_Validation:  [[ 10.86617167]]\n",
      "Loop 501 Loss_Train:  [[ 14.38153434]] Loss_Validation:  [[ 10.86300046]]\n",
      "Loop 502 Loss_Train:  [[ 14.37779443]] Loss_Validation:  [[ 10.85985408]]\n",
      "Loop 503 Loss_Train:  [[ 14.37407389]] Loss_Validation:  [[ 10.85673235]]\n",
      "Loop 504 Loss_Train:  [[ 14.37037257]] Loss_Validation:  [[ 10.85363507]]\n",
      "Loop 505 Loss_Train:  [[ 14.36669032]] Loss_Validation:  [[ 10.85056207]]\n",
      "Loop 506 Loss_Train:  [[ 14.36302701]] Loss_Validation:  [[ 10.84751316]]\n",
      "Loop 507 Loss_Train:  [[ 14.35938248]] Loss_Validation:  [[ 10.84448815]]\n",
      "Loop 508 Loss_Train:  [[ 14.3557566]] Loss_Validation:  [[ 10.84148688]]\n",
      "Loop 509 Loss_Train:  [[ 14.35214923]] Loss_Validation:  [[ 10.83850916]]\n",
      "Loop 510 Loss_Train:  [[ 14.34856022]] Loss_Validation:  [[ 10.83555481]]\n",
      "Loop 511 Loss_Train:  [[ 14.34498944]] Loss_Validation:  [[ 10.83262366]]\n",
      "Loop 512 Loss_Train:  [[ 14.34143675]] Loss_Validation:  [[ 10.82971553]]\n",
      "Loop 513 Loss_Train:  [[ 14.33790201]] Loss_Validation:  [[ 10.82683026]]\n",
      "Loop 514 Loss_Train:  [[ 14.3343851]] Loss_Validation:  [[ 10.82396766]]\n",
      "Loop 515 Loss_Train:  [[ 14.33088588]] Loss_Validation:  [[ 10.82112758]]\n",
      "Loop 516 Loss_Train:  [[ 14.32740421]] Loss_Validation:  [[ 10.81830984]]\n",
      "Loop 517 Loss_Train:  [[ 14.32393998]] Loss_Validation:  [[ 10.81551428]]\n",
      "Loop 518 Loss_Train:  [[ 14.32049304]] Loss_Validation:  [[ 10.81274072]]\n",
      "Loop 519 Loss_Train:  [[ 14.31706327]] Loss_Validation:  [[ 10.80998901]]\n",
      "Loop 520 Loss_Train:  [[ 14.31365054]] Loss_Validation:  [[ 10.80725899]]\n",
      "Loop 521 Loss_Train:  [[ 14.31025474]] Loss_Validation:  [[ 10.80455049]]\n",
      "Loop 522 Loss_Train:  [[ 14.30687572]] Loss_Validation:  [[ 10.80186334]]\n",
      "Loop 523 Loss_Train:  [[ 14.30351338]] Loss_Validation:  [[ 10.79919741]]\n",
      "Loop 524 Loss_Train:  [[ 14.30016758]] Loss_Validation:  [[ 10.79655251]]\n",
      "Loop 525 Loss_Train:  [[ 14.29683821]] Loss_Validation:  [[ 10.79392851]]\n",
      "Loop 526 Loss_Train:  [[ 14.29352515]] Loss_Validation:  [[ 10.79132524]]\n",
      "Loop 527 Loss_Train:  [[ 14.29022827]] Loss_Validation:  [[ 10.78874256]]\n",
      "Loop 528 Loss_Train:  [[ 14.28694747]] Loss_Validation:  [[ 10.7861803]]\n",
      "Loop 529 Loss_Train:  [[ 14.28368261]] Loss_Validation:  [[ 10.78363832]]\n",
      "Loop 530 Loss_Train:  [[ 14.2804336]] Loss_Validation:  [[ 10.78111646]]\n",
      "Loop 531 Loss_Train:  [[ 14.2772003]] Loss_Validation:  [[ 10.77861459]]\n",
      "Loop 532 Loss_Train:  [[ 14.27398262]] Loss_Validation:  [[ 10.77613254]]\n",
      "Loop 533 Loss_Train:  [[ 14.27078043]] Loss_Validation:  [[ 10.77367019]]\n",
      "Loop 534 Loss_Train:  [[ 14.26759363]] Loss_Validation:  [[ 10.77122737]]\n",
      "Loop 535 Loss_Train:  [[ 14.2644221]] Loss_Validation:  [[ 10.76880395]]\n",
      "Loop 536 Loss_Train:  [[ 14.26126574]] Loss_Validation:  [[ 10.76639978]]\n",
      "Loop 537 Loss_Train:  [[ 14.25812443]] Loss_Validation:  [[ 10.76401473]]\n",
      "Loop 538 Loss_Train:  [[ 14.25499807]] Loss_Validation:  [[ 10.76164865]]\n",
      "Loop 539 Loss_Train:  [[ 14.25188656]] Loss_Validation:  [[ 10.7593014]]\n",
      "Loop 540 Loss_Train:  [[ 14.24878978]] Loss_Validation:  [[ 10.75697284]]\n",
      "Loop 541 Loss_Train:  [[ 14.24570763]] Loss_Validation:  [[ 10.75466285]]\n",
      "Loop 542 Loss_Train:  [[ 14.24264001]] Loss_Validation:  [[ 10.75237127]]\n",
      "Loop 543 Loss_Train:  [[ 14.23958682]] Loss_Validation:  [[ 10.75009798]]\n",
      "Loop 544 Loss_Train:  [[ 14.23654795]] Loss_Validation:  [[ 10.74784285]]\n",
      "Loop 545 Loss_Train:  [[ 14.2335233]] Loss_Validation:  [[ 10.74560574]]\n",
      "Loop 546 Loss_Train:  [[ 14.23051277]] Loss_Validation:  [[ 10.74338651]]\n",
      "Loop 547 Loss_Train:  [[ 14.22751627]] Loss_Validation:  [[ 10.74118505]]\n",
      "Loop 548 Loss_Train:  [[ 14.22453369]] Loss_Validation:  [[ 10.73900121]]\n",
      "Loop 549 Loss_Train:  [[ 14.22156494]] Loss_Validation:  [[ 10.73683488]]\n",
      "Loop 550 Loss_Train:  [[ 14.21860992]] Loss_Validation:  [[ 10.73468592]]\n",
      "Loop 551 Loss_Train:  [[ 14.21566853]] Loss_Validation:  [[ 10.73255421]]\n",
      "Loop 552 Loss_Train:  [[ 14.21274069]] Loss_Validation:  [[ 10.73043962]]\n",
      "Loop 553 Loss_Train:  [[ 14.20982629]] Loss_Validation:  [[ 10.72834203]]\n",
      "Loop 554 Loss_Train:  [[ 14.20692524]] Loss_Validation:  [[ 10.72626131]]\n",
      "Loop 555 Loss_Train:  [[ 14.20403745]] Loss_Validation:  [[ 10.72419735]]\n",
      "Loop 556 Loss_Train:  [[ 14.20116283]] Loss_Validation:  [[ 10.72215001]]\n",
      "Loop 557 Loss_Train:  [[ 14.19830129]] Loss_Validation:  [[ 10.72011919]]\n",
      "Loop 558 Loss_Train:  [[ 14.19545274]] Loss_Validation:  [[ 10.71810476]]\n",
      "Loop 559 Loss_Train:  [[ 14.19261709]] Loss_Validation:  [[ 10.71610661]]\n",
      "Loop 560 Loss_Train:  [[ 14.18979424]] Loss_Validation:  [[ 10.7141246]]\n",
      "Loop 561 Loss_Train:  [[ 14.18698412]] Loss_Validation:  [[ 10.71215864]]\n",
      "Loop 562 Loss_Train:  [[ 14.18418664]] Loss_Validation:  [[ 10.7102086]]\n",
      "Loop 563 Loss_Train:  [[ 14.1814017]] Loss_Validation:  [[ 10.70827437]]\n",
      "Loop 564 Loss_Train:  [[ 14.17862923]] Loss_Validation:  [[ 10.70635584]]\n",
      "Loop 565 Loss_Train:  [[ 14.17586914]] Loss_Validation:  [[ 10.70445288]]\n",
      "Loop 566 Loss_Train:  [[ 14.17312135]] Loss_Validation:  [[ 10.7025654]]\n",
      "Loop 567 Loss_Train:  [[ 14.17038576]] Loss_Validation:  [[ 10.70069328]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 568 Loss_Train:  [[ 14.16766231]] Loss_Validation:  [[ 10.6988364]]\n",
      "Loop 569 Loss_Train:  [[ 14.16495091]] Loss_Validation:  [[ 10.69699466]]\n",
      "Loop 570 Loss_Train:  [[ 14.16225148]] Loss_Validation:  [[ 10.69516796]]\n",
      "Loop 571 Loss_Train:  [[ 14.15956393]] Loss_Validation:  [[ 10.69335618]]\n",
      "Loop 572 Loss_Train:  [[ 14.15688819]] Loss_Validation:  [[ 10.69155921]]\n",
      "Loop 573 Loss_Train:  [[ 14.15422418]] Loss_Validation:  [[ 10.68977696]]\n",
      "Loop 574 Loss_Train:  [[ 14.15157182]] Loss_Validation:  [[ 10.68800931]]\n",
      "Loop 575 Loss_Train:  [[ 14.14893103]] Loss_Validation:  [[ 10.68625616]]\n",
      "Loop 576 Loss_Train:  [[ 14.14630174]] Loss_Validation:  [[ 10.68451741]]\n",
      "Loop 577 Loss_Train:  [[ 14.14368387]] Loss_Validation:  [[ 10.68279295]]\n",
      "Loop 578 Loss_Train:  [[ 14.14107734]] Loss_Validation:  [[ 10.68108269]]\n",
      "Loop 579 Loss_Train:  [[ 14.13848208]] Loss_Validation:  [[ 10.67938652]]\n",
      "Loop 580 Loss_Train:  [[ 14.13589802]] Loss_Validation:  [[ 10.67770434]]\n",
      "Loop 581 Loss_Train:  [[ 14.13332508]] Loss_Validation:  [[ 10.67603605]]\n",
      "Loop 582 Loss_Train:  [[ 14.13076319]] Loss_Validation:  [[ 10.67438156]]\n",
      "Loop 583 Loss_Train:  [[ 14.12821227]] Loss_Validation:  [[ 10.67274077]]\n",
      "Loop 584 Loss_Train:  [[ 14.12567226]] Loss_Validation:  [[ 10.67111357]]\n",
      "Loop 585 Loss_Train:  [[ 14.12314308]] Loss_Validation:  [[ 10.66949987]]\n",
      "Loop 586 Loss_Train:  [[ 14.12062467]] Loss_Validation:  [[ 10.66789958]]\n",
      "Loop 587 Loss_Train:  [[ 14.11811694]] Loss_Validation:  [[ 10.6663126]]\n",
      "Loop 588 Loss_Train:  [[ 14.11561984]] Loss_Validation:  [[ 10.66473884]]\n",
      "Loop 589 Loss_Train:  [[ 14.11313329]] Loss_Validation:  [[ 10.66317821]]\n",
      "Loop 590 Loss_Train:  [[ 14.11065723]] Loss_Validation:  [[ 10.6616306]]\n",
      "Loop 591 Loss_Train:  [[ 14.10819159]] Loss_Validation:  [[ 10.66009593]]\n",
      "Loop 592 Loss_Train:  [[ 14.1057363]] Loss_Validation:  [[ 10.65857412]]\n",
      "Loop 593 Loss_Train:  [[ 14.1032913]] Loss_Validation:  [[ 10.65706505]]\n",
      "Loop 594 Loss_Train:  [[ 14.10085651]] Loss_Validation:  [[ 10.65556866]]\n",
      "Loop 595 Loss_Train:  [[ 14.09843188]] Loss_Validation:  [[ 10.65408485]]\n",
      "Loop 596 Loss_Train:  [[ 14.09601733]] Loss_Validation:  [[ 10.65261352]]\n",
      "Loop 597 Loss_Train:  [[ 14.09361281]] Loss_Validation:  [[ 10.6511546]]\n",
      "Loop 598 Loss_Train:  [[ 14.09121825]] Loss_Validation:  [[ 10.64970799]]\n",
      "Loop 599 Loss_Train:  [[ 14.08883359]] Loss_Validation:  [[ 10.64827361]]\n",
      "Loop 600 Loss_Train:  [[ 14.08645876]] Loss_Validation:  [[ 10.64685137]]\n",
      "Loop 601 Loss_Train:  [[ 14.08409371]] Loss_Validation:  [[ 10.64544119]]\n",
      "Loop 602 Loss_Train:  [[ 14.08173837]] Loss_Validation:  [[ 10.64404298]]\n",
      "Loop 603 Loss_Train:  [[ 14.07939267]] Loss_Validation:  [[ 10.64265666]]\n",
      "Loop 604 Loss_Train:  [[ 14.07705657]] Loss_Validation:  [[ 10.64128215]]\n",
      "Loop 605 Loss_Train:  [[ 14.07472999]] Loss_Validation:  [[ 10.63991936]]\n",
      "Loop 606 Loss_Train:  [[ 14.07241288]] Loss_Validation:  [[ 10.63856821]]\n",
      "Loop 607 Loss_Train:  [[ 14.07010519]] Loss_Validation:  [[ 10.63722863]]\n",
      "Loop 608 Loss_Train:  [[ 14.06780684]] Loss_Validation:  [[ 10.63590052]]\n",
      "Loop 609 Loss_Train:  [[ 14.06551779]] Loss_Validation:  [[ 10.63458381]]\n",
      "Loop 610 Loss_Train:  [[ 14.06323797]] Loss_Validation:  [[ 10.63327842]]\n",
      "Loop 611 Loss_Train:  [[ 14.06096733]] Loss_Validation:  [[ 10.63198427]]\n",
      "Loop 612 Loss_Train:  [[ 14.05870581]] Loss_Validation:  [[ 10.63070128]]\n",
      "Loop 613 Loss_Train:  [[ 14.05645336]] Loss_Validation:  [[ 10.62942938]]\n",
      "Loop 614 Loss_Train:  [[ 14.05420992]] Loss_Validation:  [[ 10.62816849]]\n",
      "Loop 615 Loss_Train:  [[ 14.05197543]] Loss_Validation:  [[ 10.62691852]]\n",
      "Loop 616 Loss_Train:  [[ 14.04974984]] Loss_Validation:  [[ 10.62567942]]\n",
      "Loop 617 Loss_Train:  [[ 14.04753309]] Loss_Validation:  [[ 10.62445109]]\n",
      "Loop 618 Loss_Train:  [[ 14.04532514]] Loss_Validation:  [[ 10.62323347]]\n",
      "Loop 619 Loss_Train:  [[ 14.04312592]] Loss_Validation:  [[ 10.62202648]]\n",
      "Loop 620 Loss_Train:  [[ 14.04093538]] Loss_Validation:  [[ 10.62083005]]\n",
      "Loop 621 Loss_Train:  [[ 14.03875348]] Loss_Validation:  [[ 10.6196441]]\n",
      "Loop 622 Loss_Train:  [[ 14.03658015]] Loss_Validation:  [[ 10.61846856]]\n",
      "Loop 623 Loss_Train:  [[ 14.03441535]] Loss_Validation:  [[ 10.61730336]]\n",
      "Loop 624 Loss_Train:  [[ 14.03225903]] Loss_Validation:  [[ 10.61614843]]\n",
      "Loop 625 Loss_Train:  [[ 14.03011113]] Loss_Validation:  [[ 10.6150037]]\n",
      "Loop 626 Loss_Train:  [[ 14.02797161]] Loss_Validation:  [[ 10.6138691]]\n",
      "Loop 627 Loss_Train:  [[ 14.0258404]] Loss_Validation:  [[ 10.61274455]]\n",
      "Loop 628 Loss_Train:  [[ 14.02371748]] Loss_Validation:  [[ 10.61162999]]\n",
      "Loop 629 Loss_Train:  [[ 14.02160277]] Loss_Validation:  [[ 10.61052535]]\n",
      "Loop 630 Loss_Train:  [[ 14.01949624]] Loss_Validation:  [[ 10.60943056]]\n",
      "Loop 631 Loss_Train:  [[ 14.01739784]] Loss_Validation:  [[ 10.60834555]]\n",
      "Loop 632 Loss_Train:  [[ 14.01530751]] Loss_Validation:  [[ 10.60727026]]\n",
      "Loop 633 Loss_Train:  [[ 14.01322522]] Loss_Validation:  [[ 10.60620462]]\n",
      "Loop 634 Loss_Train:  [[ 14.0111509]] Loss_Validation:  [[ 10.60514856]]\n",
      "Loop 635 Loss_Train:  [[ 14.00908453]] Loss_Validation:  [[ 10.60410202]]\n",
      "Loop 636 Loss_Train:  [[ 14.00702604]] Loss_Validation:  [[ 10.60306493]]\n",
      "Loop 637 Loss_Train:  [[ 14.00497539]] Loss_Validation:  [[ 10.60203722]]\n",
      "Loop 638 Loss_Train:  [[ 14.00293254]] Loss_Validation:  [[ 10.60101884]]\n",
      "Loop 639 Loss_Train:  [[ 14.00089745]] Loss_Validation:  [[ 10.60000971]]\n",
      "Loop 640 Loss_Train:  [[ 13.99887005]] Loss_Validation:  [[ 10.59900978]]\n",
      "Loop 641 Loss_Train:  [[ 13.99685032]] Loss_Validation:  [[ 10.59801899]]\n",
      "Loop 642 Loss_Train:  [[ 13.9948382]] Loss_Validation:  [[ 10.59703726]]\n",
      "Loop 643 Loss_Train:  [[ 13.99283366]] Loss_Validation:  [[ 10.59606454]]\n",
      "Loop 644 Loss_Train:  [[ 13.99083664]] Loss_Validation:  [[ 10.59510076]]\n",
      "Loop 645 Loss_Train:  [[ 13.98884711]] Loss_Validation:  [[ 10.59414588]]\n",
      "Loop 646 Loss_Train:  [[ 13.98686502]] Loss_Validation:  [[ 10.59319981]]\n",
      "Loop 647 Loss_Train:  [[ 13.98489033]] Loss_Validation:  [[ 10.59226251]]\n",
      "Loop 648 Loss_Train:  [[ 13.98292299]] Loss_Validation:  [[ 10.59133392]]\n",
      "Loop 649 Loss_Train:  [[ 13.98096297]] Loss_Validation:  [[ 10.59041396]]\n",
      "Loop 650 Loss_Train:  [[ 13.97901021]] Loss_Validation:  [[ 10.5895026]]\n",
      "Loop 651 Loss_Train:  [[ 13.97706469]] Loss_Validation:  [[ 10.58859976]]\n",
      "Loop 652 Loss_Train:  [[ 13.97512636]] Loss_Validation:  [[ 10.5877054]]\n",
      "Loop 653 Loss_Train:  [[ 13.97319518]] Loss_Validation:  [[ 10.58681944]]\n",
      "Loop 654 Loss_Train:  [[ 13.9712711]] Loss_Validation:  [[ 10.58594184]]\n",
      "Loop 655 Loss_Train:  [[ 13.96935409]] Loss_Validation:  [[ 10.58507254]]\n",
      "Loop 656 Loss_Train:  [[ 13.96744411]] Loss_Validation:  [[ 10.58421148]]\n",
      "Loop 657 Loss_Train:  [[ 13.96554111]] Loss_Validation:  [[ 10.58335861]]\n",
      "Loop 658 Loss_Train:  [[ 13.96364507]] Loss_Validation:  [[ 10.58251387]]\n",
      "Loop 659 Loss_Train:  [[ 13.96175593]] Loss_Validation:  [[ 10.5816772]]\n",
      "Loop 660 Loss_Train:  [[ 13.95987366]] Loss_Validation:  [[ 10.58084856]]\n",
      "Loop 661 Loss_Train:  [[ 13.95799823]] Loss_Validation:  [[ 10.58002788]]\n",
      "Loop 662 Loss_Train:  [[ 13.95612959]] Loss_Validation:  [[ 10.57921511]]\n",
      "Loop 663 Loss_Train:  [[ 13.95426771]] Loss_Validation:  [[ 10.5784102]]\n",
      "Loop 664 Loss_Train:  [[ 13.95241254]] Loss_Validation:  [[ 10.5776131]]\n",
      "Loop 665 Loss_Train:  [[ 13.95056405]] Loss_Validation:  [[ 10.57682375]]\n",
      "Loop 666 Loss_Train:  [[ 13.94872221]] Loss_Validation:  [[ 10.5760421]]\n",
      "Loop 667 Loss_Train:  [[ 13.94688698]] Loss_Validation:  [[ 10.57526811]]\n",
      "Loop 668 Loss_Train:  [[ 13.94505832]] Loss_Validation:  [[ 10.5745017]]\n",
      "Loop 669 Loss_Train:  [[ 13.94323619]] Loss_Validation:  [[ 10.57374285]]\n",
      "Loop 670 Loss_Train:  [[ 13.94142056]] Loss_Validation:  [[ 10.57299149]]\n",
      "Loop 671 Loss_Train:  [[ 13.9396114]] Loss_Validation:  [[ 10.57224757]]\n",
      "Loop 672 Loss_Train:  [[ 13.93780866]] Loss_Validation:  [[ 10.57151105]]\n",
      "Loop 673 Loss_Train:  [[ 13.93601232]] Loss_Validation:  [[ 10.57078187]]\n",
      "Loop 674 Loss_Train:  [[ 13.93422233]] Loss_Validation:  [[ 10.57005999]]\n",
      "Loop 675 Loss_Train:  [[ 13.93243867]] Loss_Validation:  [[ 10.56934536]]\n",
      "Loop 676 Loss_Train:  [[ 13.93066129]] Loss_Validation:  [[ 10.56863792]]\n",
      "Loop 677 Loss_Train:  [[ 13.92889018]] Loss_Validation:  [[ 10.56793763]]\n",
      "Loop 678 Loss_Train:  [[ 13.92712528]] Loss_Validation:  [[ 10.56724445]]\n",
      "Loop 679 Loss_Train:  [[ 13.92536657]] Loss_Validation:  [[ 10.56655831]]\n",
      "Loop 680 Loss_Train:  [[ 13.92361401]] Loss_Validation:  [[ 10.56587918]]\n",
      "Loop 681 Loss_Train:  [[ 13.92186758]] Loss_Validation:  [[ 10.56520702]]\n",
      "Loop 682 Loss_Train:  [[ 13.92012724]] Loss_Validation:  [[ 10.56454176]]\n",
      "Loop 683 Loss_Train:  [[ 13.91839295]] Loss_Validation:  [[ 10.56388337]]\n",
      "Loop 684 Loss_Train:  [[ 13.91666468]] Loss_Validation:  [[ 10.5632318]]\n",
      "Loop 685 Loss_Train:  [[ 13.91494241]] Loss_Validation:  [[ 10.562587]]\n",
      "Loop 686 Loss_Train:  [[ 13.91322609]] Loss_Validation:  [[ 10.56194894]]\n",
      "Loop 687 Loss_Train:  [[ 13.91151571]] Loss_Validation:  [[ 10.56131756]]\n",
      "Loop 688 Loss_Train:  [[ 13.90981122]] Loss_Validation:  [[ 10.56069281]]\n",
      "Loop 689 Loss_Train:  [[ 13.9081126]] Loss_Validation:  [[ 10.56007467]]\n",
      "Loop 690 Loss_Train:  [[ 13.90641981]] Loss_Validation:  [[ 10.55946307]]\n",
      "Loop 691 Loss_Train:  [[ 13.90473282]] Loss_Validation:  [[ 10.55885798]]\n",
      "Loop 692 Loss_Train:  [[ 13.90305161]] Loss_Validation:  [[ 10.55825936]]\n",
      "Loop 693 Loss_Train:  [[ 13.90137614]] Loss_Validation:  [[ 10.55766715]]\n",
      "Loop 694 Loss_Train:  [[ 13.89970639]] Loss_Validation:  [[ 10.55708133]]\n",
      "Loop 695 Loss_Train:  [[ 13.89804232]] Loss_Validation:  [[ 10.55650184]]\n",
      "Loop 696 Loss_Train:  [[ 13.8963839]] Loss_Validation:  [[ 10.55592864]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 697 Loss_Train:  [[ 13.89473111]] Loss_Validation:  [[ 10.55536169]]\n",
      "Loop 698 Loss_Train:  [[ 13.89308391]] Loss_Validation:  [[ 10.55480095]]\n",
      "Loop 699 Loss_Train:  [[ 13.89144228]] Loss_Validation:  [[ 10.55424638]]\n",
      "Loop 700 Loss_Train:  [[ 13.88980619]] Loss_Validation:  [[ 10.55369794]]\n",
      "Loop 701 Loss_Train:  [[ 13.8881756]] Loss_Validation:  [[ 10.55315559]]\n",
      "Loop 702 Loss_Train:  [[ 13.8865505]] Loss_Validation:  [[ 10.55261928]]\n",
      "Loop 703 Loss_Train:  [[ 13.88493085]] Loss_Validation:  [[ 10.55208897]]\n",
      "Loop 704 Loss_Train:  [[ 13.88331662]] Loss_Validation:  [[ 10.55156463]]\n",
      "Loop 705 Loss_Train:  [[ 13.88170779]] Loss_Validation:  [[ 10.55104622]]\n",
      "Loop 706 Loss_Train:  [[ 13.88010433]] Loss_Validation:  [[ 10.55053369]]\n",
      "Loop 707 Loss_Train:  [[ 13.87850621]] Loss_Validation:  [[ 10.55002702]]\n",
      "Loop 708 Loss_Train:  [[ 13.87691341]] Loss_Validation:  [[ 10.54952615]]\n",
      "Loop 709 Loss_Train:  [[ 13.87532589]] Loss_Validation:  [[ 10.54903105]]\n",
      "Loop 710 Loss_Train:  [[ 13.87374364]] Loss_Validation:  [[ 10.54854168]]\n",
      "Loop 711 Loss_Train:  [[ 13.87216662]] Loss_Validation:  [[ 10.54805801]]\n",
      "Loop 712 Loss_Train:  [[ 13.87059481]] Loss_Validation:  [[ 10.54757999]]\n",
      "Loop 713 Loss_Train:  [[ 13.86902818]] Loss_Validation:  [[ 10.5471076]]\n",
      "Loop 714 Loss_Train:  [[ 13.8674667]] Loss_Validation:  [[ 10.54664078]]\n",
      "Loop 715 Loss_Train:  [[ 13.86591036]] Loss_Validation:  [[ 10.54617951]]\n",
      "Loop 716 Loss_Train:  [[ 13.86435912]] Loss_Validation:  [[ 10.54572375]]\n",
      "Loop 717 Loss_Train:  [[ 13.86281296]] Loss_Validation:  [[ 10.54527345]]\n",
      "Loop 718 Loss_Train:  [[ 13.86127186]] Loss_Validation:  [[ 10.5448286]]\n",
      "Loop 719 Loss_Train:  [[ 13.85973578]] Loss_Validation:  [[ 10.54438914]]\n",
      "Loop 720 Loss_Train:  [[ 13.85820471]] Loss_Validation:  [[ 10.54395505]]\n",
      "Loop 721 Loss_Train:  [[ 13.85667861]] Loss_Validation:  [[ 10.54352628]]\n",
      "Loop 722 Loss_Train:  [[ 13.85515747]] Loss_Validation:  [[ 10.54310281]]\n",
      "Loop 723 Loss_Train:  [[ 13.85364126]] Loss_Validation:  [[ 10.5426846]]\n",
      "Loop 724 Loss_Train:  [[ 13.85212996]] Loss_Validation:  [[ 10.54227161]]\n",
      "Loop 725 Loss_Train:  [[ 13.85062354]] Loss_Validation:  [[ 10.54186381]]\n",
      "Loop 726 Loss_Train:  [[ 13.84912197]] Loss_Validation:  [[ 10.54146116]]\n",
      "Loop 727 Loss_Train:  [[ 13.84762524]] Loss_Validation:  [[ 10.54106364]]\n",
      "Loop 728 Loss_Train:  [[ 13.84613332]] Loss_Validation:  [[ 10.5406712]]\n",
      "Loop 729 Loss_Train:  [[ 13.84464619]] Loss_Validation:  [[ 10.54028381]]\n",
      "Loop 730 Loss_Train:  [[ 13.84316382]] Loss_Validation:  [[ 10.53990145]]\n",
      "Loop 731 Loss_Train:  [[ 13.84168619]] Loss_Validation:  [[ 10.53952407]]\n",
      "Loop 732 Loss_Train:  [[ 13.84021328]] Loss_Validation:  [[ 10.53915164]]\n",
      "Loop 733 Loss_Train:  [[ 13.83874506]] Loss_Validation:  [[ 10.53878414]]\n",
      "Loop 734 Loss_Train:  [[ 13.83728152]] Loss_Validation:  [[ 10.53842152]]\n",
      "Loop 735 Loss_Train:  [[ 13.83582262]] Loss_Validation:  [[ 10.53806377]]\n",
      "Loop 736 Loss_Train:  [[ 13.83436835]] Loss_Validation:  [[ 10.53771083]]\n",
      "Loop 737 Loss_Train:  [[ 13.83291869]] Loss_Validation:  [[ 10.5373627]]\n",
      "Loop 738 Loss_Train:  [[ 13.83147361]] Loss_Validation:  [[ 10.53701932]]\n",
      "Loop 739 Loss_Train:  [[ 13.8300331]] Loss_Validation:  [[ 10.53668067]]\n",
      "Loop 740 Loss_Train:  [[ 13.82859712]] Loss_Validation:  [[ 10.53634672]]\n",
      "Loop 741 Loss_Train:  [[ 13.82716566]] Loss_Validation:  [[ 10.53601744]]\n",
      "Loop 742 Loss_Train:  [[ 13.8257387]] Loss_Validation:  [[ 10.5356928]]\n",
      "Loop 743 Loss_Train:  [[ 13.82431621]] Loss_Validation:  [[ 10.53537276]]\n",
      "Loop 744 Loss_Train:  [[ 13.82289818]] Loss_Validation:  [[ 10.53505731]]\n",
      "Loop 745 Loss_Train:  [[ 13.82148458]] Loss_Validation:  [[ 10.53474639]]\n",
      "Loop 746 Loss_Train:  [[ 13.82007539]] Loss_Validation:  [[ 10.53444]]\n",
      "Loop 747 Loss_Train:  [[ 13.8186706]] Loss_Validation:  [[ 10.53413809]]\n",
      "Loop 748 Loss_Train:  [[ 13.81727017]] Loss_Validation:  [[ 10.53384064]]\n",
      "Loop 749 Loss_Train:  [[ 13.8158741]] Loss_Validation:  [[ 10.53354762]]\n",
      "Loop 750 Loss_Train:  [[ 13.81448235]] Loss_Validation:  [[ 10.533259]]\n",
      "Loop 751 Loss_Train:  [[ 13.81309492]] Loss_Validation:  [[ 10.53297475]]\n",
      "Loop 752 Loss_Train:  [[ 13.81171178]] Loss_Validation:  [[ 10.53269484]]\n",
      "Loop 753 Loss_Train:  [[ 13.8103329]] Loss_Validation:  [[ 10.53241924]]\n",
      "Loop 754 Loss_Train:  [[ 13.80895828]] Loss_Validation:  [[ 10.53214793]]\n",
      "Loop 755 Loss_Train:  [[ 13.80758789]] Loss_Validation:  [[ 10.53188088]]\n",
      "Loop 756 Loss_Train:  [[ 13.80622171]] Loss_Validation:  [[ 10.53161805]]\n",
      "Loop 757 Loss_Train:  [[ 13.80485972]] Loss_Validation:  [[ 10.53135943]]\n",
      "Loop 758 Loss_Train:  [[ 13.8035019]] Loss_Validation:  [[ 10.53110498]]\n",
      "Loop 759 Loss_Train:  [[ 13.80214824]] Loss_Validation:  [[ 10.53085468]]\n",
      "Loop 760 Loss_Train:  [[ 13.80079871]] Loss_Validation:  [[ 10.53060849]]\n",
      "Loop 761 Loss_Train:  [[ 13.7994533]] Loss_Validation:  [[ 10.5303664]]\n",
      "Loop 762 Loss_Train:  [[ 13.79811198]] Loss_Validation:  [[ 10.53012838]]\n",
      "Loop 763 Loss_Train:  [[ 13.79677474]] Loss_Validation:  [[ 10.52989439]]\n",
      "Loop 764 Loss_Train:  [[ 13.79544156]] Loss_Validation:  [[ 10.52966441]]\n",
      "Loop 765 Loss_Train:  [[ 13.79411242]] Loss_Validation:  [[ 10.52943843]]\n",
      "Loop 766 Loss_Train:  [[ 13.79278731]] Loss_Validation:  [[ 10.5292164]]\n",
      "Loop 767 Loss_Train:  [[ 13.7914662]] Loss_Validation:  [[ 10.5289983]]\n",
      "Loop 768 Loss_Train:  [[ 13.79014908]] Loss_Validation:  [[ 10.52878412]]\n",
      "Loop 769 Loss_Train:  [[ 13.78883592]] Loss_Validation:  [[ 10.52857382]]\n",
      "Loop 770 Loss_Train:  [[ 13.78752672]] Loss_Validation:  [[ 10.52836737]]\n",
      "Loop 771 Loss_Train:  [[ 13.78622145]] Loss_Validation:  [[ 10.52816476]]\n",
      "Loop 772 Loss_Train:  [[ 13.78492009]] Loss_Validation:  [[ 10.52796595]]\n",
      "Loop 773 Loss_Train:  [[ 13.78362264]] Loss_Validation:  [[ 10.52777093]]\n",
      "Loop 774 Loss_Train:  [[ 13.78232906]] Loss_Validation:  [[ 10.52757966]]\n",
      "Loop 775 Loss_Train:  [[ 13.78103935]] Loss_Validation:  [[ 10.52739213]]\n",
      "Loop 776 Loss_Train:  [[ 13.77975348]] Loss_Validation:  [[ 10.5272083]]\n",
      "Loop 777 Loss_Train:  [[ 13.77847145]] Loss_Validation:  [[ 10.52702816]]\n",
      "Loop 778 Loss_Train:  [[ 13.77719322]] Loss_Validation:  [[ 10.52685168]]\n",
      "Loop 779 Loss_Train:  [[ 13.7759188]] Loss_Validation:  [[ 10.52667884]]\n",
      "Loop 780 Loss_Train:  [[ 13.77464815]] Loss_Validation:  [[ 10.5265096]]\n",
      "Loop 781 Loss_Train:  [[ 13.77338126]] Loss_Validation:  [[ 10.52634396]]\n",
      "Loop 782 Loss_Train:  [[ 13.77211812]] Loss_Validation:  [[ 10.52618188]]\n",
      "Loop 783 Loss_Train:  [[ 13.77085871]] Loss_Validation:  [[ 10.52602334]]\n",
      "Loop 784 Loss_Train:  [[ 13.76960301]] Loss_Validation:  [[ 10.52586833]]\n",
      "Loop 785 Loss_Train:  [[ 13.76835101]] Loss_Validation:  [[ 10.5257168]]\n",
      "Loop 786 Loss_Train:  [[ 13.76710269]] Loss_Validation:  [[ 10.52556876]]\n",
      "Loop 787 Loss_Train:  [[ 13.76585803]] Loss_Validation:  [[ 10.52542416]]\n",
      "Loop 788 Loss_Train:  [[ 13.76461702]] Loss_Validation:  [[ 10.52528298]]\n",
      "Loop 789 Loss_Train:  [[ 13.76337965]] Loss_Validation:  [[ 10.52514522]]\n",
      "Loop 790 Loss_Train:  [[ 13.76214589]] Loss_Validation:  [[ 10.52501084]]\n",
      "Loop 791 Loss_Train:  [[ 13.76091574]] Loss_Validation:  [[ 10.52487981]]\n",
      "Loop 792 Loss_Train:  [[ 13.75968917]] Loss_Validation:  [[ 10.52475213]]\n",
      "Loop 793 Loss_Train:  [[ 13.75846617]] Loss_Validation:  [[ 10.52462776]]\n",
      "Loop 794 Loss_Train:  [[ 13.75724673]] Loss_Validation:  [[ 10.52450669]]\n",
      "Loop 795 Loss_Train:  [[ 13.75603083]] Loss_Validation:  [[ 10.52438889]]\n",
      "Loop 796 Loss_Train:  [[ 13.75481846]] Loss_Validation:  [[ 10.52427435]]\n",
      "Loop 797 Loss_Train:  [[ 13.75360959]] Loss_Validation:  [[ 10.52416303]]\n",
      "Loop 798 Loss_Train:  [[ 13.75240422]] Loss_Validation:  [[ 10.52405493]]\n",
      "Loop 799 Loss_Train:  [[ 13.75120233]] Loss_Validation:  [[ 10.52395002]]\n",
      "Loop 800 Loss_Train:  [[ 13.75000391]] Loss_Validation:  [[ 10.52384827]]\n",
      "Loop 801 Loss_Train:  [[ 13.74880893]] Loss_Validation:  [[ 10.52374967]]\n",
      "Loop 802 Loss_Train:  [[ 13.7476174]] Loss_Validation:  [[ 10.5236542]]\n",
      "Loop 803 Loss_Train:  [[ 13.74642928]] Loss_Validation:  [[ 10.52356183]]\n",
      "Loop 804 Loss_Train:  [[ 13.74524458]] Loss_Validation:  [[ 10.52347255]]\n",
      "Loop 805 Loss_Train:  [[ 13.74406326]] Loss_Validation:  [[ 10.52338633]]\n",
      "Loop 806 Loss_Train:  [[ 13.74288533]] Loss_Validation:  [[ 10.52330317]]\n",
      "Loop 807 Loss_Train:  [[ 13.74171076]] Loss_Validation:  [[ 10.52322302]]\n",
      "Loop 808 Loss_Train:  [[ 13.74053954]] Loss_Validation:  [[ 10.52314589]]\n",
      "Loop 809 Loss_Train:  [[ 13.73937166]] Loss_Validation:  [[ 10.52307173]]\n",
      "Loop 810 Loss_Train:  [[ 13.7382071]] Loss_Validation:  [[ 10.52300055]]\n",
      "Loop 811 Loss_Train:  [[ 13.73704585]] Loss_Validation:  [[ 10.52293231]]\n",
      "Loop 812 Loss_Train:  [[ 13.7358879]] Loss_Validation:  [[ 10.52286701]]\n",
      "Loop 813 Loss_Train:  [[ 13.73473323]] Loss_Validation:  [[ 10.52280461]]\n",
      "Loop 814 Loss_Train:  [[ 13.73358182]] Loss_Validation:  [[ 10.5227451]]\n",
      "Loop 815 Loss_Train:  [[ 13.73243368]] Loss_Validation:  [[ 10.52268846]]\n",
      "Loop 816 Loss_Train:  [[ 13.73128877]] Loss_Validation:  [[ 10.52263467]]\n",
      "Loop 817 Loss_Train:  [[ 13.73014709]] Loss_Validation:  [[ 10.52258372]]\n",
      "Loop 818 Loss_Train:  [[ 13.72900863]] Loss_Validation:  [[ 10.52253558]]\n",
      "Loop 819 Loss_Train:  [[ 13.72787336]] Loss_Validation:  [[ 10.52249024]]\n",
      "Loop 820 Loss_Train:  [[ 13.72674129]] Loss_Validation:  [[ 10.52244767]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 821 Loss_Train:  [[ 13.72561239]] Loss_Validation:  [[ 10.52240787]]\n",
      "Loop 822 Loss_Train:  [[ 13.72448666]] Loss_Validation:  [[ 10.52237081]]\n",
      "Loop 823 Loss_Train:  [[ 13.72336407]] Loss_Validation:  [[ 10.52233647]]\n",
      "Loop 824 Loss_Train:  [[ 13.72224462]] Loss_Validation:  [[ 10.52230484]]\n",
      "Loop 825 Loss_Train:  [[ 13.7211283]] Loss_Validation:  [[ 10.52227589]]\n",
      "Loop 826 Loss_Train:  [[ 13.72001508]] Loss_Validation:  [[ 10.52224962]]\n",
      "Loop 827 Loss_Train:  [[ 13.71890497]] Loss_Validation:  [[ 10.522226]]\n",
      "Loop 828 Loss_Train:  [[ 13.71779794]] Loss_Validation:  [[ 10.52220501]]\n",
      "Loop 829 Loss_Train:  [[ 13.71669399]] Loss_Validation:  [[ 10.52218665]]\n",
      "Loop 830 Loss_Train:  [[ 13.7155931]] Loss_Validation:  [[ 10.52217088]]\n",
      "Loop 831 Loss_Train:  [[ 13.71449526]] Loss_Validation:  [[ 10.5221577]]\n",
      "Loop 832 Loss_Train:  [[ 13.71340046]] Loss_Validation:  [[ 10.52214708]]\n",
      "Loop 833 Loss_Train:  [[ 13.71230868]] Loss_Validation:  [[ 10.52213902]]\n",
      "Loop 834 Loss_Train:  [[ 13.71121991]] Loss_Validation:  [[ 10.52213349]]\n",
      "Loop 835 Loss_Train:  [[ 13.71013415]] Loss_Validation:  [[ 10.52213047]]\n",
      "Loop 836 Loss_Train:  [[ 13.70905138]] Loss_Validation:  [[ 10.52212996]]\n",
      "Loop 837 Loss_Train:  [[ 13.70797158]] Loss_Validation:  [[ 10.52213193]]\n",
      "Loop 838 Loss_Train:  [[ 13.70689475]] Loss_Validation:  [[ 10.52213637]]\n",
      "Loop 839 Loss_Train:  [[ 13.70582087]] Loss_Validation:  [[ 10.52214325]]\n",
      "Loop 840 Loss_Train:  [[ 13.70474994]] Loss_Validation:  [[ 10.52215258]]\n",
      "Loop 841 Loss_Train:  [[ 13.70368194]] Loss_Validation:  [[ 10.52216432]]\n",
      "Loop 842 Loss_Train:  [[ 13.70261685]] Loss_Validation:  [[ 10.52217847]]\n",
      "Loop 843 Loss_Train:  [[ 13.70155468]] Loss_Validation:  [[ 10.522195]]\n",
      "Loop 844 Loss_Train:  [[ 13.7004954]] Loss_Validation:  [[ 10.5222139]]\n",
      "Loop 845 Loss_Train:  [[ 13.699439]] Loss_Validation:  [[ 10.52223516]]\n",
      "Loop 846 Loss_Train:  [[ 13.69838548]] Loss_Validation:  [[ 10.52225876]]\n",
      "Loop 847 Loss_Train:  [[ 13.69733482]] Loss_Validation:  [[ 10.52228469]]\n",
      "Loop 848 Loss_Train:  [[ 13.69628702]] Loss_Validation:  [[ 10.52231292]]\n",
      "Loop 849 Loss_Train:  [[ 13.69524205]] Loss_Validation:  [[ 10.52234345]]\n",
      "Loop 850 Loss_Train:  [[ 13.69419992]] Loss_Validation:  [[ 10.52237626]]\n",
      "Loop 851 Loss_Train:  [[ 13.6931606]] Loss_Validation:  [[ 10.52241133]]\n",
      "Loop 852 Loss_Train:  [[ 13.69212409]] Loss_Validation:  [[ 10.52244865]]\n",
      "Loop 853 Loss_Train:  [[ 13.69109037]] Loss_Validation:  [[ 10.52248821]]\n",
      "Loop 854 Loss_Train:  [[ 13.69005945]] Loss_Validation:  [[ 10.52252998]]\n",
      "Loop 855 Loss_Train:  [[ 13.68903129]] Loss_Validation:  [[ 10.52257396]]\n",
      "Loop 856 Loss_Train:  [[ 13.68800591]] Loss_Validation:  [[ 10.52262014]]\n",
      "Loop 857 Loss_Train:  [[ 13.68698327]] Loss_Validation:  [[ 10.52266848]]\n",
      "Loop 858 Loss_Train:  [[ 13.68596338]] Loss_Validation:  [[ 10.52271899]]\n",
      "Loop 859 Loss_Train:  [[ 13.68494623]] Loss_Validation:  [[ 10.52277164]]\n",
      "Loop 860 Loss_Train:  [[ 13.68393179]] Loss_Validation:  [[ 10.52282643]]\n",
      "Loop 861 Loss_Train:  [[ 13.68292007]] Loss_Validation:  [[ 10.52288334]]\n",
      "Loop 862 Loss_Train:  [[ 13.68191105]] Loss_Validation:  [[ 10.52294235]]\n",
      "Loop 863 Loss_Train:  [[ 13.68090473]] Loss_Validation:  [[ 10.52300345]]\n",
      "Loop 864 Loss_Train:  [[ 13.67990108]] Loss_Validation:  [[ 10.52306663]]\n",
      "Loop 865 Loss_Train:  [[ 13.67890011]] Loss_Validation:  [[ 10.52313187]]\n",
      "Loop 866 Loss_Train:  [[ 13.67790179]] Loss_Validation:  [[ 10.52319916]]\n",
      "Loop 867 Loss_Train:  [[ 13.67690613]] Loss_Validation:  [[ 10.52326848]]\n",
      "Loop 868 Loss_Train:  [[ 13.67591311]] Loss_Validation:  [[ 10.52333983]]\n",
      "Loop 869 Loss_Train:  [[ 13.67492272]] Loss_Validation:  [[ 10.52341319]]\n",
      "Loop 870 Loss_Train:  [[ 13.67393496]] Loss_Validation:  [[ 10.52348854]]\n",
      "Loop 871 Loss_Train:  [[ 13.6729498]] Loss_Validation:  [[ 10.52356587]]\n",
      "Loop 872 Loss_Train:  [[ 13.67196725]] Loss_Validation:  [[ 10.52364517]]\n",
      "Loop 873 Loss_Train:  [[ 13.67098729]] Loss_Validation:  [[ 10.52372643]]\n",
      "Loop 874 Loss_Train:  [[ 13.67000991]] Loss_Validation:  [[ 10.52380963]]\n",
      "Loop 875 Loss_Train:  [[ 13.66903511]] Loss_Validation:  [[ 10.52389476]]\n",
      "Loop 876 Loss_Train:  [[ 13.66806287]] Loss_Validation:  [[ 10.52398181]]\n",
      "Loop 877 Loss_Train:  [[ 13.66709318]] Loss_Validation:  [[ 10.52407076]]\n",
      "Loop 878 Loss_Train:  [[ 13.66612604]] Loss_Validation:  [[ 10.5241616]]\n",
      "Loop 879 Loss_Train:  [[ 13.66516143]] Loss_Validation:  [[ 10.52425432]]\n",
      "Loop 880 Loss_Train:  [[ 13.66419935]] Loss_Validation:  [[ 10.52434891]]\n",
      "Loop 881 Loss_Train:  [[ 13.66323979]] Loss_Validation:  [[ 10.52444535]]\n",
      "Loop 882 Loss_Train:  [[ 13.66228273]] Loss_Validation:  [[ 10.52454363]]\n",
      "Loop 883 Loss_Train:  [[ 13.66132817]] Loss_Validation:  [[ 10.52464374]]\n",
      "Loop 884 Loss_Train:  [[ 13.6603761]] Loss_Validation:  [[ 10.52474567]]\n",
      "Loop 885 Loss_Train:  [[ 13.65942651]] Loss_Validation:  [[ 10.5248494]]\n",
      "Loop 886 Loss_Train:  [[ 13.65847939]] Loss_Validation:  [[ 10.52495492]]\n",
      "Loop 887 Loss_Train:  [[ 13.65753474]] Loss_Validation:  [[ 10.52506223]]\n",
      "Loop 888 Loss_Train:  [[ 13.65659253]] Loss_Validation:  [[ 10.5251713]]\n",
      "Loop 889 Loss_Train:  [[ 13.65565277]] Loss_Validation:  [[ 10.52528213]]\n",
      "Loop 890 Loss_Train:  [[ 13.65471545]] Loss_Validation:  [[ 10.5253947]]\n",
      "Loop 891 Loss_Train:  [[ 13.65378055]] Loss_Validation:  [[ 10.525509]]\n",
      "Loop 892 Loss_Train:  [[ 13.65284807]] Loss_Validation:  [[ 10.52562503]]\n",
      "Loop 893 Loss_Train:  [[ 13.651918]] Loss_Validation:  [[ 10.52574276]]\n",
      "Loop 894 Loss_Train:  [[ 13.65099033]] Loss_Validation:  [[ 10.5258622]]\n",
      "Loop 895 Loss_Train:  [[ 13.65006505]] Loss_Validation:  [[ 10.52598332]]\n",
      "Loop 896 Loss_Train:  [[ 13.64914215]] Loss_Validation:  [[ 10.52610611]]\n",
      "Loop 897 Loss_Train:  [[ 13.64822163]] Loss_Validation:  [[ 10.52623057]]\n",
      "Loop 898 Loss_Train:  [[ 13.64730347]] Loss_Validation:  [[ 10.52635668]]\n",
      "Loop 899 Loss_Train:  [[ 13.64638767]] Loss_Validation:  [[ 10.52648444]]\n",
      "Loop 900 Loss_Train:  [[ 13.64547422]] Loss_Validation:  [[ 10.52661382]]\n",
      "Loop 901 Loss_Train:  [[ 13.64456311]] Loss_Validation:  [[ 10.52674482]]\n",
      "Loop 902 Loss_Train:  [[ 13.64365434]] Loss_Validation:  [[ 10.52687743]]\n",
      "Loop 903 Loss_Train:  [[ 13.64274788]] Loss_Validation:  [[ 10.52701164]]\n",
      "Loop 904 Loss_Train:  [[ 13.64184374]] Loss_Validation:  [[ 10.52714743]]\n",
      "Loop 905 Loss_Train:  [[ 13.64094191]] Loss_Validation:  [[ 10.5272848]]\n",
      "Loop 906 Loss_Train:  [[ 13.64004238]] Loss_Validation:  [[ 10.52742374]]\n",
      "Loop 907 Loss_Train:  [[ 13.63914515]] Loss_Validation:  [[ 10.52756423]]\n",
      "Loop 908 Loss_Train:  [[ 13.63825019]] Loss_Validation:  [[ 10.52770626]]\n",
      "Loop 909 Loss_Train:  [[ 13.63735751]] Loss_Validation:  [[ 10.52784982]]\n",
      "Loop 910 Loss_Train:  [[ 13.63646709]] Loss_Validation:  [[ 10.52799491]]\n",
      "Loop 911 Loss_Train:  [[ 13.63557894]] Loss_Validation:  [[ 10.52814151]]\n",
      "Loop 912 Loss_Train:  [[ 13.63469304]] Loss_Validation:  [[ 10.52828962]]\n",
      "Loop 913 Loss_Train:  [[ 13.63380938]] Loss_Validation:  [[ 10.52843921]]\n",
      "Loop 914 Loss_Train:  [[ 13.63292795]] Loss_Validation:  [[ 10.52859029]]\n",
      "Loop 915 Loss_Train:  [[ 13.63204876]] Loss_Validation:  [[ 10.52874283]]\n",
      "Loop 916 Loss_Train:  [[ 13.63117178]] Loss_Validation:  [[ 10.52889684]]\n",
      "Loop 917 Loss_Train:  [[ 13.63029702]] Loss_Validation:  [[ 10.5290523]]\n",
      "Loop 918 Loss_Train:  [[ 13.62942446]] Loss_Validation:  [[ 10.5292092]]\n",
      "Loop 919 Loss_Train:  [[ 13.62855409]] Loss_Validation:  [[ 10.52936753]]\n",
      "Loop 920 Loss_Train:  [[ 13.62768592]] Loss_Validation:  [[ 10.52952729]]\n",
      "Loop 921 Loss_Train:  [[ 13.62681993]] Loss_Validation:  [[ 10.52968845]]\n",
      "Loop 922 Loss_Train:  [[ 13.62595611]] Loss_Validation:  [[ 10.52985102]]\n",
      "Loop 923 Loss_Train:  [[ 13.62509446]] Loss_Validation:  [[ 10.53001498]]\n",
      "Loop 924 Loss_Train:  [[ 13.62423497]] Loss_Validation:  [[ 10.53018032]]\n",
      "Loop 925 Loss_Train:  [[ 13.62337763]] Loss_Validation:  [[ 10.53034704]]\n",
      "Loop 926 Loss_Train:  [[ 13.62252243]] Loss_Validation:  [[ 10.53051512]]\n",
      "Loop 927 Loss_Train:  [[ 13.62166938]] Loss_Validation:  [[ 10.53068455]]\n",
      "Loop 928 Loss_Train:  [[ 13.62081845]] Loss_Validation:  [[ 10.53085533]]\n",
      "Loop 929 Loss_Train:  [[ 13.61996964]] Loss_Validation:  [[ 10.53102744]]\n",
      "Loop 930 Loss_Train:  [[ 13.61912295]] Loss_Validation:  [[ 10.53120088]]\n",
      "Loop 931 Loss_Train:  [[ 13.61827837]] Loss_Validation:  [[ 10.53137564]]\n",
      "Loop 932 Loss_Train:  [[ 13.61743589]] Loss_Validation:  [[ 10.5315517]]\n",
      "Loop 933 Loss_Train:  [[ 13.6165955]] Loss_Validation:  [[ 10.53172906]]\n",
      "Loop 934 Loss_Train:  [[ 13.6157572]] Loss_Validation:  [[ 10.53190772]]\n",
      "Loop 935 Loss_Train:  [[ 13.61492098]] Loss_Validation:  [[ 10.53208765]]\n",
      "Loop 936 Loss_Train:  [[ 13.61408683]] Loss_Validation:  [[ 10.53226886]]\n",
      "Loop 937 Loss_Train:  [[ 13.61325475]] Loss_Validation:  [[ 10.53245132]]\n",
      "Loop 938 Loss_Train:  [[ 13.61242472]] Loss_Validation:  [[ 10.53263505]]\n",
      "Loop 939 Loss_Train:  [[ 13.61159675]] Loss_Validation:  [[ 10.53282001]]\n",
      "Loop 940 Loss_Train:  [[ 13.61077082]] Loss_Validation:  [[ 10.53300622]]\n",
      "Loop 941 Loss_Train:  [[ 13.60994693]] Loss_Validation:  [[ 10.53319365]]\n",
      "Loop 942 Loss_Train:  [[ 13.60912507]] Loss_Validation:  [[ 10.5333823]]\n",
      "Loop 943 Loss_Train:  [[ 13.60830524]] Loss_Validation:  [[ 10.53357216]]\n",
      "Loop 944 Loss_Train:  [[ 13.60748742]] Loss_Validation:  [[ 10.53376323]]\n",
      "Loop 945 Loss_Train:  [[ 13.60667161]] Loss_Validation:  [[ 10.53395548]]\n",
      "Loop 946 Loss_Train:  [[ 13.60585781]] Loss_Validation:  [[ 10.53414892]]\n",
      "Loop 947 Loss_Train:  [[ 13.605046]] Loss_Validation:  [[ 10.53434354]]\n",
      "Loop 948 Loss_Train:  [[ 13.60423619]] Loss_Validation:  [[ 10.53453933]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 949 Loss_Train:  [[ 13.60342836]] Loss_Validation:  [[ 10.53473628]]\n",
      "Loop 950 Loss_Train:  [[ 13.60262251]] Loss_Validation:  [[ 10.53493438]]\n",
      "Loop 951 Loss_Train:  [[ 13.60181862]] Loss_Validation:  [[ 10.53513362]]\n",
      "Loop 952 Loss_Train:  [[ 13.60101671]] Loss_Validation:  [[ 10.535334]]\n",
      "Loop 953 Loss_Train:  [[ 13.60021675]] Loss_Validation:  [[ 10.53553551]]\n",
      "Loop 954 Loss_Train:  [[ 13.59941874]] Loss_Validation:  [[ 10.53573814]]\n",
      "Loop 955 Loss_Train:  [[ 13.59862267]] Loss_Validation:  [[ 10.53594187]]\n",
      "Loop 956 Loss_Train:  [[ 13.59782855]] Loss_Validation:  [[ 10.53614671]]\n",
      "Loop 957 Loss_Train:  [[ 13.59703636]] Loss_Validation:  [[ 10.53635265]]\n",
      "Loop 958 Loss_Train:  [[ 13.59624609]] Loss_Validation:  [[ 10.53655968]]\n",
      "Loop 959 Loss_Train:  [[ 13.59545774]] Loss_Validation:  [[ 10.53676778]]\n",
      "Loop 960 Loss_Train:  [[ 13.59467131]] Loss_Validation:  [[ 10.53697696]]\n",
      "Loop 961 Loss_Train:  [[ 13.59388678]] Loss_Validation:  [[ 10.5371872]]\n",
      "Loop 962 Loss_Train:  [[ 13.59310416]] Loss_Validation:  [[ 10.5373985]]\n",
      "Loop 963 Loss_Train:  [[ 13.59232343]] Loss_Validation:  [[ 10.53761085]]\n",
      "Loop 964 Loss_Train:  [[ 13.59154458]] Loss_Validation:  [[ 10.53782424]]\n",
      "Loop 965 Loss_Train:  [[ 13.59076762]] Loss_Validation:  [[ 10.53803867]]\n",
      "Loop 966 Loss_Train:  [[ 13.58999254]] Loss_Validation:  [[ 10.53825412]]\n",
      "Loop 967 Loss_Train:  [[ 13.58921933]] Loss_Validation:  [[ 10.53847059]]\n",
      "Loop 968 Loss_Train:  [[ 13.58844798]] Loss_Validation:  [[ 10.53868807]]\n",
      "Loop 969 Loss_Train:  [[ 13.58767848]] Loss_Validation:  [[ 10.53890656]]\n",
      "Loop 970 Loss_Train:  [[ 13.58691085]] Loss_Validation:  [[ 10.53912604]]\n",
      "Loop 971 Loss_Train:  [[ 13.58614505]] Loss_Validation:  [[ 10.53934652]]\n",
      "Loop 972 Loss_Train:  [[ 13.5853811]] Loss_Validation:  [[ 10.53956797]]\n",
      "Loop 973 Loss_Train:  [[ 13.58461898]] Loss_Validation:  [[ 10.53979041]]\n",
      "Loop 974 Loss_Train:  [[ 13.58385869]] Loss_Validation:  [[ 10.54001381]]\n",
      "Loop 975 Loss_Train:  [[ 13.58310022]] Loss_Validation:  [[ 10.54023817]]\n",
      "Loop 976 Loss_Train:  [[ 13.58234357]] Loss_Validation:  [[ 10.54046349]]\n",
      "Loop 977 Loss_Train:  [[ 13.58158873]] Loss_Validation:  [[ 10.54068975]]\n",
      "Loop 978 Loss_Train:  [[ 13.58083569]] Loss_Validation:  [[ 10.54091696]]\n",
      "Loop 979 Loss_Train:  [[ 13.58008446]] Loss_Validation:  [[ 10.54114509]]\n",
      "Loop 980 Loss_Train:  [[ 13.57933502]] Loss_Validation:  [[ 10.54137416]]\n",
      "Loop 981 Loss_Train:  [[ 13.57858736]] Loss_Validation:  [[ 10.54160414]]\n",
      "Loop 982 Loss_Train:  [[ 13.57784149]] Loss_Validation:  [[ 10.54183504]]\n",
      "Loop 983 Loss_Train:  [[ 13.57709739]] Loss_Validation:  [[ 10.54206684]]\n",
      "Loop 984 Loss_Train:  [[ 13.57635507]] Loss_Validation:  [[ 10.54229955]]\n",
      "Loop 985 Loss_Train:  [[ 13.57561451]] Loss_Validation:  [[ 10.54253314]]\n",
      "Loop 986 Loss_Train:  [[ 13.57487571]] Loss_Validation:  [[ 10.54276762]]\n",
      "Loop 987 Loss_Train:  [[ 13.57413866]] Loss_Validation:  [[ 10.54300298]]\n",
      "Loop 988 Loss_Train:  [[ 13.57340337]] Loss_Validation:  [[ 10.54323922]]\n",
      "Loop 989 Loss_Train:  [[ 13.57266981]] Loss_Validation:  [[ 10.54347632]]\n",
      "Loop 990 Loss_Train:  [[ 13.571938]] Loss_Validation:  [[ 10.54371428]]\n",
      "Loop 991 Loss_Train:  [[ 13.57120791]] Loss_Validation:  [[ 10.54395309]]\n",
      "Loop 992 Loss_Train:  [[ 13.57047955]] Loss_Validation:  [[ 10.54419275]]\n",
      "Loop 993 Loss_Train:  [[ 13.56975292]] Loss_Validation:  [[ 10.54443325]]\n",
      "Loop 994 Loss_Train:  [[ 13.569028]] Loss_Validation:  [[ 10.54467458]]\n",
      "Loop 995 Loss_Train:  [[ 13.56830479]] Loss_Validation:  [[ 10.54491675]]\n",
      "Loop 996 Loss_Train:  [[ 13.56758328]] Loss_Validation:  [[ 10.54515973]]\n",
      "Loop 997 Loss_Train:  [[ 13.56686348]] Loss_Validation:  [[ 10.54540353]]\n",
      "Loop 998 Loss_Train:  [[ 13.56614537]] Loss_Validation:  [[ 10.54564814]]\n",
      "Loop 999 Loss_Train:  [[ 13.56542895]] Loss_Validation:  [[ 10.54589355]]\n",
      "Loop 1000 Loss_Train:  [[ 13.56471421]] Loss_Validation:  [[ 10.54613976]]\n",
      "Loop 1001 Loss_Train:  [[ 13.56400115]] Loss_Validation:  [[ 10.54638676]]\n",
      "Loop 1002 Loss_Train:  [[ 13.56328977]] Loss_Validation:  [[ 10.54663454]]\n",
      "Loop 1003 Loss_Train:  [[ 13.56258005]] Loss_Validation:  [[ 10.5468831]]\n",
      "Loop 1004 Loss_Train:  [[ 13.561872]] Loss_Validation:  [[ 10.54713244]]\n",
      "Loop 1005 Loss_Train:  [[ 13.5611656]] Loss_Validation:  [[ 10.54738254]]\n",
      "Loop 1006 Loss_Train:  [[ 13.56046086]] Loss_Validation:  [[ 10.5476334]]\n",
      "Loop 1007 Loss_Train:  [[ 13.55975777]] Loss_Validation:  [[ 10.54788502]]\n",
      "Loop 1008 Loss_Train:  [[ 13.55905632]] Loss_Validation:  [[ 10.54813739]]\n",
      "Loop 1009 Loss_Train:  [[ 13.55835651]] Loss_Validation:  [[ 10.5483905]]\n",
      "Loop 1010 Loss_Train:  [[ 13.55765833]] Loss_Validation:  [[ 10.54864435]]\n",
      "Loop 1011 Loss_Train:  [[ 13.55696177]] Loss_Validation:  [[ 10.54889892]]\n",
      "Loop 1012 Loss_Train:  [[ 13.55626684]] Loss_Validation:  [[ 10.54915423]]\n",
      "Loop 1013 Loss_Train:  [[ 13.55557353]] Loss_Validation:  [[ 10.54941026]]\n",
      "Loop 1014 Loss_Train:  [[ 13.55488183]] Loss_Validation:  [[ 10.549667]]\n",
      "Loop 1015 Loss_Train:  [[ 13.55419174]] Loss_Validation:  [[ 10.54992445]]\n",
      "Loop 1016 Loss_Train:  [[ 13.55350326]] Loss_Validation:  [[ 10.5501826]]\n",
      "Loop 1017 Loss_Train:  [[ 13.55281637]] Loss_Validation:  [[ 10.55044145]]\n",
      "Loop 1018 Loss_Train:  [[ 13.55213107]] Loss_Validation:  [[ 10.55070099]]\n",
      "Loop 1019 Loss_Train:  [[ 13.55144736]] Loss_Validation:  [[ 10.55096122]]\n",
      "Loop 1020 Loss_Train:  [[ 13.55076524]] Loss_Validation:  [[ 10.55122214]]\n",
      "Loop 1021 Loss_Train:  [[ 13.55008469]] Loss_Validation:  [[ 10.55148372]]\n",
      "Loop 1022 Loss_Train:  [[ 13.54940572]] Loss_Validation:  [[ 10.55174598]]\n",
      "Loop 1023 Loss_Train:  [[ 13.54872832]] Loss_Validation:  [[ 10.55200891]]\n",
      "Loop 1024 Loss_Train:  [[ 13.54805248]] Loss_Validation:  [[ 10.55227249]]\n",
      "Loop 1025 Loss_Train:  [[ 13.54737821]] Loss_Validation:  [[ 10.55253673]]\n",
      "Loop 1026 Loss_Train:  [[ 13.54670548]] Loss_Validation:  [[ 10.55280162]]\n",
      "Loop 1027 Loss_Train:  [[ 13.54603431]] Loss_Validation:  [[ 10.55306715]]\n",
      "Loop 1028 Loss_Train:  [[ 13.54536469]] Loss_Validation:  [[ 10.55333332]]\n",
      "Loop 1029 Loss_Train:  [[ 13.5446966]] Loss_Validation:  [[ 10.55360012]]\n",
      "Loop 1030 Loss_Train:  [[ 13.54403005]] Loss_Validation:  [[ 10.55386756]]\n",
      "Loop 1031 Loss_Train:  [[ 13.54336504]] Loss_Validation:  [[ 10.55413561]]\n",
      "Loop 1032 Loss_Train:  [[ 13.54270155]] Loss_Validation:  [[ 10.55440429]]\n",
      "Loop 1033 Loss_Train:  [[ 13.54203958]] Loss_Validation:  [[ 10.55467358]]\n",
      "Loop 1034 Loss_Train:  [[ 13.54137914]] Loss_Validation:  [[ 10.55494348]]\n",
      "Loop 1035 Loss_Train:  [[ 13.5407202]] Loss_Validation:  [[ 10.55521398]]\n",
      "Loop 1036 Loss_Train:  [[ 13.54006278]] Loss_Validation:  [[ 10.55548508]]\n",
      "Loop 1037 Loss_Train:  [[ 13.53940686]] Loss_Validation:  [[ 10.55575677]]\n",
      "Loop 1038 Loss_Train:  [[ 13.53875244]] Loss_Validation:  [[ 10.55602905]]\n",
      "Loop 1039 Loss_Train:  [[ 13.53809951]] Loss_Validation:  [[ 10.55630191]]\n",
      "Loop 1040 Loss_Train:  [[ 13.53744808]] Loss_Validation:  [[ 10.55657536]]\n",
      "Loop 1041 Loss_Train:  [[ 13.53679813]] Loss_Validation:  [[ 10.55684937]]\n",
      "Loop 1042 Loss_Train:  [[ 13.53614967]] Loss_Validation:  [[ 10.55712396]]\n",
      "Loop 1043 Loss_Train:  [[ 13.53550269]] Loss_Validation:  [[ 10.55739911]]\n",
      "Loop 1044 Loss_Train:  [[ 13.53485718]] Loss_Validation:  [[ 10.55767482]]\n",
      "Loop 1045 Loss_Train:  [[ 13.53421313]] Loss_Validation:  [[ 10.55795109]]\n",
      "Loop 1046 Loss_Train:  [[ 13.53357056]] Loss_Validation:  [[ 10.5582279]]\n",
      "Loop 1047 Loss_Train:  [[ 13.53292944]] Loss_Validation:  [[ 10.55850526]]\n",
      "Loop 1048 Loss_Train:  [[ 13.53228978]] Loss_Validation:  [[ 10.55878316]]\n",
      "Loop 1049 Loss_Train:  [[ 13.53165157]] Loss_Validation:  [[ 10.5590616]]\n",
      "Loop 1050 Loss_Train:  [[ 13.53101481]] Loss_Validation:  [[ 10.55934057]]\n",
      "Loop 1051 Loss_Train:  [[ 13.5303795]] Loss_Validation:  [[ 10.55962007]]\n",
      "Loop 1052 Loss_Train:  [[ 13.52974562]] Loss_Validation:  [[ 10.55990009]]\n",
      "Loop 1053 Loss_Train:  [[ 13.52911318]] Loss_Validation:  [[ 10.56018062]]\n",
      "Loop 1054 Loss_Train:  [[ 13.52848217]] Loss_Validation:  [[ 10.56046167]]\n",
      "Loop 1055 Loss_Train:  [[ 13.52785259]] Loss_Validation:  [[ 10.56074323]]\n",
      "Loop 1056 Loss_Train:  [[ 13.52722443]] Loss_Validation:  [[ 10.5610253]]\n",
      "Loop 1057 Loss_Train:  [[ 13.52659769]] Loss_Validation:  [[ 10.56130786]]\n",
      "Loop 1058 Loss_Train:  [[ 13.52597236]] Loss_Validation:  [[ 10.56159093]]\n",
      "Loop 1059 Loss_Train:  [[ 13.52534845]] Loss_Validation:  [[ 10.56187448]]\n",
      "Loop 1060 Loss_Train:  [[ 13.52472594]] Loss_Validation:  [[ 10.56215852]]\n",
      "Loop 1061 Loss_Train:  [[ 13.52410483]] Loss_Validation:  [[ 10.56244304]]\n",
      "Loop 1062 Loss_Train:  [[ 13.52348512]] Loss_Validation:  [[ 10.56272804]]\n",
      "Loop 1063 Loss_Train:  [[ 13.5228668]] Loss_Validation:  [[ 10.56301352]]\n",
      "Loop 1064 Loss_Train:  [[ 13.52224988]] Loss_Validation:  [[ 10.56329946]]\n",
      "Loop 1065 Loss_Train:  [[ 13.52163434]] Loss_Validation:  [[ 10.56358587]]\n",
      "Loop 1066 Loss_Train:  [[ 13.52102018]] Loss_Validation:  [[ 10.56387275]]\n",
      "Loop 1067 Loss_Train:  [[ 13.5204074]] Loss_Validation:  [[ 10.56416008]]\n",
      "Loop 1068 Loss_Train:  [[ 13.51979599]] Loss_Validation:  [[ 10.56444786]]\n",
      "Loop 1069 Loss_Train:  [[ 13.51918596]] Loss_Validation:  [[ 10.5647361]]\n",
      "Loop 1070 Loss_Train:  [[ 13.51857729]] Loss_Validation:  [[ 10.56502478]]\n",
      "Loop 1071 Loss_Train:  [[ 13.51796998]] Loss_Validation:  [[ 10.5653139]]\n",
      "Loop 1072 Loss_Train:  [[ 13.51736403]] Loss_Validation:  [[ 10.56560345]]\n",
      "Loop 1073 Loss_Train:  [[ 13.51675944]] Loss_Validation:  [[ 10.56589345]]\n",
      "Loop 1074 Loss_Train:  [[ 13.51615619]] Loss_Validation:  [[ 10.56618387]]\n",
      "Loop 1075 Loss_Train:  [[ 13.5155543]] Loss_Validation:  [[ 10.56647471]]\n",
      "Loop 1076 Loss_Train:  [[ 13.51495374]] Loss_Validation:  [[ 10.56676598]]\n",
      "Loop 1077 Loss_Train:  [[ 13.51435453]] Loss_Validation:  [[ 10.56705766]]\n",
      "Loop 1078 Loss_Train:  [[ 13.51375665]] Loss_Validation:  [[ 10.56734976]]\n",
      "Loop 1079 Loss_Train:  [[ 13.5131601]] Loss_Validation:  [[ 10.56764226]]\n",
      "Loop 1080 Loss_Train:  [[ 13.51256488]] Loss_Validation:  [[ 10.56793518]]\n",
      "Loop 1081 Loss_Train:  [[ 13.51197099]] Loss_Validation:  [[ 10.56822849]]\n",
      "Loop 1082 Loss_Train:  [[ 13.51137841]] Loss_Validation:  [[ 10.5685222]]\n",
      "Loop 1083 Loss_Train:  [[ 13.51078715]] Loss_Validation:  [[ 10.56881631]]\n",
      "Loop 1084 Loss_Train:  [[ 13.5101972]] Loss_Validation:  [[ 10.5691108]]\n",
      "Loop 1085 Loss_Train:  [[ 13.50960856]] Loss_Validation:  [[ 10.56940569]]\n",
      "Loop 1086 Loss_Train:  [[ 13.50902123]] Loss_Validation:  [[ 10.56970095]]\n",
      "Loop 1087 Loss_Train:  [[ 13.5084352]] Loss_Validation:  [[ 10.5699966]]\n",
      "Loop 1088 Loss_Train:  [[ 13.50785047]] Loss_Validation:  [[ 10.57029262]]\n",
      "Loop 1089 Loss_Train:  [[ 13.50726703]] Loss_Validation:  [[ 10.57058901]]\n",
      "Loop 1090 Loss_Train:  [[ 13.50668488]] Loss_Validation:  [[ 10.57088577]]\n",
      "Loop 1091 Loss_Train:  [[ 13.50610402]] Loss_Validation:  [[ 10.5711829]]\n",
      "Loop 1092 Loss_Train:  [[ 13.50552444]] Loss_Validation:  [[ 10.57148039]]\n",
      "Loop 1093 Loss_Train:  [[ 13.50494614]] Loss_Validation:  [[ 10.57177823]]\n",
      "Loop 1094 Loss_Train:  [[ 13.50436912]] Loss_Validation:  [[ 10.57207643]]\n",
      "Loop 1095 Loss_Train:  [[ 13.50379337]] Loss_Validation:  [[ 10.57237498]]\n",
      "Loop 1096 Loss_Train:  [[ 13.50321889]] Loss_Validation:  [[ 10.57267387]]\n",
      "Loop 1097 Loss_Train:  [[ 13.50264567]] Loss_Validation:  [[ 10.57297311]]\n",
      "Loop 1098 Loss_Train:  [[ 13.50207372]] Loss_Validation:  [[ 10.57327269]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1099 Loss_Train:  [[ 13.50150302]] Loss_Validation:  [[ 10.5735726]]\n",
      "Loop 1100 Loss_Train:  [[ 13.50093358]] Loss_Validation:  [[ 10.57387285]]\n",
      "Loop 1101 Loss_Train:  [[ 13.50036539]] Loss_Validation:  [[ 10.57417343]]\n",
      "Loop 1102 Loss_Train:  [[ 13.49979845]] Loss_Validation:  [[ 10.57447433]]\n",
      "Loop 1103 Loss_Train:  [[ 13.49923275]] Loss_Validation:  [[ 10.57477556]]\n",
      "Loop 1104 Loss_Train:  [[ 13.4986683]] Loss_Validation:  [[ 10.5750771]]\n",
      "Loop 1105 Loss_Train:  [[ 13.49810508]] Loss_Validation:  [[ 10.57537896]]\n",
      "Loop 1106 Loss_Train:  [[ 13.4975431]] Loss_Validation:  [[ 10.57568114]]\n",
      "Loop 1107 Loss_Train:  [[ 13.49698234]] Loss_Validation:  [[ 10.57598362]]\n",
      "Loop 1108 Loss_Train:  [[ 13.49642282]] Loss_Validation:  [[ 10.57628641]]\n",
      "Loop 1109 Loss_Train:  [[ 13.49586452]] Loss_Validation:  [[ 10.5765895]]\n",
      "Loop 1110 Loss_Train:  [[ 13.49530743]] Loss_Validation:  [[ 10.57689289]]\n",
      "Loop 1111 Loss_Train:  [[ 13.49475157]] Loss_Validation:  [[ 10.57719658]]\n",
      "Loop 1112 Loss_Train:  [[ 13.49419692]] Loss_Validation:  [[ 10.57750056]]\n",
      "Loop 1113 Loss_Train:  [[ 13.49364348]] Loss_Validation:  [[ 10.57780483]]\n",
      "Loop 1114 Loss_Train:  [[ 13.49309125]] Loss_Validation:  [[ 10.57810939]]\n",
      "Loop 1115 Loss_Train:  [[ 13.49254022]] Loss_Validation:  [[ 10.57841423]]\n",
      "Loop 1116 Loss_Train:  [[ 13.49199039]] Loss_Validation:  [[ 10.57871935]]\n",
      "Loop 1117 Loss_Train:  [[ 13.49144176]] Loss_Validation:  [[ 10.57902475]]\n",
      "Loop 1118 Loss_Train:  [[ 13.49089432]] Loss_Validation:  [[ 10.57933043]]\n",
      "Loop 1119 Loss_Train:  [[ 13.49034807]] Loss_Validation:  [[ 10.57963637]]\n",
      "Loop 1120 Loss_Train:  [[ 13.48980301]] Loss_Validation:  [[ 10.57994258]]\n",
      "Loop 1121 Loss_Train:  [[ 13.48925914]] Loss_Validation:  [[ 10.58024906]]\n",
      "Loop 1122 Loss_Train:  [[ 13.48871644]] Loss_Validation:  [[ 10.5805558]]\n",
      "Loop 1123 Loss_Train:  [[ 13.48817492]] Loss_Validation:  [[ 10.5808628]]\n",
      "Loop 1124 Loss_Train:  [[ 13.48763458]] Loss_Validation:  [[ 10.58117005]]\n",
      "Loop 1125 Loss_Train:  [[ 13.48709541]] Loss_Validation:  [[ 10.58147756]]\n",
      "Loop 1126 Loss_Train:  [[ 13.48655741]] Loss_Validation:  [[ 10.58178532]]\n",
      "Loop 1127 Loss_Train:  [[ 13.48602057]] Loss_Validation:  [[ 10.58209332]]\n",
      "Loop 1128 Loss_Train:  [[ 13.48548489]] Loss_Validation:  [[ 10.58240157]]\n",
      "Loop 1129 Loss_Train:  [[ 13.48495037]] Loss_Validation:  [[ 10.58271006]]\n",
      "Loop 1130 Loss_Train:  [[ 13.48441701]] Loss_Validation:  [[ 10.58301879]]\n",
      "Loop 1131 Loss_Train:  [[ 13.4838848]] Loss_Validation:  [[ 10.58332775]]\n",
      "Loop 1132 Loss_Train:  [[ 13.48335374]] Loss_Validation:  [[ 10.58363695]]\n",
      "Loop 1133 Loss_Train:  [[ 13.48282382]] Loss_Validation:  [[ 10.58394637]]\n",
      "Loop 1134 Loss_Train:  [[ 13.48229505]] Loss_Validation:  [[ 10.58425603]]\n",
      "Loop 1135 Loss_Train:  [[ 13.48176742]] Loss_Validation:  [[ 10.5845659]]\n",
      "Loop 1136 Loss_Train:  [[ 13.48124092]] Loss_Validation:  [[ 10.584876]]\n",
      "Loop 1137 Loss_Train:  [[ 13.48071556]] Loss_Validation:  [[ 10.58518632]]\n",
      "Loop 1138 Loss_Train:  [[ 13.48019133]] Loss_Validation:  [[ 10.58549685]]\n",
      "Loop 1139 Loss_Train:  [[ 13.47966823]] Loss_Validation:  [[ 10.5858076]]\n",
      "Loop 1140 Loss_Train:  [[ 13.47914625]] Loss_Validation:  [[ 10.58611855]]\n",
      "Loop 1141 Loss_Train:  [[ 13.47862539]] Loss_Validation:  [[ 10.58642972]]\n",
      "Loop 1142 Loss_Train:  [[ 13.47810565]] Loss_Validation:  [[ 10.58674108]]\n",
      "Loop 1143 Loss_Train:  [[ 13.47758703]] Loss_Validation:  [[ 10.58705265]]\n",
      "Loop 1144 Loss_Train:  [[ 13.47706952]] Loss_Validation:  [[ 10.58736442]]\n",
      "Loop 1145 Loss_Train:  [[ 13.47655312]] Loss_Validation:  [[ 10.58767639]]\n",
      "Loop 1146 Loss_Train:  [[ 13.47603782]] Loss_Validation:  [[ 10.58798855]]\n",
      "Loop 1147 Loss_Train:  [[ 13.47552363]] Loss_Validation:  [[ 10.5883009]]\n",
      "Loop 1148 Loss_Train:  [[ 13.47501054]] Loss_Validation:  [[ 10.58861344]]\n",
      "Loop 1149 Loss_Train:  [[ 13.47449855]] Loss_Validation:  [[ 10.58892617]]\n",
      "Loop 1150 Loss_Train:  [[ 13.47398765]] Loss_Validation:  [[ 10.58923908]]\n",
      "Loop 1151 Loss_Train:  [[ 13.47347784]] Loss_Validation:  [[ 10.58955217]]\n",
      "Loop 1152 Loss_Train:  [[ 13.47296913]] Loss_Validation:  [[ 10.58986544]]\n",
      "Loop 1153 Loss_Train:  [[ 13.4724615]] Loss_Validation:  [[ 10.59017889]]\n",
      "Loop 1154 Loss_Train:  [[ 13.47195495]] Loss_Validation:  [[ 10.59049251]]\n",
      "Loop 1155 Loss_Train:  [[ 13.47144948]] Loss_Validation:  [[ 10.5908063]]\n",
      "Loop 1156 Loss_Train:  [[ 13.47094509]] Loss_Validation:  [[ 10.59112026]]\n",
      "Loop 1157 Loss_Train:  [[ 13.47044178]] Loss_Validation:  [[ 10.59143439]]\n",
      "Loop 1158 Loss_Train:  [[ 13.46993953]] Loss_Validation:  [[ 10.59174868]]\n",
      "Loop 1159 Loss_Train:  [[ 13.46943836]] Loss_Validation:  [[ 10.59206313]]\n",
      "Loop 1160 Loss_Train:  [[ 13.46893825]] Loss_Validation:  [[ 10.59237774]]\n",
      "Loop 1161 Loss_Train:  [[ 13.46843921]] Loss_Validation:  [[ 10.5926925]]\n",
      "Loop 1162 Loss_Train:  [[ 13.46794122]] Loss_Validation:  [[ 10.59300742]]\n",
      "Loop 1163 Loss_Train:  [[ 13.46744429]] Loss_Validation:  [[ 10.59332249]]\n",
      "Loop 1164 Loss_Train:  [[ 13.46694842]] Loss_Validation:  [[ 10.59363771]]\n",
      "Loop 1165 Loss_Train:  [[ 13.4664536]] Loss_Validation:  [[ 10.59395308]]\n",
      "Loop 1166 Loss_Train:  [[ 13.46595983]] Loss_Validation:  [[ 10.59426859]]\n",
      "Loop 1167 Loss_Train:  [[ 13.46546711]] Loss_Validation:  [[ 10.59458424]]\n",
      "Loop 1168 Loss_Train:  [[ 13.46497543]] Loss_Validation:  [[ 10.59490004]]\n",
      "Loop 1169 Loss_Train:  [[ 13.46448479]] Loss_Validation:  [[ 10.59521597]]\n",
      "Loop 1170 Loss_Train:  [[ 13.46399519]] Loss_Validation:  [[ 10.59553203]]\n",
      "Loop 1171 Loss_Train:  [[ 13.46350663]] Loss_Validation:  [[ 10.59584823]]\n",
      "Loop 1172 Loss_Train:  [[ 13.46301909]] Loss_Validation:  [[ 10.59616456]]\n",
      "Loop 1173 Loss_Train:  [[ 13.46253259]] Loss_Validation:  [[ 10.59648101]]\n",
      "Loop 1174 Loss_Train:  [[ 13.46204712]] Loss_Validation:  [[ 10.5967976]]\n",
      "Loop 1175 Loss_Train:  [[ 13.46156267]] Loss_Validation:  [[ 10.5971143]]\n",
      "Loop 1176 Loss_Train:  [[ 13.46107924]] Loss_Validation:  [[ 10.59743113]]\n",
      "Loop 1177 Loss_Train:  [[ 13.46059684]] Loss_Validation:  [[ 10.59774808]]\n",
      "Loop 1178 Loss_Train:  [[ 13.46011545]] Loss_Validation:  [[ 10.59806514]]\n",
      "Loop 1179 Loss_Train:  [[ 13.45963507]] Loss_Validation:  [[ 10.59838232]]\n",
      "Loop 1180 Loss_Train:  [[ 13.4591557]] Loss_Validation:  [[ 10.59869961]]\n",
      "Loop 1181 Loss_Train:  [[ 13.45867735]] Loss_Validation:  [[ 10.59901701]]\n",
      "Loop 1182 Loss_Train:  [[ 13.4582]] Loss_Validation:  [[ 10.59933453]]\n",
      "Loop 1183 Loss_Train:  [[ 13.45772365]] Loss_Validation:  [[ 10.59965214]]\n",
      "Loop 1184 Loss_Train:  [[ 13.45724831]] Loss_Validation:  [[ 10.59996986]]\n",
      "Loop 1185 Loss_Train:  [[ 13.45677396]] Loss_Validation:  [[ 10.60028769]]\n",
      "Loop 1186 Loss_Train:  [[ 13.45630061]] Loss_Validation:  [[ 10.60060561]]\n",
      "Loop 1187 Loss_Train:  [[ 13.45582825]] Loss_Validation:  [[ 10.60092363]]\n",
      "Loop 1188 Loss_Train:  [[ 13.45535689]] Loss_Validation:  [[ 10.60124175]]\n",
      "Loop 1189 Loss_Train:  [[ 13.45488651]] Loss_Validation:  [[ 10.60155996]]\n",
      "Loop 1190 Loss_Train:  [[ 13.45441712]] Loss_Validation:  [[ 10.60187826]]\n",
      "Loop 1191 Loss_Train:  [[ 13.45394871]] Loss_Validation:  [[ 10.60219666]]\n",
      "Loop 1192 Loss_Train:  [[ 13.45348128]] Loss_Validation:  [[ 10.60251514]]\n",
      "Loop 1193 Loss_Train:  [[ 13.45301483]] Loss_Validation:  [[ 10.6028337]]\n",
      "Loop 1194 Loss_Train:  [[ 13.45254936]] Loss_Validation:  [[ 10.60315235]]\n",
      "Loop 1195 Loss_Train:  [[ 13.45208485]] Loss_Validation:  [[ 10.60347108]]\n",
      "Loop 1196 Loss_Train:  [[ 13.45162132]] Loss_Validation:  [[ 10.60378989]]\n",
      "Loop 1197 Loss_Train:  [[ 13.45115876]] Loss_Validation:  [[ 10.60410878]]\n",
      "Loop 1198 Loss_Train:  [[ 13.45069716]] Loss_Validation:  [[ 10.60442774]]\n",
      "Loop 1199 Loss_Train:  [[ 13.45023653]] Loss_Validation:  [[ 10.60474678]]\n",
      "Loop 1200 Loss_Train:  [[ 13.44977685]] Loss_Validation:  [[ 10.60506589]]\n",
      "Loop 1201 Loss_Train:  [[ 13.44931814]] Loss_Validation:  [[ 10.60538507]]\n",
      "Loop 1202 Loss_Train:  [[ 13.44886038]] Loss_Validation:  [[ 10.60570432]]\n",
      "Loop 1203 Loss_Train:  [[ 13.44840357]] Loss_Validation:  [[ 10.60602363]]\n",
      "Loop 1204 Loss_Train:  [[ 13.44794771]] Loss_Validation:  [[ 10.60634301]]\n",
      "Loop 1205 Loss_Train:  [[ 13.4474928]] Loss_Validation:  [[ 10.60666245]]\n",
      "Loop 1206 Loss_Train:  [[ 13.44703884]] Loss_Validation:  [[ 10.60698195]]\n",
      "Loop 1207 Loss_Train:  [[ 13.44658582]] Loss_Validation:  [[ 10.60730151]]\n",
      "Loop 1208 Loss_Train:  [[ 13.44613375]] Loss_Validation:  [[ 10.60762113]]\n",
      "Loop 1209 Loss_Train:  [[ 13.44568261]] Loss_Validation:  [[ 10.6079408]]\n",
      "Loop 1210 Loss_Train:  [[ 13.44523241]] Loss_Validation:  [[ 10.60826052]]\n",
      "Loop 1211 Loss_Train:  [[ 13.44478314]] Loss_Validation:  [[ 10.6085803]]\n",
      "Loop 1212 Loss_Train:  [[ 13.4443348]] Loss_Validation:  [[ 10.60890012]]\n",
      "Loop 1213 Loss_Train:  [[ 13.44388739]] Loss_Validation:  [[ 10.60921999]]\n",
      "Loop 1214 Loss_Train:  [[ 13.44344091]] Loss_Validation:  [[ 10.60953991]]\n",
      "Loop 1215 Loss_Train:  [[ 13.44299536]] Loss_Validation:  [[ 10.60985988]]\n",
      "Loop 1216 Loss_Train:  [[ 13.44255072]] Loss_Validation:  [[ 10.61017988]]\n",
      "Loop 1217 Loss_Train:  [[ 13.44210701]] Loss_Validation:  [[ 10.61049993]]\n",
      "Loop 1218 Loss_Train:  [[ 13.44166421]] Loss_Validation:  [[ 10.61082001]]\n",
      "Loop 1219 Loss_Train:  [[ 13.44122233]] Loss_Validation:  [[ 10.61114013]]\n",
      "Loop 1220 Loss_Train:  [[ 13.44078136]] Loss_Validation:  [[ 10.61146029]]\n",
      "Loop 1221 Loss_Train:  [[ 13.44034131]] Loss_Validation:  [[ 10.61178048]]\n",
      "Loop 1222 Loss_Train:  [[ 13.43990216]] Loss_Validation:  [[ 10.6121007]]\n",
      "Loop 1223 Loss_Train:  [[ 13.43946391]] Loss_Validation:  [[ 10.61242096]]\n",
      "Loop 1224 Loss_Train:  [[ 13.43902657]] Loss_Validation:  [[ 10.61274124]]\n",
      "Loop 1225 Loss_Train:  [[ 13.43859014]] Loss_Validation:  [[ 10.61306155]]\n",
      "Loop 1226 Loss_Train:  [[ 13.4381546]] Loss_Validation:  [[ 10.61338188]]\n",
      "Loop 1227 Loss_Train:  [[ 13.43771995]] Loss_Validation:  [[ 10.61370224]]\n",
      "Loop 1228 Loss_Train:  [[ 13.43728621]] Loss_Validation:  [[ 10.61402262]]\n",
      "Loop 1229 Loss_Train:  [[ 13.43685335]] Loss_Validation:  [[ 10.61434302]]\n",
      "Loop 1230 Loss_Train:  [[ 13.43642139]] Loss_Validation:  [[ 10.61466344]]\n",
      "Loop 1231 Loss_Train:  [[ 13.43599031]] Loss_Validation:  [[ 10.61498387]]\n",
      "Loop 1232 Loss_Train:  [[ 13.43556012]] Loss_Validation:  [[ 10.61530432]]\n",
      "Loop 1233 Loss_Train:  [[ 13.43513081]] Loss_Validation:  [[ 10.61562479]]\n",
      "Loop 1234 Loss_Train:  [[ 13.43470239]] Loss_Validation:  [[ 10.61594527]]\n",
      "Loop 1235 Loss_Train:  [[ 13.43427484]] Loss_Validation:  [[ 10.61626576]]\n",
      "Loop 1236 Loss_Train:  [[ 13.43384817]] Loss_Validation:  [[ 10.61658625]]\n",
      "Loop 1237 Loss_Train:  [[ 13.43342237]] Loss_Validation:  [[ 10.61690676]]\n",
      "Loop 1238 Loss_Train:  [[ 13.43299745]] Loss_Validation:  [[ 10.61722727]]\n",
      "Loop 1239 Loss_Train:  [[ 13.4325734]] Loss_Validation:  [[ 10.61754779]]\n",
      "Loop 1240 Loss_Train:  [[ 13.43215021]] Loss_Validation:  [[ 10.61786831]]\n",
      "Loop 1241 Loss_Train:  [[ 13.43172789]] Loss_Validation:  [[ 10.61818883]]\n",
      "Loop 1242 Loss_Train:  [[ 13.43130644]] Loss_Validation:  [[ 10.61850935]]\n",
      "Loop 1243 Loss_Train:  [[ 13.43088585]] Loss_Validation:  [[ 10.61882987]]\n",
      "Loop 1244 Loss_Train:  [[ 13.43046611]] Loss_Validation:  [[ 10.61915038]]\n",
      "Loop 1245 Loss_Train:  [[ 13.43004724]] Loss_Validation:  [[ 10.6194709]]\n",
      "Loop 1246 Loss_Train:  [[ 13.42962922]] Loss_Validation:  [[ 10.6197914]]\n",
      "Loop 1247 Loss_Train:  [[ 13.42921205]] Loss_Validation:  [[ 10.6201119]]\n",
      "Loop 1248 Loss_Train:  [[ 13.42879573]] Loss_Validation:  [[ 10.62043239]]\n",
      "Loop 1249 Loss_Train:  [[ 13.42838027]] Loss_Validation:  [[ 10.62075287]]\n",
      "Loop 1250 Loss_Train:  [[ 13.42796565]] Loss_Validation:  [[ 10.62107334]]\n",
      "Loop 1251 Loss_Train:  [[ 13.42755187]] Loss_Validation:  [[ 10.62139379]]\n",
      "Loop 1252 Loss_Train:  [[ 13.42713894]] Loss_Validation:  [[ 10.62171423]]\n",
      "Loop 1253 Loss_Train:  [[ 13.42672685]] Loss_Validation:  [[ 10.62203466]]\n",
      "Loop 1254 Loss_Train:  [[ 13.42631559]] Loss_Validation:  [[ 10.62235506]]\n",
      "Loop 1255 Loss_Train:  [[ 13.42590518]] Loss_Validation:  [[ 10.62267545]]\n",
      "Loop 1256 Loss_Train:  [[ 13.42549559]] Loss_Validation:  [[ 10.62299582]]\n",
      "Loop 1257 Loss_Train:  [[ 13.42508684]] Loss_Validation:  [[ 10.62331616]]\n",
      "Loop 1258 Loss_Train:  [[ 13.42467892]] Loss_Validation:  [[ 10.62363649]]\n",
      "Loop 1259 Loss_Train:  [[ 13.42427183]] Loss_Validation:  [[ 10.62395679]]\n",
      "Loop 1260 Loss_Train:  [[ 13.42386557]] Loss_Validation:  [[ 10.62427706]]\n",
      "Loop 1261 Loss_Train:  [[ 13.42346013]] Loss_Validation:  [[ 10.62459731]]\n",
      "Loop 1262 Loss_Train:  [[ 13.42305551]] Loss_Validation:  [[ 10.62491752]]\n",
      "Loop 1263 Loss_Train:  [[ 13.42265171]] Loss_Validation:  [[ 10.62523771]]\n",
      "Loop 1264 Loss_Train:  [[ 13.42224873]] Loss_Validation:  [[ 10.62555787]]\n",
      "Loop 1265 Loss_Train:  [[ 13.42184656]] Loss_Validation:  [[ 10.62587799]]\n",
      "Loop 1266 Loss_Train:  [[ 13.42144521]] Loss_Validation:  [[ 10.62619808]]\n",
      "Loop 1267 Loss_Train:  [[ 13.42104468]] Loss_Validation:  [[ 10.62651814]]\n",
      "Loop 1268 Loss_Train:  [[ 13.42064495]] Loss_Validation:  [[ 10.62683816]]\n",
      "Loop 1269 Loss_Train:  [[ 13.42024603]] Loss_Validation:  [[ 10.62715814]]\n",
      "Loop 1270 Loss_Train:  [[ 13.41984792]] Loss_Validation:  [[ 10.62747808]]\n",
      "Loop 1271 Loss_Train:  [[ 13.41945061]] Loss_Validation:  [[ 10.62779799]]\n",
      "Loop 1272 Loss_Train:  [[ 13.4190541]] Loss_Validation:  [[ 10.62811785]]\n",
      "Loop 1273 Loss_Train:  [[ 13.41865839]] Loss_Validation:  [[ 10.62843767]]\n",
      "Loop 1274 Loss_Train:  [[ 13.41826349]] Loss_Validation:  [[ 10.62875744]]\n",
      "Loop 1275 Loss_Train:  [[ 13.41786937]] Loss_Validation:  [[ 10.62907717]]\n",
      "Loop 1276 Loss_Train:  [[ 13.41747606]] Loss_Validation:  [[ 10.62939686]]\n",
      "Loop 1277 Loss_Train:  [[ 13.41708353]] Loss_Validation:  [[ 10.62971649]]\n",
      "Loop 1278 Loss_Train:  [[ 13.4166918]] Loss_Validation:  [[ 10.63003608]]\n",
      "Loop 1279 Loss_Train:  [[ 13.41630086]] Loss_Validation:  [[ 10.63035562]]\n",
      "Loop 1280 Loss_Train:  [[ 13.4159107]] Loss_Validation:  [[ 10.6306751]]\n",
      "Loop 1281 Loss_Train:  [[ 13.41552132]] Loss_Validation:  [[ 10.63099454]]\n",
      "Loop 1282 Loss_Train:  [[ 13.41513273]] Loss_Validation:  [[ 10.63131392]]\n",
      "Loop 1283 Loss_Train:  [[ 13.41474493]] Loss_Validation:  [[ 10.63163324]]\n",
      "Loop 1284 Loss_Train:  [[ 13.4143579]] Loss_Validation:  [[ 10.63195251]]\n",
      "Loop 1285 Loss_Train:  [[ 13.41397164]] Loss_Validation:  [[ 10.63227173]]\n",
      "Loop 1286 Loss_Train:  [[ 13.41358617]] Loss_Validation:  [[ 10.63259088]]\n",
      "Loop 1287 Loss_Train:  [[ 13.41320146]] Loss_Validation:  [[ 10.63290998]]\n",
      "Loop 1288 Loss_Train:  [[ 13.41281753]] Loss_Validation:  [[ 10.63322901]]\n",
      "Loop 1289 Loss_Train:  [[ 13.41243437]] Loss_Validation:  [[ 10.63354798]]\n",
      "Loop 1290 Loss_Train:  [[ 13.41205198]] Loss_Validation:  [[ 10.63386689]]\n",
      "Loop 1291 Loss_Train:  [[ 13.41167035]] Loss_Validation:  [[ 10.63418574]]\n",
      "Loop 1292 Loss_Train:  [[ 13.41128949]] Loss_Validation:  [[ 10.63450452]]\n",
      "Loop 1293 Loss_Train:  [[ 13.41090939]] Loss_Validation:  [[ 10.63482323]]\n",
      "Loop 1294 Loss_Train:  [[ 13.41053005]] Loss_Validation:  [[ 10.63514188]]\n",
      "Loop 1295 Loss_Train:  [[ 13.41015146]] Loss_Validation:  [[ 10.63546046]]\n",
      "Loop 1296 Loss_Train:  [[ 13.40977364]] Loss_Validation:  [[ 10.63577897]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1297 Loss_Train:  [[ 13.40939657]] Loss_Validation:  [[ 10.63609741]]\n",
      "Loop 1298 Loss_Train:  [[ 13.40902026]] Loss_Validation:  [[ 10.63641578]]\n",
      "Loop 1299 Loss_Train:  [[ 13.40864469]] Loss_Validation:  [[ 10.63673407]]\n",
      "Loop 1300 Loss_Train:  [[ 13.40826988]] Loss_Validation:  [[ 10.63705229]]\n",
      "Loop 1301 Loss_Train:  [[ 13.40789581]] Loss_Validation:  [[ 10.63737044]]\n",
      "Loop 1302 Loss_Train:  [[ 13.40752249]] Loss_Validation:  [[ 10.63768851]]\n",
      "Loop 1303 Loss_Train:  [[ 13.40714992]] Loss_Validation:  [[ 10.6380065]]\n",
      "Loop 1304 Loss_Train:  [[ 13.40677808]] Loss_Validation:  [[ 10.63832442]]\n",
      "Loop 1305 Loss_Train:  [[ 13.40640699]] Loss_Validation:  [[ 10.63864226]]\n",
      "Loop 1306 Loss_Train:  [[ 13.40603664]] Loss_Validation:  [[ 10.63896001]]\n",
      "Loop 1307 Loss_Train:  [[ 13.40566702]] Loss_Validation:  [[ 10.63927769]]\n",
      "Loop 1308 Loss_Train:  [[ 13.40529814]] Loss_Validation:  [[ 10.63959528]]\n",
      "Loop 1309 Loss_Train:  [[ 13.40493]] Loss_Validation:  [[ 10.63991279]]\n",
      "Loop 1310 Loss_Train:  [[ 13.40456258]] Loss_Validation:  [[ 10.64023022]]\n",
      "Loop 1311 Loss_Train:  [[ 13.4041959]] Loss_Validation:  [[ 10.64054756]]\n",
      "Loop 1312 Loss_Train:  [[ 13.40382994]] Loss_Validation:  [[ 10.64086482]]\n",
      "Loop 1313 Loss_Train:  [[ 13.40346472]] Loss_Validation:  [[ 10.64118199]]\n",
      "Loop 1314 Loss_Train:  [[ 13.40310021]] Loss_Validation:  [[ 10.64149907]]\n",
      "Loop 1315 Loss_Train:  [[ 13.40273643]] Loss_Validation:  [[ 10.64181606]]\n",
      "Loop 1316 Loss_Train:  [[ 13.40237337]] Loss_Validation:  [[ 10.64213296]]\n",
      "Loop 1317 Loss_Train:  [[ 13.40201104]] Loss_Validation:  [[ 10.64244977]]\n",
      "Loop 1318 Loss_Train:  [[ 13.40164942]] Loss_Validation:  [[ 10.64276649]]\n",
      "Loop 1319 Loss_Train:  [[ 13.40128851]] Loss_Validation:  [[ 10.64308312]]\n",
      "Loop 1320 Loss_Train:  [[ 13.40092832]] Loss_Validation:  [[ 10.64339965]]\n",
      "Loop 1321 Loss_Train:  [[ 13.40056885]] Loss_Validation:  [[ 10.64371609]]\n",
      "Loop 1322 Loss_Train:  [[ 13.40021009]] Loss_Validation:  [[ 10.64403243]]\n",
      "Loop 1323 Loss_Train:  [[ 13.39985203]] Loss_Validation:  [[ 10.64434868]]\n",
      "Loop 1324 Loss_Train:  [[ 13.39949469]] Loss_Validation:  [[ 10.64466482]]\n",
      "Loop 1325 Loss_Train:  [[ 13.39913805]] Loss_Validation:  [[ 10.64498087]]\n",
      "Loop 1326 Loss_Train:  [[ 13.39878211]] Loss_Validation:  [[ 10.64529683]]\n",
      "Loop 1327 Loss_Train:  [[ 13.39842688]] Loss_Validation:  [[ 10.64561268]]\n",
      "Loop 1328 Loss_Train:  [[ 13.39807235]] Loss_Validation:  [[ 10.64592843]]\n",
      "Loop 1329 Loss_Train:  [[ 13.39771852]] Loss_Validation:  [[ 10.64624408]]\n",
      "Loop 1330 Loss_Train:  [[ 13.39736539]] Loss_Validation:  [[ 10.64655962]]\n",
      "Loop 1331 Loss_Train:  [[ 13.39701295]] Loss_Validation:  [[ 10.64687506]]\n",
      "Loop 1332 Loss_Train:  [[ 13.39666121]] Loss_Validation:  [[ 10.6471904]]\n",
      "Loop 1333 Loss_Train:  [[ 13.39631016]] Loss_Validation:  [[ 10.64750563]]\n",
      "Loop 1334 Loss_Train:  [[ 13.39595981]] Loss_Validation:  [[ 10.64782076]]\n",
      "Loop 1335 Loss_Train:  [[ 13.39561014]] Loss_Validation:  [[ 10.64813578]]\n",
      "Loop 1336 Loss_Train:  [[ 13.39526117]] Loss_Validation:  [[ 10.64845069]]\n",
      "Loop 1337 Loss_Train:  [[ 13.39491288]] Loss_Validation:  [[ 10.64876549]]\n",
      "Loop 1338 Loss_Train:  [[ 13.39456527]] Loss_Validation:  [[ 10.64908018]]\n",
      "Loop 1339 Loss_Train:  [[ 13.39421835]] Loss_Validation:  [[ 10.64939477]]\n",
      "Loop 1340 Loss_Train:  [[ 13.39387211]] Loss_Validation:  [[ 10.64970924]]\n",
      "Loop 1341 Loss_Train:  [[ 13.39352655]] Loss_Validation:  [[ 10.6500236]]\n",
      "Loop 1342 Loss_Train:  [[ 13.39318167]] Loss_Validation:  [[ 10.65033784]]\n",
      "Loop 1343 Loss_Train:  [[ 13.39283747]] Loss_Validation:  [[ 10.65065198]]\n",
      "Loop 1344 Loss_Train:  [[ 13.39249394]] Loss_Validation:  [[ 10.65096599]]\n",
      "Loop 1345 Loss_Train:  [[ 13.39215109]] Loss_Validation:  [[ 10.6512799]]\n",
      "Loop 1346 Loss_Train:  [[ 13.3918089]] Loss_Validation:  [[ 10.65159368]]\n",
      "Loop 1347 Loss_Train:  [[ 13.39146739]] Loss_Validation:  [[ 10.65190735]]\n",
      "Loop 1348 Loss_Train:  [[ 13.39112655]] Loss_Validation:  [[ 10.6522209]]\n",
      "Loop 1349 Loss_Train:  [[ 13.39078638]] Loss_Validation:  [[ 10.65253434]]\n",
      "Loop 1350 Loss_Train:  [[ 13.39044687]] Loss_Validation:  [[ 10.65284765]]\n",
      "Loop 1351 Loss_Train:  [[ 13.39010803]] Loss_Validation:  [[ 10.65316085]]\n",
      "Loop 1352 Loss_Train:  [[ 13.38976985]] Loss_Validation:  [[ 10.65347392]]\n",
      "Loop 1353 Loss_Train:  [[ 13.38943233]] Loss_Validation:  [[ 10.65378687]]\n",
      "Loop 1354 Loss_Train:  [[ 13.38909548]] Loss_Validation:  [[ 10.6540997]]\n",
      "Loop 1355 Loss_Train:  [[ 13.38875928]] Loss_Validation:  [[ 10.65441241]]\n",
      "Loop 1356 Loss_Train:  [[ 13.38842374]] Loss_Validation:  [[ 10.65472499]]\n",
      "Loop 1357 Loss_Train:  [[ 13.38808885]] Loss_Validation:  [[ 10.65503745]]\n",
      "Loop 1358 Loss_Train:  [[ 13.38775462]] Loss_Validation:  [[ 10.65534979]]\n",
      "Loop 1359 Loss_Train:  [[ 13.38742104]] Loss_Validation:  [[ 10.65566199]]\n",
      "Loop 1360 Loss_Train:  [[ 13.38708811]] Loss_Validation:  [[ 10.65597407]]\n",
      "Loop 1361 Loss_Train:  [[ 13.38675583]] Loss_Validation:  [[ 10.65628603]]\n",
      "Loop 1362 Loss_Train:  [[ 13.3864242]] Loss_Validation:  [[ 10.65659785]]\n",
      "Loop 1363 Loss_Train:  [[ 13.38609321]] Loss_Validation:  [[ 10.65690955]]\n",
      "Loop 1364 Loss_Train:  [[ 13.38576287]] Loss_Validation:  [[ 10.65722112]]\n",
      "Loop 1365 Loss_Train:  [[ 13.38543318]] Loss_Validation:  [[ 10.65753255]]\n",
      "Loop 1366 Loss_Train:  [[ 13.38510412]] Loss_Validation:  [[ 10.65784386]]\n",
      "Loop 1367 Loss_Train:  [[ 13.38477571]] Loss_Validation:  [[ 10.65815504]]\n",
      "Loop 1368 Loss_Train:  [[ 13.38444793]] Loss_Validation:  [[ 10.65846608]]\n",
      "Loop 1369 Loss_Train:  [[ 13.38412079]] Loss_Validation:  [[ 10.65877699]]\n",
      "Loop 1370 Loss_Train:  [[ 13.38379429]] Loss_Validation:  [[ 10.65908776]]\n",
      "Loop 1371 Loss_Train:  [[ 13.38346842]] Loss_Validation:  [[ 10.6593984]]\n",
      "Loop 1372 Loss_Train:  [[ 13.38314319]] Loss_Validation:  [[ 10.65970891]]\n",
      "Loop 1373 Loss_Train:  [[ 13.38281859]] Loss_Validation:  [[ 10.66001928]]\n",
      "Loop 1374 Loss_Train:  [[ 13.38249462]] Loss_Validation:  [[ 10.66032952]]\n",
      "Loop 1375 Loss_Train:  [[ 13.38217127]] Loss_Validation:  [[ 10.66063961]]\n",
      "Loop 1376 Loss_Train:  [[ 13.38184856]] Loss_Validation:  [[ 10.66094957]]\n",
      "Loop 1377 Loss_Train:  [[ 13.38152647]] Loss_Validation:  [[ 10.66125939]]\n",
      "Loop 1378 Loss_Train:  [[ 13.381205]] Loss_Validation:  [[ 10.66156908]]\n",
      "Loop 1379 Loss_Train:  [[ 13.38088416]] Loss_Validation:  [[ 10.66187862]]\n",
      "Loop 1380 Loss_Train:  [[ 13.38056394]] Loss_Validation:  [[ 10.66218802]]\n",
      "Loop 1381 Loss_Train:  [[ 13.38024434]] Loss_Validation:  [[ 10.66249729]]\n",
      "Loop 1382 Loss_Train:  [[ 13.37992535]] Loss_Validation:  [[ 10.66280641]]\n",
      "Loop 1383 Loss_Train:  [[ 13.37960699]] Loss_Validation:  [[ 10.66311539]]\n",
      "Loop 1384 Loss_Train:  [[ 13.37928924]] Loss_Validation:  [[ 10.66342422]]\n",
      "Loop 1385 Loss_Train:  [[ 13.37897211]] Loss_Validation:  [[ 10.66373291]]\n",
      "Loop 1386 Loss_Train:  [[ 13.37865559]] Loss_Validation:  [[ 10.66404146]]\n",
      "Loop 1387 Loss_Train:  [[ 13.37833968]] Loss_Validation:  [[ 10.66434987]]\n",
      "Loop 1388 Loss_Train:  [[ 13.37802438]] Loss_Validation:  [[ 10.66465813]]\n",
      "Loop 1389 Loss_Train:  [[ 13.37770969]] Loss_Validation:  [[ 10.66496624]]\n",
      "Loop 1390 Loss_Train:  [[ 13.37739561]] Loss_Validation:  [[ 10.66527421]]\n",
      "Loop 1391 Loss_Train:  [[ 13.37708213]] Loss_Validation:  [[ 10.66558203]]\n",
      "Loop 1392 Loss_Train:  [[ 13.37676926]] Loss_Validation:  [[ 10.6658897]]\n",
      "Loop 1393 Loss_Train:  [[ 13.37645699]] Loss_Validation:  [[ 10.66619723]]\n",
      "Loop 1394 Loss_Train:  [[ 13.37614533]] Loss_Validation:  [[ 10.66650461]]\n",
      "Loop 1395 Loss_Train:  [[ 13.37583426]] Loss_Validation:  [[ 10.66681183]]\n",
      "Loop 1396 Loss_Train:  [[ 13.3755238]] Loss_Validation:  [[ 10.66711891]]\n",
      "Loop 1397 Loss_Train:  [[ 13.37521393]] Loss_Validation:  [[ 10.66742584]]\n",
      "Loop 1398 Loss_Train:  [[ 13.37490466]] Loss_Validation:  [[ 10.66773262]]\n",
      "Loop 1399 Loss_Train:  [[ 13.37459598]] Loss_Validation:  [[ 10.66803924]]\n",
      "Loop 1400 Loss_Train:  [[ 13.3742879]] Loss_Validation:  [[ 10.66834571]]\n",
      "Loop 1401 Loss_Train:  [[ 13.37398041]] Loss_Validation:  [[ 10.66865204]]\n",
      "Loop 1402 Loss_Train:  [[ 13.37367351]] Loss_Validation:  [[ 10.6689582]]\n",
      "Loop 1403 Loss_Train:  [[ 13.3733672]] Loss_Validation:  [[ 10.66926422]]\n",
      "Loop 1404 Loss_Train:  [[ 13.37306149]] Loss_Validation:  [[ 10.66957008]]\n",
      "Loop 1405 Loss_Train:  [[ 13.37275635]] Loss_Validation:  [[ 10.66987578]]\n",
      "Loop 1406 Loss_Train:  [[ 13.37245181]] Loss_Validation:  [[ 10.67018133]]\n",
      "Loop 1407 Loss_Train:  [[ 13.37214784]] Loss_Validation:  [[ 10.67048673]]\n",
      "Loop 1408 Loss_Train:  [[ 13.37184447]] Loss_Validation:  [[ 10.67079197]]\n",
      "Loop 1409 Loss_Train:  [[ 13.37154167]] Loss_Validation:  [[ 10.67109705]]\n",
      "Loop 1410 Loss_Train:  [[ 13.37123945]] Loss_Validation:  [[ 10.67140198]]\n",
      "Loop 1411 Loss_Train:  [[ 13.37093782]] Loss_Validation:  [[ 10.67170674]]\n",
      "Loop 1412 Loss_Train:  [[ 13.37063676]] Loss_Validation:  [[ 10.67201135]]\n",
      "Loop 1413 Loss_Train:  [[ 13.37033628]] Loss_Validation:  [[ 10.6723158]]\n",
      "Loop 1414 Loss_Train:  [[ 13.37003637]] Loss_Validation:  [[ 10.67262009]]\n",
      "Loop 1415 Loss_Train:  [[ 13.36973704]] Loss_Validation:  [[ 10.67292422]]\n",
      "Loop 1416 Loss_Train:  [[ 13.36943828]] Loss_Validation:  [[ 10.6732282]]\n",
      "Loop 1417 Loss_Train:  [[ 13.36914009]] Loss_Validation:  [[ 10.67353201]]\n",
      "Loop 1418 Loss_Train:  [[ 13.36884247]] Loss_Validation:  [[ 10.67383565]]\n",
      "Loop 1419 Loss_Train:  [[ 13.36854542]] Loss_Validation:  [[ 10.67413914]]\n",
      "Loop 1420 Loss_Train:  [[ 13.36824894]] Loss_Validation:  [[ 10.67444247]]\n",
      "Loop 1421 Loss_Train:  [[ 13.36795303]] Loss_Validation:  [[ 10.67474563]]\n",
      "Loop 1422 Loss_Train:  [[ 13.36765768]] Loss_Validation:  [[ 10.67504863]]\n",
      "Loop 1423 Loss_Train:  [[ 13.36736289]] Loss_Validation:  [[ 10.67535147]]\n",
      "Loop 1424 Loss_Train:  [[ 13.36706867]] Loss_Validation:  [[ 10.67565414]]\n",
      "Loop 1425 Loss_Train:  [[ 13.36677501]] Loss_Validation:  [[ 10.67595665]]\n",
      "Loop 1426 Loss_Train:  [[ 13.36648191]] Loss_Validation:  [[ 10.67625899]]\n",
      "Loop 1427 Loss_Train:  [[ 13.36618937]] Loss_Validation:  [[ 10.67656117]]\n",
      "Loop 1428 Loss_Train:  [[ 13.36589738]] Loss_Validation:  [[ 10.67686318]]\n",
      "Loop 1429 Loss_Train:  [[ 13.36560595]] Loss_Validation:  [[ 10.67716502]]\n",
      "Loop 1430 Loss_Train:  [[ 13.36531508]] Loss_Validation:  [[ 10.6774667]]\n",
      "Loop 1431 Loss_Train:  [[ 13.36502476]] Loss_Validation:  [[ 10.67776821]]\n",
      "Loop 1432 Loss_Train:  [[ 13.36473499]] Loss_Validation:  [[ 10.67806956]]\n",
      "Loop 1433 Loss_Train:  [[ 13.36444578]] Loss_Validation:  [[ 10.67837073]]\n",
      "Loop 1434 Loss_Train:  [[ 13.36415711]] Loss_Validation:  [[ 10.67867174]]\n",
      "Loop 1435 Loss_Train:  [[ 13.363869]] Loss_Validation:  [[ 10.67897258]]\n",
      "Loop 1436 Loss_Train:  [[ 13.36358143]] Loss_Validation:  [[ 10.67927325]]\n",
      "Loop 1437 Loss_Train:  [[ 13.36329441]] Loss_Validation:  [[ 10.67957375]]\n",
      "Loop 1438 Loss_Train:  [[ 13.36300793]] Loss_Validation:  [[ 10.67987408]]\n",
      "Loop 1439 Loss_Train:  [[ 13.362722]] Loss_Validation:  [[ 10.68017424]]\n",
      "Loop 1440 Loss_Train:  [[ 13.36243661]] Loss_Validation:  [[ 10.68047423]]\n",
      "Loop 1441 Loss_Train:  [[ 13.36215176]] Loss_Validation:  [[ 10.68077404]]\n",
      "Loop 1442 Loss_Train:  [[ 13.36186745]] Loss_Validation:  [[ 10.68107369]]\n",
      "Loop 1443 Loss_Train:  [[ 13.36158369]] Loss_Validation:  [[ 10.68137316]]\n",
      "Loop 1444 Loss_Train:  [[ 13.36130046]] Loss_Validation:  [[ 10.68167246]]\n",
      "Loop 1445 Loss_Train:  [[ 13.36101776]] Loss_Validation:  [[ 10.68197159]]\n",
      "Loop 1446 Loss_Train:  [[ 13.36073561]] Loss_Validation:  [[ 10.68227054]]\n",
      "Loop 1447 Loss_Train:  [[ 13.36045398]] Loss_Validation:  [[ 10.68256932]]\n",
      "Loop 1448 Loss_Train:  [[ 13.3601729]] Loss_Validation:  [[ 10.68286793]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1449 Loss_Train:  [[ 13.35989234]] Loss_Validation:  [[ 10.68316636]]\n",
      "Loop 1450 Loss_Train:  [[ 13.35961231]] Loss_Validation:  [[ 10.68346462]]\n",
      "Loop 1451 Loss_Train:  [[ 13.35933282]] Loss_Validation:  [[ 10.6837627]]\n",
      "Loop 1452 Loss_Train:  [[ 13.35905385]] Loss_Validation:  [[ 10.68406061]]\n",
      "Loop 1453 Loss_Train:  [[ 13.35877541]] Loss_Validation:  [[ 10.68435834]]\n",
      "Loop 1454 Loss_Train:  [[ 13.3584975]] Loss_Validation:  [[ 10.68465589]]\n",
      "Loop 1455 Loss_Train:  [[ 13.35822011]] Loss_Validation:  [[ 10.68495327]]\n",
      "Loop 1456 Loss_Train:  [[ 13.35794324]] Loss_Validation:  [[ 10.68525047]]\n",
      "Loop 1457 Loss_Train:  [[ 13.3576669]] Loss_Validation:  [[ 10.68554749]]\n",
      "Loop 1458 Loss_Train:  [[ 13.35739108]] Loss_Validation:  [[ 10.68584434]]\n",
      "Loop 1459 Loss_Train:  [[ 13.35711578]] Loss_Validation:  [[ 10.68614101]]\n",
      "Loop 1460 Loss_Train:  [[ 13.356841]] Loss_Validation:  [[ 10.6864375]]\n",
      "Loop 1461 Loss_Train:  [[ 13.35656674]] Loss_Validation:  [[ 10.68673381]]\n",
      "Loop 1462 Loss_Train:  [[ 13.356293]] Loss_Validation:  [[ 10.68702994]]\n",
      "Loop 1463 Loss_Train:  [[ 13.35601977]] Loss_Validation:  [[ 10.68732589]]\n",
      "Loop 1464 Loss_Train:  [[ 13.35574705]] Loss_Validation:  [[ 10.68762166]]\n",
      "Loop 1465 Loss_Train:  [[ 13.35547485]] Loss_Validation:  [[ 10.68791725]]\n",
      "Loop 1466 Loss_Train:  [[ 13.35520317]] Loss_Validation:  [[ 10.68821266]]\n",
      "Loop 1467 Loss_Train:  [[ 13.35493199]] Loss_Validation:  [[ 10.68850789]]\n",
      "Loop 1468 Loss_Train:  [[ 13.35466132]] Loss_Validation:  [[ 10.68880294]]\n",
      "Loop 1469 Loss_Train:  [[ 13.35439117]] Loss_Validation:  [[ 10.68909781]]\n",
      "Loop 1470 Loss_Train:  [[ 13.35412152]] Loss_Validation:  [[ 10.68939249]]\n",
      "Loop 1471 Loss_Train:  [[ 13.35385238]] Loss_Validation:  [[ 10.689687]]\n",
      "Loop 1472 Loss_Train:  [[ 13.35358374]] Loss_Validation:  [[ 10.68998132]]\n",
      "Loop 1473 Loss_Train:  [[ 13.35331561]] Loss_Validation:  [[ 10.69027546]]\n",
      "Loop 1474 Loss_Train:  [[ 13.35304799]] Loss_Validation:  [[ 10.69056941]]\n",
      "Loop 1475 Loss_Train:  [[ 13.35278086]] Loss_Validation:  [[ 10.69086318]]\n",
      "Loop 1476 Loss_Train:  [[ 13.35251424]] Loss_Validation:  [[ 10.69115677]]\n",
      "Loop 1477 Loss_Train:  [[ 13.35224812]] Loss_Validation:  [[ 10.69145018]]\n",
      "Loop 1478 Loss_Train:  [[ 13.35198249]] Loss_Validation:  [[ 10.6917434]]\n",
      "Loop 1479 Loss_Train:  [[ 13.35171737]] Loss_Validation:  [[ 10.69203643]]\n",
      "Loop 1480 Loss_Train:  [[ 13.35145274]] Loss_Validation:  [[ 10.69232928]]\n",
      "Loop 1481 Loss_Train:  [[ 13.35118861]] Loss_Validation:  [[ 10.69262195]]\n",
      "Loop 1482 Loss_Train:  [[ 13.35092497]] Loss_Validation:  [[ 10.69291443]]\n",
      "Loop 1483 Loss_Train:  [[ 13.35066183]] Loss_Validation:  [[ 10.69320672]]\n",
      "Loop 1484 Loss_Train:  [[ 13.35039918]] Loss_Validation:  [[ 10.69349883]]\n",
      "Loop 1485 Loss_Train:  [[ 13.35013702]] Loss_Validation:  [[ 10.69379075]]\n",
      "Loop 1486 Loss_Train:  [[ 13.34987535]] Loss_Validation:  [[ 10.69408249]]\n",
      "Loop 1487 Loss_Train:  [[ 13.34961418]] Loss_Validation:  [[ 10.69437404]]\n",
      "Loop 1488 Loss_Train:  [[ 13.34935349]] Loss_Validation:  [[ 10.6946654]]\n",
      "Loop 1489 Loss_Train:  [[ 13.34909328]] Loss_Validation:  [[ 10.69495658]]\n",
      "Loop 1490 Loss_Train:  [[ 13.34883357]] Loss_Validation:  [[ 10.69524756]]\n",
      "Loop 1491 Loss_Train:  [[ 13.34857434]] Loss_Validation:  [[ 10.69553836]]\n",
      "Loop 1492 Loss_Train:  [[ 13.34831559]] Loss_Validation:  [[ 10.69582897]]\n",
      "Loop 1493 Loss_Train:  [[ 13.34805733]] Loss_Validation:  [[ 10.69611939]]\n",
      "Loop 1494 Loss_Train:  [[ 13.34779955]] Loss_Validation:  [[ 10.69640963]]\n",
      "Loop 1495 Loss_Train:  [[ 13.34754225]] Loss_Validation:  [[ 10.69669967]]\n",
      "Loop 1496 Loss_Train:  [[ 13.34728543]] Loss_Validation:  [[ 10.69698953]]\n",
      "Loop 1497 Loss_Train:  [[ 13.34702909]] Loss_Validation:  [[ 10.6972792]]\n",
      "Loop 1498 Loss_Train:  [[ 13.34677323]] Loss_Validation:  [[ 10.69756867]]\n",
      "Loop 1499 Loss_Train:  [[ 13.34651785]] Loss_Validation:  [[ 10.69785796]]\n",
      "Loop 1500 Loss_Train:  [[ 13.34626294]] Loss_Validation:  [[ 10.69814705]]\n",
      "Loop 1501 Loss_Train:  [[ 13.3460085]] Loss_Validation:  [[ 10.69843596]]\n",
      "Loop 1502 Loss_Train:  [[ 13.34575454]] Loss_Validation:  [[ 10.69872468]]\n",
      "Loop 1503 Loss_Train:  [[ 13.34550106]] Loss_Validation:  [[ 10.6990132]]\n",
      "Loop 1504 Loss_Train:  [[ 13.34524804]] Loss_Validation:  [[ 10.69930153]]\n",
      "Loop 1505 Loss_Train:  [[ 13.3449955]] Loss_Validation:  [[ 10.69958968]]\n",
      "Loop 1506 Loss_Train:  [[ 13.34474342]] Loss_Validation:  [[ 10.69987763]]\n",
      "Loop 1507 Loss_Train:  [[ 13.34449182]] Loss_Validation:  [[ 10.70016538]]\n",
      "Loop 1508 Loss_Train:  [[ 13.34424068]] Loss_Validation:  [[ 10.70045295]]\n",
      "Loop 1509 Loss_Train:  [[ 13.34399001]] Loss_Validation:  [[ 10.70074032]]\n",
      "Loop 1510 Loss_Train:  [[ 13.3437398]] Loss_Validation:  [[ 10.70102751]]\n",
      "Loop 1511 Loss_Train:  [[ 13.34349006]] Loss_Validation:  [[ 10.70131449]]\n",
      "Loop 1512 Loss_Train:  [[ 13.34324079]] Loss_Validation:  [[ 10.70160129]]\n",
      "Loop 1513 Loss_Train:  [[ 13.34299197]] Loss_Validation:  [[ 10.70188789]]\n",
      "Loop 1514 Loss_Train:  [[ 13.34274362]] Loss_Validation:  [[ 10.7021743]]\n",
      "Loop 1515 Loss_Train:  [[ 13.34249573]] Loss_Validation:  [[ 10.70246052]]\n",
      "Loop 1516 Loss_Train:  [[ 13.3422483]] Loss_Validation:  [[ 10.70274654]]\n",
      "Loop 1517 Loss_Train:  [[ 13.34200133]] Loss_Validation:  [[ 10.70303237]]\n",
      "Loop 1518 Loss_Train:  [[ 13.34175481]] Loss_Validation:  [[ 10.703318]]\n",
      "Loop 1519 Loss_Train:  [[ 13.34150876]] Loss_Validation:  [[ 10.70360344]]\n",
      "Loop 1520 Loss_Train:  [[ 13.34126316]] Loss_Validation:  [[ 10.70388869]]\n",
      "Loop 1521 Loss_Train:  [[ 13.34101801]] Loss_Validation:  [[ 10.70417374]]\n",
      "Loop 1522 Loss_Train:  [[ 13.34077332]] Loss_Validation:  [[ 10.70445859]]\n",
      "Loop 1523 Loss_Train:  [[ 13.34052908]] Loss_Validation:  [[ 10.70474325]]\n",
      "Loop 1524 Loss_Train:  [[ 13.34028529]] Loss_Validation:  [[ 10.70502772]]\n",
      "Loop 1525 Loss_Train:  [[ 13.34004196]] Loss_Validation:  [[ 10.70531198]]\n",
      "Loop 1526 Loss_Train:  [[ 13.33979907]] Loss_Validation:  [[ 10.70559606]]\n",
      "Loop 1527 Loss_Train:  [[ 13.33955663]] Loss_Validation:  [[ 10.70587993]]\n",
      "Loop 1528 Loss_Train:  [[ 13.33931464]] Loss_Validation:  [[ 10.70616362]]\n",
      "Loop 1529 Loss_Train:  [[ 13.3390731]] Loss_Validation:  [[ 10.7064471]]\n",
      "Loop 1530 Loss_Train:  [[ 13.33883201]] Loss_Validation:  [[ 10.70673039]]\n",
      "Loop 1531 Loss_Train:  [[ 13.33859136]] Loss_Validation:  [[ 10.70701348]]\n",
      "Loop 1532 Loss_Train:  [[ 13.33835115]] Loss_Validation:  [[ 10.70729637]]\n",
      "Loop 1533 Loss_Train:  [[ 13.33811139]] Loss_Validation:  [[ 10.70757907]]\n",
      "Loop 1534 Loss_Train:  [[ 13.33787207]] Loss_Validation:  [[ 10.70786157]]\n",
      "Loop 1535 Loss_Train:  [[ 13.33763319]] Loss_Validation:  [[ 10.70814387]]\n",
      "Loop 1536 Loss_Train:  [[ 13.33739476]] Loss_Validation:  [[ 10.70842598]]\n",
      "Loop 1537 Loss_Train:  [[ 13.33715676]] Loss_Validation:  [[ 10.70870789]]\n",
      "Loop 1538 Loss_Train:  [[ 13.3369192]] Loss_Validation:  [[ 10.7089896]]\n",
      "Loop 1539 Loss_Train:  [[ 13.33668208]] Loss_Validation:  [[ 10.70927111]]\n",
      "Loop 1540 Loss_Train:  [[ 13.33644539]] Loss_Validation:  [[ 10.70955242]]\n",
      "Loop 1541 Loss_Train:  [[ 13.33620915]] Loss_Validation:  [[ 10.70983354]]\n",
      "Loop 1542 Loss_Train:  [[ 13.33597333]] Loss_Validation:  [[ 10.71011446]]\n",
      "Loop 1543 Loss_Train:  [[ 13.33573795]] Loss_Validation:  [[ 10.71039517]]\n",
      "Loop 1544 Loss_Train:  [[ 13.33550301]] Loss_Validation:  [[ 10.71067569]]\n",
      "Loop 1545 Loss_Train:  [[ 13.33526849]] Loss_Validation:  [[ 10.71095601]]\n",
      "Loop 1546 Loss_Train:  [[ 13.33503441]] Loss_Validation:  [[ 10.71123613]]\n",
      "Loop 1547 Loss_Train:  [[ 13.33480076]] Loss_Validation:  [[ 10.71151606]]\n",
      "Loop 1548 Loss_Train:  [[ 13.33456754]] Loss_Validation:  [[ 10.71179578]]\n",
      "Loop 1549 Loss_Train:  [[ 13.33433474]] Loss_Validation:  [[ 10.7120753]]\n",
      "Loop 1550 Loss_Train:  [[ 13.33410238]] Loss_Validation:  [[ 10.71235463]]\n",
      "Loop 1551 Loss_Train:  [[ 13.33387044]] Loss_Validation:  [[ 10.71263375]]\n",
      "Loop 1552 Loss_Train:  [[ 13.33363893]] Loss_Validation:  [[ 10.71291267]]\n",
      "Loop 1553 Loss_Train:  [[ 13.33340784]] Loss_Validation:  [[ 10.7131914]]\n",
      "Loop 1554 Loss_Train:  [[ 13.33317717]] Loss_Validation:  [[ 10.71346992]]\n",
      "Loop 1555 Loss_Train:  [[ 13.33294693]] Loss_Validation:  [[ 10.71374824]]\n",
      "Loop 1556 Loss_Train:  [[ 13.33271711]] Loss_Validation:  [[ 10.71402636]]\n",
      "Loop 1557 Loss_Train:  [[ 13.33248772]] Loss_Validation:  [[ 10.71430429]]\n",
      "Loop 1558 Loss_Train:  [[ 13.33225874]] Loss_Validation:  [[ 10.71458201]]\n",
      "Loop 1559 Loss_Train:  [[ 13.33203018]] Loss_Validation:  [[ 10.71485953]]\n",
      "Loop 1560 Loss_Train:  [[ 13.33180204]] Loss_Validation:  [[ 10.71513685]]\n",
      "Loop 1561 Loss_Train:  [[ 13.33157432]] Loss_Validation:  [[ 10.71541396]]\n",
      "Loop 1562 Loss_Train:  [[ 13.33134702]] Loss_Validation:  [[ 10.71569088]]\n",
      "Loop 1563 Loss_Train:  [[ 13.33112013]] Loss_Validation:  [[ 10.71596759]]\n",
      "Loop 1564 Loss_Train:  [[ 13.33089366]] Loss_Validation:  [[ 10.71624411]]\n",
      "Loop 1565 Loss_Train:  [[ 13.3306676]] Loss_Validation:  [[ 10.71652042]]\n",
      "Loop 1566 Loss_Train:  [[ 13.33044196]] Loss_Validation:  [[ 10.71679653]]\n",
      "Loop 1567 Loss_Train:  [[ 13.33021673]] Loss_Validation:  [[ 10.71707244]]\n",
      "Loop 1568 Loss_Train:  [[ 13.32999191]] Loss_Validation:  [[ 10.71734814]]\n",
      "Loop 1569 Loss_Train:  [[ 13.3297675]] Loss_Validation:  [[ 10.71762365]]\n",
      "Loop 1570 Loss_Train:  [[ 13.3295435]] Loss_Validation:  [[ 10.71789895]]\n",
      "Loop 1571 Loss_Train:  [[ 13.32931991]] Loss_Validation:  [[ 10.71817405]]\n",
      "Loop 1572 Loss_Train:  [[ 13.32909673]] Loss_Validation:  [[ 10.71844895]]\n",
      "Loop 1573 Loss_Train:  [[ 13.32887396]] Loss_Validation:  [[ 10.71872364]]\n",
      "Loop 1574 Loss_Train:  [[ 13.32865159]] Loss_Validation:  [[ 10.71899814]]\n",
      "Loop 1575 Loss_Train:  [[ 13.32842963]] Loss_Validation:  [[ 10.71927243]]\n",
      "Loop 1576 Loss_Train:  [[ 13.32820807]] Loss_Validation:  [[ 10.71954651]]\n",
      "Loop 1577 Loss_Train:  [[ 13.32798692]] Loss_Validation:  [[ 10.7198204]]\n",
      "Loop 1578 Loss_Train:  [[ 13.32776617]] Loss_Validation:  [[ 10.72009408]]\n",
      "Loop 1579 Loss_Train:  [[ 13.32754583]] Loss_Validation:  [[ 10.72036756]]\n",
      "Loop 1580 Loss_Train:  [[ 13.32732588]] Loss_Validation:  [[ 10.72064083]]\n",
      "Loop 1581 Loss_Train:  [[ 13.32710634]] Loss_Validation:  [[ 10.7209139]]\n",
      "Loop 1582 Loss_Train:  [[ 13.32688719]] Loss_Validation:  [[ 10.72118677]]\n",
      "Loop 1583 Loss_Train:  [[ 13.32666845]] Loss_Validation:  [[ 10.72145943]]\n",
      "Loop 1584 Loss_Train:  [[ 13.3264501]] Loss_Validation:  [[ 10.72173189]]\n",
      "Loop 1585 Loss_Train:  [[ 13.32623215]] Loss_Validation:  [[ 10.72200415]]\n",
      "Loop 1586 Loss_Train:  [[ 13.3260146]] Loss_Validation:  [[ 10.72227621]]\n",
      "Loop 1587 Loss_Train:  [[ 13.32579744]] Loss_Validation:  [[ 10.72254806]]\n",
      "Loop 1588 Loss_Train:  [[ 13.32558068]] Loss_Validation:  [[ 10.7228197]]\n",
      "Loop 1589 Loss_Train:  [[ 13.32536431]] Loss_Validation:  [[ 10.72309114]]\n",
      "Loop 1590 Loss_Train:  [[ 13.32514834]] Loss_Validation:  [[ 10.72336238]]\n",
      "Loop 1591 Loss_Train:  [[ 13.32493275]] Loss_Validation:  [[ 10.72363342]]\n",
      "Loop 1592 Loss_Train:  [[ 13.32471756]] Loss_Validation:  [[ 10.72390425]]\n",
      "Loop 1593 Loss_Train:  [[ 13.32450276]] Loss_Validation:  [[ 10.72417487]]\n",
      "Loop 1594 Loss_Train:  [[ 13.32428835]] Loss_Validation:  [[ 10.72444529]]\n",
      "Loop 1595 Loss_Train:  [[ 13.32407433]] Loss_Validation:  [[ 10.72471551]]\n",
      "Loop 1596 Loss_Train:  [[ 13.3238607]] Loss_Validation:  [[ 10.72498552]]\n",
      "Loop 1597 Loss_Train:  [[ 13.32364745]] Loss_Validation:  [[ 10.72525533]]\n",
      "Loop 1598 Loss_Train:  [[ 13.32343459]] Loss_Validation:  [[ 10.72552493]]\n",
      "Loop 1599 Loss_Train:  [[ 13.32322212]] Loss_Validation:  [[ 10.72579433]]\n",
      "Loop 1600 Loss_Train:  [[ 13.32301003]] Loss_Validation:  [[ 10.72606352]]\n",
      "Loop 1601 Loss_Train:  [[ 13.32279833]] Loss_Validation:  [[ 10.72633251]]\n",
      "Loop 1602 Loss_Train:  [[ 13.32258701]] Loss_Validation:  [[ 10.7266013]]\n",
      "Loop 1603 Loss_Train:  [[ 13.32237608]] Loss_Validation:  [[ 10.72686988]]\n",
      "Loop 1604 Loss_Train:  [[ 13.32216552]] Loss_Validation:  [[ 10.72713825]]\n",
      "Loop 1605 Loss_Train:  [[ 13.32195535]] Loss_Validation:  [[ 10.72740642]]\n",
      "Loop 1606 Loss_Train:  [[ 13.32174556]] Loss_Validation:  [[ 10.72767438]]\n",
      "Loop 1607 Loss_Train:  [[ 13.32153614]] Loss_Validation:  [[ 10.72794214]]\n",
      "Loop 1608 Loss_Train:  [[ 13.32132711]] Loss_Validation:  [[ 10.7282097]]\n",
      "Loop 1609 Loss_Train:  [[ 13.32111845]] Loss_Validation:  [[ 10.72847705]]\n",
      "Loop 1610 Loss_Train:  [[ 13.32091017]] Loss_Validation:  [[ 10.72874419]]\n",
      "Loop 1611 Loss_Train:  [[ 13.32070227]] Loss_Validation:  [[ 10.72901113]]\n",
      "Loop 1612 Loss_Train:  [[ 13.32049474]] Loss_Validation:  [[ 10.72927786]]\n",
      "Loop 1613 Loss_Train:  [[ 13.32028759]] Loss_Validation:  [[ 10.72954439]]\n",
      "Loop 1614 Loss_Train:  [[ 13.32008081]] Loss_Validation:  [[ 10.72981071]]\n",
      "Loop 1615 Loss_Train:  [[ 13.31987441]] Loss_Validation:  [[ 10.73007682]]\n",
      "Loop 1616 Loss_Train:  [[ 13.31966838]] Loss_Validation:  [[ 10.73034274]]\n",
      "Loop 1617 Loss_Train:  [[ 13.31946272]] Loss_Validation:  [[ 10.73060844]]\n",
      "Loop 1618 Loss_Train:  [[ 13.31925743]] Loss_Validation:  [[ 10.73087394]]\n",
      "Loop 1619 Loss_Train:  [[ 13.31905251]] Loss_Validation:  [[ 10.73113923]]\n",
      "Loop 1620 Loss_Train:  [[ 13.31884796]] Loss_Validation:  [[ 10.73140432]]\n",
      "Loop 1621 Loss_Train:  [[ 13.31864378]] Loss_Validation:  [[ 10.7316692]]\n",
      "Loop 1622 Loss_Train:  [[ 13.31843997]] Loss_Validation:  [[ 10.73193388]]\n",
      "Loop 1623 Loss_Train:  [[ 13.31823653]] Loss_Validation:  [[ 10.73219835]]\n",
      "Loop 1624 Loss_Train:  [[ 13.31803345]] Loss_Validation:  [[ 10.73246261]]\n",
      "Loop 1625 Loss_Train:  [[ 13.31783074]] Loss_Validation:  [[ 10.73272667]]\n",
      "Loop 1626 Loss_Train:  [[ 13.31762839]] Loss_Validation:  [[ 10.73299053]]\n",
      "Loop 1627 Loss_Train:  [[ 13.31742641]] Loss_Validation:  [[ 10.73325417]]\n",
      "Loop 1628 Loss_Train:  [[ 13.31722479]] Loss_Validation:  [[ 10.73351761]]\n",
      "Loop 1629 Loss_Train:  [[ 13.31702353]] Loss_Validation:  [[ 10.73378085]]\n",
      "Loop 1630 Loss_Train:  [[ 13.31682264]] Loss_Validation:  [[ 10.73404388]]\n",
      "Loop 1631 Loss_Train:  [[ 13.3166221]] Loss_Validation:  [[ 10.7343067]]\n",
      "Loop 1632 Loss_Train:  [[ 13.31642193]] Loss_Validation:  [[ 10.73456932]]\n",
      "Loop 1633 Loss_Train:  [[ 13.31622212]] Loss_Validation:  [[ 10.73483173]]\n",
      "Loop 1634 Loss_Train:  [[ 13.31602266]] Loss_Validation:  [[ 10.73509393]]\n",
      "Loop 1635 Loss_Train:  [[ 13.31582357]] Loss_Validation:  [[ 10.73535593]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1636 Loss_Train:  [[ 13.31562483]] Loss_Validation:  [[ 10.73561772]]\n",
      "Loop 1637 Loss_Train:  [[ 13.31542645]] Loss_Validation:  [[ 10.73587931]]\n",
      "Loop 1638 Loss_Train:  [[ 13.31522843]] Loss_Validation:  [[ 10.73614068]]\n",
      "Loop 1639 Loss_Train:  [[ 13.31503076]] Loss_Validation:  [[ 10.73640186]]\n",
      "Loop 1640 Loss_Train:  [[ 13.31483344]] Loss_Validation:  [[ 10.73666282]]\n",
      "Loop 1641 Loss_Train:  [[ 13.31463648]] Loss_Validation:  [[ 10.73692359]]\n",
      "Loop 1642 Loss_Train:  [[ 13.31443988]] Loss_Validation:  [[ 10.73718414]]\n",
      "Loop 1643 Loss_Train:  [[ 13.31424362]] Loss_Validation:  [[ 10.73744449]]\n",
      "Loop 1644 Loss_Train:  [[ 13.31404772]] Loss_Validation:  [[ 10.73770463]]\n",
      "Loop 1645 Loss_Train:  [[ 13.31385217]] Loss_Validation:  [[ 10.73796457]]\n",
      "Loop 1646 Loss_Train:  [[ 13.31365697]] Loss_Validation:  [[ 10.73822429]]\n",
      "Loop 1647 Loss_Train:  [[ 13.31346211]] Loss_Validation:  [[ 10.73848382]]\n",
      "Loop 1648 Loss_Train:  [[ 13.31326761]] Loss_Validation:  [[ 10.73874313]]\n",
      "Loop 1649 Loss_Train:  [[ 13.31307346]] Loss_Validation:  [[ 10.73900224]]\n",
      "Loop 1650 Loss_Train:  [[ 13.31287965]] Loss_Validation:  [[ 10.73926115]]\n",
      "Loop 1651 Loss_Train:  [[ 13.31268619]] Loss_Validation:  [[ 10.73951985]]\n",
      "Loop 1652 Loss_Train:  [[ 13.31249308]] Loss_Validation:  [[ 10.73977834]]\n",
      "Loop 1653 Loss_Train:  [[ 13.31230031]] Loss_Validation:  [[ 10.74003662]]\n",
      "Loop 1654 Loss_Train:  [[ 13.31210789]] Loss_Validation:  [[ 10.7402947]]\n",
      "Loop 1655 Loss_Train:  [[ 13.31191581]] Loss_Validation:  [[ 10.74055257]]\n",
      "Loop 1656 Loss_Train:  [[ 13.31172407]] Loss_Validation:  [[ 10.74081024]]\n",
      "Loop 1657 Loss_Train:  [[ 13.31153268]] Loss_Validation:  [[ 10.7410677]]\n",
      "Loop 1658 Loss_Train:  [[ 13.31134163]] Loss_Validation:  [[ 10.74132495]]\n",
      "Loop 1659 Loss_Train:  [[ 13.31115092]] Loss_Validation:  [[ 10.741582]]\n",
      "Loop 1660 Loss_Train:  [[ 13.31096055]] Loss_Validation:  [[ 10.74183884]]\n",
      "Loop 1661 Loss_Train:  [[ 13.31077052]] Loss_Validation:  [[ 10.74209547]]\n",
      "Loop 1662 Loss_Train:  [[ 13.31058083]] Loss_Validation:  [[ 10.7423519]]\n",
      "Loop 1663 Loss_Train:  [[ 13.31039147]] Loss_Validation:  [[ 10.74260812]]\n",
      "Loop 1664 Loss_Train:  [[ 13.31020246]] Loss_Validation:  [[ 10.74286414]]\n",
      "Loop 1665 Loss_Train:  [[ 13.31001378]] Loss_Validation:  [[ 10.74311995]]\n",
      "Loop 1666 Loss_Train:  [[ 13.30982544]] Loss_Validation:  [[ 10.74337555]]\n",
      "Loop 1667 Loss_Train:  [[ 13.30963744]] Loss_Validation:  [[ 10.74363095]]\n",
      "Loop 1668 Loss_Train:  [[ 13.30944977]] Loss_Validation:  [[ 10.74388614]]\n",
      "Loop 1669 Loss_Train:  [[ 13.30926243]] Loss_Validation:  [[ 10.74414112]]\n",
      "Loop 1670 Loss_Train:  [[ 13.30907543]] Loss_Validation:  [[ 10.7443959]]\n",
      "Loop 1671 Loss_Train:  [[ 13.30888876]] Loss_Validation:  [[ 10.74465047]]\n",
      "Loop 1672 Loss_Train:  [[ 13.30870243]] Loss_Validation:  [[ 10.74490484]]\n",
      "Loop 1673 Loss_Train:  [[ 13.30851642]] Loss_Validation:  [[ 10.745159]]\n",
      "Loop 1674 Loss_Train:  [[ 13.30833075]] Loss_Validation:  [[ 10.74541295]]\n",
      "Loop 1675 Loss_Train:  [[ 13.30814541]] Loss_Validation:  [[ 10.7456667]]\n",
      "Loop 1676 Loss_Train:  [[ 13.3079604]] Loss_Validation:  [[ 10.74592024]]\n",
      "Loop 1677 Loss_Train:  [[ 13.30777571]] Loss_Validation:  [[ 10.74617357]]\n",
      "Loop 1678 Loss_Train:  [[ 13.30759136]] Loss_Validation:  [[ 10.7464267]]\n",
      "Loop 1679 Loss_Train:  [[ 13.30740733]] Loss_Validation:  [[ 10.74667962]]\n",
      "Loop 1680 Loss_Train:  [[ 13.30722363]] Loss_Validation:  [[ 10.74693234]]\n",
      "Loop 1681 Loss_Train:  [[ 13.30704025]] Loss_Validation:  [[ 10.74718485]]\n",
      "Loop 1682 Loss_Train:  [[ 13.3068572]] Loss_Validation:  [[ 10.74743716]]\n",
      "Loop 1683 Loss_Train:  [[ 13.30667448]] Loss_Validation:  [[ 10.74768926]]\n",
      "Loop 1684 Loss_Train:  [[ 13.30649208]] Loss_Validation:  [[ 10.74794115]]\n",
      "Loop 1685 Loss_Train:  [[ 13.30631001]] Loss_Validation:  [[ 10.74819284]]\n",
      "Loop 1686 Loss_Train:  [[ 13.30612825]] Loss_Validation:  [[ 10.74844432]]\n",
      "Loop 1687 Loss_Train:  [[ 13.30594683]] Loss_Validation:  [[ 10.74869559]]\n",
      "Loop 1688 Loss_Train:  [[ 13.30576572]] Loss_Validation:  [[ 10.74894666]]\n",
      "Loop 1689 Loss_Train:  [[ 13.30558493]] Loss_Validation:  [[ 10.74919753]]\n",
      "Loop 1690 Loss_Train:  [[ 13.30540447]] Loss_Validation:  [[ 10.74944818]]\n",
      "Loop 1691 Loss_Train:  [[ 13.30522432]] Loss_Validation:  [[ 10.74969864]]\n",
      "Loop 1692 Loss_Train:  [[ 13.30504449]] Loss_Validation:  [[ 10.74994888]]\n",
      "Loop 1693 Loss_Train:  [[ 13.30486499]] Loss_Validation:  [[ 10.75019893]]\n",
      "Loop 1694 Loss_Train:  [[ 13.3046858]] Loss_Validation:  [[ 10.75044876]]\n",
      "Loop 1695 Loss_Train:  [[ 13.30450692]] Loss_Validation:  [[ 10.75069839]]\n",
      "Loop 1696 Loss_Train:  [[ 13.30432837]] Loss_Validation:  [[ 10.75094782]]\n",
      "Loop 1697 Loss_Train:  [[ 13.30415013]] Loss_Validation:  [[ 10.75119704]]\n",
      "Loop 1698 Loss_Train:  [[ 13.3039722]] Loss_Validation:  [[ 10.75144605]]\n",
      "Loop 1699 Loss_Train:  [[ 13.30379459]] Loss_Validation:  [[ 10.75169486]]\n",
      "Loop 1700 Loss_Train:  [[ 13.3036173]] Loss_Validation:  [[ 10.75194346]]\n",
      "Loop 1701 Loss_Train:  [[ 13.30344032]] Loss_Validation:  [[ 10.75219186]]\n",
      "Loop 1702 Loss_Train:  [[ 13.30326365]] Loss_Validation:  [[ 10.75244005]]\n",
      "Loop 1703 Loss_Train:  [[ 13.30308729]] Loss_Validation:  [[ 10.75268804]]\n",
      "Loop 1704 Loss_Train:  [[ 13.30291125]] Loss_Validation:  [[ 10.75293582]]\n",
      "Loop 1705 Loss_Train:  [[ 13.30273551]] Loss_Validation:  [[ 10.7531834]]\n",
      "Loop 1706 Loss_Train:  [[ 13.30256009]] Loss_Validation:  [[ 10.75343077]]\n",
      "Loop 1707 Loss_Train:  [[ 13.30238498]] Loss_Validation:  [[ 10.75367794]]\n",
      "Loop 1708 Loss_Train:  [[ 13.30221017]] Loss_Validation:  [[ 10.7539249]]\n",
      "Loop 1709 Loss_Train:  [[ 13.30203568]] Loss_Validation:  [[ 10.75417166]]\n",
      "Loop 1710 Loss_Train:  [[ 13.30186149]] Loss_Validation:  [[ 10.75441821]]\n",
      "Loop 1711 Loss_Train:  [[ 13.30168761]] Loss_Validation:  [[ 10.75466456]]\n",
      "Loop 1712 Loss_Train:  [[ 13.30151404]] Loss_Validation:  [[ 10.7549107]]\n",
      "Loop 1713 Loss_Train:  [[ 13.30134077]] Loss_Validation:  [[ 10.75515664]]\n",
      "Loop 1714 Loss_Train:  [[ 13.30116781]] Loss_Validation:  [[ 10.75540237]]\n",
      "Loop 1715 Loss_Train:  [[ 13.30099515]] Loss_Validation:  [[ 10.7556479]]\n",
      "Loop 1716 Loss_Train:  [[ 13.3008228]] Loss_Validation:  [[ 10.75589322]]\n",
      "Loop 1717 Loss_Train:  [[ 13.30065075]] Loss_Validation:  [[ 10.75613834]]\n",
      "Loop 1718 Loss_Train:  [[ 13.30047901]] Loss_Validation:  [[ 10.75638326]]\n",
      "Loop 1719 Loss_Train:  [[ 13.30030757]] Loss_Validation:  [[ 10.75662797]]\n",
      "Loop 1720 Loss_Train:  [[ 13.30013643]] Loss_Validation:  [[ 10.75687247]]\n",
      "Loop 1721 Loss_Train:  [[ 13.29996559]] Loss_Validation:  [[ 10.75711677]]\n",
      "Loop 1722 Loss_Train:  [[ 13.29979505]] Loss_Validation:  [[ 10.75736087]]\n",
      "Loop 1723 Loss_Train:  [[ 13.29962481]] Loss_Validation:  [[ 10.75760477]]\n",
      "Loop 1724 Loss_Train:  [[ 13.29945487]] Loss_Validation:  [[ 10.75784846]]\n",
      "Loop 1725 Loss_Train:  [[ 13.29928523]] Loss_Validation:  [[ 10.75809194]]\n",
      "Loop 1726 Loss_Train:  [[ 13.29911589]] Loss_Validation:  [[ 10.75833522]]\n",
      "Loop 1727 Loss_Train:  [[ 13.29894684]] Loss_Validation:  [[ 10.7585783]]\n",
      "Loop 1728 Loss_Train:  [[ 13.2987781]] Loss_Validation:  [[ 10.75882117]]\n",
      "Loop 1729 Loss_Train:  [[ 13.29860965]] Loss_Validation:  [[ 10.75906384]]\n",
      "Loop 1730 Loss_Train:  [[ 13.29844149]] Loss_Validation:  [[ 10.75930631]]\n",
      "Loop 1731 Loss_Train:  [[ 13.29827364]] Loss_Validation:  [[ 10.75954857]]\n",
      "Loop 1732 Loss_Train:  [[ 13.29810607]] Loss_Validation:  [[ 10.75979063]]\n",
      "Loop 1733 Loss_Train:  [[ 13.2979388]] Loss_Validation:  [[ 10.76003248]]\n",
      "Loop 1734 Loss_Train:  [[ 13.29777183]] Loss_Validation:  [[ 10.76027413]]\n",
      "Loop 1735 Loss_Train:  [[ 13.29760514]] Loss_Validation:  [[ 10.76051558]]\n",
      "Loop 1736 Loss_Train:  [[ 13.29743875]] Loss_Validation:  [[ 10.76075683]]\n",
      "Loop 1737 Loss_Train:  [[ 13.29727266]] Loss_Validation:  [[ 10.76099787]]\n",
      "Loop 1738 Loss_Train:  [[ 13.29710685]] Loss_Validation:  [[ 10.76123871]]\n",
      "Loop 1739 Loss_Train:  [[ 13.29694133]] Loss_Validation:  [[ 10.76147934]]\n",
      "Loop 1740 Loss_Train:  [[ 13.29677611]] Loss_Validation:  [[ 10.76171977]]\n",
      "Loop 1741 Loss_Train:  [[ 13.29661117]] Loss_Validation:  [[ 10.76196]]\n",
      "Loop 1742 Loss_Train:  [[ 13.29644652]] Loss_Validation:  [[ 10.76220003]]\n",
      "Loop 1743 Loss_Train:  [[ 13.29628217]] Loss_Validation:  [[ 10.76243985]]\n",
      "Loop 1744 Loss_Train:  [[ 13.2961181]] Loss_Validation:  [[ 10.76267947]]\n",
      "Loop 1745 Loss_Train:  [[ 13.29595431]] Loss_Validation:  [[ 10.76291889]]\n",
      "Loop 1746 Loss_Train:  [[ 13.29579082]] Loss_Validation:  [[ 10.7631581]]\n",
      "Loop 1747 Loss_Train:  [[ 13.29562761]] Loss_Validation:  [[ 10.76339711]]\n",
      "Loop 1748 Loss_Train:  [[ 13.29546468]] Loss_Validation:  [[ 10.76363592]]\n",
      "Loop 1749 Loss_Train:  [[ 13.29530204]] Loss_Validation:  [[ 10.76387453]]\n",
      "Loop 1750 Loss_Train:  [[ 13.29513969]] Loss_Validation:  [[ 10.76411293]]\n",
      "Loop 1751 Loss_Train:  [[ 13.29497762]] Loss_Validation:  [[ 10.76435113]]\n",
      "Loop 1752 Loss_Train:  [[ 13.29481583]] Loss_Validation:  [[ 10.76458913]]\n",
      "Loop 1753 Loss_Train:  [[ 13.29465432]] Loss_Validation:  [[ 10.76482693]]\n",
      "Loop 1754 Loss_Train:  [[ 13.2944931]] Loss_Validation:  [[ 10.76506453]]\n",
      "Loop 1755 Loss_Train:  [[ 13.29433216]] Loss_Validation:  [[ 10.76530192]]\n",
      "Loop 1756 Loss_Train:  [[ 13.2941715]] Loss_Validation:  [[ 10.76553911]]\n",
      "Loop 1757 Loss_Train:  [[ 13.29401112]] Loss_Validation:  [[ 10.7657761]]\n",
      "Loop 1758 Loss_Train:  [[ 13.29385103]] Loss_Validation:  [[ 10.76601289]]\n",
      "Loop 1759 Loss_Train:  [[ 13.29369121]] Loss_Validation:  [[ 10.76624948]]\n",
      "Loop 1760 Loss_Train:  [[ 13.29353167]] Loss_Validation:  [[ 10.76648586]]\n",
      "Loop 1761 Loss_Train:  [[ 13.29337241]] Loss_Validation:  [[ 10.76672204]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1762 Loss_Train:  [[ 13.29321342]] Loss_Validation:  [[ 10.76695803]]\n",
      "Loop 1763 Loss_Train:  [[ 13.29305472]] Loss_Validation:  [[ 10.76719381]]\n",
      "Loop 1764 Loss_Train:  [[ 13.29289629]] Loss_Validation:  [[ 10.76742939]]\n",
      "Loop 1765 Loss_Train:  [[ 13.29273814]] Loss_Validation:  [[ 10.76766476]]\n",
      "Loop 1766 Loss_Train:  [[ 13.29258026]] Loss_Validation:  [[ 10.76789994]]\n",
      "Loop 1767 Loss_Train:  [[ 13.29242266]] Loss_Validation:  [[ 10.76813492]]\n",
      "Loop 1768 Loss_Train:  [[ 13.29226533]] Loss_Validation:  [[ 10.76836969]]\n",
      "Loop 1769 Loss_Train:  [[ 13.29210828]] Loss_Validation:  [[ 10.76860427]]\n",
      "Loop 1770 Loss_Train:  [[ 13.2919515]] Loss_Validation:  [[ 10.76883864]]\n",
      "Loop 1771 Loss_Train:  [[ 13.29179499]] Loss_Validation:  [[ 10.76907281]]\n",
      "Loop 1772 Loss_Train:  [[ 13.29163876]] Loss_Validation:  [[ 10.76930678]]\n",
      "Loop 1773 Loss_Train:  [[ 13.2914828]] Loss_Validation:  [[ 10.76954055]]\n",
      "Loop 1774 Loss_Train:  [[ 13.29132711]] Loss_Validation:  [[ 10.76977413]]\n",
      "Loop 1775 Loss_Train:  [[ 13.29117169]] Loss_Validation:  [[ 10.7700075]]\n",
      "Loop 1776 Loss_Train:  [[ 13.29101654]] Loss_Validation:  [[ 10.77024067]]\n",
      "Loop 1777 Loss_Train:  [[ 13.29086166]] Loss_Validation:  [[ 10.77047364]]\n",
      "Loop 1778 Loss_Train:  [[ 13.29070705]] Loss_Validation:  [[ 10.77070641]]\n",
      "Loop 1779 Loss_Train:  [[ 13.29055271]] Loss_Validation:  [[ 10.77093898]]\n",
      "Loop 1780 Loss_Train:  [[ 13.29039864]] Loss_Validation:  [[ 10.77117135]]\n",
      "Loop 1781 Loss_Train:  [[ 13.29024483]] Loss_Validation:  [[ 10.77140352]]\n",
      "Loop 1782 Loss_Train:  [[ 13.2900913]] Loss_Validation:  [[ 10.77163549]]\n",
      "Loop 1783 Loss_Train:  [[ 13.28993803]] Loss_Validation:  [[ 10.77186726]]\n",
      "Loop 1784 Loss_Train:  [[ 13.28978502]] Loss_Validation:  [[ 10.77209883]]\n",
      "Loop 1785 Loss_Train:  [[ 13.28963229]] Loss_Validation:  [[ 10.7723302]]\n",
      "Loop 1786 Loss_Train:  [[ 13.28947981]] Loss_Validation:  [[ 10.77256138]]\n",
      "Loop 1787 Loss_Train:  [[ 13.2893276]] Loss_Validation:  [[ 10.77279235]]\n",
      "Loop 1788 Loss_Train:  [[ 13.28917566]] Loss_Validation:  [[ 10.77302312]]\n",
      "Loop 1789 Loss_Train:  [[ 13.28902398]] Loss_Validation:  [[ 10.7732537]]\n",
      "Loop 1790 Loss_Train:  [[ 13.28887256]] Loss_Validation:  [[ 10.77348407]]\n",
      "Loop 1791 Loss_Train:  [[ 13.28872141]] Loss_Validation:  [[ 10.77371425]]\n",
      "Loop 1792 Loss_Train:  [[ 13.28857052]] Loss_Validation:  [[ 10.77394423]]\n",
      "Loop 1793 Loss_Train:  [[ 13.28841988]] Loss_Validation:  [[ 10.77417401]]\n",
      "Loop 1794 Loss_Train:  [[ 13.28826952]] Loss_Validation:  [[ 10.77440359]]\n",
      "Loop 1795 Loss_Train:  [[ 13.28811941]] Loss_Validation:  [[ 10.77463297]]\n",
      "Loop 1796 Loss_Train:  [[ 13.28796956]] Loss_Validation:  [[ 10.77486216]]\n",
      "Loop 1797 Loss_Train:  [[ 13.28781997]] Loss_Validation:  [[ 10.77509115]]\n",
      "Loop 1798 Loss_Train:  [[ 13.28767064]] Loss_Validation:  [[ 10.77531993]]\n",
      "Loop 1799 Loss_Train:  [[ 13.28752157]] Loss_Validation:  [[ 10.77554852]]\n",
      "Loop 1800 Loss_Train:  [[ 13.28737275]] Loss_Validation:  [[ 10.77577692]]\n",
      "Loop 1801 Loss_Train:  [[ 13.2872242]] Loss_Validation:  [[ 10.77600511]]\n",
      "Loop 1802 Loss_Train:  [[ 13.2870759]] Loss_Validation:  [[ 10.77623311]]\n",
      "Loop 1803 Loss_Train:  [[ 13.28692786]] Loss_Validation:  [[ 10.7764609]]\n",
      "Loop 1804 Loss_Train:  [[ 13.28678007]] Loss_Validation:  [[ 10.77668851]]\n",
      "Loop 1805 Loss_Train:  [[ 13.28663254]] Loss_Validation:  [[ 10.77691591]]\n",
      "Loop 1806 Loss_Train:  [[ 13.28648527]] Loss_Validation:  [[ 10.77714311]]\n",
      "Loop 1807 Loss_Train:  [[ 13.28633825]] Loss_Validation:  [[ 10.77737012]]\n",
      "Loop 1808 Loss_Train:  [[ 13.28619148]] Loss_Validation:  [[ 10.77759694]]\n",
      "Loop 1809 Loss_Train:  [[ 13.28604497]] Loss_Validation:  [[ 10.77782355]]\n",
      "Loop 1810 Loss_Train:  [[ 13.28589871]] Loss_Validation:  [[ 10.77804997]]\n",
      "Loop 1811 Loss_Train:  [[ 13.2857527]] Loss_Validation:  [[ 10.77827619]]\n",
      "Loop 1812 Loss_Train:  [[ 13.28560695]] Loss_Validation:  [[ 10.77850221]]\n",
      "Loop 1813 Loss_Train:  [[ 13.28546144]] Loss_Validation:  [[ 10.77872804]]\n",
      "Loop 1814 Loss_Train:  [[ 13.28531619]] Loss_Validation:  [[ 10.77895367]]\n",
      "Loop 1815 Loss_Train:  [[ 13.28517119]] Loss_Validation:  [[ 10.7791791]]\n",
      "Loop 1816 Loss_Train:  [[ 13.28502644]] Loss_Validation:  [[ 10.77940434]]\n",
      "Loop 1817 Loss_Train:  [[ 13.28488194]] Loss_Validation:  [[ 10.77962938]]\n",
      "Loop 1818 Loss_Train:  [[ 13.28473769]] Loss_Validation:  [[ 10.77985423]]\n",
      "Loop 1819 Loss_Train:  [[ 13.28459369]] Loss_Validation:  [[ 10.78007888]]\n",
      "Loop 1820 Loss_Train:  [[ 13.28444993]] Loss_Validation:  [[ 10.78030333]]\n",
      "Loop 1821 Loss_Train:  [[ 13.28430643]] Loss_Validation:  [[ 10.78052759]]\n",
      "Loop 1822 Loss_Train:  [[ 13.28416317]] Loss_Validation:  [[ 10.78075165]]\n",
      "Loop 1823 Loss_Train:  [[ 13.28402016]] Loss_Validation:  [[ 10.78097552]]\n",
      "Loop 1824 Loss_Train:  [[ 13.28387739]] Loss_Validation:  [[ 10.78119919]]\n",
      "Loop 1825 Loss_Train:  [[ 13.28373487]] Loss_Validation:  [[ 10.78142266]]\n",
      "Loop 1826 Loss_Train:  [[ 13.2835926]] Loss_Validation:  [[ 10.78164594]]\n",
      "Loop 1827 Loss_Train:  [[ 13.28345057]] Loss_Validation:  [[ 10.78186903]]\n",
      "Loop 1828 Loss_Train:  [[ 13.28330878]] Loss_Validation:  [[ 10.78209192]]\n",
      "Loop 1829 Loss_Train:  [[ 13.28316724]] Loss_Validation:  [[ 10.78231462]]\n",
      "Loop 1830 Loss_Train:  [[ 13.28302595]] Loss_Validation:  [[ 10.78253712]]\n",
      "Loop 1831 Loss_Train:  [[ 13.28288489]] Loss_Validation:  [[ 10.78275942]]\n",
      "Loop 1832 Loss_Train:  [[ 13.28274408]] Loss_Validation:  [[ 10.78298153]]\n",
      "Loop 1833 Loss_Train:  [[ 13.28260351]] Loss_Validation:  [[ 10.78320345]]\n",
      "Loop 1834 Loss_Train:  [[ 13.28246319]] Loss_Validation:  [[ 10.78342517]]\n",
      "Loop 1835 Loss_Train:  [[ 13.2823231]] Loss_Validation:  [[ 10.7836467]]\n",
      "Loop 1836 Loss_Train:  [[ 13.28218326]] Loss_Validation:  [[ 10.78386803]]\n",
      "Loop 1837 Loss_Train:  [[ 13.28204365]] Loss_Validation:  [[ 10.78408917]]\n",
      "Loop 1838 Loss_Train:  [[ 13.28190429]] Loss_Validation:  [[ 10.78431012]]\n",
      "Loop 1839 Loss_Train:  [[ 13.28176516]] Loss_Validation:  [[ 10.78453087]]\n",
      "Loop 1840 Loss_Train:  [[ 13.28162628]] Loss_Validation:  [[ 10.78475143]]\n",
      "Loop 1841 Loss_Train:  [[ 13.28148763]] Loss_Validation:  [[ 10.78497179]]\n",
      "Loop 1842 Loss_Train:  [[ 13.28134922]] Loss_Validation:  [[ 10.78519196]]\n",
      "Loop 1843 Loss_Train:  [[ 13.28121105]] Loss_Validation:  [[ 10.78541194]]\n",
      "Loop 1844 Loss_Train:  [[ 13.28107312]] Loss_Validation:  [[ 10.78563172]]\n",
      "Loop 1845 Loss_Train:  [[ 13.28093542]] Loss_Validation:  [[ 10.78585132]]\n",
      "Loop 1846 Loss_Train:  [[ 13.28079796]] Loss_Validation:  [[ 10.78607071]]\n",
      "Loop 1847 Loss_Train:  [[ 13.28066073]] Loss_Validation:  [[ 10.78628992]]\n",
      "Loop 1848 Loss_Train:  [[ 13.28052374]] Loss_Validation:  [[ 10.78650893]]\n",
      "Loop 1849 Loss_Train:  [[ 13.28038699]] Loss_Validation:  [[ 10.78672775]]\n",
      "Loop 1850 Loss_Train:  [[ 13.28025047]] Loss_Validation:  [[ 10.78694638]]\n",
      "Loop 1851 Loss_Train:  [[ 13.28011418]] Loss_Validation:  [[ 10.78716481]]\n",
      "Loop 1852 Loss_Train:  [[ 13.27997813]] Loss_Validation:  [[ 10.78738306]]\n",
      "Loop 1853 Loss_Train:  [[ 13.27984231]] Loss_Validation:  [[ 10.78760111]]\n",
      "Loop 1854 Loss_Train:  [[ 13.27970672]] Loss_Validation:  [[ 10.78781897]]\n",
      "Loop 1855 Loss_Train:  [[ 13.27957137]] Loss_Validation:  [[ 10.78803663]]\n",
      "Loop 1856 Loss_Train:  [[ 13.27943624]] Loss_Validation:  [[ 10.78825411]]\n",
      "Loop 1857 Loss_Train:  [[ 13.27930135]] Loss_Validation:  [[ 10.78847139]]\n",
      "Loop 1858 Loss_Train:  [[ 13.27916669]] Loss_Validation:  [[ 10.78868848]]\n",
      "Loop 1859 Loss_Train:  [[ 13.27903226]] Loss_Validation:  [[ 10.78890538]]\n",
      "Loop 1860 Loss_Train:  [[ 13.27889806]] Loss_Validation:  [[ 10.78912209]]\n",
      "Loop 1861 Loss_Train:  [[ 13.27876409]] Loss_Validation:  [[ 10.78933861]]\n",
      "Loop 1862 Loss_Train:  [[ 13.27863035]] Loss_Validation:  [[ 10.78955493]]\n",
      "Loop 1863 Loss_Train:  [[ 13.27849684]] Loss_Validation:  [[ 10.78977107]]\n",
      "Loop 1864 Loss_Train:  [[ 13.27836355]] Loss_Validation:  [[ 10.78998701]]\n",
      "Loop 1865 Loss_Train:  [[ 13.2782305]] Loss_Validation:  [[ 10.79020276]]\n",
      "Loop 1866 Loss_Train:  [[ 13.27809767]] Loss_Validation:  [[ 10.79041833]]\n",
      "Loop 1867 Loss_Train:  [[ 13.27796507]] Loss_Validation:  [[ 10.7906337]]\n",
      "Loop 1868 Loss_Train:  [[ 13.27783269]] Loss_Validation:  [[ 10.79084888]]\n",
      "Loop 1869 Loss_Train:  [[ 13.27770054]] Loss_Validation:  [[ 10.79106387]]\n",
      "Loop 1870 Loss_Train:  [[ 13.27756862]] Loss_Validation:  [[ 10.79127867]]\n",
      "Loop 1871 Loss_Train:  [[ 13.27743692]] Loss_Validation:  [[ 10.79149328]]\n",
      "Loop 1872 Loss_Train:  [[ 13.27730545]] Loss_Validation:  [[ 10.79170771]]\n",
      "Loop 1873 Loss_Train:  [[ 13.2771742]] Loss_Validation:  [[ 10.79192194]]\n",
      "Loop 1874 Loss_Train:  [[ 13.27704318]] Loss_Validation:  [[ 10.79213598]]\n",
      "Loop 1875 Loss_Train:  [[ 13.27691237]] Loss_Validation:  [[ 10.79234983]]\n",
      "Loop 1876 Loss_Train:  [[ 13.2767818]] Loss_Validation:  [[ 10.79256349]]\n",
      "Loop 1877 Loss_Train:  [[ 13.27665144]] Loss_Validation:  [[ 10.79277697]]\n",
      "Loop 1878 Loss_Train:  [[ 13.27652131]] Loss_Validation:  [[ 10.79299025]]\n",
      "Loop 1879 Loss_Train:  [[ 13.2763914]] Loss_Validation:  [[ 10.79320335]]\n",
      "Loop 1880 Loss_Train:  [[ 13.27626171]] Loss_Validation:  [[ 10.79341625]]\n",
      "Loop 1881 Loss_Train:  [[ 13.27613224]] Loss_Validation:  [[ 10.79362897]]\n",
      "Loop 1882 Loss_Train:  [[ 13.276003]] Loss_Validation:  [[ 10.7938415]]\n",
      "Loop 1883 Loss_Train:  [[ 13.27587397]] Loss_Validation:  [[ 10.79405384]]\n",
      "Loop 1884 Loss_Train:  [[ 13.27574516]] Loss_Validation:  [[ 10.79426599]]\n",
      "Loop 1885 Loss_Train:  [[ 13.27561657]] Loss_Validation:  [[ 10.79447796]]\n",
      "Loop 1886 Loss_Train:  [[ 13.2754882]] Loss_Validation:  [[ 10.79468973]]\n",
      "Loop 1887 Loss_Train:  [[ 13.27536005]] Loss_Validation:  [[ 10.79490132]]\n",
      "Loop 1888 Loss_Train:  [[ 13.27523212]] Loss_Validation:  [[ 10.79511272]]\n",
      "Loop 1889 Loss_Train:  [[ 13.27510441]] Loss_Validation:  [[ 10.79532393]]\n",
      "Loop 1890 Loss_Train:  [[ 13.27497691]] Loss_Validation:  [[ 10.79553496]]\n",
      "Loop 1891 Loss_Train:  [[ 13.27484963]] Loss_Validation:  [[ 10.79574579]]\n",
      "Loop 1892 Loss_Train:  [[ 13.27472257]] Loss_Validation:  [[ 10.79595644]]\n",
      "Loop 1893 Loss_Train:  [[ 13.27459572]] Loss_Validation:  [[ 10.7961669]]\n",
      "Loop 1894 Loss_Train:  [[ 13.27446909]] Loss_Validation:  [[ 10.79637718]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1895 Loss_Train:  [[ 13.27434268]] Loss_Validation:  [[ 10.79658727]]\n",
      "Loop 1896 Loss_Train:  [[ 13.27421648]] Loss_Validation:  [[ 10.79679717]]\n",
      "Loop 1897 Loss_Train:  [[ 13.27409049]] Loss_Validation:  [[ 10.79700688]]\n",
      "Loop 1898 Loss_Train:  [[ 13.27396472]] Loss_Validation:  [[ 10.79721641]]\n",
      "Loop 1899 Loss_Train:  [[ 13.27383916]] Loss_Validation:  [[ 10.79742575]]\n",
      "Loop 1900 Loss_Train:  [[ 13.27371381]] Loss_Validation:  [[ 10.7976349]]\n",
      "Loop 1901 Loss_Train:  [[ 13.27358868]] Loss_Validation:  [[ 10.79784387]]\n",
      "Loop 1902 Loss_Train:  [[ 13.27346376]] Loss_Validation:  [[ 10.79805266]]\n",
      "Loop 1903 Loss_Train:  [[ 13.27333905]] Loss_Validation:  [[ 10.79826125]]\n",
      "Loop 1904 Loss_Train:  [[ 13.27321456]] Loss_Validation:  [[ 10.79846966]]\n",
      "Loop 1905 Loss_Train:  [[ 13.27309027]] Loss_Validation:  [[ 10.79867789]]\n",
      "Loop 1906 Loss_Train:  [[ 13.2729662]] Loss_Validation:  [[ 10.79888593]]\n",
      "Loop 1907 Loss_Train:  [[ 13.27284234]] Loss_Validation:  [[ 10.79909378]]\n",
      "Loop 1908 Loss_Train:  [[ 13.27271868]] Loss_Validation:  [[ 10.79930145]]\n",
      "Loop 1909 Loss_Train:  [[ 13.27259524]] Loss_Validation:  [[ 10.79950893]]\n",
      "Loop 1910 Loss_Train:  [[ 13.27247201]] Loss_Validation:  [[ 10.79971623]]\n",
      "Loop 1911 Loss_Train:  [[ 13.27234898]] Loss_Validation:  [[ 10.79992334]]\n",
      "Loop 1912 Loss_Train:  [[ 13.27222617]] Loss_Validation:  [[ 10.80013027]]\n",
      "Loop 1913 Loss_Train:  [[ 13.27210356]] Loss_Validation:  [[ 10.80033701]]\n",
      "Loop 1914 Loss_Train:  [[ 13.27198116]] Loss_Validation:  [[ 10.80054357]]\n",
      "Loop 1915 Loss_Train:  [[ 13.27185896]] Loss_Validation:  [[ 10.80074995]]\n",
      "Loop 1916 Loss_Train:  [[ 13.27173698]] Loss_Validation:  [[ 10.80095614]]\n",
      "Loop 1917 Loss_Train:  [[ 13.2716152]] Loss_Validation:  [[ 10.80116214]]\n",
      "Loop 1918 Loss_Train:  [[ 13.27149363]] Loss_Validation:  [[ 10.80136796]]\n",
      "Loop 1919 Loss_Train:  [[ 13.27137226]] Loss_Validation:  [[ 10.8015736]]\n",
      "Loop 1920 Loss_Train:  [[ 13.2712511]] Loss_Validation:  [[ 10.80177906]]\n",
      "Loop 1921 Loss_Train:  [[ 13.27113014]] Loss_Validation:  [[ 10.80198433]]\n",
      "Loop 1922 Loss_Train:  [[ 13.27100939]] Loss_Validation:  [[ 10.80218942]]\n",
      "Loop 1923 Loss_Train:  [[ 13.27088884]] Loss_Validation:  [[ 10.80239432]]\n",
      "Loop 1924 Loss_Train:  [[ 13.2707685]] Loss_Validation:  [[ 10.80259904]]\n",
      "Loop 1925 Loss_Train:  [[ 13.27064836]] Loss_Validation:  [[ 10.80280358]]\n",
      "Loop 1926 Loss_Train:  [[ 13.27052842]] Loss_Validation:  [[ 10.80300793]]\n",
      "Loop 1927 Loss_Train:  [[ 13.27040869]] Loss_Validation:  [[ 10.8032121]]\n",
      "Loop 1928 Loss_Train:  [[ 13.27028916]] Loss_Validation:  [[ 10.80341609]]\n",
      "Loop 1929 Loss_Train:  [[ 13.27016983]] Loss_Validation:  [[ 10.8036199]]\n",
      "Loop 1930 Loss_Train:  [[ 13.2700507]] Loss_Validation:  [[ 10.80382352]]\n",
      "Loop 1931 Loss_Train:  [[ 13.26993177]] Loss_Validation:  [[ 10.80402696]]\n",
      "Loop 1932 Loss_Train:  [[ 13.26981305]] Loss_Validation:  [[ 10.80423022]]\n",
      "Loop 1933 Loss_Train:  [[ 13.26969452]] Loss_Validation:  [[ 10.8044333]]\n",
      "Loop 1934 Loss_Train:  [[ 13.2695762]] Loss_Validation:  [[ 10.8046362]]\n",
      "Loop 1935 Loss_Train:  [[ 13.26945808]] Loss_Validation:  [[ 10.80483891]]\n",
      "Loop 1936 Loss_Train:  [[ 13.26934015]] Loss_Validation:  [[ 10.80504144]]\n",
      "Loop 1937 Loss_Train:  [[ 13.26922242]] Loss_Validation:  [[ 10.80524379]]\n",
      "Loop 1938 Loss_Train:  [[ 13.2691049]] Loss_Validation:  [[ 10.80544596]]\n",
      "Loop 1939 Loss_Train:  [[ 13.26898757]] Loss_Validation:  [[ 10.80564795]]\n",
      "Loop 1940 Loss_Train:  [[ 13.26887044]] Loss_Validation:  [[ 10.80584976]]\n",
      "Loop 1941 Loss_Train:  [[ 13.2687535]] Loss_Validation:  [[ 10.80605139]]\n",
      "Loop 1942 Loss_Train:  [[ 13.26863677]] Loss_Validation:  [[ 10.80625283]]\n",
      "Loop 1943 Loss_Train:  [[ 13.26852023]] Loss_Validation:  [[ 10.8064541]]\n",
      "Loop 1944 Loss_Train:  [[ 13.26840388]] Loss_Validation:  [[ 10.80665518]]\n",
      "Loop 1945 Loss_Train:  [[ 13.26828774]] Loss_Validation:  [[ 10.80685608]]\n",
      "Loop 1946 Loss_Train:  [[ 13.26817178]] Loss_Validation:  [[ 10.80705681]]\n",
      "Loop 1947 Loss_Train:  [[ 13.26805603]] Loss_Validation:  [[ 10.80725735]]\n",
      "Loop 1948 Loss_Train:  [[ 13.26794047]] Loss_Validation:  [[ 10.80745771]]\n",
      "Loop 1949 Loss_Train:  [[ 13.2678251]] Loss_Validation:  [[ 10.8076579]]\n",
      "Loop 1950 Loss_Train:  [[ 13.26770993]] Loss_Validation:  [[ 10.8078579]]\n",
      "Loop 1951 Loss_Train:  [[ 13.26759495]] Loss_Validation:  [[ 10.80805773]]\n",
      "Loop 1952 Loss_Train:  [[ 13.26748017]] Loss_Validation:  [[ 10.80825737]]\n",
      "Loop 1953 Loss_Train:  [[ 13.26736558]] Loss_Validation:  [[ 10.80845684]]\n",
      "Loop 1954 Loss_Train:  [[ 13.26725118]] Loss_Validation:  [[ 10.80865612]]\n",
      "Loop 1955 Loss_Train:  [[ 13.26713697]] Loss_Validation:  [[ 10.80885523]]\n",
      "Loop 1956 Loss_Train:  [[ 13.26702296]] Loss_Validation:  [[ 10.80905416]]\n",
      "Loop 1957 Loss_Train:  [[ 13.26690914]] Loss_Validation:  [[ 10.80925291]]\n",
      "Loop 1958 Loss_Train:  [[ 13.26679551]] Loss_Validation:  [[ 10.80945148]]\n",
      "Loop 1959 Loss_Train:  [[ 13.26668207]] Loss_Validation:  [[ 10.80964987]]\n",
      "Loop 1960 Loss_Train:  [[ 13.26656882]] Loss_Validation:  [[ 10.80984808]]\n",
      "Loop 1961 Loss_Train:  [[ 13.26645577]] Loss_Validation:  [[ 10.81004612]]\n",
      "Loop 1962 Loss_Train:  [[ 13.2663429]] Loss_Validation:  [[ 10.81024398]]\n",
      "Loop 1963 Loss_Train:  [[ 13.26623022]] Loss_Validation:  [[ 10.81044166]]\n",
      "Loop 1964 Loss_Train:  [[ 13.26611773]] Loss_Validation:  [[ 10.81063916]]\n",
      "Loop 1965 Loss_Train:  [[ 13.26600543]] Loss_Validation:  [[ 10.81083649]]\n",
      "Loop 1966 Loss_Train:  [[ 13.26589332]] Loss_Validation:  [[ 10.81103363]]\n",
      "Loop 1967 Loss_Train:  [[ 13.2657814]] Loss_Validation:  [[ 10.8112306]]\n",
      "Loop 1968 Loss_Train:  [[ 13.26566966]] Loss_Validation:  [[ 10.81142739]]\n",
      "Loop 1969 Loss_Train:  [[ 13.26555812]] Loss_Validation:  [[ 10.81162401]]\n",
      "Loop 1970 Loss_Train:  [[ 13.26544676]] Loss_Validation:  [[ 10.81182045]]\n",
      "Loop 1971 Loss_Train:  [[ 13.26533559]] Loss_Validation:  [[ 10.81201671]]\n",
      "Loop 1972 Loss_Train:  [[ 13.2652246]] Loss_Validation:  [[ 10.81221279]]\n",
      "Loop 1973 Loss_Train:  [[ 13.2651138]] Loss_Validation:  [[ 10.8124087]]\n",
      "Loop 1974 Loss_Train:  [[ 13.26500319]] Loss_Validation:  [[ 10.81260443]]\n",
      "Loop 1975 Loss_Train:  [[ 13.26489276]] Loss_Validation:  [[ 10.81279999]]\n",
      "Loop 1976 Loss_Train:  [[ 13.26478251]] Loss_Validation:  [[ 10.81299537]]\n",
      "Loop 1977 Loss_Train:  [[ 13.26467246]] Loss_Validation:  [[ 10.81319057]]\n",
      "Loop 1978 Loss_Train:  [[ 13.26456258]] Loss_Validation:  [[ 10.8133856]]\n",
      "Loop 1979 Loss_Train:  [[ 13.26445289]] Loss_Validation:  [[ 10.81358045]]\n",
      "Loop 1980 Loss_Train:  [[ 13.26434339]] Loss_Validation:  [[ 10.81377513]]\n",
      "Loop 1981 Loss_Train:  [[ 13.26423406]] Loss_Validation:  [[ 10.81396963]]\n",
      "Loop 1982 Loss_Train:  [[ 13.26412492]] Loss_Validation:  [[ 10.81416395]]\n",
      "Loop 1983 Loss_Train:  [[ 13.26401597]] Loss_Validation:  [[ 10.8143581]]\n",
      "Loop 1984 Loss_Train:  [[ 13.2639072]] Loss_Validation:  [[ 10.81455208]]\n",
      "Loop 1985 Loss_Train:  [[ 13.2637986]] Loss_Validation:  [[ 10.81474588]]\n",
      "Loop 1986 Loss_Train:  [[ 13.26369019]] Loss_Validation:  [[ 10.8149395]]\n",
      "Loop 1987 Loss_Train:  [[ 13.26358197]] Loss_Validation:  [[ 10.81513296]]\n",
      "Loop 1988 Loss_Train:  [[ 13.26347392]] Loss_Validation:  [[ 10.81532623]]\n",
      "Loop 1989 Loss_Train:  [[ 13.26336605]] Loss_Validation:  [[ 10.81551933]]\n",
      "Loop 1990 Loss_Train:  [[ 13.26325837]] Loss_Validation:  [[ 10.81571226]]\n",
      "Loop 1991 Loss_Train:  [[ 13.26315086]] Loss_Validation:  [[ 10.81590502]]\n",
      "Loop 1992 Loss_Train:  [[ 13.26304354]] Loss_Validation:  [[ 10.8160976]]\n",
      "Loop 1993 Loss_Train:  [[ 13.26293639]] Loss_Validation:  [[ 10.81629]]\n",
      "Loop 1994 Loss_Train:  [[ 13.26282942]] Loss_Validation:  [[ 10.81648224]]\n",
      "Loop 1995 Loss_Train:  [[ 13.26272264]] Loss_Validation:  [[ 10.8166743]]\n",
      "Loop 1996 Loss_Train:  [[ 13.26261603]] Loss_Validation:  [[ 10.81686618]]\n",
      "Loop 1997 Loss_Train:  [[ 13.26250959]] Loss_Validation:  [[ 10.81705789]]\n",
      "Loop 1998 Loss_Train:  [[ 13.26240334]] Loss_Validation:  [[ 10.81724943]]\n",
      "Loop 1999 Loss_Train:  [[ 13.26229727]] Loss_Validation:  [[ 10.8174408]]\n",
      "Loop 2000 Loss_Train:  [[ 13.26219137]] Loss_Validation:  [[ 10.81763199]]\n",
      "Loop 2001 Loss_Train:  [[ 13.26208565]] Loss_Validation:  [[ 10.81782302]]\n",
      "Loop 2002 Loss_Train:  [[ 13.2619801]] Loss_Validation:  [[ 10.81801387]]\n",
      "Loop 2003 Loss_Train:  [[ 13.26187473]] Loss_Validation:  [[ 10.81820454]]\n",
      "Loop 2004 Loss_Train:  [[ 13.26176954]] Loss_Validation:  [[ 10.81839505]]\n",
      "Loop 2005 Loss_Train:  [[ 13.26166452]] Loss_Validation:  [[ 10.81858538]]\n",
      "Loop 2006 Loss_Train:  [[ 13.26155968]] Loss_Validation:  [[ 10.81877554]]\n",
      "Loop 2007 Loss_Train:  [[ 13.26145501]] Loss_Validation:  [[ 10.81896553]]\n",
      "Loop 2008 Loss_Train:  [[ 13.26135052]] Loss_Validation:  [[ 10.81915534]]\n",
      "Loop 2009 Loss_Train:  [[ 13.2612462]] Loss_Validation:  [[ 10.81934499]]\n",
      "Loop 2010 Loss_Train:  [[ 13.26114206]] Loss_Validation:  [[ 10.81953446]]\n",
      "Loop 2011 Loss_Train:  [[ 13.26103809]] Loss_Validation:  [[ 10.81972377]]\n",
      "Loop 2012 Loss_Train:  [[ 13.26093429]] Loss_Validation:  [[ 10.8199129]]\n",
      "Loop 2013 Loss_Train:  [[ 13.26083067]] Loss_Validation:  [[ 10.82010186]]\n",
      "Loop 2014 Loss_Train:  [[ 13.26072722]] Loss_Validation:  [[ 10.82029065]]\n",
      "Loop 2015 Loss_Train:  [[ 13.26062394]] Loss_Validation:  [[ 10.82047927]]\n",
      "Loop 2016 Loss_Train:  [[ 13.26052083]] Loss_Validation:  [[ 10.82066772]]\n",
      "Loop 2017 Loss_Train:  [[ 13.2604179]] Loss_Validation:  [[ 10.820856]]\n",
      "Loop 2018 Loss_Train:  [[ 13.26031514]] Loss_Validation:  [[ 10.82104411]]\n",
      "Loop 2019 Loss_Train:  [[ 13.26021254]] Loss_Validation:  [[ 10.82123204]]\n",
      "Loop 2020 Loss_Train:  [[ 13.26011012]] Loss_Validation:  [[ 10.82141981]]\n",
      "Loop 2021 Loss_Train:  [[ 13.26000787]] Loss_Validation:  [[ 10.82160741]]\n",
      "Loop 2022 Loss_Train:  [[ 13.25990579]] Loss_Validation:  [[ 10.82179484]]\n",
      "Loop 2023 Loss_Train:  [[ 13.25980388]] Loss_Validation:  [[ 10.8219821]]\n",
      "Loop 2024 Loss_Train:  [[ 13.25970214]] Loss_Validation:  [[ 10.82216919]]\n",
      "Loop 2025 Loss_Train:  [[ 13.25960057]] Loss_Validation:  [[ 10.82235611]]\n",
      "Loop 2026 Loss_Train:  [[ 13.25949917]] Loss_Validation:  [[ 10.82254286]]\n",
      "Loop 2027 Loss_Train:  [[ 13.25939794]] Loss_Validation:  [[ 10.82272944]]\n",
      "Loop 2028 Loss_Train:  [[ 13.25929687]] Loss_Validation:  [[ 10.82291586]]\n",
      "Loop 2029 Loss_Train:  [[ 13.25919597]] Loss_Validation:  [[ 10.8231021]]\n",
      "Loop 2030 Loss_Train:  [[ 13.25909525]] Loss_Validation:  [[ 10.82328818]]\n",
      "Loop 2031 Loss_Train:  [[ 13.25899468]] Loss_Validation:  [[ 10.82347409]]\n",
      "Loop 2032 Loss_Train:  [[ 13.25889429]] Loss_Validation:  [[ 10.82365983]]\n",
      "Loop 2033 Loss_Train:  [[ 13.25879406]] Loss_Validation:  [[ 10.8238454]]\n",
      "Loop 2034 Loss_Train:  [[ 13.258694]] Loss_Validation:  [[ 10.8240308]]\n",
      "Loop 2035 Loss_Train:  [[ 13.25859411]] Loss_Validation:  [[ 10.82421604]]\n",
      "Loop 2036 Loss_Train:  [[ 13.25849438]] Loss_Validation:  [[ 10.82440111]]\n",
      "Loop 2037 Loss_Train:  [[ 13.25839482]] Loss_Validation:  [[ 10.82458601]]\n",
      "Loop 2038 Loss_Train:  [[ 13.25829542]] Loss_Validation:  [[ 10.82477074]]\n",
      "Loop 2039 Loss_Train:  [[ 13.25819619]] Loss_Validation:  [[ 10.82495531]]\n",
      "Loop 2040 Loss_Train:  [[ 13.25809712]] Loss_Validation:  [[ 10.82513971]]\n",
      "Loop 2041 Loss_Train:  [[ 13.25799821]] Loss_Validation:  [[ 10.82532394]]\n",
      "Loop 2042 Loss_Train:  [[ 13.25789948]] Loss_Validation:  [[ 10.82550801]]\n",
      "Loop 2043 Loss_Train:  [[ 13.2578009]] Loss_Validation:  [[ 10.82569191]]\n",
      "Loop 2044 Loss_Train:  [[ 13.25770249]] Loss_Validation:  [[ 10.82587564]]\n",
      "Loop 2045 Loss_Train:  [[ 13.25760424]] Loss_Validation:  [[ 10.82605921]]\n",
      "Loop 2046 Loss_Train:  [[ 13.25750616]] Loss_Validation:  [[ 10.82624261]]\n",
      "Loop 2047 Loss_Train:  [[ 13.25740823]] Loss_Validation:  [[ 10.82642584]]\n",
      "Loop 2048 Loss_Train:  [[ 13.25731047]] Loss_Validation:  [[ 10.82660891]]\n",
      "Loop 2049 Loss_Train:  [[ 13.25721288]] Loss_Validation:  [[ 10.82679181]]\n",
      "Loop 2050 Loss_Train:  [[ 13.25711544]] Loss_Validation:  [[ 10.82697454]]\n",
      "Loop 2051 Loss_Train:  [[ 13.25701817]] Loss_Validation:  [[ 10.82715712]]\n",
      "Loop 2052 Loss_Train:  [[ 13.25692105]] Loss_Validation:  [[ 10.82733952]]\n",
      "Loop 2053 Loss_Train:  [[ 13.2568241]] Loss_Validation:  [[ 10.82752176]]\n",
      "Loop 2054 Loss_Train:  [[ 13.25672731]] Loss_Validation:  [[ 10.82770384]]\n",
      "Loop 2055 Loss_Train:  [[ 13.25663068]] Loss_Validation:  [[ 10.82788575]]\n",
      "Loop 2056 Loss_Train:  [[ 13.25653421]] Loss_Validation:  [[ 10.82806749]]\n",
      "Loop 2057 Loss_Train:  [[ 13.2564379]] Loss_Validation:  [[ 10.82824907]]\n",
      "Loop 2058 Loss_Train:  [[ 13.25634174]] Loss_Validation:  [[ 10.82843049]]\n",
      "Loop 2059 Loss_Train:  [[ 13.25624575]] Loss_Validation:  [[ 10.82861174]]\n",
      "Loop 2060 Loss_Train:  [[ 13.25614992]] Loss_Validation:  [[ 10.82879283]]\n",
      "Loop 2061 Loss_Train:  [[ 13.25605424]] Loss_Validation:  [[ 10.82897375]]\n",
      "Loop 2062 Loss_Train:  [[ 13.25595873]] Loss_Validation:  [[ 10.82915451]]\n",
      "Loop 2063 Loss_Train:  [[ 13.25586337]] Loss_Validation:  [[ 10.8293351]]\n",
      "Loop 2064 Loss_Train:  [[ 13.25576817]] Loss_Validation:  [[ 10.82951554]]\n",
      "Loop 2065 Loss_Train:  [[ 13.25567312]] Loss_Validation:  [[ 10.8296958]]\n",
      "Loop 2066 Loss_Train:  [[ 13.25557824]] Loss_Validation:  [[ 10.82987591]]\n",
      "Loop 2067 Loss_Train:  [[ 13.25548351]] Loss_Validation:  [[ 10.83005585]]\n",
      "Loop 2068 Loss_Train:  [[ 13.25538894]] Loss_Validation:  [[ 10.83023563]]\n",
      "Loop 2069 Loss_Train:  [[ 13.25529452]] Loss_Validation:  [[ 10.83041524]]\n",
      "Loop 2070 Loss_Train:  [[ 13.25520026]] Loss_Validation:  [[ 10.8305947]]\n",
      "Loop 2071 Loss_Train:  [[ 13.25510616]] Loss_Validation:  [[ 10.83077399]]\n",
      "Loop 2072 Loss_Train:  [[ 13.25501221]] Loss_Validation:  [[ 10.83095311]]\n",
      "Loop 2073 Loss_Train:  [[ 13.25491842]] Loss_Validation:  [[ 10.83113208]]\n",
      "Loop 2074 Loss_Train:  [[ 13.25482478]] Loss_Validation:  [[ 10.83131088]]\n",
      "Loop 2075 Loss_Train:  [[ 13.25473129]] Loss_Validation:  [[ 10.83148952]]\n",
      "Loop 2076 Loss_Train:  [[ 13.25463797]] Loss_Validation:  [[ 10.831668]]\n",
      "Loop 2077 Loss_Train:  [[ 13.25454479]] Loss_Validation:  [[ 10.83184632]]\n",
      "Loop 2078 Loss_Train:  [[ 13.25445177]] Loss_Validation:  [[ 10.83202447]]\n",
      "Loop 2079 Loss_Train:  [[ 13.2543589]] Loss_Validation:  [[ 10.83220247]]\n",
      "Loop 2080 Loss_Train:  [[ 13.25426619]] Loss_Validation:  [[ 10.8323803]]\n",
      "Loop 2081 Loss_Train:  [[ 13.25417363]] Loss_Validation:  [[ 10.83255797]]\n",
      "Loop 2082 Loss_Train:  [[ 13.25408122]] Loss_Validation:  [[ 10.83273548]]\n",
      "Loop 2083 Loss_Train:  [[ 13.25398896]] Loss_Validation:  [[ 10.83291283]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2084 Loss_Train:  [[ 13.25389686]] Loss_Validation:  [[ 10.83309002]]\n",
      "Loop 2085 Loss_Train:  [[ 13.25380491]] Loss_Validation:  [[ 10.83326704]]\n",
      "Loop 2086 Loss_Train:  [[ 13.25371311]] Loss_Validation:  [[ 10.83344391]]\n",
      "Loop 2087 Loss_Train:  [[ 13.25362146]] Loss_Validation:  [[ 10.83362062]]\n",
      "Loop 2088 Loss_Train:  [[ 13.25352996]] Loss_Validation:  [[ 10.83379716]]\n",
      "Loop 2089 Loss_Train:  [[ 13.25343862]] Loss_Validation:  [[ 10.83397355]]\n",
      "Loop 2090 Loss_Train:  [[ 13.25334742]] Loss_Validation:  [[ 10.83414978]]\n",
      "Loop 2091 Loss_Train:  [[ 13.25325637]] Loss_Validation:  [[ 10.83432584]]\n",
      "Loop 2092 Loss_Train:  [[ 13.25316548]] Loss_Validation:  [[ 10.83450175]]\n",
      "Loop 2093 Loss_Train:  [[ 13.25307473]] Loss_Validation:  [[ 10.8346775]]\n",
      "Loop 2094 Loss_Train:  [[ 13.25298414]] Loss_Validation:  [[ 10.83485308]]\n",
      "Loop 2095 Loss_Train:  [[ 13.25289369]] Loss_Validation:  [[ 10.83502851]]\n",
      "Loop 2096 Loss_Train:  [[ 13.25280339]] Loss_Validation:  [[ 10.83520378]]\n",
      "Loop 2097 Loss_Train:  [[ 13.25271324]] Loss_Validation:  [[ 10.83537889]]\n",
      "Loop 2098 Loss_Train:  [[ 13.25262324]] Loss_Validation:  [[ 10.83555384]]\n",
      "Loop 2099 Loss_Train:  [[ 13.25253339]] Loss_Validation:  [[ 10.83572864]]\n",
      "Loop 2100 Loss_Train:  [[ 13.25244369]] Loss_Validation:  [[ 10.83590327]]\n",
      "Loop 2101 Loss_Train:  [[ 13.25235413]] Loss_Validation:  [[ 10.83607775]]\n",
      "Loop 2102 Loss_Train:  [[ 13.25226472]] Loss_Validation:  [[ 10.83625206]]\n",
      "Loop 2103 Loss_Train:  [[ 13.25217546]] Loss_Validation:  [[ 10.83642622]]\n",
      "Loop 2104 Loss_Train:  [[ 13.25208634]] Loss_Validation:  [[ 10.83660023]]\n",
      "Loop 2105 Loss_Train:  [[ 13.25199737]] Loss_Validation:  [[ 10.83677407]]\n",
      "Loop 2106 Loss_Train:  [[ 13.25190855]] Loss_Validation:  [[ 10.83694775]]\n",
      "Loop 2107 Loss_Train:  [[ 13.25181987]] Loss_Validation:  [[ 10.83712128]]\n",
      "Loop 2108 Loss_Train:  [[ 13.25173134]] Loss_Validation:  [[ 10.83729465]]\n",
      "Loop 2109 Loss_Train:  [[ 13.25164296]] Loss_Validation:  [[ 10.83746787]]\n",
      "Loop 2110 Loss_Train:  [[ 13.25155472]] Loss_Validation:  [[ 10.83764092]]\n",
      "Loop 2111 Loss_Train:  [[ 13.25146662]] Loss_Validation:  [[ 10.83781382]]\n",
      "Loop 2112 Loss_Train:  [[ 13.25137867]] Loss_Validation:  [[ 10.83798657]]\n",
      "Loop 2113 Loss_Train:  [[ 13.25129087]] Loss_Validation:  [[ 10.83815915]]\n",
      "Loop 2114 Loss_Train:  [[ 13.25120321]] Loss_Validation:  [[ 10.83833158]]\n",
      "Loop 2115 Loss_Train:  [[ 13.25111569]] Loss_Validation:  [[ 10.83850386]]\n",
      "Loop 2116 Loss_Train:  [[ 13.25102832]] Loss_Validation:  [[ 10.83867597]]\n",
      "Loop 2117 Loss_Train:  [[ 13.25094109]] Loss_Validation:  [[ 10.83884793]]\n",
      "Loop 2118 Loss_Train:  [[ 13.250854]] Loss_Validation:  [[ 10.83901974]]\n",
      "Loop 2119 Loss_Train:  [[ 13.25076706]] Loss_Validation:  [[ 10.83919139]]\n",
      "Loop 2120 Loss_Train:  [[ 13.25068026]] Loss_Validation:  [[ 10.83936288]]\n",
      "Loop 2121 Loss_Train:  [[ 13.2505936]] Loss_Validation:  [[ 10.83953422]]\n",
      "Loop 2122 Loss_Train:  [[ 13.25050708]] Loss_Validation:  [[ 10.8397054]]\n",
      "Loop 2123 Loss_Train:  [[ 13.25042071]] Loss_Validation:  [[ 10.83987643]]\n",
      "Loop 2124 Loss_Train:  [[ 13.25033448]] Loss_Validation:  [[ 10.8400473]]\n",
      "Loop 2125 Loss_Train:  [[ 13.25024839]] Loss_Validation:  [[ 10.84021801]]\n",
      "Loop 2126 Loss_Train:  [[ 13.25016244]] Loss_Validation:  [[ 10.84038858]]\n",
      "Loop 2127 Loss_Train:  [[ 13.25007663]] Loss_Validation:  [[ 10.84055898]]\n",
      "Loop 2128 Loss_Train:  [[ 13.24999096]] Loss_Validation:  [[ 10.84072924]]\n",
      "Loop 2129 Loss_Train:  [[ 13.24990544]] Loss_Validation:  [[ 10.84089933]]\n",
      "Loop 2130 Loss_Train:  [[ 13.24982005]] Loss_Validation:  [[ 10.84106928]]\n",
      "Loop 2131 Loss_Train:  [[ 13.2497348]] Loss_Validation:  [[ 10.84123907]]\n",
      "Loop 2132 Loss_Train:  [[ 13.24964969]] Loss_Validation:  [[ 10.8414087]]\n",
      "Loop 2133 Loss_Train:  [[ 13.24956473]] Loss_Validation:  [[ 10.84157819]]\n",
      "Loop 2134 Loss_Train:  [[ 13.2494799]] Loss_Validation:  [[ 10.84174751]]\n",
      "Loop 2135 Loss_Train:  [[ 13.24939521]] Loss_Validation:  [[ 10.84191669]]\n",
      "Loop 2136 Loss_Train:  [[ 13.24931066]] Loss_Validation:  [[ 10.84208571]]\n",
      "Loop 2137 Loss_Train:  [[ 13.24922625]] Loss_Validation:  [[ 10.84225458]]\n",
      "Loop 2138 Loss_Train:  [[ 13.24914197]] Loss_Validation:  [[ 10.84242329]]\n",
      "Loop 2139 Loss_Train:  [[ 13.24905784]] Loss_Validation:  [[ 10.84259185]]\n",
      "Loop 2140 Loss_Train:  [[ 13.24897384]] Loss_Validation:  [[ 10.84276026]]\n",
      "Loop 2141 Loss_Train:  [[ 13.24888998]] Loss_Validation:  [[ 10.84292852]]\n",
      "Loop 2142 Loss_Train:  [[ 13.24880625]] Loss_Validation:  [[ 10.84309662]]\n",
      "Loop 2143 Loss_Train:  [[ 13.24872267]] Loss_Validation:  [[ 10.84326457]]\n",
      "Loop 2144 Loss_Train:  [[ 13.24863922]] Loss_Validation:  [[ 10.84343237]]\n",
      "Loop 2145 Loss_Train:  [[ 13.2485559]] Loss_Validation:  [[ 10.84360002]]\n",
      "Loop 2146 Loss_Train:  [[ 13.24847273]] Loss_Validation:  [[ 10.84376751]]\n",
      "Loop 2147 Loss_Train:  [[ 13.24838969]] Loss_Validation:  [[ 10.84393485]]\n",
      "Loop 2148 Loss_Train:  [[ 13.24830678]] Loss_Validation:  [[ 10.84410204]]\n",
      "Loop 2149 Loss_Train:  [[ 13.24822401]] Loss_Validation:  [[ 10.84426908]]\n",
      "Loop 2150 Loss_Train:  [[ 13.24814138]] Loss_Validation:  [[ 10.84443597]]\n",
      "Loop 2151 Loss_Train:  [[ 13.24805888]] Loss_Validation:  [[ 10.84460271]]\n",
      "Loop 2152 Loss_Train:  [[ 13.24797652]] Loss_Validation:  [[ 10.84476929]]\n",
      "Loop 2153 Loss_Train:  [[ 13.24789429]] Loss_Validation:  [[ 10.84493572]]\n",
      "Loop 2154 Loss_Train:  [[ 13.24781219]] Loss_Validation:  [[ 10.84510201]]\n",
      "Loop 2155 Loss_Train:  [[ 13.24773023]] Loss_Validation:  [[ 10.84526814]]\n",
      "Loop 2156 Loss_Train:  [[ 13.24764841]] Loss_Validation:  [[ 10.84543412]]\n",
      "Loop 2157 Loss_Train:  [[ 13.24756671]] Loss_Validation:  [[ 10.84559995]]\n",
      "Loop 2158 Loss_Train:  [[ 13.24748515]] Loss_Validation:  [[ 10.84576563]]\n",
      "Loop 2159 Loss_Train:  [[ 13.24740373]] Loss_Validation:  [[ 10.84593116]]\n",
      "Loop 2160 Loss_Train:  [[ 13.24732243]] Loss_Validation:  [[ 10.84609654]]\n",
      "Loop 2161 Loss_Train:  [[ 13.24724127]] Loss_Validation:  [[ 10.84626177]]\n",
      "Loop 2162 Loss_Train:  [[ 13.24716025]] Loss_Validation:  [[ 10.84642685]]\n",
      "Loop 2163 Loss_Train:  [[ 13.24707935]] Loss_Validation:  [[ 10.84659179]]\n",
      "Loop 2164 Loss_Train:  [[ 13.24699859]] Loss_Validation:  [[ 10.84675657]]\n",
      "Loop 2165 Loss_Train:  [[ 13.24691795]] Loss_Validation:  [[ 10.8469212]]\n",
      "Loop 2166 Loss_Train:  [[ 13.24683745]] Loss_Validation:  [[ 10.84708568]]\n",
      "Loop 2167 Loss_Train:  [[ 13.24675709]] Loss_Validation:  [[ 10.84725002]]\n",
      "Loop 2168 Loss_Train:  [[ 13.24667685]] Loss_Validation:  [[ 10.8474142]]\n",
      "Loop 2169 Loss_Train:  [[ 13.24659674]] Loss_Validation:  [[ 10.84757824]]\n",
      "Loop 2170 Loss_Train:  [[ 13.24651677]] Loss_Validation:  [[ 10.84774212]]\n",
      "Loop 2171 Loss_Train:  [[ 13.24643692]] Loss_Validation:  [[ 10.84790586]]\n",
      "Loop 2172 Loss_Train:  [[ 13.2463572]] Loss_Validation:  [[ 10.84806945]]\n",
      "Loop 2173 Loss_Train:  [[ 13.24627762]] Loss_Validation:  [[ 10.8482329]]\n",
      "Loop 2174 Loss_Train:  [[ 13.24619816]] Loss_Validation:  [[ 10.84839619]]\n",
      "Loop 2175 Loss_Train:  [[ 13.24611884]] Loss_Validation:  [[ 10.84855933]]\n",
      "Loop 2176 Loss_Train:  [[ 13.24603964]] Loss_Validation:  [[ 10.84872233]]\n",
      "Loop 2177 Loss_Train:  [[ 13.24596057]] Loss_Validation:  [[ 10.84888518]]\n",
      "Loop 2178 Loss_Train:  [[ 13.24588163]] Loss_Validation:  [[ 10.84904789]]\n",
      "Loop 2179 Loss_Train:  [[ 13.24580282]] Loss_Validation:  [[ 10.84921044]]\n",
      "Loop 2180 Loss_Train:  [[ 13.24572414]] Loss_Validation:  [[ 10.84937285]]\n",
      "Loop 2181 Loss_Train:  [[ 13.24564559]] Loss_Validation:  [[ 10.84953511]]\n",
      "Loop 2182 Loss_Train:  [[ 13.24556716]] Loss_Validation:  [[ 10.84969722]]\n",
      "Loop 2183 Loss_Train:  [[ 13.24548886]] Loss_Validation:  [[ 10.84985919]]\n",
      "Loop 2184 Loss_Train:  [[ 13.24541069]] Loss_Validation:  [[ 10.85002101]]\n",
      "Loop 2185 Loss_Train:  [[ 13.24533265]] Loss_Validation:  [[ 10.85018269]]\n",
      "Loop 2186 Loss_Train:  [[ 13.24525473]] Loss_Validation:  [[ 10.85034421]]\n",
      "Loop 2187 Loss_Train:  [[ 13.24517694]] Loss_Validation:  [[ 10.85050559]]\n",
      "Loop 2188 Loss_Train:  [[ 13.24509928]] Loss_Validation:  [[ 10.85066683]]\n",
      "Loop 2189 Loss_Train:  [[ 13.24502174]] Loss_Validation:  [[ 10.85082792]]\n",
      "Loop 2190 Loss_Train:  [[ 13.24494433]] Loss_Validation:  [[ 10.85098886]]\n",
      "Loop 2191 Loss_Train:  [[ 13.24486705]] Loss_Validation:  [[ 10.85114966]]\n",
      "Loop 2192 Loss_Train:  [[ 13.24478989]] Loss_Validation:  [[ 10.85131031]]\n",
      "Loop 2193 Loss_Train:  [[ 13.24471286]] Loss_Validation:  [[ 10.85147081]]\n",
      "Loop 2194 Loss_Train:  [[ 13.24463595]] Loss_Validation:  [[ 10.85163117]]\n",
      "Loop 2195 Loss_Train:  [[ 13.24455917]] Loss_Validation:  [[ 10.85179139]]\n",
      "Loop 2196 Loss_Train:  [[ 13.24448251]] Loss_Validation:  [[ 10.85195146]]\n",
      "Loop 2197 Loss_Train:  [[ 13.24440597]] Loss_Validation:  [[ 10.85211138]]\n",
      "Loop 2198 Loss_Train:  [[ 13.24432956]] Loss_Validation:  [[ 10.85227116]]\n",
      "Loop 2199 Loss_Train:  [[ 13.24425328]] Loss_Validation:  [[ 10.8524308]]\n",
      "Loop 2200 Loss_Train:  [[ 13.24417712]] Loss_Validation:  [[ 10.85259029]]\n",
      "Loop 2201 Loss_Train:  [[ 13.24410108]] Loss_Validation:  [[ 10.85274964]]\n",
      "Loop 2202 Loss_Train:  [[ 13.24402517]] Loss_Validation:  [[ 10.85290884]]\n",
      "Loop 2203 Loss_Train:  [[ 13.24394938]] Loss_Validation:  [[ 10.8530679]]\n",
      "Loop 2204 Loss_Train:  [[ 13.24387371]] Loss_Validation:  [[ 10.85322681]]\n",
      "Loop 2205 Loss_Train:  [[ 13.24379817]] Loss_Validation:  [[ 10.85338558]]\n",
      "Loop 2206 Loss_Train:  [[ 13.24372275]] Loss_Validation:  [[ 10.85354421]]\n",
      "Loop 2207 Loss_Train:  [[ 13.24364745]] Loss_Validation:  [[ 10.85370269]]\n",
      "Loop 2208 Loss_Train:  [[ 13.24357227]] Loss_Validation:  [[ 10.85386103]]\n",
      "Loop 2209 Loss_Train:  [[ 13.24349721]] Loss_Validation:  [[ 10.85401923]]\n",
      "Loop 2210 Loss_Train:  [[ 13.24342228]] Loss_Validation:  [[ 10.85417728]]\n",
      "Loop 2211 Loss_Train:  [[ 13.24334747]] Loss_Validation:  [[ 10.85433519]]\n",
      "Loop 2212 Loss_Train:  [[ 13.24327278]] Loss_Validation:  [[ 10.85449296]]\n",
      "Loop 2213 Loss_Train:  [[ 13.24319821]] Loss_Validation:  [[ 10.85465059]]\n",
      "Loop 2214 Loss_Train:  [[ 13.24312376]] Loss_Validation:  [[ 10.85480807]]\n",
      "Loop 2215 Loss_Train:  [[ 13.24304944]] Loss_Validation:  [[ 10.85496541]]\n",
      "Loop 2216 Loss_Train:  [[ 13.24297523]] Loss_Validation:  [[ 10.8551226]]\n",
      "Loop 2217 Loss_Train:  [[ 13.24290114]] Loss_Validation:  [[ 10.85527966]]\n",
      "Loop 2218 Loss_Train:  [[ 13.24282718]] Loss_Validation:  [[ 10.85543657]]\n",
      "Loop 2219 Loss_Train:  [[ 13.24275333]] Loss_Validation:  [[ 10.85559334]]\n",
      "Loop 2220 Loss_Train:  [[ 13.2426796]] Loss_Validation:  [[ 10.85574997]]\n",
      "Loop 2221 Loss_Train:  [[ 13.242606]] Loss_Validation:  [[ 10.85590646]]\n",
      "Loop 2222 Loss_Train:  [[ 13.24253251]] Loss_Validation:  [[ 10.85606281]]\n",
      "Loop 2223 Loss_Train:  [[ 13.24245914]] Loss_Validation:  [[ 10.85621901]]\n",
      "Loop 2224 Loss_Train:  [[ 13.24238589]] Loss_Validation:  [[ 10.85637507]]\n",
      "Loop 2225 Loss_Train:  [[ 13.24231276]] Loss_Validation:  [[ 10.85653099]]\n",
      "Loop 2226 Loss_Train:  [[ 13.24223975]] Loss_Validation:  [[ 10.85668678]]\n",
      "Loop 2227 Loss_Train:  [[ 13.24216686]] Loss_Validation:  [[ 10.85684242]]\n",
      "Loop 2228 Loss_Train:  [[ 13.24209408]] Loss_Validation:  [[ 10.85699792]]\n",
      "Loop 2229 Loss_Train:  [[ 13.24202142]] Loss_Validation:  [[ 10.85715327]]\n",
      "Loop 2230 Loss_Train:  [[ 13.24194888]] Loss_Validation:  [[ 10.85730849]]\n",
      "Loop 2231 Loss_Train:  [[ 13.24187646]] Loss_Validation:  [[ 10.85746357]]\n",
      "Loop 2232 Loss_Train:  [[ 13.24180415]] Loss_Validation:  [[ 10.85761851]]\n",
      "Loop 2233 Loss_Train:  [[ 13.24173196]] Loss_Validation:  [[ 10.85777331]]\n",
      "Loop 2234 Loss_Train:  [[ 13.24165989]] Loss_Validation:  [[ 10.85792797]]\n",
      "Loop 2235 Loss_Train:  [[ 13.24158793]] Loss_Validation:  [[ 10.85808248]]\n",
      "Loop 2236 Loss_Train:  [[ 13.2415161]] Loss_Validation:  [[ 10.85823686]]\n",
      "Loop 2237 Loss_Train:  [[ 13.24144437]] Loss_Validation:  [[ 10.8583911]]\n",
      "Loop 2238 Loss_Train:  [[ 13.24137277]] Loss_Validation:  [[ 10.8585452]]\n",
      "Loop 2239 Loss_Train:  [[ 13.24130128]] Loss_Validation:  [[ 10.85869916]]\n",
      "Loop 2240 Loss_Train:  [[ 13.2412299]] Loss_Validation:  [[ 10.85885298]]\n",
      "Loop 2241 Loss_Train:  [[ 13.24115864]] Loss_Validation:  [[ 10.85900667]]\n",
      "Loop 2242 Loss_Train:  [[ 13.2410875]] Loss_Validation:  [[ 10.85916021]]\n",
      "Loop 2243 Loss_Train:  [[ 13.24101647]] Loss_Validation:  [[ 10.85931361]]\n",
      "Loop 2244 Loss_Train:  [[ 13.24094555]] Loss_Validation:  [[ 10.85946688]]\n",
      "Loop 2245 Loss_Train:  [[ 13.24087475]] Loss_Validation:  [[ 10.85962001]]\n",
      "Loop 2246 Loss_Train:  [[ 13.24080407]] Loss_Validation:  [[ 10.859773]]\n",
      "Loop 2247 Loss_Train:  [[ 13.24073349]] Loss_Validation:  [[ 10.85992585]]\n",
      "Loop 2248 Loss_Train:  [[ 13.24066304]] Loss_Validation:  [[ 10.86007856]]\n",
      "Loop 2249 Loss_Train:  [[ 13.24059269]] Loss_Validation:  [[ 10.86023114]]\n",
      "Loop 2250 Loss_Train:  [[ 13.24052246]] Loss_Validation:  [[ 10.86038358]]\n",
      "Loop 2251 Loss_Train:  [[ 13.24045235]] Loss_Validation:  [[ 10.86053588]]\n",
      "Loop 2252 Loss_Train:  [[ 13.24038234]] Loss_Validation:  [[ 10.86068804]]\n",
      "Loop 2253 Loss_Train:  [[ 13.24031245]] Loss_Validation:  [[ 10.86084006]]\n",
      "Loop 2254 Loss_Train:  [[ 13.24024268]] Loss_Validation:  [[ 10.86099195]]\n",
      "Loop 2255 Loss_Train:  [[ 13.24017301]] Loss_Validation:  [[ 10.8611437]]\n",
      "Loop 2256 Loss_Train:  [[ 13.24010346]] Loss_Validation:  [[ 10.86129532]]\n",
      "Loop 2257 Loss_Train:  [[ 13.24003402]] Loss_Validation:  [[ 10.86144679]]\n",
      "Loop 2258 Loss_Train:  [[ 13.23996469]] Loss_Validation:  [[ 10.86159813]]\n",
      "Loop 2259 Loss_Train:  [[ 13.23989548]] Loss_Validation:  [[ 10.86174934]]\n",
      "Loop 2260 Loss_Train:  [[ 13.23982637]] Loss_Validation:  [[ 10.8619004]]\n",
      "Loop 2261 Loss_Train:  [[ 13.23975738]] Loss_Validation:  [[ 10.86205133]]\n",
      "Loop 2262 Loss_Train:  [[ 13.2396885]] Loss_Validation:  [[ 10.86220213]]\n",
      "Loop 2263 Loss_Train:  [[ 13.23961973]] Loss_Validation:  [[ 10.86235279]]\n",
      "Loop 2264 Loss_Train:  [[ 13.23955107]] Loss_Validation:  [[ 10.86250331]]\n",
      "Loop 2265 Loss_Train:  [[ 13.23948252]] Loss_Validation:  [[ 10.8626537]]\n",
      "Loop 2266 Loss_Train:  [[ 13.23941408]] Loss_Validation:  [[ 10.86280395]]\n",
      "Loop 2267 Loss_Train:  [[ 13.23934575]] Loss_Validation:  [[ 10.86295407]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2268 Loss_Train:  [[ 13.23927754]] Loss_Validation:  [[ 10.86310405]]\n",
      "Loop 2269 Loss_Train:  [[ 13.23920943]] Loss_Validation:  [[ 10.86325389]]\n",
      "Loop 2270 Loss_Train:  [[ 13.23914143]] Loss_Validation:  [[ 10.8634036]]\n",
      "Loop 2271 Loss_Train:  [[ 13.23907354]] Loss_Validation:  [[ 10.86355318]]\n",
      "Loop 2272 Loss_Train:  [[ 13.23900576]] Loss_Validation:  [[ 10.86370262]]\n",
      "Loop 2273 Loss_Train:  [[ 13.23893809]] Loss_Validation:  [[ 10.86385192]]\n",
      "Loop 2274 Loss_Train:  [[ 13.23887053]] Loss_Validation:  [[ 10.86400109]]\n",
      "Loop 2275 Loss_Train:  [[ 13.23880308]] Loss_Validation:  [[ 10.86415013]]\n",
      "Loop 2276 Loss_Train:  [[ 13.23873574]] Loss_Validation:  [[ 10.86429903]]\n",
      "Loop 2277 Loss_Train:  [[ 13.2386685]] Loss_Validation:  [[ 10.8644478]]\n",
      "Loop 2278 Loss_Train:  [[ 13.23860138]] Loss_Validation:  [[ 10.86459643]]\n",
      "Loop 2279 Loss_Train:  [[ 13.23853436]] Loss_Validation:  [[ 10.86474493]]\n",
      "Loop 2280 Loss_Train:  [[ 13.23846745]] Loss_Validation:  [[ 10.8648933]]\n",
      "Loop 2281 Loss_Train:  [[ 13.23840064]] Loss_Validation:  [[ 10.86504153]]\n",
      "Loop 2282 Loss_Train:  [[ 13.23833395]] Loss_Validation:  [[ 10.86518963]]\n",
      "Loop 2283 Loss_Train:  [[ 13.23826736]] Loss_Validation:  [[ 10.8653376]]\n",
      "Loop 2284 Loss_Train:  [[ 13.23820088]] Loss_Validation:  [[ 10.86548543]]\n",
      "Loop 2285 Loss_Train:  [[ 13.23813451]] Loss_Validation:  [[ 10.86563313]]\n",
      "Loop 2286 Loss_Train:  [[ 13.23806824]] Loss_Validation:  [[ 10.8657807]]\n",
      "Loop 2287 Loss_Train:  [[ 13.23800208]] Loss_Validation:  [[ 10.86592813]]\n",
      "Loop 2288 Loss_Train:  [[ 13.23793603]] Loss_Validation:  [[ 10.86607543]]\n",
      "Loop 2289 Loss_Train:  [[ 13.23787008]] Loss_Validation:  [[ 10.8662226]]\n",
      "Loop 2290 Loss_Train:  [[ 13.23780424]] Loss_Validation:  [[ 10.86636963]]\n",
      "Loop 2291 Loss_Train:  [[ 13.2377385]] Loss_Validation:  [[ 10.86651654]]\n",
      "Loop 2292 Loss_Train:  [[ 13.23767287]] Loss_Validation:  [[ 10.86666331]]\n",
      "Loop 2293 Loss_Train:  [[ 13.23760735]] Loss_Validation:  [[ 10.86680995]]\n",
      "Loop 2294 Loss_Train:  [[ 13.23754193]] Loss_Validation:  [[ 10.86695645]]\n",
      "Loop 2295 Loss_Train:  [[ 13.23747661]] Loss_Validation:  [[ 10.86710283]]\n",
      "Loop 2296 Loss_Train:  [[ 13.23741141]] Loss_Validation:  [[ 10.86724907]]\n",
      "Loop 2297 Loss_Train:  [[ 13.2373463]] Loss_Validation:  [[ 10.86739518]]\n",
      "Loop 2298 Loss_Train:  [[ 13.2372813]] Loss_Validation:  [[ 10.86754116]]\n",
      "Loop 2299 Loss_Train:  [[ 13.23721641]] Loss_Validation:  [[ 10.86768701]]\n",
      "Loop 2300 Loss_Train:  [[ 13.23715162]] Loss_Validation:  [[ 10.86783273]]\n",
      "Loop 2301 Loss_Train:  [[ 13.23708693]] Loss_Validation:  [[ 10.86797831]]\n",
      "Loop 2302 Loss_Train:  [[ 13.23702235]] Loss_Validation:  [[ 10.86812377]]\n",
      "Loop 2303 Loss_Train:  [[ 13.23695787]] Loss_Validation:  [[ 10.86826909]]\n",
      "Loop 2304 Loss_Train:  [[ 13.23689349]] Loss_Validation:  [[ 10.86841429]]\n",
      "Loop 2305 Loss_Train:  [[ 13.23682922]] Loss_Validation:  [[ 10.86855935]]\n",
      "Loop 2306 Loss_Train:  [[ 13.23676505]] Loss_Validation:  [[ 10.86870428]]\n",
      "Loop 2307 Loss_Train:  [[ 13.23670098]] Loss_Validation:  [[ 10.86884909]]\n",
      "Loop 2308 Loss_Train:  [[ 13.23663702]] Loss_Validation:  [[ 10.86899376]]\n",
      "Loop 2309 Loss_Train:  [[ 13.23657316]] Loss_Validation:  [[ 10.8691383]]\n",
      "Loop 2310 Loss_Train:  [[ 13.2365094]] Loss_Validation:  [[ 10.86928271]]\n",
      "Loop 2311 Loss_Train:  [[ 13.23644575]] Loss_Validation:  [[ 10.869427]]\n",
      "Loop 2312 Loss_Train:  [[ 13.23638219]] Loss_Validation:  [[ 10.86957115]]\n",
      "Loop 2313 Loss_Train:  [[ 13.23631874]] Loss_Validation:  [[ 10.86971517]]\n",
      "Loop 2314 Loss_Train:  [[ 13.23625539]] Loss_Validation:  [[ 10.86985907]]\n",
      "Loop 2315 Loss_Train:  [[ 13.23619214]] Loss_Validation:  [[ 10.87000283]]\n",
      "Loop 2316 Loss_Train:  [[ 13.236129]] Loss_Validation:  [[ 10.87014647]]\n",
      "Loop 2317 Loss_Train:  [[ 13.23606595]] Loss_Validation:  [[ 10.87028997]]\n",
      "Loop 2318 Loss_Train:  [[ 13.23600301]] Loss_Validation:  [[ 10.87043335]]\n",
      "Loop 2319 Loss_Train:  [[ 13.23594016]] Loss_Validation:  [[ 10.8705766]]\n",
      "Loop 2320 Loss_Train:  [[ 13.23587742]] Loss_Validation:  [[ 10.87071972]]\n",
      "Loop 2321 Loss_Train:  [[ 13.23581478]] Loss_Validation:  [[ 10.87086271]]\n",
      "Loop 2322 Loss_Train:  [[ 13.23575223]] Loss_Validation:  [[ 10.87100558]]\n",
      "Loop 2323 Loss_Train:  [[ 13.23568979]] Loss_Validation:  [[ 10.87114831]]\n",
      "Loop 2324 Loss_Train:  [[ 13.23562745]] Loss_Validation:  [[ 10.87129092]]\n",
      "Loop 2325 Loss_Train:  [[ 13.23556521]] Loss_Validation:  [[ 10.8714334]]\n",
      "Loop 2326 Loss_Train:  [[ 13.23550307]] Loss_Validation:  [[ 10.87157575]]\n",
      "Loop 2327 Loss_Train:  [[ 13.23544103]] Loss_Validation:  [[ 10.87171797]]\n",
      "Loop 2328 Loss_Train:  [[ 13.23537908]] Loss_Validation:  [[ 10.87186007]]\n",
      "Loop 2329 Loss_Train:  [[ 13.23531724]] Loss_Validation:  [[ 10.87200203]]\n",
      "Loop 2330 Loss_Train:  [[ 13.23525549]] Loss_Validation:  [[ 10.87214388]]\n",
      "Loop 2331 Loss_Train:  [[ 13.23519385]] Loss_Validation:  [[ 10.87228559]]\n",
      "Loop 2332 Loss_Train:  [[ 13.2351323]] Loss_Validation:  [[ 10.87242718]]\n",
      "Loop 2333 Loss_Train:  [[ 13.23507085]] Loss_Validation:  [[ 10.87256863]]\n",
      "Loop 2334 Loss_Train:  [[ 13.2350095]] Loss_Validation:  [[ 10.87270997]]\n",
      "Loop 2335 Loss_Train:  [[ 13.23494825]] Loss_Validation:  [[ 10.87285117]]\n",
      "Loop 2336 Loss_Train:  [[ 13.2348871]] Loss_Validation:  [[ 10.87299225]]\n",
      "Loop 2337 Loss_Train:  [[ 13.23482604]] Loss_Validation:  [[ 10.8731332]]\n",
      "Loop 2338 Loss_Train:  [[ 13.23476508]] Loss_Validation:  [[ 10.87327403]]\n",
      "Loop 2339 Loss_Train:  [[ 13.23470422]] Loss_Validation:  [[ 10.87341473]]\n",
      "Loop 2340 Loss_Train:  [[ 13.23464346]] Loss_Validation:  [[ 10.8735553]]\n",
      "Loop 2341 Loss_Train:  [[ 13.23458279]] Loss_Validation:  [[ 10.87369575]]\n",
      "Loop 2342 Loss_Train:  [[ 13.23452222]] Loss_Validation:  [[ 10.87383607]]\n",
      "Loop 2343 Loss_Train:  [[ 13.23446175]] Loss_Validation:  [[ 10.87397627]]\n",
      "Loop 2344 Loss_Train:  [[ 13.23440137]] Loss_Validation:  [[ 10.87411634]]\n",
      "Loop 2345 Loss_Train:  [[ 13.23434109]] Loss_Validation:  [[ 10.87425629]]\n",
      "Loop 2346 Loss_Train:  [[ 13.23428091]] Loss_Validation:  [[ 10.87439611]]\n",
      "Loop 2347 Loss_Train:  [[ 13.23422082]] Loss_Validation:  [[ 10.8745358]]\n",
      "Loop 2348 Loss_Train:  [[ 13.23416083]] Loss_Validation:  [[ 10.87467537]]\n",
      "Loop 2349 Loss_Train:  [[ 13.23410094]] Loss_Validation:  [[ 10.87481481]]\n",
      "Loop 2350 Loss_Train:  [[ 13.23404114]] Loss_Validation:  [[ 10.87495413]]\n",
      "Loop 2351 Loss_Train:  [[ 13.23398144]] Loss_Validation:  [[ 10.87509333]]\n",
      "Loop 2352 Loss_Train:  [[ 13.23392183]] Loss_Validation:  [[ 10.8752324]]\n",
      "Loop 2353 Loss_Train:  [[ 13.23386232]] Loss_Validation:  [[ 10.87537134]]\n",
      "Loop 2354 Loss_Train:  [[ 13.2338029]] Loss_Validation:  [[ 10.87551016]]\n",
      "Loop 2355 Loss_Train:  [[ 13.23374357]] Loss_Validation:  [[ 10.87564886]]\n",
      "Loop 2356 Loss_Train:  [[ 13.23368435]] Loss_Validation:  [[ 10.87578743]]\n",
      "Loop 2357 Loss_Train:  [[ 13.23362521]] Loss_Validation:  [[ 10.87592588]]\n",
      "Loop 2358 Loss_Train:  [[ 13.23356617]] Loss_Validation:  [[ 10.87606421]]\n",
      "Loop 2359 Loss_Train:  [[ 13.23350723]] Loss_Validation:  [[ 10.87620241]]\n",
      "Loop 2360 Loss_Train:  [[ 13.23344838]] Loss_Validation:  [[ 10.87634049]]\n",
      "Loop 2361 Loss_Train:  [[ 13.23338962]] Loss_Validation:  [[ 10.87647844]]\n",
      "Loop 2362 Loss_Train:  [[ 13.23333096]] Loss_Validation:  [[ 10.87661627]]\n",
      "Loop 2363 Loss_Train:  [[ 13.23327239]] Loss_Validation:  [[ 10.87675398]]\n",
      "Loop 2364 Loss_Train:  [[ 13.23321391]] Loss_Validation:  [[ 10.87689156]]\n",
      "Loop 2365 Loss_Train:  [[ 13.23315553]] Loss_Validation:  [[ 10.87702902]]\n",
      "Loop 2366 Loss_Train:  [[ 13.23309724]] Loss_Validation:  [[ 10.87716636]]\n",
      "Loop 2367 Loss_Train:  [[ 13.23303905]] Loss_Validation:  [[ 10.87730358]]\n",
      "Loop 2368 Loss_Train:  [[ 13.23298094]] Loss_Validation:  [[ 10.87744067]]\n",
      "Loop 2369 Loss_Train:  [[ 13.23292293]] Loss_Validation:  [[ 10.87757764]]\n",
      "Loop 2370 Loss_Train:  [[ 13.23286501]] Loss_Validation:  [[ 10.87771449]]\n",
      "Loop 2371 Loss_Train:  [[ 13.23280719]] Loss_Validation:  [[ 10.87785121]]\n",
      "Loop 2372 Loss_Train:  [[ 13.23274945]] Loss_Validation:  [[ 10.87798781]]\n",
      "Loop 2373 Loss_Train:  [[ 13.23269181]] Loss_Validation:  [[ 10.8781243]]\n",
      "Loop 2374 Loss_Train:  [[ 13.23263426]] Loss_Validation:  [[ 10.87826065]]\n",
      "Loop 2375 Loss_Train:  [[ 13.2325768]] Loss_Validation:  [[ 10.87839689]]\n",
      "Loop 2376 Loss_Train:  [[ 13.23251944]] Loss_Validation:  [[ 10.87853301]]\n",
      "Loop 2377 Loss_Train:  [[ 13.23246216]] Loss_Validation:  [[ 10.878669]]\n",
      "Loop 2378 Loss_Train:  [[ 13.23240498]] Loss_Validation:  [[ 10.87880487]]\n",
      "Loop 2379 Loss_Train:  [[ 13.23234789]] Loss_Validation:  [[ 10.87894063]]\n",
      "Loop 2380 Loss_Train:  [[ 13.23229088]] Loss_Validation:  [[ 10.87907626]]\n",
      "Loop 2381 Loss_Train:  [[ 13.23223397]] Loss_Validation:  [[ 10.87921177]]\n",
      "Loop 2382 Loss_Train:  [[ 13.23217715]] Loss_Validation:  [[ 10.87934715]]\n",
      "Loop 2383 Loss_Train:  [[ 13.23212042]] Loss_Validation:  [[ 10.87948242]]\n",
      "Loop 2384 Loss_Train:  [[ 13.23206378]] Loss_Validation:  [[ 10.87961757]]\n",
      "Loop 2385 Loss_Train:  [[ 13.23200724]] Loss_Validation:  [[ 10.87975259]]\n",
      "Loop 2386 Loss_Train:  [[ 13.23195078]] Loss_Validation:  [[ 10.8798875]]\n",
      "Loop 2387 Loss_Train:  [[ 13.23189441]] Loss_Validation:  [[ 10.88002228]]\n",
      "Loop 2388 Loss_Train:  [[ 13.23183813]] Loss_Validation:  [[ 10.88015695]]\n",
      "Loop 2389 Loss_Train:  [[ 13.23178194]] Loss_Validation:  [[ 10.88029149]]\n",
      "Loop 2390 Loss_Train:  [[ 13.23172584]] Loss_Validation:  [[ 10.88042592]]\n",
      "Loop 2391 Loss_Train:  [[ 13.23166983]] Loss_Validation:  [[ 10.88056022]]\n",
      "Loop 2392 Loss_Train:  [[ 13.2316139]] Loss_Validation:  [[ 10.88069441]]\n",
      "Loop 2393 Loss_Train:  [[ 13.23155807]] Loss_Validation:  [[ 10.88082847]]\n",
      "Loop 2394 Loss_Train:  [[ 13.23150233]] Loss_Validation:  [[ 10.88096242]]\n",
      "Loop 2395 Loss_Train:  [[ 13.23144667]] Loss_Validation:  [[ 10.88109625]]\n",
      "Loop 2396 Loss_Train:  [[ 13.23139111]] Loss_Validation:  [[ 10.88122995]]\n",
      "Loop 2397 Loss_Train:  [[ 13.23133563]] Loss_Validation:  [[ 10.88136354]]\n",
      "Loop 2398 Loss_Train:  [[ 13.23128024]] Loss_Validation:  [[ 10.88149701]]\n",
      "Loop 2399 Loss_Train:  [[ 13.23122494]] Loss_Validation:  [[ 10.88163036]]\n",
      "Loop 2400 Loss_Train:  [[ 13.23116972]] Loss_Validation:  [[ 10.88176359]]\n",
      "Loop 2401 Loss_Train:  [[ 13.23111459]] Loss_Validation:  [[ 10.88189671]]\n",
      "Loop 2402 Loss_Train:  [[ 13.23105956]] Loss_Validation:  [[ 10.8820297]]\n",
      "Loop 2403 Loss_Train:  [[ 13.23100461]] Loss_Validation:  [[ 10.88216257]]\n",
      "Loop 2404 Loss_Train:  [[ 13.23094974]] Loss_Validation:  [[ 10.88229533]]\n",
      "Loop 2405 Loss_Train:  [[ 13.23089496]] Loss_Validation:  [[ 10.88242797]]\n",
      "Loop 2406 Loss_Train:  [[ 13.23084028]] Loss_Validation:  [[ 10.88256049]]\n",
      "Loop 2407 Loss_Train:  [[ 13.23078567]] Loss_Validation:  [[ 10.8826929]]\n",
      "Loop 2408 Loss_Train:  [[ 13.23073116]] Loss_Validation:  [[ 10.88282518]]\n",
      "Loop 2409 Loss_Train:  [[ 13.23067673]] Loss_Validation:  [[ 10.88295735]]\n",
      "Loop 2410 Loss_Train:  [[ 13.23062238]] Loss_Validation:  [[ 10.8830894]]\n",
      "Loop 2411 Loss_Train:  [[ 13.23056813]] Loss_Validation:  [[ 10.88322133]]\n",
      "Loop 2412 Loss_Train:  [[ 13.23051396]] Loss_Validation:  [[ 10.88335315]]\n",
      "Loop 2413 Loss_Train:  [[ 13.23045987]] Loss_Validation:  [[ 10.88348484]]\n",
      "Loop 2414 Loss_Train:  [[ 13.23040588]] Loss_Validation:  [[ 10.88361642]]\n",
      "Loop 2415 Loss_Train:  [[ 13.23035196]] Loss_Validation:  [[ 10.88374789]]\n",
      "Loop 2416 Loss_Train:  [[ 13.23029814]] Loss_Validation:  [[ 10.88387923]]\n",
      "Loop 2417 Loss_Train:  [[ 13.2302444]] Loss_Validation:  [[ 10.88401046]]\n",
      "Loop 2418 Loss_Train:  [[ 13.23019074]] Loss_Validation:  [[ 10.88414158]]\n",
      "Loop 2419 Loss_Train:  [[ 13.23013717]] Loss_Validation:  [[ 10.88427257]]\n",
      "Loop 2420 Loss_Train:  [[ 13.23008368]] Loss_Validation:  [[ 10.88440345]]\n",
      "Loop 2421 Loss_Train:  [[ 13.23003028]] Loss_Validation:  [[ 10.88453422]]\n",
      "Loop 2422 Loss_Train:  [[ 13.22997696]] Loss_Validation:  [[ 10.88466486]]\n",
      "Loop 2423 Loss_Train:  [[ 13.22992373]] Loss_Validation:  [[ 10.8847954]]\n",
      "Loop 2424 Loss_Train:  [[ 13.22987059]] Loss_Validation:  [[ 10.88492581]]\n",
      "Loop 2425 Loss_Train:  [[ 13.22981752]] Loss_Validation:  [[ 10.88505611]]\n",
      "Loop 2426 Loss_Train:  [[ 13.22976454]] Loss_Validation:  [[ 10.8851863]]\n",
      "Loop 2427 Loss_Train:  [[ 13.22971165]] Loss_Validation:  [[ 10.88531636]]\n",
      "Loop 2428 Loss_Train:  [[ 13.22965884]] Loss_Validation:  [[ 10.88544632]]\n",
      "Loop 2429 Loss_Train:  [[ 13.22960611]] Loss_Validation:  [[ 10.88557615]]\n",
      "Loop 2430 Loss_Train:  [[ 13.22955347]] Loss_Validation:  [[ 10.88570588]]\n",
      "Loop 2431 Loss_Train:  [[ 13.22950091]] Loss_Validation:  [[ 10.88583548]]\n",
      "Loop 2432 Loss_Train:  [[ 13.22944843]] Loss_Validation:  [[ 10.88596497]]\n",
      "Loop 2433 Loss_Train:  [[ 13.22939604]] Loss_Validation:  [[ 10.88609435]]\n",
      "Loop 2434 Loss_Train:  [[ 13.22934373]] Loss_Validation:  [[ 10.88622361]]\n",
      "Loop 2435 Loss_Train:  [[ 13.2292915]] Loss_Validation:  [[ 10.88635276]]\n",
      "Loop 2436 Loss_Train:  [[ 13.22923936]] Loss_Validation:  [[ 10.88648179]]\n",
      "Loop 2437 Loss_Train:  [[ 13.2291873]] Loss_Validation:  [[ 10.88661071]]\n",
      "Loop 2438 Loss_Train:  [[ 13.22913532]] Loss_Validation:  [[ 10.88673952]]\n",
      "Loop 2439 Loss_Train:  [[ 13.22908342]] Loss_Validation:  [[ 10.88686821]]\n",
      "Loop 2440 Loss_Train:  [[ 13.2290316]] Loss_Validation:  [[ 10.88699678]]\n",
      "Loop 2441 Loss_Train:  [[ 13.22897987]] Loss_Validation:  [[ 10.88712524]]\n",
      "Loop 2442 Loss_Train:  [[ 13.22892822]] Loss_Validation:  [[ 10.88725359]]\n",
      "Loop 2443 Loss_Train:  [[ 13.22887665]] Loss_Validation:  [[ 10.88738182]]\n",
      "Loop 2444 Loss_Train:  [[ 13.22882516]] Loss_Validation:  [[ 10.88750994]]\n",
      "Loop 2445 Loss_Train:  [[ 13.22877376]] Loss_Validation:  [[ 10.88763795]]\n",
      "Loop 2446 Loss_Train:  [[ 13.22872243]] Loss_Validation:  [[ 10.88776584]]\n",
      "Loop 2447 Loss_Train:  [[ 13.22867119]] Loss_Validation:  [[ 10.88789362]]\n",
      "Loop 2448 Loss_Train:  [[ 13.22862003]] Loss_Validation:  [[ 10.88802129]]\n",
      "Loop 2449 Loss_Train:  [[ 13.22856895]] Loss_Validation:  [[ 10.88814885]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2450 Loss_Train:  [[ 13.22851795]] Loss_Validation:  [[ 10.88827629]]\n",
      "Loop 2451 Loss_Train:  [[ 13.22846703]] Loss_Validation:  [[ 10.88840361]]\n",
      "Loop 2452 Loss_Train:  [[ 13.22841619]] Loss_Validation:  [[ 10.88853083]]\n",
      "Loop 2453 Loss_Train:  [[ 13.22836543]] Loss_Validation:  [[ 10.88865793]]\n",
      "Loop 2454 Loss_Train:  [[ 13.22831475]] Loss_Validation:  [[ 10.88878492]]\n",
      "Loop 2455 Loss_Train:  [[ 13.22826416]] Loss_Validation:  [[ 10.8889118]]\n",
      "Loop 2456 Loss_Train:  [[ 13.22821364]] Loss_Validation:  [[ 10.88903856]]\n",
      "Loop 2457 Loss_Train:  [[ 13.2281632]] Loss_Validation:  [[ 10.88916522]]\n",
      "Loop 2458 Loss_Train:  [[ 13.22811284]] Loss_Validation:  [[ 10.88929176]]\n",
      "Loop 2459 Loss_Train:  [[ 13.22806256]] Loss_Validation:  [[ 10.88941819]]\n",
      "Loop 2460 Loss_Train:  [[ 13.22801237]] Loss_Validation:  [[ 10.8895445]]\n",
      "Loop 2461 Loss_Train:  [[ 13.22796225]] Loss_Validation:  [[ 10.88967071]]\n",
      "Loop 2462 Loss_Train:  [[ 13.22791221]] Loss_Validation:  [[ 10.8897968]]\n",
      "Loop 2463 Loss_Train:  [[ 13.22786224]] Loss_Validation:  [[ 10.88992278]]\n",
      "Loop 2464 Loss_Train:  [[ 13.22781236]] Loss_Validation:  [[ 10.89004865]]\n",
      "Loop 2465 Loss_Train:  [[ 13.22776256]] Loss_Validation:  [[ 10.89017441]]\n",
      "Loop 2466 Loss_Train:  [[ 13.22771283]] Loss_Validation:  [[ 10.89030006]]\n",
      "Loop 2467 Loss_Train:  [[ 13.22766319]] Loss_Validation:  [[ 10.8904256]]\n",
      "Loop 2468 Loss_Train:  [[ 13.22761362]] Loss_Validation:  [[ 10.89055103]]\n",
      "Loop 2469 Loss_Train:  [[ 13.22756413]] Loss_Validation:  [[ 10.89067634]]\n",
      "Loop 2470 Loss_Train:  [[ 13.22751472]] Loss_Validation:  [[ 10.89080155]]\n",
      "Loop 2471 Loss_Train:  [[ 13.22746539]] Loss_Validation:  [[ 10.89092664]]\n",
      "Loop 2472 Loss_Train:  [[ 13.22741613]] Loss_Validation:  [[ 10.89105162]]\n",
      "Loop 2473 Loss_Train:  [[ 13.22736696]] Loss_Validation:  [[ 10.8911765]]\n",
      "Loop 2474 Loss_Train:  [[ 13.22731786]] Loss_Validation:  [[ 10.89130126]]\n",
      "Loop 2475 Loss_Train:  [[ 13.22726884]] Loss_Validation:  [[ 10.89142591]]\n",
      "Loop 2476 Loss_Train:  [[ 13.22721989]] Loss_Validation:  [[ 10.89155045]]\n",
      "Loop 2477 Loss_Train:  [[ 13.22717102]] Loss_Validation:  [[ 10.89167489]]\n",
      "Loop 2478 Loss_Train:  [[ 13.22712223]] Loss_Validation:  [[ 10.89179921]]\n",
      "Loop 2479 Loss_Train:  [[ 13.22707352]] Loss_Validation:  [[ 10.89192342]]\n",
      "Loop 2480 Loss_Train:  [[ 13.22702489]] Loss_Validation:  [[ 10.89204753]]\n",
      "Loop 2481 Loss_Train:  [[ 13.22697633]] Loss_Validation:  [[ 10.89217152]]\n",
      "Loop 2482 Loss_Train:  [[ 13.22692784]] Loss_Validation:  [[ 10.89229541]]\n",
      "Loop 2483 Loss_Train:  [[ 13.22687944]] Loss_Validation:  [[ 10.89241918]]\n",
      "Loop 2484 Loss_Train:  [[ 13.22683111]] Loss_Validation:  [[ 10.89254285]]\n",
      "Loop 2485 Loss_Train:  [[ 13.22678285]] Loss_Validation:  [[ 10.8926664]]\n",
      "Loop 2486 Loss_Train:  [[ 13.22673468]] Loss_Validation:  [[ 10.89278985]]\n",
      "Loop 2487 Loss_Train:  [[ 13.22668658]] Loss_Validation:  [[ 10.89291319]]\n",
      "Loop 2488 Loss_Train:  [[ 13.22663855]] Loss_Validation:  [[ 10.89303642]]\n",
      "Loop 2489 Loss_Train:  [[ 13.2265906]] Loss_Validation:  [[ 10.89315954]]\n",
      "Loop 2490 Loss_Train:  [[ 13.22654273]] Loss_Validation:  [[ 10.89328256]]\n",
      "Loop 2491 Loss_Train:  [[ 13.22649493]] Loss_Validation:  [[ 10.89340546]]\n",
      "Loop 2492 Loss_Train:  [[ 13.22644721]] Loss_Validation:  [[ 10.89352826]]\n",
      "Loop 2493 Loss_Train:  [[ 13.22639956]] Loss_Validation:  [[ 10.89365095]]\n",
      "Loop 2494 Loss_Train:  [[ 13.22635199]] Loss_Validation:  [[ 10.89377353]]\n",
      "Loop 2495 Loss_Train:  [[ 13.22630449]] Loss_Validation:  [[ 10.893896]]\n",
      "Loop 2496 Loss_Train:  [[ 13.22625707]] Loss_Validation:  [[ 10.89401836]]\n",
      "Loop 2497 Loss_Train:  [[ 13.22620972]] Loss_Validation:  [[ 10.89414062]]\n",
      "Loop 2498 Loss_Train:  [[ 13.22616244]] Loss_Validation:  [[ 10.89426277]]\n",
      "Loop 2499 Loss_Train:  [[ 13.22611525]] Loss_Validation:  [[ 10.89438481]]\n",
      "Loop 2500 Loss_Train:  [[ 13.22606812]] Loss_Validation:  [[ 10.89450675]]\n",
      "Loop 2501 Loss_Train:  [[ 13.22602107]] Loss_Validation:  [[ 10.89462857]]\n",
      "Loop 2502 Loss_Train:  [[ 13.2259741]] Loss_Validation:  [[ 10.89475029]]\n",
      "Loop 2503 Loss_Train:  [[ 13.22592719]] Loss_Validation:  [[ 10.8948719]]\n",
      "Loop 2504 Loss_Train:  [[ 13.22588037]] Loss_Validation:  [[ 10.89499341]]\n",
      "Loop 2505 Loss_Train:  [[ 13.22583361]] Loss_Validation:  [[ 10.89511481]]\n",
      "Loop 2506 Loss_Train:  [[ 13.22578693]] Loss_Validation:  [[ 10.8952361]]\n",
      "Loop 2507 Loss_Train:  [[ 13.22574032]] Loss_Validation:  [[ 10.89535729]]\n",
      "Loop 2508 Loss_Train:  [[ 13.22569379]] Loss_Validation:  [[ 10.89547836]]\n",
      "Loop 2509 Loss_Train:  [[ 13.22564733]] Loss_Validation:  [[ 10.89559934]]\n",
      "Loop 2510 Loss_Train:  [[ 13.22560094]] Loss_Validation:  [[ 10.8957202]]\n",
      "Loop 2511 Loss_Train:  [[ 13.22555463]] Loss_Validation:  [[ 10.89584096]]\n",
      "Loop 2512 Loss_Train:  [[ 13.22550839]] Loss_Validation:  [[ 10.89596161]]\n",
      "Loop 2513 Loss_Train:  [[ 13.22546222]] Loss_Validation:  [[ 10.89608216]]\n",
      "Loop 2514 Loss_Train:  [[ 13.22541612]] Loss_Validation:  [[ 10.8962026]]\n",
      "Loop 2515 Loss_Train:  [[ 13.2253701]] Loss_Validation:  [[ 10.89632294]]\n",
      "Loop 2516 Loss_Train:  [[ 13.22532415]] Loss_Validation:  [[ 10.89644317]]\n",
      "Loop 2517 Loss_Train:  [[ 13.22527827]] Loss_Validation:  [[ 10.89656329]]\n",
      "Loop 2518 Loss_Train:  [[ 13.22523246]] Loss_Validation:  [[ 10.89668331]]\n",
      "Loop 2519 Loss_Train:  [[ 13.22518673]] Loss_Validation:  [[ 10.89680323]]\n",
      "Loop 2520 Loss_Train:  [[ 13.22514107]] Loss_Validation:  [[ 10.89692303]]\n",
      "Loop 2521 Loss_Train:  [[ 13.22509548]] Loss_Validation:  [[ 10.89704274]]\n",
      "Loop 2522 Loss_Train:  [[ 13.22504996]] Loss_Validation:  [[ 10.89716233]]\n",
      "Loop 2523 Loss_Train:  [[ 13.22500451]] Loss_Validation:  [[ 10.89728183]]\n",
      "Loop 2524 Loss_Train:  [[ 13.22495914]] Loss_Validation:  [[ 10.89740122]]\n",
      "Loop 2525 Loss_Train:  [[ 13.22491383]] Loss_Validation:  [[ 10.8975205]]\n",
      "Loop 2526 Loss_Train:  [[ 13.2248686]] Loss_Validation:  [[ 10.89763968]]\n",
      "Loop 2527 Loss_Train:  [[ 13.22482344]] Loss_Validation:  [[ 10.89775875]]\n",
      "Loop 2528 Loss_Train:  [[ 13.22477835]] Loss_Validation:  [[ 10.89787772]]\n",
      "Loop 2529 Loss_Train:  [[ 13.22473333]] Loss_Validation:  [[ 10.89799659]]\n",
      "Loop 2530 Loss_Train:  [[ 13.22468838]] Loss_Validation:  [[ 10.89811535]]\n",
      "Loop 2531 Loss_Train:  [[ 13.2246435]] Loss_Validation:  [[ 10.89823401]]\n",
      "Loop 2532 Loss_Train:  [[ 13.22459869]] Loss_Validation:  [[ 10.89835256]]\n",
      "Loop 2533 Loss_Train:  [[ 13.22455396]] Loss_Validation:  [[ 10.89847101]]\n",
      "Loop 2534 Loss_Train:  [[ 13.22450929]] Loss_Validation:  [[ 10.89858935]]\n",
      "Loop 2535 Loss_Train:  [[ 13.22446469]] Loss_Validation:  [[ 10.8987076]]\n",
      "Loop 2536 Loss_Train:  [[ 13.22442016]] Loss_Validation:  [[ 10.89882573]]\n",
      "Loop 2537 Loss_Train:  [[ 13.22437571]] Loss_Validation:  [[ 10.89894377]]\n",
      "Loop 2538 Loss_Train:  [[ 13.22433132]] Loss_Validation:  [[ 10.8990617]]\n",
      "Loop 2539 Loss_Train:  [[ 13.224287]] Loss_Validation:  [[ 10.89917953]]\n",
      "Loop 2540 Loss_Train:  [[ 13.22424276]] Loss_Validation:  [[ 10.89929725]]\n",
      "Loop 2541 Loss_Train:  [[ 13.22419858]] Loss_Validation:  [[ 10.89941487]]\n",
      "Loop 2542 Loss_Train:  [[ 13.22415447]] Loss_Validation:  [[ 10.89953239]]\n",
      "Loop 2543 Loss_Train:  [[ 13.22411043]] Loss_Validation:  [[ 10.89964981]]\n",
      "Loop 2544 Loss_Train:  [[ 13.22406646]] Loss_Validation:  [[ 10.89976712]]\n",
      "Loop 2545 Loss_Train:  [[ 13.22402256]] Loss_Validation:  [[ 10.89988433]]\n",
      "Loop 2546 Loss_Train:  [[ 13.22397873]] Loss_Validation:  [[ 10.90000144]]\n",
      "Loop 2547 Loss_Train:  [[ 13.22393496]] Loss_Validation:  [[ 10.90011845]]\n",
      "Loop 2548 Loss_Train:  [[ 13.22389127]] Loss_Validation:  [[ 10.90023535]]\n",
      "Loop 2549 Loss_Train:  [[ 13.22384764]] Loss_Validation:  [[ 10.90035215]]\n",
      "Loop 2550 Loss_Train:  [[ 13.22380408]] Loss_Validation:  [[ 10.90046885]]\n",
      "Loop 2551 Loss_Train:  [[ 13.2237606]] Loss_Validation:  [[ 10.90058544]]\n",
      "Loop 2552 Loss_Train:  [[ 13.22371717]] Loss_Validation:  [[ 10.90070194]]\n",
      "Loop 2553 Loss_Train:  [[ 13.22367382]] Loss_Validation:  [[ 10.90081833]]\n",
      "Loop 2554 Loss_Train:  [[ 13.22363054]] Loss_Validation:  [[ 10.90093462]]\n",
      "Loop 2555 Loss_Train:  [[ 13.22358732]] Loss_Validation:  [[ 10.90105081]]\n",
      "Loop 2556 Loss_Train:  [[ 13.22354417]] Loss_Validation:  [[ 10.9011669]]\n",
      "Loop 2557 Loss_Train:  [[ 13.22350109]] Loss_Validation:  [[ 10.90128289]]\n",
      "Loop 2558 Loss_Train:  [[ 13.22345808]] Loss_Validation:  [[ 10.90139877]]\n",
      "Loop 2559 Loss_Train:  [[ 13.22341513]] Loss_Validation:  [[ 10.90151456]]\n",
      "Loop 2560 Loss_Train:  [[ 13.22337225]] Loss_Validation:  [[ 10.90163024]]\n",
      "Loop 2561 Loss_Train:  [[ 13.22332944]] Loss_Validation:  [[ 10.90174582]]\n",
      "Loop 2562 Loss_Train:  [[ 13.22328669]] Loss_Validation:  [[ 10.9018613]]\n",
      "Loop 2563 Loss_Train:  [[ 13.22324402]] Loss_Validation:  [[ 10.90197668]]\n",
      "Loop 2564 Loss_Train:  [[ 13.22320141]] Loss_Validation:  [[ 10.90209196]]\n",
      "Loop 2565 Loss_Train:  [[ 13.22315886]] Loss_Validation:  [[ 10.90220714]]\n",
      "Loop 2566 Loss_Train:  [[ 13.22311638]] Loss_Validation:  [[ 10.90232222]]\n",
      "Loop 2567 Loss_Train:  [[ 13.22307397]] Loss_Validation:  [[ 10.9024372]]\n",
      "Loop 2568 Loss_Train:  [[ 13.22303163]] Loss_Validation:  [[ 10.90255208]]\n",
      "Loop 2569 Loss_Train:  [[ 13.22298935]] Loss_Validation:  [[ 10.90266686]]\n",
      "Loop 2570 Loss_Train:  [[ 13.22294714]] Loss_Validation:  [[ 10.90278153]]\n",
      "Loop 2571 Loss_Train:  [[ 13.222905]] Loss_Validation:  [[ 10.90289611]]\n",
      "Loop 2572 Loss_Train:  [[ 13.22286292]] Loss_Validation:  [[ 10.90301059]]\n",
      "Loop 2573 Loss_Train:  [[ 13.2228209]] Loss_Validation:  [[ 10.90312497]]\n",
      "Loop 2574 Loss_Train:  [[ 13.22277896]] Loss_Validation:  [[ 10.90323924]]\n",
      "Loop 2575 Loss_Train:  [[ 13.22273707]] Loss_Validation:  [[ 10.90335342]]\n",
      "Loop 2576 Loss_Train:  [[ 13.22269526]] Loss_Validation:  [[ 10.9034675]]\n",
      "Loop 2577 Loss_Train:  [[ 13.22265351]] Loss_Validation:  [[ 10.90358148]]\n",
      "Loop 2578 Loss_Train:  [[ 13.22261182]] Loss_Validation:  [[ 10.90369536]]\n",
      "Loop 2579 Loss_Train:  [[ 13.2225702]] Loss_Validation:  [[ 10.90380914]]\n",
      "Loop 2580 Loss_Train:  [[ 13.22252865]] Loss_Validation:  [[ 10.90392283]]\n",
      "Loop 2581 Loss_Train:  [[ 13.22248716]] Loss_Validation:  [[ 10.90403641]]\n",
      "Loop 2582 Loss_Train:  [[ 13.22244573]] Loss_Validation:  [[ 10.90414989]]\n",
      "Loop 2583 Loss_Train:  [[ 13.22240437]] Loss_Validation:  [[ 10.90426328]]\n",
      "Loop 2584 Loss_Train:  [[ 13.22236308]] Loss_Validation:  [[ 10.90437657]]\n",
      "Loop 2585 Loss_Train:  [[ 13.22232185]] Loss_Validation:  [[ 10.90448975]]\n",
      "Loop 2586 Loss_Train:  [[ 13.22228068]] Loss_Validation:  [[ 10.90460284]]\n",
      "Loop 2587 Loss_Train:  [[ 13.22223958]] Loss_Validation:  [[ 10.90471583]]\n",
      "Loop 2588 Loss_Train:  [[ 13.22219854]] Loss_Validation:  [[ 10.90482873]]\n",
      "Loop 2589 Loss_Train:  [[ 13.22215757]] Loss_Validation:  [[ 10.90494152]]\n",
      "Loop 2590 Loss_Train:  [[ 13.22211666]] Loss_Validation:  [[ 10.90505422]]\n",
      "Loop 2591 Loss_Train:  [[ 13.22207582]] Loss_Validation:  [[ 10.90516682]]\n",
      "Loop 2592 Loss_Train:  [[ 13.22203503]] Loss_Validation:  [[ 10.90527932]]\n",
      "Loop 2593 Loss_Train:  [[ 13.22199432]] Loss_Validation:  [[ 10.90539172]]\n",
      "Loop 2594 Loss_Train:  [[ 13.22195366]] Loss_Validation:  [[ 10.90550403]]\n",
      "Loop 2595 Loss_Train:  [[ 13.22191307]] Loss_Validation:  [[ 10.90561624]]\n",
      "Loop 2596 Loss_Train:  [[ 13.22187255]] Loss_Validation:  [[ 10.90572835]]\n",
      "Loop 2597 Loss_Train:  [[ 13.22183209]] Loss_Validation:  [[ 10.90584036]]\n",
      "Loop 2598 Loss_Train:  [[ 13.22179169]] Loss_Validation:  [[ 10.90595228]]\n",
      "Loop 2599 Loss_Train:  [[ 13.22175135]] Loss_Validation:  [[ 10.90606409]]\n",
      "Loop 2600 Loss_Train:  [[ 13.22171108]] Loss_Validation:  [[ 10.90617582]]\n",
      "Loop 2601 Loss_Train:  [[ 13.22167087]] Loss_Validation:  [[ 10.90628744]]\n",
      "Loop 2602 Loss_Train:  [[ 13.22163072]] Loss_Validation:  [[ 10.90639897]]\n",
      "Loop 2603 Loss_Train:  [[ 13.22159063]] Loss_Validation:  [[ 10.9065104]]\n",
      "Loop 2604 Loss_Train:  [[ 13.22155061]] Loss_Validation:  [[ 10.90662173]]\n",
      "Loop 2605 Loss_Train:  [[ 13.22151065]] Loss_Validation:  [[ 10.90673297]]\n",
      "Loop 2606 Loss_Train:  [[ 13.22147075]] Loss_Validation:  [[ 10.90684411]]\n",
      "Loop 2607 Loss_Train:  [[ 13.22143092]] Loss_Validation:  [[ 10.90695515]]\n",
      "Loop 2608 Loss_Train:  [[ 13.22139115]] Loss_Validation:  [[ 10.9070661]]\n",
      "Loop 2609 Loss_Train:  [[ 13.22135144]] Loss_Validation:  [[ 10.90717695]]\n",
      "Loop 2610 Loss_Train:  [[ 13.22131179]] Loss_Validation:  [[ 10.90728771]]\n",
      "Loop 2611 Loss_Train:  [[ 13.2212722]] Loss_Validation:  [[ 10.90739837]]\n",
      "Loop 2612 Loss_Train:  [[ 13.22123268]] Loss_Validation:  [[ 10.90750893]]\n",
      "Loop 2613 Loss_Train:  [[ 13.22119321]] Loss_Validation:  [[ 10.9076194]]\n",
      "Loop 2614 Loss_Train:  [[ 13.22115381]] Loss_Validation:  [[ 10.90772977]]\n",
      "Loop 2615 Loss_Train:  [[ 13.22111447]] Loss_Validation:  [[ 10.90784005]]\n",
      "Loop 2616 Loss_Train:  [[ 13.2210752]] Loss_Validation:  [[ 10.90795023]]\n",
      "Loop 2617 Loss_Train:  [[ 13.22103598]] Loss_Validation:  [[ 10.90806032]]\n",
      "Loop 2618 Loss_Train:  [[ 13.22099682]] Loss_Validation:  [[ 10.90817031]]\n",
      "Loop 2619 Loss_Train:  [[ 13.22095773]] Loss_Validation:  [[ 10.9082802]]\n",
      "Loop 2620 Loss_Train:  [[ 13.2209187]] Loss_Validation:  [[ 10.90839]]\n",
      "Loop 2621 Loss_Train:  [[ 13.22087972]] Loss_Validation:  [[ 10.90849971]]\n",
      "Loop 2622 Loss_Train:  [[ 13.22084081]] Loss_Validation:  [[ 10.90860932]]\n",
      "Loop 2623 Loss_Train:  [[ 13.22080196]] Loss_Validation:  [[ 10.90871883]]\n",
      "Loop 2624 Loss_Train:  [[ 13.22076317]] Loss_Validation:  [[ 10.90882825]]\n",
      "Loop 2625 Loss_Train:  [[ 13.22072444]] Loss_Validation:  [[ 10.90893758]]\n",
      "Loop 2626 Loss_Train:  [[ 13.22068577]] Loss_Validation:  [[ 10.90904681]]\n",
      "Loop 2627 Loss_Train:  [[ 13.22064716]] Loss_Validation:  [[ 10.90915594]]\n",
      "Loop 2628 Loss_Train:  [[ 13.22060861]] Loss_Validation:  [[ 10.90926499]]\n",
      "Loop 2629 Loss_Train:  [[ 13.22057013]] Loss_Validation:  [[ 10.90937393]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2630 Loss_Train:  [[ 13.2205317]] Loss_Validation:  [[ 10.90948279]]\n",
      "Loop 2631 Loss_Train:  [[ 13.22049333]] Loss_Validation:  [[ 10.90959155]]\n",
      "Loop 2632 Loss_Train:  [[ 13.22045502]] Loss_Validation:  [[ 10.90970021]]\n",
      "Loop 2633 Loss_Train:  [[ 13.22041677]] Loss_Validation:  [[ 10.90980878]]\n",
      "Loop 2634 Loss_Train:  [[ 13.22037858]] Loss_Validation:  [[ 10.90991726]]\n",
      "Loop 2635 Loss_Train:  [[ 13.22034045]] Loss_Validation:  [[ 10.91002565]]\n",
      "Loop 2636 Loss_Train:  [[ 13.22030238]] Loss_Validation:  [[ 10.91013394]]\n",
      "Loop 2637 Loss_Train:  [[ 13.22026437]] Loss_Validation:  [[ 10.91024213]]\n",
      "Loop 2638 Loss_Train:  [[ 13.22022642]] Loss_Validation:  [[ 10.91035024]]\n",
      "Loop 2639 Loss_Train:  [[ 13.22018853]] Loss_Validation:  [[ 10.91045825]]\n",
      "Loop 2640 Loss_Train:  [[ 13.2201507]] Loss_Validation:  [[ 10.91056616]]\n",
      "Loop 2641 Loss_Train:  [[ 13.22011292]] Loss_Validation:  [[ 10.91067399]]\n",
      "Loop 2642 Loss_Train:  [[ 13.22007521]] Loss_Validation:  [[ 10.91078172]]\n",
      "Loop 2643 Loss_Train:  [[ 13.22003755]] Loss_Validation:  [[ 10.91088935]]\n",
      "Loop 2644 Loss_Train:  [[ 13.21999995]] Loss_Validation:  [[ 10.9109969]]\n",
      "Loop 2645 Loss_Train:  [[ 13.21996241]] Loss_Validation:  [[ 10.91110435]]\n",
      "Loop 2646 Loss_Train:  [[ 13.21992493]] Loss_Validation:  [[ 10.91121171]]\n",
      "Loop 2647 Loss_Train:  [[ 13.21988751]] Loss_Validation:  [[ 10.91131898]]\n",
      "Loop 2648 Loss_Train:  [[ 13.21985015]] Loss_Validation:  [[ 10.91142615]]\n",
      "Loop 2649 Loss_Train:  [[ 13.21981284]] Loss_Validation:  [[ 10.91153323]]\n",
      "Loop 2650 Loss_Train:  [[ 13.21977559]] Loss_Validation:  [[ 10.91164022]]\n",
      "Loop 2651 Loss_Train:  [[ 13.2197384]] Loss_Validation:  [[ 10.91174712]]\n",
      "Loop 2652 Loss_Train:  [[ 13.21970127]] Loss_Validation:  [[ 10.91185392]]\n",
      "Loop 2653 Loss_Train:  [[ 13.2196642]] Loss_Validation:  [[ 10.91196064]]\n",
      "Loop 2654 Loss_Train:  [[ 13.21962718]] Loss_Validation:  [[ 10.91206726]]\n",
      "Loop 2655 Loss_Train:  [[ 13.21959022]] Loss_Validation:  [[ 10.91217379]]\n",
      "Loop 2656 Loss_Train:  [[ 13.21955332]] Loss_Validation:  [[ 10.91228022]]\n",
      "Loop 2657 Loss_Train:  [[ 13.21951648]] Loss_Validation:  [[ 10.91238657]]\n",
      "Loop 2658 Loss_Train:  [[ 13.21947969]] Loss_Validation:  [[ 10.91249282]]\n",
      "Loop 2659 Loss_Train:  [[ 13.21944296]] Loss_Validation:  [[ 10.91259899]]\n",
      "Loop 2660 Loss_Train:  [[ 13.21940629]] Loss_Validation:  [[ 10.91270506]]\n",
      "Loop 2661 Loss_Train:  [[ 13.21936968]] Loss_Validation:  [[ 10.91281104]]\n",
      "Loop 2662 Loss_Train:  [[ 13.21933312]] Loss_Validation:  [[ 10.91291692]]\n",
      "Loop 2663 Loss_Train:  [[ 13.21929662]] Loss_Validation:  [[ 10.91302272]]\n",
      "Loop 2664 Loss_Train:  [[ 13.21926018]] Loss_Validation:  [[ 10.91312843]]\n",
      "Loop 2665 Loss_Train:  [[ 13.21922379]] Loss_Validation:  [[ 10.91323404]]\n",
      "Loop 2666 Loss_Train:  [[ 13.21918746]] Loss_Validation:  [[ 10.91333957]]\n",
      "Loop 2667 Loss_Train:  [[ 13.21915118]] Loss_Validation:  [[ 10.913445]]\n",
      "Loop 2668 Loss_Train:  [[ 13.21911497]] Loss_Validation:  [[ 10.91355035]]\n",
      "Loop 2669 Loss_Train:  [[ 13.21907881]] Loss_Validation:  [[ 10.9136556]]\n",
      "Loop 2670 Loss_Train:  [[ 13.2190427]] Loss_Validation:  [[ 10.91376076]]\n",
      "Loop 2671 Loss_Train:  [[ 13.21900665]] Loss_Validation:  [[ 10.91386583]]\n",
      "Loop 2672 Loss_Train:  [[ 13.21897066]] Loss_Validation:  [[ 10.91397081]]\n",
      "Loop 2673 Loss_Train:  [[ 13.21893472]] Loss_Validation:  [[ 10.91407571]]\n",
      "Loop 2674 Loss_Train:  [[ 13.21889884]] Loss_Validation:  [[ 10.91418051]]\n",
      "Loop 2675 Loss_Train:  [[ 13.21886302]] Loss_Validation:  [[ 10.91428522]]\n",
      "Loop 2676 Loss_Train:  [[ 13.21882725]] Loss_Validation:  [[ 10.91438984]]\n",
      "Loop 2677 Loss_Train:  [[ 13.21879154]] Loss_Validation:  [[ 10.91449437]]\n",
      "Loop 2678 Loss_Train:  [[ 13.21875588]] Loss_Validation:  [[ 10.91459881]]\n",
      "Loop 2679 Loss_Train:  [[ 13.21872027]] Loss_Validation:  [[ 10.91470316]]\n",
      "Loop 2680 Loss_Train:  [[ 13.21868473]] Loss_Validation:  [[ 10.91480743]]\n",
      "Loop 2681 Loss_Train:  [[ 13.21864924]] Loss_Validation:  [[ 10.9149116]]\n",
      "Loop 2682 Loss_Train:  [[ 13.2186138]] Loss_Validation:  [[ 10.91501568]]\n",
      "Loop 2683 Loss_Train:  [[ 13.21857842]] Loss_Validation:  [[ 10.91511968]]\n",
      "Loop 2684 Loss_Train:  [[ 13.21854309]] Loss_Validation:  [[ 10.91522358]]\n",
      "Loop 2685 Loss_Train:  [[ 13.21850782]] Loss_Validation:  [[ 10.9153274]]\n",
      "Loop 2686 Loss_Train:  [[ 13.2184726]] Loss_Validation:  [[ 10.91543113]]\n",
      "Loop 2687 Loss_Train:  [[ 13.21843744]] Loss_Validation:  [[ 10.91553476]]\n",
      "Loop 2688 Loss_Train:  [[ 13.21840233]] Loss_Validation:  [[ 10.91563831]]\n",
      "Loop 2689 Loss_Train:  [[ 13.21836728]] Loss_Validation:  [[ 10.91574177]]\n",
      "Loop 2690 Loss_Train:  [[ 13.21833228]] Loss_Validation:  [[ 10.91584515]]\n",
      "Loop 2691 Loss_Train:  [[ 13.21829734]] Loss_Validation:  [[ 10.91594843]]\n",
      "Loop 2692 Loss_Train:  [[ 13.21826245]] Loss_Validation:  [[ 10.91605162]]\n",
      "Loop 2693 Loss_Train:  [[ 13.21822761]] Loss_Validation:  [[ 10.91615473]]\n",
      "Loop 2694 Loss_Train:  [[ 13.21819283]] Loss_Validation:  [[ 10.91625775]]\n",
      "Loop 2695 Loss_Train:  [[ 13.2181581]] Loss_Validation:  [[ 10.91636068]]\n",
      "Loop 2696 Loss_Train:  [[ 13.21812343]] Loss_Validation:  [[ 10.91646352]]\n",
      "Loop 2697 Loss_Train:  [[ 13.21808881]] Loss_Validation:  [[ 10.91656627]]\n",
      "Loop 2698 Loss_Train:  [[ 13.21805424]] Loss_Validation:  [[ 10.91666894]]\n",
      "Loop 2699 Loss_Train:  [[ 13.21801973]] Loss_Validation:  [[ 10.91677151]]\n",
      "Loop 2700 Loss_Train:  [[ 13.21798527]] Loss_Validation:  [[ 10.916874]]\n",
      "Loop 2701 Loss_Train:  [[ 13.21795087]] Loss_Validation:  [[ 10.91697641]]\n",
      "Loop 2702 Loss_Train:  [[ 13.21791652]] Loss_Validation:  [[ 10.91707872]]\n",
      "Loop 2703 Loss_Train:  [[ 13.21788222]] Loss_Validation:  [[ 10.91718095]]\n",
      "Loop 2704 Loss_Train:  [[ 13.21784797]] Loss_Validation:  [[ 10.91728309]]\n",
      "Loop 2705 Loss_Train:  [[ 13.21781378]] Loss_Validation:  [[ 10.91738514]]\n",
      "Loop 2706 Loss_Train:  [[ 13.21777964]] Loss_Validation:  [[ 10.9174871]]\n",
      "Loop 2707 Loss_Train:  [[ 13.21774555]] Loss_Validation:  [[ 10.91758898]]\n",
      "Loop 2708 Loss_Train:  [[ 13.21771152]] Loss_Validation:  [[ 10.91769077]]\n",
      "Loop 2709 Loss_Train:  [[ 13.21767754]] Loss_Validation:  [[ 10.91779248]]\n",
      "Loop 2710 Loss_Train:  [[ 13.21764361]] Loss_Validation:  [[ 10.91789409]]\n",
      "Loop 2711 Loss_Train:  [[ 13.21760974]] Loss_Validation:  [[ 10.91799562]]\n",
      "Loop 2712 Loss_Train:  [[ 13.21757592]] Loss_Validation:  [[ 10.91809707]]\n",
      "Loop 2713 Loss_Train:  [[ 13.21754215]] Loss_Validation:  [[ 10.91819842]]\n",
      "Loop 2714 Loss_Train:  [[ 13.21750843]] Loss_Validation:  [[ 10.91829969]]\n",
      "Loop 2715 Loss_Train:  [[ 13.21747476]] Loss_Validation:  [[ 10.91840088]]\n",
      "Loop 2716 Loss_Train:  [[ 13.21744115]] Loss_Validation:  [[ 10.91850197]]\n",
      "Loop 2717 Loss_Train:  [[ 13.21740759]] Loss_Validation:  [[ 10.91860298]]\n",
      "Loop 2718 Loss_Train:  [[ 13.21737408]] Loss_Validation:  [[ 10.91870391]]\n",
      "Loop 2719 Loss_Train:  [[ 13.21734063]] Loss_Validation:  [[ 10.91880475]]\n",
      "Loop 2720 Loss_Train:  [[ 13.21730722]] Loss_Validation:  [[ 10.9189055]]\n",
      "Loop 2721 Loss_Train:  [[ 13.21727387]] Loss_Validation:  [[ 10.91900617]]\n",
      "Loop 2722 Loss_Train:  [[ 13.21724057]] Loss_Validation:  [[ 10.91910675]]\n",
      "Loop 2723 Loss_Train:  [[ 13.21720732]] Loss_Validation:  [[ 10.91920724]]\n",
      "Loop 2724 Loss_Train:  [[ 13.21717412]] Loss_Validation:  [[ 10.91930765]]\n",
      "Loop 2725 Loss_Train:  [[ 13.21714097]] Loss_Validation:  [[ 10.91940797]]\n",
      "Loop 2726 Loss_Train:  [[ 13.21710788]] Loss_Validation:  [[ 10.91950821]]\n",
      "Loop 2727 Loss_Train:  [[ 13.21707483]] Loss_Validation:  [[ 10.91960837]]\n",
      "Loop 2728 Loss_Train:  [[ 13.21704184]] Loss_Validation:  [[ 10.91970843]]\n",
      "Loop 2729 Loss_Train:  [[ 13.2170089]] Loss_Validation:  [[ 10.91980841]]\n",
      "Loop 2730 Loss_Train:  [[ 13.21697601]] Loss_Validation:  [[ 10.91990831]]\n",
      "Loop 2731 Loss_Train:  [[ 13.21694317]] Loss_Validation:  [[ 10.92000812]]\n",
      "Loop 2732 Loss_Train:  [[ 13.21691038]] Loss_Validation:  [[ 10.92010785]]\n",
      "Loop 2733 Loss_Train:  [[ 13.21687764]] Loss_Validation:  [[ 10.92020749]]\n",
      "Loop 2734 Loss_Train:  [[ 13.21684495]] Loss_Validation:  [[ 10.92030705]]\n",
      "Loop 2735 Loss_Train:  [[ 13.21681232]] Loss_Validation:  [[ 10.92040652]]\n",
      "Loop 2736 Loss_Train:  [[ 13.21677973]] Loss_Validation:  [[ 10.92050591]]\n",
      "Loop 2737 Loss_Train:  [[ 13.2167472]] Loss_Validation:  [[ 10.92060521]]\n",
      "Loop 2738 Loss_Train:  [[ 13.21671471]] Loss_Validation:  [[ 10.92070443]]\n",
      "Loop 2739 Loss_Train:  [[ 13.21668228]] Loss_Validation:  [[ 10.92080356]]\n",
      "Loop 2740 Loss_Train:  [[ 13.21664989]] Loss_Validation:  [[ 10.92090261]]\n",
      "Loop 2741 Loss_Train:  [[ 13.21661756]] Loss_Validation:  [[ 10.92100158]]\n",
      "Loop 2742 Loss_Train:  [[ 13.21658527]] Loss_Validation:  [[ 10.92110046]]\n",
      "Loop 2743 Loss_Train:  [[ 13.21655304]] Loss_Validation:  [[ 10.92119926]]\n",
      "Loop 2744 Loss_Train:  [[ 13.21652085]] Loss_Validation:  [[ 10.92129797]]\n",
      "Loop 2745 Loss_Train:  [[ 13.21648872]] Loss_Validation:  [[ 10.9213966]]\n",
      "Loop 2746 Loss_Train:  [[ 13.21645663]] Loss_Validation:  [[ 10.92149514]]\n",
      "Loop 2747 Loss_Train:  [[ 13.2164246]] Loss_Validation:  [[ 10.92159361]]\n",
      "Loop 2748 Loss_Train:  [[ 13.21639261]] Loss_Validation:  [[ 10.92169198]]\n",
      "Loop 2749 Loss_Train:  [[ 13.21636068]] Loss_Validation:  [[ 10.92179028]]\n",
      "Loop 2750 Loss_Train:  [[ 13.21632879]] Loss_Validation:  [[ 10.92188849]]\n",
      "Loop 2751 Loss_Train:  [[ 13.21629695]] Loss_Validation:  [[ 10.92198662]]\n",
      "Loop 2752 Loss_Train:  [[ 13.21626516]] Loss_Validation:  [[ 10.92208466]]\n",
      "Loop 2753 Loss_Train:  [[ 13.21623343]] Loss_Validation:  [[ 10.92218262]]\n",
      "Loop 2754 Loss_Train:  [[ 13.21620174]] Loss_Validation:  [[ 10.9222805]]\n",
      "Loop 2755 Loss_Train:  [[ 13.21617009]] Loss_Validation:  [[ 10.92237829]]\n",
      "Loop 2756 Loss_Train:  [[ 13.2161385]] Loss_Validation:  [[ 10.92247601]]\n",
      "Loop 2757 Loss_Train:  [[ 13.21610696]] Loss_Validation:  [[ 10.92257363]]\n",
      "Loop 2758 Loss_Train:  [[ 13.21607547]] Loss_Validation:  [[ 10.92267118]]\n",
      "Loop 2759 Loss_Train:  [[ 13.21604402]] Loss_Validation:  [[ 10.92276864]]\n",
      "Loop 2760 Loss_Train:  [[ 13.21601262]] Loss_Validation:  [[ 10.92286602]]\n",
      "Loop 2761 Loss_Train:  [[ 13.21598128]] Loss_Validation:  [[ 10.92296332]]\n",
      "Loop 2762 Loss_Train:  [[ 13.21594998]] Loss_Validation:  [[ 10.92306054]]\n",
      "Loop 2763 Loss_Train:  [[ 13.21591872]] Loss_Validation:  [[ 10.92315767]]\n",
      "Loop 2764 Loss_Train:  [[ 13.21588752]] Loss_Validation:  [[ 10.92325472]]\n",
      "Loop 2765 Loss_Train:  [[ 13.21585637]] Loss_Validation:  [[ 10.92335169]]\n",
      "Loop 2766 Loss_Train:  [[ 13.21582526]] Loss_Validation:  [[ 10.92344858]]\n",
      "Loop 2767 Loss_Train:  [[ 13.2157942]] Loss_Validation:  [[ 10.92354538]]\n",
      "Loop 2768 Loss_Train:  [[ 13.21576319]] Loss_Validation:  [[ 10.9236421]]\n",
      "Loop 2769 Loss_Train:  [[ 13.21573223]] Loss_Validation:  [[ 10.92373874]]\n",
      "Loop 2770 Loss_Train:  [[ 13.21570131]] Loss_Validation:  [[ 10.9238353]]\n",
      "Loop 2771 Loss_Train:  [[ 13.21567045]] Loss_Validation:  [[ 10.92393178]]\n",
      "Loop 2772 Loss_Train:  [[ 13.21563963]] Loss_Validation:  [[ 10.92402817]]\n",
      "Loop 2773 Loss_Train:  [[ 13.21560886]] Loss_Validation:  [[ 10.92412449]]\n",
      "Loop 2774 Loss_Train:  [[ 13.21557813]] Loss_Validation:  [[ 10.92422072]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2775 Loss_Train:  [[ 13.21554746]] Loss_Validation:  [[ 10.92431687]]\n",
      "Loop 2776 Loss_Train:  [[ 13.21551683]] Loss_Validation:  [[ 10.92441294]]\n",
      "Loop 2777 Loss_Train:  [[ 13.21548625]] Loss_Validation:  [[ 10.92450893]]\n",
      "Loop 2778 Loss_Train:  [[ 13.21545571]] Loss_Validation:  [[ 10.92460483]]\n",
      "Loop 2779 Loss_Train:  [[ 13.21542522]] Loss_Validation:  [[ 10.92470066]]\n",
      "Loop 2780 Loss_Train:  [[ 13.21539478]] Loss_Validation:  [[ 10.9247964]]\n",
      "Loop 2781 Loss_Train:  [[ 13.21536439]] Loss_Validation:  [[ 10.92489207]]\n",
      "Loop 2782 Loss_Train:  [[ 13.21533404]] Loss_Validation:  [[ 10.92498765]]\n",
      "Loop 2783 Loss_Train:  [[ 13.21530375]] Loss_Validation:  [[ 10.92508315]]\n",
      "Loop 2784 Loss_Train:  [[ 13.21527349]] Loss_Validation:  [[ 10.92517857]]\n",
      "Loop 2785 Loss_Train:  [[ 13.21524329]] Loss_Validation:  [[ 10.92527391]]\n",
      "Loop 2786 Loss_Train:  [[ 13.21521313]] Loss_Validation:  [[ 10.92536917]]\n",
      "Loop 2787 Loss_Train:  [[ 13.21518302]] Loss_Validation:  [[ 10.92546435]]\n",
      "Loop 2788 Loss_Train:  [[ 13.21515295]] Loss_Validation:  [[ 10.92555945]]\n",
      "Loop 2789 Loss_Train:  [[ 13.21512293]] Loss_Validation:  [[ 10.92565447]]\n",
      "Loop 2790 Loss_Train:  [[ 13.21509296]] Loss_Validation:  [[ 10.92574941]]\n",
      "Loop 2791 Loss_Train:  [[ 13.21506303]] Loss_Validation:  [[ 10.92584427]]\n",
      "Loop 2792 Loss_Train:  [[ 13.21503315]] Loss_Validation:  [[ 10.92593905]]\n",
      "Loop 2793 Loss_Train:  [[ 13.21500331]] Loss_Validation:  [[ 10.92603375]]\n",
      "Loop 2794 Loss_Train:  [[ 13.21497353]] Loss_Validation:  [[ 10.92612836]]\n",
      "Loop 2795 Loss_Train:  [[ 13.21494378]] Loss_Validation:  [[ 10.9262229]]\n",
      "Loop 2796 Loss_Train:  [[ 13.21491409]] Loss_Validation:  [[ 10.92631736]]\n",
      "Loop 2797 Loss_Train:  [[ 13.21488444]] Loss_Validation:  [[ 10.92641174]]\n",
      "Loop 2798 Loss_Train:  [[ 13.21485483]] Loss_Validation:  [[ 10.92650604]]\n",
      "Loop 2799 Loss_Train:  [[ 13.21482527]] Loss_Validation:  [[ 10.92660026]]\n",
      "Loop 2800 Loss_Train:  [[ 13.21479576]] Loss_Validation:  [[ 10.9266944]]\n",
      "Loop 2801 Loss_Train:  [[ 13.21476629]] Loss_Validation:  [[ 10.92678846]]\n",
      "Loop 2802 Loss_Train:  [[ 13.21473687]] Loss_Validation:  [[ 10.92688245]]\n",
      "Loop 2803 Loss_Train:  [[ 13.21470749]] Loss_Validation:  [[ 10.92697635]]\n",
      "Loop 2804 Loss_Train:  [[ 13.21467816]] Loss_Validation:  [[ 10.92707017]]\n",
      "Loop 2805 Loss_Train:  [[ 13.21464887]] Loss_Validation:  [[ 10.92716392]]\n",
      "Loop 2806 Loss_Train:  [[ 13.21461963]] Loss_Validation:  [[ 10.92725759]]\n",
      "Loop 2807 Loss_Train:  [[ 13.21459043]] Loss_Validation:  [[ 10.92735117]]\n",
      "Loop 2808 Loss_Train:  [[ 13.21456128]] Loss_Validation:  [[ 10.92744468]]\n",
      "Loop 2809 Loss_Train:  [[ 13.21453217]] Loss_Validation:  [[ 10.92753811]]\n",
      "Loop 2810 Loss_Train:  [[ 13.21450311]] Loss_Validation:  [[ 10.92763146]]\n",
      "Loop 2811 Loss_Train:  [[ 13.21447409]] Loss_Validation:  [[ 10.92772473]]\n",
      "Loop 2812 Loss_Train:  [[ 13.21444512]] Loss_Validation:  [[ 10.92781793]]\n",
      "Loop 2813 Loss_Train:  [[ 13.2144162]] Loss_Validation:  [[ 10.92791104]]\n",
      "Loop 2814 Loss_Train:  [[ 13.21438731]] Loss_Validation:  [[ 10.92800408]]\n",
      "Loop 2815 Loss_Train:  [[ 13.21435847]] Loss_Validation:  [[ 10.92809704]]\n",
      "Loop 2816 Loss_Train:  [[ 13.21432968]] Loss_Validation:  [[ 10.92818992]]\n",
      "Loop 2817 Loss_Train:  [[ 13.21430093]] Loss_Validation:  [[ 10.92828272]]\n",
      "Loop 2818 Loss_Train:  [[ 13.21427223]] Loss_Validation:  [[ 10.92837545]]\n",
      "Loop 2819 Loss_Train:  [[ 13.21424356]] Loss_Validation:  [[ 10.92846809]]\n",
      "Loop 2820 Loss_Train:  [[ 13.21421495]] Loss_Validation:  [[ 10.92856066]]\n",
      "Loop 2821 Loss_Train:  [[ 13.21418638]] Loss_Validation:  [[ 10.92865315]]\n",
      "Loop 2822 Loss_Train:  [[ 13.21415785]] Loss_Validation:  [[ 10.92874557]]\n",
      "Loop 2823 Loss_Train:  [[ 13.21412936]] Loss_Validation:  [[ 10.9288379]]\n",
      "Loop 2824 Loss_Train:  [[ 13.21410092]] Loss_Validation:  [[ 10.92893016]]\n",
      "Loop 2825 Loss_Train:  [[ 13.21407252]] Loss_Validation:  [[ 10.92902234]]\n",
      "Loop 2826 Loss_Train:  [[ 13.21404417]] Loss_Validation:  [[ 10.92911445]]\n",
      "Loop 2827 Loss_Train:  [[ 13.21401586]] Loss_Validation:  [[ 10.92920647]]\n",
      "Loop 2828 Loss_Train:  [[ 13.2139876]] Loss_Validation:  [[ 10.92929842]]\n",
      "Loop 2829 Loss_Train:  [[ 13.21395937]] Loss_Validation:  [[ 10.92939029]]\n",
      "Loop 2830 Loss_Train:  [[ 13.2139312]] Loss_Validation:  [[ 10.92948209]]\n",
      "Loop 2831 Loss_Train:  [[ 13.21390306]] Loss_Validation:  [[ 10.9295738]]\n",
      "Loop 2832 Loss_Train:  [[ 13.21387497]] Loss_Validation:  [[ 10.92966545]]\n",
      "Loop 2833 Loss_Train:  [[ 13.21384692]] Loss_Validation:  [[ 10.92975701]]\n",
      "Loop 2834 Loss_Train:  [[ 13.21381891]] Loss_Validation:  [[ 10.9298485]]\n",
      "Loop 2835 Loss_Train:  [[ 13.21379095]] Loss_Validation:  [[ 10.92993991]]\n",
      "Loop 2836 Loss_Train:  [[ 13.21376303]] Loss_Validation:  [[ 10.93003124]]\n",
      "Loop 2837 Loss_Train:  [[ 13.21373515]] Loss_Validation:  [[ 10.9301225]]\n",
      "Loop 2838 Loss_Train:  [[ 13.21370732]] Loss_Validation:  [[ 10.93021368]]\n",
      "Loop 2839 Loss_Train:  [[ 13.21367953]] Loss_Validation:  [[ 10.93030478]]\n",
      "Loop 2840 Loss_Train:  [[ 13.21365178]] Loss_Validation:  [[ 10.93039581]]\n",
      "Loop 2841 Loss_Train:  [[ 13.21362408]] Loss_Validation:  [[ 10.93048676]]\n",
      "Loop 2842 Loss_Train:  [[ 13.21359642]] Loss_Validation:  [[ 10.93057764]]\n",
      "Loop 2843 Loss_Train:  [[ 13.2135688]] Loss_Validation:  [[ 10.93066844]]\n",
      "Loop 2844 Loss_Train:  [[ 13.21354122]] Loss_Validation:  [[ 10.93075916]]\n",
      "Loop 2845 Loss_Train:  [[ 13.21351368]] Loss_Validation:  [[ 10.93084981]]\n",
      "Loop 2846 Loss_Train:  [[ 13.21348619]] Loss_Validation:  [[ 10.93094038]]\n",
      "Loop 2847 Loss_Train:  [[ 13.21345874]] Loss_Validation:  [[ 10.93103087]]\n",
      "Loop 2848 Loss_Train:  [[ 13.21343133]] Loss_Validation:  [[ 10.93112129]]\n",
      "Loop 2849 Loss_Train:  [[ 13.21340397]] Loss_Validation:  [[ 10.93121164]]\n",
      "Loop 2850 Loss_Train:  [[ 13.21337664]] Loss_Validation:  [[ 10.93130191]]\n",
      "Loop 2851 Loss_Train:  [[ 13.21334936]] Loss_Validation:  [[ 10.9313921]]\n",
      "Loop 2852 Loss_Train:  [[ 13.21332212]] Loss_Validation:  [[ 10.93148222]]\n",
      "Loop 2853 Loss_Train:  [[ 13.21329492]] Loss_Validation:  [[ 10.93157226]]\n",
      "Loop 2854 Loss_Train:  [[ 13.21326777]] Loss_Validation:  [[ 10.93166223]]\n",
      "Loop 2855 Loss_Train:  [[ 13.21324065]] Loss_Validation:  [[ 10.93175212]]\n",
      "Loop 2856 Loss_Train:  [[ 13.21321358]] Loss_Validation:  [[ 10.93184193]]\n",
      "Loop 2857 Loss_Train:  [[ 13.21318655]] Loss_Validation:  [[ 10.93193168]]\n",
      "Loop 2858 Loss_Train:  [[ 13.21315956]] Loss_Validation:  [[ 10.93202134]]\n",
      "Loop 2859 Loss_Train:  [[ 13.21313261]] Loss_Validation:  [[ 10.93211093]]\n",
      "Loop 2860 Loss_Train:  [[ 13.21310571]] Loss_Validation:  [[ 10.93220045]]\n",
      "Loop 2861 Loss_Train:  [[ 13.21307884]] Loss_Validation:  [[ 10.93228989]]\n",
      "Loop 2862 Loss_Train:  [[ 13.21305202]] Loss_Validation:  [[ 10.93237926]]\n",
      "Loop 2863 Loss_Train:  [[ 13.21302524]] Loss_Validation:  [[ 10.93246855]]\n",
      "Loop 2864 Loss_Train:  [[ 13.21299849]] Loss_Validation:  [[ 10.93255777]]\n",
      "Loop 2865 Loss_Train:  [[ 13.21297179]] Loss_Validation:  [[ 10.93264692]]\n",
      "Loop 2866 Loss_Train:  [[ 13.21294514]] Loss_Validation:  [[ 10.93273599]]\n",
      "Loop 2867 Loss_Train:  [[ 13.21291852]] Loss_Validation:  [[ 10.93282498]]\n",
      "Loop 2868 Loss_Train:  [[ 13.21289194]] Loss_Validation:  [[ 10.9329139]]\n",
      "Loop 2869 Loss_Train:  [[ 13.2128654]] Loss_Validation:  [[ 10.93300275]]\n",
      "Loop 2870 Loss_Train:  [[ 13.21283891]] Loss_Validation:  [[ 10.93309152]]\n",
      "Loop 2871 Loss_Train:  [[ 13.21281245]] Loss_Validation:  [[ 10.93318022]]\n",
      "Loop 2872 Loss_Train:  [[ 13.21278604]] Loss_Validation:  [[ 10.93326884]]\n",
      "Loop 2873 Loss_Train:  [[ 13.21275967]] Loss_Validation:  [[ 10.9333574]]\n",
      "Loop 2874 Loss_Train:  [[ 13.21273333]] Loss_Validation:  [[ 10.93344587]]\n",
      "Loop 2875 Loss_Train:  [[ 13.21270704]] Loss_Validation:  [[ 10.93353428]]\n",
      "Loop 2876 Loss_Train:  [[ 13.21268079]] Loss_Validation:  [[ 10.93362261]]\n",
      "Loop 2877 Loss_Train:  [[ 13.21265458]] Loss_Validation:  [[ 10.93371086]]\n",
      "Loop 2878 Loss_Train:  [[ 13.2126284]] Loss_Validation:  [[ 10.93379904]]\n",
      "Loop 2879 Loss_Train:  [[ 13.21260227]] Loss_Validation:  [[ 10.93388715]]\n",
      "Loop 2880 Loss_Train:  [[ 13.21257618]] Loss_Validation:  [[ 10.93397519]]\n",
      "Loop 2881 Loss_Train:  [[ 13.21255013]] Loss_Validation:  [[ 10.93406315]]\n",
      "Loop 2882 Loss_Train:  [[ 13.21252412]] Loss_Validation:  [[ 10.93415104]]\n",
      "Loop 2883 Loss_Train:  [[ 13.21249815]] Loss_Validation:  [[ 10.93423886]]\n",
      "Loop 2884 Loss_Train:  [[ 13.21247222]] Loss_Validation:  [[ 10.9343266]]\n",
      "Loop 2885 Loss_Train:  [[ 13.21244633]] Loss_Validation:  [[ 10.93441427]]\n",
      "Loop 2886 Loss_Train:  [[ 13.21242047]] Loss_Validation:  [[ 10.93450187]]\n",
      "Loop 2887 Loss_Train:  [[ 13.21239466]] Loss_Validation:  [[ 10.93458939]]\n",
      "Loop 2888 Loss_Train:  [[ 13.21236889]] Loss_Validation:  [[ 10.93467684]]\n",
      "Loop 2889 Loss_Train:  [[ 13.21234316]] Loss_Validation:  [[ 10.93476422]]\n",
      "Loop 2890 Loss_Train:  [[ 13.21231746]] Loss_Validation:  [[ 10.93485153]]\n",
      "Loop 2891 Loss_Train:  [[ 13.21229181]] Loss_Validation:  [[ 10.93493876]]\n",
      "Loop 2892 Loss_Train:  [[ 13.2122662]] Loss_Validation:  [[ 10.93502592]]\n",
      "Loop 2893 Loss_Train:  [[ 13.21224062]] Loss_Validation:  [[ 10.93511301]]\n",
      "Loop 2894 Loss_Train:  [[ 13.21221509]] Loss_Validation:  [[ 10.93520002]]\n",
      "Loop 2895 Loss_Train:  [[ 13.21218959]] Loss_Validation:  [[ 10.93528697]]\n",
      "Loop 2896 Loss_Train:  [[ 13.21216413]] Loss_Validation:  [[ 10.93537384]]\n",
      "Loop 2897 Loss_Train:  [[ 13.21213871]] Loss_Validation:  [[ 10.93546064]]\n",
      "Loop 2898 Loss_Train:  [[ 13.21211333]] Loss_Validation:  [[ 10.93554737]]\n",
      "Loop 2899 Loss_Train:  [[ 13.21208799]] Loss_Validation:  [[ 10.93563402]]\n",
      "Loop 2900 Loss_Train:  [[ 13.21206269]] Loss_Validation:  [[ 10.9357206]]\n",
      "Loop 2901 Loss_Train:  [[ 13.21203743]] Loss_Validation:  [[ 10.93580712]]\n",
      "Loop 2902 Loss_Train:  [[ 13.2120122]] Loss_Validation:  [[ 10.93589356]]\n",
      "Loop 2903 Loss_Train:  [[ 13.21198702]] Loss_Validation:  [[ 10.93597992]]\n",
      "Loop 2904 Loss_Train:  [[ 13.21196187]] Loss_Validation:  [[ 10.93606622]]\n",
      "Loop 2905 Loss_Train:  [[ 13.21193676]] Loss_Validation:  [[ 10.93615245]]\n",
      "Loop 2906 Loss_Train:  [[ 13.2119117]] Loss_Validation:  [[ 10.9362386]]\n",
      "Loop 2907 Loss_Train:  [[ 13.21188666]] Loss_Validation:  [[ 10.93632468]]\n",
      "Loop 2908 Loss_Train:  [[ 13.21186167]] Loss_Validation:  [[ 10.93641069]]\n",
      "Loop 2909 Loss_Train:  [[ 13.21183672]] Loss_Validation:  [[ 10.93649663]]\n",
      "Loop 2910 Loss_Train:  [[ 13.2118118]] Loss_Validation:  [[ 10.9365825]]\n",
      "Loop 2911 Loss_Train:  [[ 13.21178692]] Loss_Validation:  [[ 10.93666829]]\n",
      "Loop 2912 Loss_Train:  [[ 13.21176208]] Loss_Validation:  [[ 10.93675402]]\n",
      "Loop 2913 Loss_Train:  [[ 13.21173728]] Loss_Validation:  [[ 10.93683967]]\n",
      "Loop 2914 Loss_Train:  [[ 13.21171252]] Loss_Validation:  [[ 10.93692526]]\n",
      "Loop 2915 Loss_Train:  [[ 13.21168779]] Loss_Validation:  [[ 10.93701077]]\n",
      "Loop 2916 Loss_Train:  [[ 13.21166311]] Loss_Validation:  [[ 10.93709621]]\n",
      "Loop 2917 Loss_Train:  [[ 13.21163846]] Loss_Validation:  [[ 10.93718158]]\n",
      "Loop 2918 Loss_Train:  [[ 13.21161384]] Loss_Validation:  [[ 10.93726688]]\n",
      "Loop 2919 Loss_Train:  [[ 13.21158927]] Loss_Validation:  [[ 10.93735211]]\n",
      "Loop 2920 Loss_Train:  [[ 13.21156473]] Loss_Validation:  [[ 10.93743727]]\n",
      "Loop 2921 Loss_Train:  [[ 13.21154023]] Loss_Validation:  [[ 10.93752236]]\n",
      "Loop 2922 Loss_Train:  [[ 13.21151577]] Loss_Validation:  [[ 10.93760738]]\n",
      "Loop 2923 Loss_Train:  [[ 13.21149135]] Loss_Validation:  [[ 10.93769233]]\n",
      "Loop 2924 Loss_Train:  [[ 13.21146696]] Loss_Validation:  [[ 10.93777721]]\n",
      "Loop 2925 Loss_Train:  [[ 13.21144261]] Loss_Validation:  [[ 10.93786201]]\n",
      "Loop 2926 Loss_Train:  [[ 13.2114183]] Loss_Validation:  [[ 10.93794675]]\n",
      "Loop 2927 Loss_Train:  [[ 13.21139403]] Loss_Validation:  [[ 10.93803142]]\n",
      "Loop 2928 Loss_Train:  [[ 13.21136979]] Loss_Validation:  [[ 10.93811602]]\n",
      "Loop 2929 Loss_Train:  [[ 13.21134559]] Loss_Validation:  [[ 10.93820054]]\n",
      "Loop 2930 Loss_Train:  [[ 13.21132142]] Loss_Validation:  [[ 10.938285]]\n",
      "Loop 2931 Loss_Train:  [[ 13.2112973]] Loss_Validation:  [[ 10.93836939]]\n",
      "Loop 2932 Loss_Train:  [[ 13.21127321]] Loss_Validation:  [[ 10.93845371]]\n",
      "Loop 2933 Loss_Train:  [[ 13.21124916]] Loss_Validation:  [[ 10.93853796]]\n",
      "Loop 2934 Loss_Train:  [[ 13.21122514]] Loss_Validation:  [[ 10.93862214]]\n",
      "Loop 2935 Loss_Train:  [[ 13.21120116]] Loss_Validation:  [[ 10.93870624]]\n",
      "Loop 2936 Loss_Train:  [[ 13.21117722]] Loss_Validation:  [[ 10.93879028]]\n",
      "Loop 2937 Loss_Train:  [[ 13.21115332]] Loss_Validation:  [[ 10.93887426]]\n",
      "Loop 2938 Loss_Train:  [[ 13.21112945]] Loss_Validation:  [[ 10.93895816]]\n",
      "Loop 2939 Loss_Train:  [[ 13.21110562]] Loss_Validation:  [[ 10.93904199]]\n",
      "Loop 2940 Loss_Train:  [[ 13.21108182]] Loss_Validation:  [[ 10.93912575]]\n",
      "Loop 2941 Loss_Train:  [[ 13.21105806]] Loss_Validation:  [[ 10.93920945]]\n",
      "Loop 2942 Loss_Train:  [[ 13.21103434]] Loss_Validation:  [[ 10.93929307]]\n",
      "Loop 2943 Loss_Train:  [[ 13.21101065]] Loss_Validation:  [[ 10.93937663]]\n",
      "Loop 2944 Loss_Train:  [[ 13.210987]] Loss_Validation:  [[ 10.93946011]]\n",
      "Loop 2945 Loss_Train:  [[ 13.21096339]] Loss_Validation:  [[ 10.93954353]]\n",
      "Loop 2946 Loss_Train:  [[ 13.21093981]] Loss_Validation:  [[ 10.93962688]]\n",
      "Loop 2947 Loss_Train:  [[ 13.21091627]] Loss_Validation:  [[ 10.93971016]]\n",
      "Loop 2948 Loss_Train:  [[ 13.21089276]] Loss_Validation:  [[ 10.93979337]]\n",
      "Loop 2949 Loss_Train:  [[ 13.21086929]] Loss_Validation:  [[ 10.93987652]]\n",
      "Loop 2950 Loss_Train:  [[ 13.21084586]] Loss_Validation:  [[ 10.93995959]]\n",
      "Loop 2951 Loss_Train:  [[ 13.21082246]] Loss_Validation:  [[ 10.9400426]]\n",
      "Loop 2952 Loss_Train:  [[ 13.2107991]] Loss_Validation:  [[ 10.94012554]]\n",
      "Loop 2953 Loss_Train:  [[ 13.21077577]] Loss_Validation:  [[ 10.94020841]]\n",
      "Loop 2954 Loss_Train:  [[ 13.21075248]] Loss_Validation:  [[ 10.94029121]]\n",
      "Loop 2955 Loss_Train:  [[ 13.21072923]] Loss_Validation:  [[ 10.94037394]]\n",
      "Loop 2956 Loss_Train:  [[ 13.21070601]] Loss_Validation:  [[ 10.94045661]]\n",
      "Loop 2957 Loss_Train:  [[ 13.21068282]] Loss_Validation:  [[ 10.9405392]]\n",
      "Loop 2958 Loss_Train:  [[ 13.21065967]] Loss_Validation:  [[ 10.94062173]]\n",
      "Loop 2959 Loss_Train:  [[ 13.21063656]] Loss_Validation:  [[ 10.94070419]]\n",
      "Loop 2960 Loss_Train:  [[ 13.21061348]] Loss_Validation:  [[ 10.94078659]]\n",
      "Loop 2961 Loss_Train:  [[ 13.21059044]] Loss_Validation:  [[ 10.94086891]]\n",
      "Loop 2962 Loss_Train:  [[ 13.21056743]] Loss_Validation:  [[ 10.94095117]]\n",
      "Loop 2963 Loss_Train:  [[ 13.21054446]] Loss_Validation:  [[ 10.94103336]]\n",
      "Loop 2964 Loss_Train:  [[ 13.21052153]] Loss_Validation:  [[ 10.94111548]]\n",
      "Loop 2965 Loss_Train:  [[ 13.21049862]] Loss_Validation:  [[ 10.94119754]]\n",
      "Loop 2966 Loss_Train:  [[ 13.21047576]] Loss_Validation:  [[ 10.94127953]]\n",
      "Loop 2967 Loss_Train:  [[ 13.21045293]] Loss_Validation:  [[ 10.94136145]]\n",
      "Loop 2968 Loss_Train:  [[ 13.21043013]] Loss_Validation:  [[ 10.9414433]]\n",
      "Loop 2969 Loss_Train:  [[ 13.21040737]] Loss_Validation:  [[ 10.94152509]]\n",
      "Loop 2970 Loss_Train:  [[ 13.21038464]] Loss_Validation:  [[ 10.94160681]]\n",
      "Loop 2971 Loss_Train:  [[ 13.21036195]] Loss_Validation:  [[ 10.94168846]]\n",
      "Loop 2972 Loss_Train:  [[ 13.21033929]] Loss_Validation:  [[ 10.94177004]]\n",
      "Loop 2973 Loss_Train:  [[ 13.21031667]] Loss_Validation:  [[ 10.94185156]]\n",
      "Loop 2974 Loss_Train:  [[ 13.21029408]] Loss_Validation:  [[ 10.94193301]]\n",
      "Loop 2975 Loss_Train:  [[ 13.21027153]] Loss_Validation:  [[ 10.9420144]]\n",
      "Loop 2976 Loss_Train:  [[ 13.21024901]] Loss_Validation:  [[ 10.94209571]]\n",
      "Loop 2977 Loss_Train:  [[ 13.21022652]] Loss_Validation:  [[ 10.94217696]]\n",
      "Loop 2978 Loss_Train:  [[ 13.21020407]] Loss_Validation:  [[ 10.94225815]]\n",
      "Loop 2979 Loss_Train:  [[ 13.21018165]] Loss_Validation:  [[ 10.94233926]]\n",
      "Loop 2980 Loss_Train:  [[ 13.21015927]] Loss_Validation:  [[ 10.94242031]]\n",
      "Loop 2981 Loss_Train:  [[ 13.21013692]] Loss_Validation:  [[ 10.9425013]]\n",
      "Loop 2982 Loss_Train:  [[ 13.21011461]] Loss_Validation:  [[ 10.94258222]]\n",
      "Loop 2983 Loss_Train:  [[ 13.21009233]] Loss_Validation:  [[ 10.94266307]]\n",
      "Loop 2984 Loss_Train:  [[ 13.21007009]] Loss_Validation:  [[ 10.94274385]]\n",
      "Loop 2985 Loss_Train:  [[ 13.21004787]] Loss_Validation:  [[ 10.94282457]]\n",
      "Loop 2986 Loss_Train:  [[ 13.2100257]] Loss_Validation:  [[ 10.94290522]]\n",
      "Loop 2987 Loss_Train:  [[ 13.21000355]] Loss_Validation:  [[ 10.94298581]]\n",
      "Loop 2988 Loss_Train:  [[ 13.20998144]] Loss_Validation:  [[ 10.94306633]]\n",
      "Loop 2989 Loss_Train:  [[ 13.20995937]] Loss_Validation:  [[ 10.94314679]]\n",
      "Loop 2990 Loss_Train:  [[ 13.20993733]] Loss_Validation:  [[ 10.94322718]]\n",
      "Loop 2991 Loss_Train:  [[ 13.20991532]] Loss_Validation:  [[ 10.9433075]]\n",
      "Loop 2992 Loss_Train:  [[ 13.20989334]] Loss_Validation:  [[ 10.94338776]]\n",
      "Loop 2993 Loss_Train:  [[ 13.2098714]] Loss_Validation:  [[ 10.94346795]]\n",
      "Loop 2994 Loss_Train:  [[ 13.20984949]] Loss_Validation:  [[ 10.94354807]]\n",
      "Loop 2995 Loss_Train:  [[ 13.20982762]] Loss_Validation:  [[ 10.94362813]]\n",
      "Loop 2996 Loss_Train:  [[ 13.20980578]] Loss_Validation:  [[ 10.94370813]]\n",
      "Loop 2997 Loss_Train:  [[ 13.20978397]] Loss_Validation:  [[ 10.94378806]]\n",
      "Loop 2998 Loss_Train:  [[ 13.20976219]] Loss_Validation:  [[ 10.94386792]]\n",
      "Loop 2999 Loss_Train:  [[ 13.20974045]] Loss_Validation:  [[ 10.94394772]]\n",
      "Loop 3000 Loss_Train:  [[ 13.20971874]] Loss_Validation:  [[ 10.94402746]]\n",
      "Loop 3001 Loss_Train:  [[ 13.20969707]] Loss_Validation:  [[ 10.94410712]]\n",
      "Loop 3002 Loss_Train:  [[ 13.20967543]] Loss_Validation:  [[ 10.94418673]]\n",
      "Loop 3003 Loss_Train:  [[ 13.20965382]] Loss_Validation:  [[ 10.94426627]]\n",
      "Loop 3004 Loss_Train:  [[ 13.20963224]] Loss_Validation:  [[ 10.94434574]]\n",
      "Loop 3005 Loss_Train:  [[ 13.2096107]] Loss_Validation:  [[ 10.94442515]]\n",
      "Loop 3006 Loss_Train:  [[ 13.20958919]] Loss_Validation:  [[ 10.94450449]]\n",
      "Loop 3007 Loss_Train:  [[ 13.20956771]] Loss_Validation:  [[ 10.94458377]]\n",
      "Loop 3008 Loss_Train:  [[ 13.20954627]] Loss_Validation:  [[ 10.94466298]]\n",
      "Loop 3009 Loss_Train:  [[ 13.20952486]] Loss_Validation:  [[ 10.94474213]]\n",
      "Loop 3010 Loss_Train:  [[ 13.20950348]] Loss_Validation:  [[ 10.94482122]]\n",
      "Loop 3011 Loss_Train:  [[ 13.20948213]] Loss_Validation:  [[ 10.94490024]]\n",
      "Loop 3012 Loss_Train:  [[ 13.20946082]] Loss_Validation:  [[ 10.94497919]]\n",
      "Loop 3013 Loss_Train:  [[ 13.20943954]] Loss_Validation:  [[ 10.94505808]]\n",
      "Loop 3014 Loss_Train:  [[ 13.20941829]] Loss_Validation:  [[ 10.94513691]]\n",
      "Loop 3015 Loss_Train:  [[ 13.20939707]] Loss_Validation:  [[ 10.94521567]]\n",
      "Loop 3016 Loss_Train:  [[ 13.20937589]] Loss_Validation:  [[ 10.94529437]]\n",
      "Loop 3017 Loss_Train:  [[ 13.20935474]] Loss_Validation:  [[ 10.94537301]]\n",
      "Loop 3018 Loss_Train:  [[ 13.20933362]] Loss_Validation:  [[ 10.94545158]]\n",
      "Loop 3019 Loss_Train:  [[ 13.20931253]] Loss_Validation:  [[ 10.94553008]]\n",
      "Loop 3020 Loss_Train:  [[ 13.20929148]] Loss_Validation:  [[ 10.94560852]]\n",
      "Loop 3021 Loss_Train:  [[ 13.20927045]] Loss_Validation:  [[ 10.9456869]]\n",
      "Loop 3022 Loss_Train:  [[ 13.20924946]] Loss_Validation:  [[ 10.94576521]]\n",
      "Loop 3023 Loss_Train:  [[ 13.20922851]] Loss_Validation:  [[ 10.94584346]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3024 Loss_Train:  [[ 13.20920758]] Loss_Validation:  [[ 10.94592165]]\n",
      "Loop 3025 Loss_Train:  [[ 13.20918668]] Loss_Validation:  [[ 10.94599977]]\n",
      "Loop 3026 Loss_Train:  [[ 13.20916582]] Loss_Validation:  [[ 10.94607783]]\n",
      "Loop 3027 Loss_Train:  [[ 13.20914499]] Loss_Validation:  [[ 10.94615583]]\n",
      "Loop 3028 Loss_Train:  [[ 13.20912419]] Loss_Validation:  [[ 10.94623376]]\n",
      "Loop 3029 Loss_Train:  [[ 13.20910342]] Loss_Validation:  [[ 10.94631163]]\n",
      "Loop 3030 Loss_Train:  [[ 13.20908269]] Loss_Validation:  [[ 10.94638943]]\n",
      "Loop 3031 Loss_Train:  [[ 13.20906198]] Loss_Validation:  [[ 10.94646718]]\n",
      "Loop 3032 Loss_Train:  [[ 13.20904131]] Loss_Validation:  [[ 10.94654486]]\n",
      "Loop 3033 Loss_Train:  [[ 13.20902067]] Loss_Validation:  [[ 10.94662247]]\n",
      "Loop 3034 Loss_Train:  [[ 13.20900006]] Loss_Validation:  [[ 10.94670002]]\n",
      "Loop 3035 Loss_Train:  [[ 13.20897948]] Loss_Validation:  [[ 10.94677751]]\n",
      "Loop 3036 Loss_Train:  [[ 13.20895893]] Loss_Validation:  [[ 10.94685494]]\n",
      "Loop 3037 Loss_Train:  [[ 13.20893842]] Loss_Validation:  [[ 10.9469323]]\n",
      "Loop 3038 Loss_Train:  [[ 13.20891793]] Loss_Validation:  [[ 10.9470096]]\n",
      "Loop 3039 Loss_Train:  [[ 13.20889748]] Loss_Validation:  [[ 10.94708684]]\n",
      "Loop 3040 Loss_Train:  [[ 13.20887706]] Loss_Validation:  [[ 10.94716401]]\n",
      "Loop 3041 Loss_Train:  [[ 13.20885667]] Loss_Validation:  [[ 10.94724113]]\n",
      "Loop 3042 Loss_Train:  [[ 13.20883631]] Loss_Validation:  [[ 10.94731818]]\n",
      "Loop 3043 Loss_Train:  [[ 13.20881598]] Loss_Validation:  [[ 10.94739516]]\n",
      "Loop 3044 Loss_Train:  [[ 13.20879568]] Loss_Validation:  [[ 10.94747209]]\n",
      "Loop 3045 Loss_Train:  [[ 13.20877541]] Loss_Validation:  [[ 10.94754895]]\n",
      "Loop 3046 Loss_Train:  [[ 13.20875518]] Loss_Validation:  [[ 10.94762575]]\n",
      "Loop 3047 Loss_Train:  [[ 13.20873497]] Loss_Validation:  [[ 10.94770248]]\n",
      "Loop 3048 Loss_Train:  [[ 13.2087148]] Loss_Validation:  [[ 10.94777916]]\n",
      "Loop 3049 Loss_Train:  [[ 13.20869466]] Loss_Validation:  [[ 10.94785577]]\n",
      "Loop 3050 Loss_Train:  [[ 13.20867454]] Loss_Validation:  [[ 10.94793232]]\n",
      "Loop 3051 Loss_Train:  [[ 13.20865446]] Loss_Validation:  [[ 10.94800881]]\n",
      "Loop 3052 Loss_Train:  [[ 13.20863441]] Loss_Validation:  [[ 10.94808524]]\n",
      "Loop 3053 Loss_Train:  [[ 13.20861439]] Loss_Validation:  [[ 10.9481616]]\n",
      "Loop 3054 Loss_Train:  [[ 13.2085944]] Loss_Validation:  [[ 10.9482379]]\n",
      "Loop 3055 Loss_Train:  [[ 13.20857444]] Loss_Validation:  [[ 10.94831414]]\n",
      "Loop 3056 Loss_Train:  [[ 13.20855451]] Loss_Validation:  [[ 10.94839032]]\n",
      "Loop 3057 Loss_Train:  [[ 13.20853461]] Loss_Validation:  [[ 10.94846644]]\n",
      "Loop 3058 Loss_Train:  [[ 13.20851474]] Loss_Validation:  [[ 10.94854249]]\n",
      "Loop 3059 Loss_Train:  [[ 13.2084949]] Loss_Validation:  [[ 10.94861849]]\n",
      "Loop 3060 Loss_Train:  [[ 13.20847509]] Loss_Validation:  [[ 10.94869442]]\n",
      "Loop 3061 Loss_Train:  [[ 13.20845531]] Loss_Validation:  [[ 10.94877029]]\n",
      "Loop 3062 Loss_Train:  [[ 13.20843556]] Loss_Validation:  [[ 10.9488461]]\n",
      "Loop 3063 Loss_Train:  [[ 13.20841585]] Loss_Validation:  [[ 10.94892184]]\n",
      "Loop 3064 Loss_Train:  [[ 13.20839616]] Loss_Validation:  [[ 10.94899753]]\n",
      "Loop 3065 Loss_Train:  [[ 13.2083765]] Loss_Validation:  [[ 10.94907316]]\n",
      "Loop 3066 Loss_Train:  [[ 13.20835687]] Loss_Validation:  [[ 10.94914872]]\n",
      "Loop 3067 Loss_Train:  [[ 13.20833727]] Loss_Validation:  [[ 10.94922422]]\n",
      "Loop 3068 Loss_Train:  [[ 13.2083177]] Loss_Validation:  [[ 10.94929966]]\n",
      "Loop 3069 Loss_Train:  [[ 13.20829817]] Loss_Validation:  [[ 10.94937504]]\n",
      "Loop 3070 Loss_Train:  [[ 13.20827866]] Loss_Validation:  [[ 10.94945036]]\n",
      "Loop 3071 Loss_Train:  [[ 13.20825918]] Loss_Validation:  [[ 10.94952562]]\n",
      "Loop 3072 Loss_Train:  [[ 13.20823973]] Loss_Validation:  [[ 10.94960082]]\n",
      "Loop 3073 Loss_Train:  [[ 13.20822031]] Loss_Validation:  [[ 10.94967595]]\n",
      "Loop 3074 Loss_Train:  [[ 13.20820092]] Loss_Validation:  [[ 10.94975103]]\n",
      "Loop 3075 Loss_Train:  [[ 13.20818156]] Loss_Validation:  [[ 10.94982605]]\n",
      "Loop 3076 Loss_Train:  [[ 13.20816222]] Loss_Validation:  [[ 10.949901]]\n",
      "Loop 3077 Loss_Train:  [[ 13.20814292]] Loss_Validation:  [[ 10.94997589]]\n",
      "Loop 3078 Loss_Train:  [[ 13.20812365]] Loss_Validation:  [[ 10.95005073]]\n",
      "Loop 3079 Loss_Train:  [[ 13.20810441]] Loss_Validation:  [[ 10.9501255]]\n",
      "Loop 3080 Loss_Train:  [[ 13.20808519]] Loss_Validation:  [[ 10.95020021]]\n",
      "Loop 3081 Loss_Train:  [[ 13.20806601]] Loss_Validation:  [[ 10.95027487]]\n",
      "Loop 3082 Loss_Train:  [[ 13.20804685]] Loss_Validation:  [[ 10.95034946]]\n",
      "Loop 3083 Loss_Train:  [[ 13.20802772]] Loss_Validation:  [[ 10.95042399]]\n",
      "Loop 3084 Loss_Train:  [[ 13.20800863]] Loss_Validation:  [[ 10.95049846]]\n",
      "Loop 3085 Loss_Train:  [[ 13.20798956]] Loss_Validation:  [[ 10.95057287]]\n",
      "Loop 3086 Loss_Train:  [[ 13.20797052]] Loss_Validation:  [[ 10.95064722]]\n",
      "Loop 3087 Loss_Train:  [[ 13.20795151]] Loss_Validation:  [[ 10.95072151]]\n",
      "Loop 3088 Loss_Train:  [[ 13.20793253]] Loss_Validation:  [[ 10.95079575]]\n",
      "Loop 3089 Loss_Train:  [[ 13.20791357]] Loss_Validation:  [[ 10.95086992]]\n",
      "Loop 3090 Loss_Train:  [[ 13.20789465]] Loss_Validation:  [[ 10.95094403]]\n",
      "Loop 3091 Loss_Train:  [[ 13.20787575]] Loss_Validation:  [[ 10.95101808]]\n",
      "Loop 3092 Loss_Train:  [[ 13.20785689]] Loss_Validation:  [[ 10.95109207]]\n",
      "Loop 3093 Loss_Train:  [[ 13.20783805]] Loss_Validation:  [[ 10.951166]]\n",
      "Loop 3094 Loss_Train:  [[ 13.20781924]] Loss_Validation:  [[ 10.95123988]]\n",
      "Loop 3095 Loss_Train:  [[ 13.20780046]] Loss_Validation:  [[ 10.95131369]]\n",
      "Loop 3096 Loss_Train:  [[ 13.20778171]] Loss_Validation:  [[ 10.95138744]]\n",
      "Loop 3097 Loss_Train:  [[ 13.20776299]] Loss_Validation:  [[ 10.95146114]]\n",
      "Loop 3098 Loss_Train:  [[ 13.20774429]] Loss_Validation:  [[ 10.95153477]]\n",
      "Loop 3099 Loss_Train:  [[ 13.20772562]] Loss_Validation:  [[ 10.95160835]]\n",
      "Loop 3100 Loss_Train:  [[ 13.20770699]] Loss_Validation:  [[ 10.95168187]]\n",
      "Loop 3101 Loss_Train:  [[ 13.20768838]] Loss_Validation:  [[ 10.95175532]]\n",
      "Loop 3102 Loss_Train:  [[ 13.20766979]] Loss_Validation:  [[ 10.95182872]]\n",
      "Loop 3103 Loss_Train:  [[ 13.20765124]] Loss_Validation:  [[ 10.95190206]]\n",
      "Loop 3104 Loss_Train:  [[ 13.20763272]] Loss_Validation:  [[ 10.95197534]]\n",
      "Loop 3105 Loss_Train:  [[ 13.20761422]] Loss_Validation:  [[ 10.95204856]]\n",
      "Loop 3106 Loss_Train:  [[ 13.20759575]] Loss_Validation:  [[ 10.95212172]]\n",
      "Loop 3107 Loss_Train:  [[ 13.20757731]] Loss_Validation:  [[ 10.95219482]]\n",
      "Loop 3108 Loss_Train:  [[ 13.2075589]] Loss_Validation:  [[ 10.95226787]]\n",
      "Loop 3109 Loss_Train:  [[ 13.20754051]] Loss_Validation:  [[ 10.95234085]]\n",
      "Loop 3110 Loss_Train:  [[ 13.20752215]] Loss_Validation:  [[ 10.95241378]]\n",
      "Loop 3111 Loss_Train:  [[ 13.20750383]] Loss_Validation:  [[ 10.95248665]]\n",
      "Loop 3112 Loss_Train:  [[ 13.20748552]] Loss_Validation:  [[ 10.95255946]]\n",
      "Loop 3113 Loss_Train:  [[ 13.20746725]] Loss_Validation:  [[ 10.95263221]]\n",
      "Loop 3114 Loss_Train:  [[ 13.20744901]] Loss_Validation:  [[ 10.9527049]]\n",
      "Loop 3115 Loss_Train:  [[ 13.20743079]] Loss_Validation:  [[ 10.95277754]]\n",
      "Loop 3116 Loss_Train:  [[ 13.2074126]] Loss_Validation:  [[ 10.95285011]]\n",
      "Loop 3117 Loss_Train:  [[ 13.20739444]] Loss_Validation:  [[ 10.95292263]]\n",
      "Loop 3118 Loss_Train:  [[ 13.2073763]] Loss_Validation:  [[ 10.95299509]]\n",
      "Loop 3119 Loss_Train:  [[ 13.20735819]] Loss_Validation:  [[ 10.95306749]]\n",
      "Loop 3120 Loss_Train:  [[ 13.20734011]] Loss_Validation:  [[ 10.95313983]]\n",
      "Loop 3121 Loss_Train:  [[ 13.20732206]] Loss_Validation:  [[ 10.95321212]]\n",
      "Loop 3122 Loss_Train:  [[ 13.20730404]] Loss_Validation:  [[ 10.95328434]]\n",
      "Loop 3123 Loss_Train:  [[ 13.20728604]] Loss_Validation:  [[ 10.95335651]]\n",
      "Loop 3124 Loss_Train:  [[ 13.20726807]] Loss_Validation:  [[ 10.95342862]]\n",
      "Loop 3125 Loss_Train:  [[ 13.20725013]] Loss_Validation:  [[ 10.95350067]]\n",
      "Loop 3126 Loss_Train:  [[ 13.20723221]] Loss_Validation:  [[ 10.95357267]]\n",
      "Loop 3127 Loss_Train:  [[ 13.20721432]] Loss_Validation:  [[ 10.95364461]]\n",
      "Loop 3128 Loss_Train:  [[ 13.20719646]] Loss_Validation:  [[ 10.95371649]]\n",
      "Loop 3129 Loss_Train:  [[ 13.20717863]] Loss_Validation:  [[ 10.95378831]]\n",
      "Loop 3130 Loss_Train:  [[ 13.20716082]] Loss_Validation:  [[ 10.95386007]]\n",
      "Loop 3131 Loss_Train:  [[ 13.20714304]] Loss_Validation:  [[ 10.95393178]]\n",
      "Loop 3132 Loss_Train:  [[ 13.20712529]] Loss_Validation:  [[ 10.95400343]]\n",
      "Loop 3133 Loss_Train:  [[ 13.20710756]] Loss_Validation:  [[ 10.95407502]]\n",
      "Loop 3134 Loss_Train:  [[ 13.20708986]] Loss_Validation:  [[ 10.95414655]]\n",
      "Loop 3135 Loss_Train:  [[ 13.20707219]] Loss_Validation:  [[ 10.95421803]]\n",
      "Loop 3136 Loss_Train:  [[ 13.20705454]] Loss_Validation:  [[ 10.95428945]]\n",
      "Loop 3137 Loss_Train:  [[ 13.20703692]] Loss_Validation:  [[ 10.95436081]]\n",
      "Loop 3138 Loss_Train:  [[ 13.20701933]] Loss_Validation:  [[ 10.95443212]]\n",
      "Loop 3139 Loss_Train:  [[ 13.20700177]] Loss_Validation:  [[ 10.95450337]]\n",
      "Loop 3140 Loss_Train:  [[ 13.20698423]] Loss_Validation:  [[ 10.95457456]]\n",
      "Loop 3141 Loss_Train:  [[ 13.20696672]] Loss_Validation:  [[ 10.95464569]]\n",
      "Loop 3142 Loss_Train:  [[ 13.20694923]] Loss_Validation:  [[ 10.95471677]]\n",
      "Loop 3143 Loss_Train:  [[ 13.20693177]] Loss_Validation:  [[ 10.95478779]]\n",
      "Loop 3144 Loss_Train:  [[ 13.20691434]] Loss_Validation:  [[ 10.95485875]]\n",
      "Loop 3145 Loss_Train:  [[ 13.20689693]] Loss_Validation:  [[ 10.95492966]]\n",
      "Loop 3146 Loss_Train:  [[ 13.20687955]] Loss_Validation:  [[ 10.95500051]]\n",
      "Loop 3147 Loss_Train:  [[ 13.2068622]] Loss_Validation:  [[ 10.9550713]]\n",
      "Loop 3148 Loss_Train:  [[ 13.20684487]] Loss_Validation:  [[ 10.95514204]]\n",
      "Loop 3149 Loss_Train:  [[ 13.20682757]] Loss_Validation:  [[ 10.95521272]]\n",
      "Loop 3150 Loss_Train:  [[ 13.2068103]] Loss_Validation:  [[ 10.95528334]]\n",
      "Loop 3151 Loss_Train:  [[ 13.20679305]] Loss_Validation:  [[ 10.95535391]]\n",
      "Loop 3152 Loss_Train:  [[ 13.20677583]] Loss_Validation:  [[ 10.95542442]]\n",
      "Loop 3153 Loss_Train:  [[ 13.20675863]] Loss_Validation:  [[ 10.95549487]]\n",
      "Loop 3154 Loss_Train:  [[ 13.20674146]] Loss_Validation:  [[ 10.95556527]]\n",
      "Loop 3155 Loss_Train:  [[ 13.20672432]] Loss_Validation:  [[ 10.95563561]]\n",
      "Loop 3156 Loss_Train:  [[ 13.2067072]] Loss_Validation:  [[ 10.9557059]]\n",
      "Loop 3157 Loss_Train:  [[ 13.20669011]] Loss_Validation:  [[ 10.95577613]]\n",
      "Loop 3158 Loss_Train:  [[ 13.20667304]] Loss_Validation:  [[ 10.9558463]]\n",
      "Loop 3159 Loss_Train:  [[ 13.206656]] Loss_Validation:  [[ 10.95591642]]\n",
      "Loop 3160 Loss_Train:  [[ 13.20663899]] Loss_Validation:  [[ 10.95598648]]\n",
      "Loop 3161 Loss_Train:  [[ 13.206622]] Loss_Validation:  [[ 10.95605648]]\n",
      "Loop 3162 Loss_Train:  [[ 13.20660504]] Loss_Validation:  [[ 10.95612643]]\n",
      "Loop 3163 Loss_Train:  [[ 13.2065881]] Loss_Validation:  [[ 10.95619633]]\n",
      "Loop 3164 Loss_Train:  [[ 13.20657119]] Loss_Validation:  [[ 10.95626616]]\n",
      "Loop 3165 Loss_Train:  [[ 13.20655431]] Loss_Validation:  [[ 10.95633595]]\n",
      "Loop 3166 Loss_Train:  [[ 13.20653745]] Loss_Validation:  [[ 10.95640567]]\n",
      "Loop 3167 Loss_Train:  [[ 13.20652061]] Loss_Validation:  [[ 10.95647534]]\n",
      "Loop 3168 Loss_Train:  [[ 13.2065038]] Loss_Validation:  [[ 10.95654496]]\n",
      "Loop 3169 Loss_Train:  [[ 13.20648702]] Loss_Validation:  [[ 10.95661452]]\n",
      "Loop 3170 Loss_Train:  [[ 13.20647026]] Loss_Validation:  [[ 10.95668402]]\n",
      "Loop 3171 Loss_Train:  [[ 13.20645353]] Loss_Validation:  [[ 10.95675347]]\n",
      "Loop 3172 Loss_Train:  [[ 13.20643682]] Loss_Validation:  [[ 10.95682286]]\n",
      "Loop 3173 Loss_Train:  [[ 13.20642014]] Loss_Validation:  [[ 10.9568922]]\n",
      "Loop 3174 Loss_Train:  [[ 13.20640348]] Loss_Validation:  [[ 10.95696148]]\n",
      "Loop 3175 Loss_Train:  [[ 13.20638685]] Loss_Validation:  [[ 10.95703071]]\n",
      "Loop 3176 Loss_Train:  [[ 13.20637025]] Loss_Validation:  [[ 10.95709988]]\n",
      "Loop 3177 Loss_Train:  [[ 13.20635367]] Loss_Validation:  [[ 10.957169]]\n",
      "Loop 3178 Loss_Train:  [[ 13.20633711]] Loss_Validation:  [[ 10.95723806]]\n",
      "Loop 3179 Loss_Train:  [[ 13.20632058]] Loss_Validation:  [[ 10.95730707]]\n",
      "Loop 3180 Loss_Train:  [[ 13.20630407]] Loss_Validation:  [[ 10.95737602]]\n",
      "Loop 3181 Loss_Train:  [[ 13.20628759]] Loss_Validation:  [[ 10.95744492]]\n",
      "Loop 3182 Loss_Train:  [[ 13.20627114]] Loss_Validation:  [[ 10.95751376]]\n",
      "Loop 3183 Loss_Train:  [[ 13.20625471]] Loss_Validation:  [[ 10.95758255]]\n",
      "Loop 3184 Loss_Train:  [[ 13.2062383]] Loss_Validation:  [[ 10.95765128]]\n",
      "Loop 3185 Loss_Train:  [[ 13.20622192]] Loss_Validation:  [[ 10.95771996]]\n",
      "Loop 3186 Loss_Train:  [[ 13.20620556]] Loss_Validation:  [[ 10.95778858]]\n",
      "Loop 3187 Loss_Train:  [[ 13.20618923]] Loss_Validation:  [[ 10.95785715]]\n",
      "Loop 3188 Loss_Train:  [[ 13.20617293]] Loss_Validation:  [[ 10.95792567]]\n",
      "Loop 3189 Loss_Train:  [[ 13.20615664]] Loss_Validation:  [[ 10.95799413]]\n",
      "Loop 3190 Loss_Train:  [[ 13.20614039]] Loss_Validation:  [[ 10.95806253]]\n",
      "Loop 3191 Loss_Train:  [[ 13.20612415]] Loss_Validation:  [[ 10.95813088]]\n",
      "Loop 3192 Loss_Train:  [[ 13.20610795]] Loss_Validation:  [[ 10.95819918]]\n",
      "Loop 3193 Loss_Train:  [[ 13.20609176]] Loss_Validation:  [[ 10.95826742]]\n",
      "Loop 3194 Loss_Train:  [[ 13.2060756]] Loss_Validation:  [[ 10.95833561]]\n",
      "Loop 3195 Loss_Train:  [[ 13.20605947]] Loss_Validation:  [[ 10.95840375]]\n",
      "Loop 3196 Loss_Train:  [[ 13.20604336]] Loss_Validation:  [[ 10.95847183]]\n",
      "Loop 3197 Loss_Train:  [[ 13.20602727]] Loss_Validation:  [[ 10.95853985]]\n",
      "Loop 3198 Loss_Train:  [[ 13.20601121]] Loss_Validation:  [[ 10.95860782]]\n",
      "Loop 3199 Loss_Train:  [[ 13.20599517]] Loss_Validation:  [[ 10.95867574]]\n",
      "Loop 3200 Loss_Train:  [[ 13.20597916]] Loss_Validation:  [[ 10.95874361]]\n",
      "Loop 3201 Loss_Train:  [[ 13.20596317]] Loss_Validation:  [[ 10.95881142]]\n",
      "Loop 3202 Loss_Train:  [[ 13.20594721]] Loss_Validation:  [[ 10.95887917]]\n",
      "Loop 3203 Loss_Train:  [[ 13.20593127]] Loss_Validation:  [[ 10.95894687]]\n",
      "Loop 3204 Loss_Train:  [[ 13.20591535]] Loss_Validation:  [[ 10.95901452]]\n",
      "Loop 3205 Loss_Train:  [[ 13.20589946]] Loss_Validation:  [[ 10.95908212]]\n",
      "Loop 3206 Loss_Train:  [[ 13.20588359]] Loss_Validation:  [[ 10.95914966]]\n",
      "Loop 3207 Loss_Train:  [[ 13.20586775]] Loss_Validation:  [[ 10.95921715]]\n",
      "Loop 3208 Loss_Train:  [[ 13.20585193]] Loss_Validation:  [[ 10.95928458]]\n",
      "Loop 3209 Loss_Train:  [[ 13.20583613]] Loss_Validation:  [[ 10.95935196]]\n",
      "Loop 3210 Loss_Train:  [[ 13.20582036]] Loss_Validation:  [[ 10.95941929]]\n",
      "Loop 3211 Loss_Train:  [[ 13.20580461]] Loss_Validation:  [[ 10.95948656]]\n",
      "Loop 3212 Loss_Train:  [[ 13.20578889]] Loss_Validation:  [[ 10.95955378]]\n",
      "Loop 3213 Loss_Train:  [[ 13.20577319]] Loss_Validation:  [[ 10.95962095]]\n",
      "Loop 3214 Loss_Train:  [[ 13.20575751]] Loss_Validation:  [[ 10.95968807]]\n",
      "Loop 3215 Loss_Train:  [[ 13.20574186]] Loss_Validation:  [[ 10.95975513]]\n",
      "Loop 3216 Loss_Train:  [[ 13.20572623]] Loss_Validation:  [[ 10.95982214]]\n",
      "Loop 3217 Loss_Train:  [[ 13.20571063]] Loss_Validation:  [[ 10.95988909]]\n",
      "Loop 3218 Loss_Train:  [[ 13.20569504]] Loss_Validation:  [[ 10.95995599]]\n",
      "Loop 3219 Loss_Train:  [[ 13.20567948]] Loss_Validation:  [[ 10.96002284]]\n",
      "Loop 3220 Loss_Train:  [[ 13.20566395]] Loss_Validation:  [[ 10.96008964]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3221 Loss_Train:  [[ 13.20564844]] Loss_Validation:  [[ 10.96015638]]\n",
      "Loop 3222 Loss_Train:  [[ 13.20563295]] Loss_Validation:  [[ 10.96022307]]\n",
      "Loop 3223 Loss_Train:  [[ 13.20561749]] Loss_Validation:  [[ 10.96028971]]\n",
      "Loop 3224 Loss_Train:  [[ 13.20560204]] Loss_Validation:  [[ 10.96035629]]\n",
      "Loop 3225 Loss_Train:  [[ 13.20558663]] Loss_Validation:  [[ 10.96042282]]\n",
      "Loop 3226 Loss_Train:  [[ 13.20557123]] Loss_Validation:  [[ 10.9604893]]\n",
      "Loop 3227 Loss_Train:  [[ 13.20555586]] Loss_Validation:  [[ 10.96055573]]\n",
      "Loop 3228 Loss_Train:  [[ 13.20554051]] Loss_Validation:  [[ 10.9606221]]\n",
      "Loop 3229 Loss_Train:  [[ 13.20552519]] Loss_Validation:  [[ 10.96068843]]\n",
      "Loop 3230 Loss_Train:  [[ 13.20550989]] Loss_Validation:  [[ 10.96075469]]\n",
      "Loop 3231 Loss_Train:  [[ 13.20549461]] Loss_Validation:  [[ 10.96082091]]\n",
      "Loop 3232 Loss_Train:  [[ 13.20547935]] Loss_Validation:  [[ 10.96088708]]\n",
      "Loop 3233 Loss_Train:  [[ 13.20546412]] Loss_Validation:  [[ 10.96095319]]\n",
      "Loop 3234 Loss_Train:  [[ 13.20544891]] Loss_Validation:  [[ 10.96101925]]\n",
      "Loop 3235 Loss_Train:  [[ 13.20543373]] Loss_Validation:  [[ 10.96108526]]\n",
      "Loop 3236 Loss_Train:  [[ 13.20541856]] Loss_Validation:  [[ 10.96115121]]\n",
      "Loop 3237 Loss_Train:  [[ 13.20540342]] Loss_Validation:  [[ 10.96121712]]\n",
      "Loop 3238 Loss_Train:  [[ 13.20538831]] Loss_Validation:  [[ 10.96128297]]\n",
      "Loop 3239 Loss_Train:  [[ 13.20537321]] Loss_Validation:  [[ 10.96134877]]\n",
      "Loop 3240 Loss_Train:  [[ 13.20535814]] Loss_Validation:  [[ 10.96141451]]\n",
      "Loop 3241 Loss_Train:  [[ 13.20534309]] Loss_Validation:  [[ 10.96148021]]\n",
      "Loop 3242 Loss_Train:  [[ 13.20532806]] Loss_Validation:  [[ 10.96154585]]\n",
      "Loop 3243 Loss_Train:  [[ 13.20531306]] Loss_Validation:  [[ 10.96161145]]\n",
      "Loop 3244 Loss_Train:  [[ 13.20529808]] Loss_Validation:  [[ 10.96167699]]\n",
      "Loop 3245 Loss_Train:  [[ 13.20528312]] Loss_Validation:  [[ 10.96174247]]\n",
      "Loop 3246 Loss_Train:  [[ 13.20526819]] Loss_Validation:  [[ 10.96180791]]\n",
      "Loop 3247 Loss_Train:  [[ 13.20525327]] Loss_Validation:  [[ 10.9618733]]\n",
      "Loop 3248 Loss_Train:  [[ 13.20523838]] Loss_Validation:  [[ 10.96193863]]\n",
      "Loop 3249 Loss_Train:  [[ 13.20522352]] Loss_Validation:  [[ 10.96200391]]\n",
      "Loop 3250 Loss_Train:  [[ 13.20520867]] Loss_Validation:  [[ 10.96206914]]\n",
      "Loop 3251 Loss_Train:  [[ 13.20519385]] Loss_Validation:  [[ 10.96213432]]\n",
      "Loop 3252 Loss_Train:  [[ 13.20517905]] Loss_Validation:  [[ 10.96219945]]\n",
      "Loop 3253 Loss_Train:  [[ 13.20516427]] Loss_Validation:  [[ 10.96226453]]\n",
      "Loop 3254 Loss_Train:  [[ 13.20514951]] Loss_Validation:  [[ 10.96232955]]\n",
      "Loop 3255 Loss_Train:  [[ 13.20513478]] Loss_Validation:  [[ 10.96239452]]\n",
      "Loop 3256 Loss_Train:  [[ 13.20512007]] Loss_Validation:  [[ 10.96245945]]\n",
      "Loop 3257 Loss_Train:  [[ 13.20510538]] Loss_Validation:  [[ 10.96252432]]\n",
      "Loop 3258 Loss_Train:  [[ 13.20509071]] Loss_Validation:  [[ 10.96258914]]\n",
      "Loop 3259 Loss_Train:  [[ 13.20507607]] Loss_Validation:  [[ 10.96265391]]\n",
      "Loop 3260 Loss_Train:  [[ 13.20506145]] Loss_Validation:  [[ 10.96271863]]\n",
      "Loop 3261 Loss_Train:  [[ 13.20504684]] Loss_Validation:  [[ 10.96278329]]\n",
      "Loop 3262 Loss_Train:  [[ 13.20503227]] Loss_Validation:  [[ 10.96284791]]\n",
      "Loop 3263 Loss_Train:  [[ 13.20501771]] Loss_Validation:  [[ 10.96291248]]\n",
      "Loop 3264 Loss_Train:  [[ 13.20500318]] Loss_Validation:  [[ 10.96297699]]\n",
      "Loop 3265 Loss_Train:  [[ 13.20498866]] Loss_Validation:  [[ 10.96304146]]\n",
      "Loop 3266 Loss_Train:  [[ 13.20497417]] Loss_Validation:  [[ 10.96310587]]\n",
      "Loop 3267 Loss_Train:  [[ 13.2049597]] Loss_Validation:  [[ 10.96317023]]\n",
      "Loop 3268 Loss_Train:  [[ 13.20494526]] Loss_Validation:  [[ 10.96323454]]\n",
      "Loop 3269 Loss_Train:  [[ 13.20493083]] Loss_Validation:  [[ 10.96329881]]\n",
      "Loop 3270 Loss_Train:  [[ 13.20491643]] Loss_Validation:  [[ 10.96336302]]\n",
      "Loop 3271 Loss_Train:  [[ 13.20490205]] Loss_Validation:  [[ 10.96342718]]\n",
      "Loop 3272 Loss_Train:  [[ 13.20488769]] Loss_Validation:  [[ 10.96349129]]\n",
      "Loop 3273 Loss_Train:  [[ 13.20487335]] Loss_Validation:  [[ 10.96355535]]\n",
      "Loop 3274 Loss_Train:  [[ 13.20485903]] Loss_Validation:  [[ 10.96361936]]\n",
      "Loop 3275 Loss_Train:  [[ 13.20484474]] Loss_Validation:  [[ 10.96368332]]\n",
      "Loop 3276 Loss_Train:  [[ 13.20483047]] Loss_Validation:  [[ 10.96374722]]\n",
      "Loop 3277 Loss_Train:  [[ 13.20481621]] Loss_Validation:  [[ 10.96381108]]\n",
      "Loop 3278 Loss_Train:  [[ 13.20480198]] Loss_Validation:  [[ 10.96387489]]\n",
      "Loop 3279 Loss_Train:  [[ 13.20478778]] Loss_Validation:  [[ 10.96393865]]\n",
      "Loop 3280 Loss_Train:  [[ 13.20477359]] Loss_Validation:  [[ 10.96400236]]\n",
      "Loop 3281 Loss_Train:  [[ 13.20475942]] Loss_Validation:  [[ 10.96406602]]\n",
      "Loop 3282 Loss_Train:  [[ 13.20474528]] Loss_Validation:  [[ 10.96412962]]\n",
      "Loop 3283 Loss_Train:  [[ 13.20473116]] Loss_Validation:  [[ 10.96419318]]\n",
      "Loop 3284 Loss_Train:  [[ 13.20471705]] Loss_Validation:  [[ 10.96425669]]\n",
      "Loop 3285 Loss_Train:  [[ 13.20470297]] Loss_Validation:  [[ 10.96432015]]\n",
      "Loop 3286 Loss_Train:  [[ 13.20468891]] Loss_Validation:  [[ 10.96438356]]\n",
      "Loop 3287 Loss_Train:  [[ 13.20467488]] Loss_Validation:  [[ 10.96444692]]\n",
      "Loop 3288 Loss_Train:  [[ 13.20466086]] Loss_Validation:  [[ 10.96451023]]\n",
      "Loop 3289 Loss_Train:  [[ 13.20464686]] Loss_Validation:  [[ 10.96457349]]\n",
      "Loop 3290 Loss_Train:  [[ 13.20463289]] Loss_Validation:  [[ 10.9646367]]\n",
      "Loop 3291 Loss_Train:  [[ 13.20461894]] Loss_Validation:  [[ 10.96469986]]\n",
      "Loop 3292 Loss_Train:  [[ 13.204605]] Loss_Validation:  [[ 10.96476297]]\n",
      "Loop 3293 Loss_Train:  [[ 13.20459109]] Loss_Validation:  [[ 10.96482603]]\n",
      "Loop 3294 Loss_Train:  [[ 13.2045772]] Loss_Validation:  [[ 10.96488904]]\n",
      "Loop 3295 Loss_Train:  [[ 13.20456333]] Loss_Validation:  [[ 10.96495201]]\n",
      "Loop 3296 Loss_Train:  [[ 13.20454948]] Loss_Validation:  [[ 10.96501492]]\n",
      "Loop 3297 Loss_Train:  [[ 13.20453566]] Loss_Validation:  [[ 10.96507778]]\n",
      "Loop 3298 Loss_Train:  [[ 13.20452185]] Loss_Validation:  [[ 10.9651406]]\n",
      "Loop 3299 Loss_Train:  [[ 13.20450806]] Loss_Validation:  [[ 10.96520336]]\n",
      "Loop 3300 Loss_Train:  [[ 13.2044943]] Loss_Validation:  [[ 10.96526608]]\n",
      "Loop 3301 Loss_Train:  [[ 13.20448056]] Loss_Validation:  [[ 10.96532875]]\n",
      "Loop 3302 Loss_Train:  [[ 13.20446683]] Loss_Validation:  [[ 10.96539137]]\n",
      "Loop 3303 Loss_Train:  [[ 13.20445313]] Loss_Validation:  [[ 10.96545393]]\n",
      "Loop 3304 Loss_Train:  [[ 13.20443945]] Loss_Validation:  [[ 10.96551646]]\n",
      "Loop 3305 Loss_Train:  [[ 13.20442579]] Loss_Validation:  [[ 10.96557893]]\n",
      "Loop 3306 Loss_Train:  [[ 13.20441214]] Loss_Validation:  [[ 10.96564135]]\n",
      "Loop 3307 Loss_Train:  [[ 13.20439852]] Loss_Validation:  [[ 10.96570372]]\n",
      "Loop 3308 Loss_Train:  [[ 13.20438492]] Loss_Validation:  [[ 10.96576605]]\n",
      "Loop 3309 Loss_Train:  [[ 13.20437134]] Loss_Validation:  [[ 10.96582832]]\n",
      "Loop 3310 Loss_Train:  [[ 13.20435779]] Loss_Validation:  [[ 10.96589055]]\n",
      "Loop 3311 Loss_Train:  [[ 13.20434425]] Loss_Validation:  [[ 10.96595273]]\n",
      "Loop 3312 Loss_Train:  [[ 13.20433073]] Loss_Validation:  [[ 10.96601486]]\n",
      "Loop 3313 Loss_Train:  [[ 13.20431723]] Loss_Validation:  [[ 10.96607694]]\n",
      "Loop 3314 Loss_Train:  [[ 13.20430376]] Loss_Validation:  [[ 10.96613897]]\n",
      "Loop 3315 Loss_Train:  [[ 13.2042903]] Loss_Validation:  [[ 10.96620096]]\n",
      "Loop 3316 Loss_Train:  [[ 13.20427686]] Loss_Validation:  [[ 10.9662629]]\n",
      "Loop 3317 Loss_Train:  [[ 13.20426345]] Loss_Validation:  [[ 10.96632478]]\n",
      "Loop 3318 Loss_Train:  [[ 13.20425005]] Loss_Validation:  [[ 10.96638662]]\n",
      "Loop 3319 Loss_Train:  [[ 13.20423667]] Loss_Validation:  [[ 10.96644841]]\n",
      "Loop 3320 Loss_Train:  [[ 13.20422332]] Loss_Validation:  [[ 10.96651016]]\n",
      "Loop 3321 Loss_Train:  [[ 13.20420998]] Loss_Validation:  [[ 10.96657185]]\n",
      "Loop 3322 Loss_Train:  [[ 13.20419667]] Loss_Validation:  [[ 10.9666335]]\n",
      "Loop 3323 Loss_Train:  [[ 13.20418337]] Loss_Validation:  [[ 10.9666951]]\n",
      "Loop 3324 Loss_Train:  [[ 13.2041701]] Loss_Validation:  [[ 10.96675665]]\n",
      "Loop 3325 Loss_Train:  [[ 13.20415684]] Loss_Validation:  [[ 10.96681815]]\n",
      "Loop 3326 Loss_Train:  [[ 13.20414361]] Loss_Validation:  [[ 10.9668796]]\n",
      "Loop 3327 Loss_Train:  [[ 13.20413039]] Loss_Validation:  [[ 10.96694101]]\n",
      "Loop 3328 Loss_Train:  [[ 13.20411719]] Loss_Validation:  [[ 10.96700237]]\n",
      "Loop 3329 Loss_Train:  [[ 13.20410402]] Loss_Validation:  [[ 10.96706368]]\n",
      "Loop 3330 Loss_Train:  [[ 13.20409086]] Loss_Validation:  [[ 10.96712494]]\n",
      "Loop 3331 Loss_Train:  [[ 13.20407773]] Loss_Validation:  [[ 10.96718615]]\n",
      "Loop 3332 Loss_Train:  [[ 13.20406461]] Loss_Validation:  [[ 10.96724732]]\n",
      "Loop 3333 Loss_Train:  [[ 13.20405152]] Loss_Validation:  [[ 10.96730844]]\n",
      "Loop 3334 Loss_Train:  [[ 13.20403844]] Loss_Validation:  [[ 10.96736951]]\n",
      "Loop 3335 Loss_Train:  [[ 13.20402538]] Loss_Validation:  [[ 10.96743054]]\n",
      "Loop 3336 Loss_Train:  [[ 13.20401234]] Loss_Validation:  [[ 10.96749151]]\n",
      "Loop 3337 Loss_Train:  [[ 13.20399933]] Loss_Validation:  [[ 10.96755244]]\n",
      "Loop 3338 Loss_Train:  [[ 13.20398633]] Loss_Validation:  [[ 10.96761332]]\n",
      "Loop 3339 Loss_Train:  [[ 13.20397335]] Loss_Validation:  [[ 10.96767416]]\n",
      "Loop 3340 Loss_Train:  [[ 13.20396039]] Loss_Validation:  [[ 10.96773494]]\n",
      "Loop 3341 Loss_Train:  [[ 13.20394745]] Loss_Validation:  [[ 10.96779568]]\n",
      "Loop 3342 Loss_Train:  [[ 13.20393453]] Loss_Validation:  [[ 10.96785638]]\n",
      "Loop 3343 Loss_Train:  [[ 13.20392163]] Loss_Validation:  [[ 10.96791702]]\n",
      "Loop 3344 Loss_Train:  [[ 13.20390875]] Loss_Validation:  [[ 10.96797762]]\n",
      "Loop 3345 Loss_Train:  [[ 13.20389589]] Loss_Validation:  [[ 10.96803817]]\n",
      "Loop 3346 Loss_Train:  [[ 13.20388305]] Loss_Validation:  [[ 10.96809867]]\n",
      "Loop 3347 Loss_Train:  [[ 13.20387022]] Loss_Validation:  [[ 10.96815913]]\n",
      "Loop 3348 Loss_Train:  [[ 13.20385742]] Loss_Validation:  [[ 10.96821954]]\n",
      "Loop 3349 Loss_Train:  [[ 13.20384464]] Loss_Validation:  [[ 10.9682799]]\n",
      "Loop 3350 Loss_Train:  [[ 13.20383187]] Loss_Validation:  [[ 10.96834022]]\n",
      "Loop 3351 Loss_Train:  [[ 13.20381913]] Loss_Validation:  [[ 10.96840048]]\n",
      "Loop 3352 Loss_Train:  [[ 13.2038064]] Loss_Validation:  [[ 10.9684607]]\n",
      "Loop 3353 Loss_Train:  [[ 13.20379369]] Loss_Validation:  [[ 10.96852088]]\n",
      "Loop 3354 Loss_Train:  [[ 13.203781]] Loss_Validation:  [[ 10.96858101]]\n",
      "Loop 3355 Loss_Train:  [[ 13.20376834]] Loss_Validation:  [[ 10.96864109]]\n",
      "Loop 3356 Loss_Train:  [[ 13.20375569]] Loss_Validation:  [[ 10.96870112]]\n",
      "Loop 3357 Loss_Train:  [[ 13.20374305]] Loss_Validation:  [[ 10.96876111]]\n",
      "Loop 3358 Loss_Train:  [[ 13.20373044]] Loss_Validation:  [[ 10.96882105]]\n",
      "Loop 3359 Loss_Train:  [[ 13.20371785]] Loss_Validation:  [[ 10.96888095]]\n",
      "Loop 3360 Loss_Train:  [[ 13.20370528]] Loss_Validation:  [[ 10.96894079]]\n",
      "Loop 3361 Loss_Train:  [[ 13.20369272]] Loss_Validation:  [[ 10.9690006]]\n",
      "Loop 3362 Loss_Train:  [[ 13.20368018]] Loss_Validation:  [[ 10.96906035]]\n",
      "Loop 3363 Loss_Train:  [[ 13.20366767]] Loss_Validation:  [[ 10.96912006]]\n",
      "Loop 3364 Loss_Train:  [[ 13.20365517]] Loss_Validation:  [[ 10.96917972]]\n",
      "Loop 3365 Loss_Train:  [[ 13.20364269]] Loss_Validation:  [[ 10.96923934]]\n",
      "Loop 3366 Loss_Train:  [[ 13.20363023]] Loss_Validation:  [[ 10.96929891]]\n",
      "Loop 3367 Loss_Train:  [[ 13.20361779]] Loss_Validation:  [[ 10.96935843]]\n",
      "Loop 3368 Loss_Train:  [[ 13.20360536]] Loss_Validation:  [[ 10.96941791]]\n",
      "Loop 3369 Loss_Train:  [[ 13.20359296]] Loss_Validation:  [[ 10.96947734]]\n",
      "Loop 3370 Loss_Train:  [[ 13.20358057]] Loss_Validation:  [[ 10.96953672]]\n",
      "Loop 3371 Loss_Train:  [[ 13.20356821]] Loss_Validation:  [[ 10.96959606]]\n",
      "Loop 3372 Loss_Train:  [[ 13.20355586]] Loss_Validation:  [[ 10.96965535]]\n",
      "Loop 3373 Loss_Train:  [[ 13.20354353]] Loss_Validation:  [[ 10.9697146]]\n",
      "Loop 3374 Loss_Train:  [[ 13.20353121]] Loss_Validation:  [[ 10.9697738]]\n",
      "Loop 3375 Loss_Train:  [[ 13.20351892]] Loss_Validation:  [[ 10.96983296]]\n",
      "Loop 3376 Loss_Train:  [[ 13.20350665]] Loss_Validation:  [[ 10.96989207]]\n",
      "Loop 3377 Loss_Train:  [[ 13.20349439]] Loss_Validation:  [[ 10.96995113]]\n",
      "Loop 3378 Loss_Train:  [[ 13.20348215]] Loss_Validation:  [[ 10.97001015]]\n",
      "Loop 3379 Loss_Train:  [[ 13.20346993]] Loss_Validation:  [[ 10.97006912]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3380 Loss_Train:  [[ 13.20345773]] Loss_Validation:  [[ 10.97012804]]\n",
      "Loop 3381 Loss_Train:  [[ 13.20344555]] Loss_Validation:  [[ 10.97018693]]\n",
      "Loop 3382 Loss_Train:  [[ 13.20343339]] Loss_Validation:  [[ 10.97024576]]\n",
      "Loop 3383 Loss_Train:  [[ 13.20342124]] Loss_Validation:  [[ 10.97030455]]\n",
      "Loop 3384 Loss_Train:  [[ 13.20340911]] Loss_Validation:  [[ 10.97036329]]\n",
      "Loop 3385 Loss_Train:  [[ 13.203397]] Loss_Validation:  [[ 10.97042199]]\n",
      "Loop 3386 Loss_Train:  [[ 13.20338491]] Loss_Validation:  [[ 10.97048064]]\n",
      "Loop 3387 Loss_Train:  [[ 13.20337284]] Loss_Validation:  [[ 10.97053925]]\n",
      "Loop 3388 Loss_Train:  [[ 13.20336079]] Loss_Validation:  [[ 10.97059781]]\n",
      "Loop 3389 Loss_Train:  [[ 13.20334875]] Loss_Validation:  [[ 10.97065633]]\n",
      "Loop 3390 Loss_Train:  [[ 13.20333673]] Loss_Validation:  [[ 10.9707148]]\n",
      "Loop 3391 Loss_Train:  [[ 13.20332473]] Loss_Validation:  [[ 10.97077323]]\n",
      "Loop 3392 Loss_Train:  [[ 13.20331275]] Loss_Validation:  [[ 10.97083161]]\n",
      "Loop 3393 Loss_Train:  [[ 13.20330078]] Loss_Validation:  [[ 10.97088994]]\n",
      "Loop 3394 Loss_Train:  [[ 13.20328884]] Loss_Validation:  [[ 10.97094823]]\n",
      "Loop 3395 Loss_Train:  [[ 13.20327691]] Loss_Validation:  [[ 10.97100648]]\n",
      "Loop 3396 Loss_Train:  [[ 13.203265]] Loss_Validation:  [[ 10.97106468]]\n",
      "Loop 3397 Loss_Train:  [[ 13.20325311]] Loss_Validation:  [[ 10.97112284]]\n",
      "Loop 3398 Loss_Train:  [[ 13.20324123]] Loss_Validation:  [[ 10.97118095]]\n",
      "Loop 3399 Loss_Train:  [[ 13.20322937]] Loss_Validation:  [[ 10.97123901]]\n",
      "Loop 3400 Loss_Train:  [[ 13.20321754]] Loss_Validation:  [[ 10.97129703]]\n",
      "Loop 3401 Loss_Train:  [[ 13.20320571]] Loss_Validation:  [[ 10.97135501]]\n",
      "Loop 3402 Loss_Train:  [[ 13.20319391]] Loss_Validation:  [[ 10.97141294]]\n",
      "Loop 3403 Loss_Train:  [[ 13.20318213]] Loss_Validation:  [[ 10.97147082]]\n",
      "Loop 3404 Loss_Train:  [[ 13.20317036]] Loss_Validation:  [[ 10.97152867]]\n",
      "Loop 3405 Loss_Train:  [[ 13.20315861]] Loss_Validation:  [[ 10.97158646]]\n",
      "Loop 3406 Loss_Train:  [[ 13.20314687]] Loss_Validation:  [[ 10.97164422]]\n",
      "Loop 3407 Loss_Train:  [[ 13.20313516]] Loss_Validation:  [[ 10.97170192]]\n",
      "Loop 3408 Loss_Train:  [[ 13.20312346]] Loss_Validation:  [[ 10.97175959]]\n",
      "Loop 3409 Loss_Train:  [[ 13.20311178]] Loss_Validation:  [[ 10.9718172]]\n",
      "Loop 3410 Loss_Train:  [[ 13.20310012]] Loss_Validation:  [[ 10.97187478]]\n",
      "Loop 3411 Loss_Train:  [[ 13.20308848]] Loss_Validation:  [[ 10.97193231]]\n",
      "Loop 3412 Loss_Train:  [[ 13.20307685]] Loss_Validation:  [[ 10.97198979]]\n",
      "Loop 3413 Loss_Train:  [[ 13.20306524]] Loss_Validation:  [[ 10.97204723]]\n",
      "Loop 3414 Loss_Train:  [[ 13.20305365]] Loss_Validation:  [[ 10.97210463]]\n",
      "Loop 3415 Loss_Train:  [[ 13.20304207]] Loss_Validation:  [[ 10.97216198]]\n",
      "Loop 3416 Loss_Train:  [[ 13.20303052]] Loss_Validation:  [[ 10.97221929]]\n",
      "Loop 3417 Loss_Train:  [[ 13.20301898]] Loss_Validation:  [[ 10.97227655]]\n",
      "Loop 3418 Loss_Train:  [[ 13.20300745]] Loss_Validation:  [[ 10.97233377]]\n",
      "Loop 3419 Loss_Train:  [[ 13.20299595]] Loss_Validation:  [[ 10.97239095]]\n",
      "Loop 3420 Loss_Train:  [[ 13.20298446]] Loss_Validation:  [[ 10.97244808]]\n",
      "Loop 3421 Loss_Train:  [[ 13.20297299]] Loss_Validation:  [[ 10.97250517]]\n",
      "Loop 3422 Loss_Train:  [[ 13.20296154]] Loss_Validation:  [[ 10.97256221]]\n",
      "Loop 3423 Loss_Train:  [[ 13.2029501]] Loss_Validation:  [[ 10.97261921]]\n",
      "Loop 3424 Loss_Train:  [[ 13.20293868]] Loss_Validation:  [[ 10.97267617]]\n",
      "Loop 3425 Loss_Train:  [[ 13.20292728]] Loss_Validation:  [[ 10.97273308]]\n",
      "Loop 3426 Loss_Train:  [[ 13.20291589]] Loss_Validation:  [[ 10.97278995]]\n",
      "Loop 3427 Loss_Train:  [[ 13.20290453]] Loss_Validation:  [[ 10.97284677]]\n",
      "Loop 3428 Loss_Train:  [[ 13.20289317]] Loss_Validation:  [[ 10.97290355]]\n",
      "Loop 3429 Loss_Train:  [[ 13.20288184]] Loss_Validation:  [[ 10.97296029]]\n",
      "Loop 3430 Loss_Train:  [[ 13.20287052]] Loss_Validation:  [[ 10.97301698]]\n",
      "Loop 3431 Loss_Train:  [[ 13.20285922]] Loss_Validation:  [[ 10.97307363]]\n",
      "Loop 3432 Loss_Train:  [[ 13.20284794]] Loss_Validation:  [[ 10.97313023]]\n",
      "Loop 3433 Loss_Train:  [[ 13.20283668]] Loss_Validation:  [[ 10.9731868]]\n",
      "Loop 3434 Loss_Train:  [[ 13.20282543]] Loss_Validation:  [[ 10.97324331]]\n",
      "Loop 3435 Loss_Train:  [[ 13.2028142]] Loss_Validation:  [[ 10.97329979]]\n",
      "Loop 3436 Loss_Train:  [[ 13.20280298]] Loss_Validation:  [[ 10.97335622]]\n",
      "Loop 3437 Loss_Train:  [[ 13.20279178]] Loss_Validation:  [[ 10.97341261]]\n",
      "Loop 3438 Loss_Train:  [[ 13.2027806]] Loss_Validation:  [[ 10.97346895]]\n",
      "Loop 3439 Loss_Train:  [[ 13.20276944]] Loss_Validation:  [[ 10.97352525]]\n",
      "Loop 3440 Loss_Train:  [[ 13.20275829]] Loss_Validation:  [[ 10.97358151]]\n",
      "Loop 3441 Loss_Train:  [[ 13.20274716]] Loss_Validation:  [[ 10.97363773]]\n",
      "Loop 3442 Loss_Train:  [[ 13.20273604]] Loss_Validation:  [[ 10.9736939]]\n",
      "Loop 3443 Loss_Train:  [[ 13.20272495]] Loss_Validation:  [[ 10.97375003]]\n",
      "Loop 3444 Loss_Train:  [[ 13.20271387]] Loss_Validation:  [[ 10.97380611]]\n",
      "Loop 3445 Loss_Train:  [[ 13.2027028]] Loss_Validation:  [[ 10.97386215]]\n",
      "Loop 3446 Loss_Train:  [[ 13.20269175]] Loss_Validation:  [[ 10.97391815]]\n",
      "Loop 3447 Loss_Train:  [[ 13.20268072]] Loss_Validation:  [[ 10.97397411]]\n",
      "Loop 3448 Loss_Train:  [[ 13.20266971]] Loss_Validation:  [[ 10.97403002]]\n",
      "Loop 3449 Loss_Train:  [[ 13.20265871]] Loss_Validation:  [[ 10.97408589]]\n",
      "Loop 3450 Loss_Train:  [[ 13.20264773]] Loss_Validation:  [[ 10.97414172]]\n",
      "Loop 3451 Loss_Train:  [[ 13.20263676]] Loss_Validation:  [[ 10.9741975]]\n",
      "Loop 3452 Loss_Train:  [[ 13.20262582]] Loss_Validation:  [[ 10.97425325]]\n",
      "Loop 3453 Loss_Train:  [[ 13.20261488]] Loss_Validation:  [[ 10.97430894]]\n",
      "Loop 3454 Loss_Train:  [[ 13.20260397]] Loss_Validation:  [[ 10.9743646]]\n",
      "Loop 3455 Loss_Train:  [[ 13.20259307]] Loss_Validation:  [[ 10.97442021]]\n",
      "Loop 3456 Loss_Train:  [[ 13.20258219]] Loss_Validation:  [[ 10.97447578]]\n",
      "Loop 3457 Loss_Train:  [[ 13.20257132]] Loss_Validation:  [[ 10.97453131]]\n",
      "Loop 3458 Loss_Train:  [[ 13.20256047]] Loss_Validation:  [[ 10.9745868]]\n",
      "Loop 3459 Loss_Train:  [[ 13.20254964]] Loss_Validation:  [[ 10.97464224]]\n",
      "Loop 3460 Loss_Train:  [[ 13.20253882]] Loss_Validation:  [[ 10.97469764]]\n",
      "Loop 3461 Loss_Train:  [[ 13.20252802]] Loss_Validation:  [[ 10.974753]]\n",
      "Loop 3462 Loss_Train:  [[ 13.20251723]] Loss_Validation:  [[ 10.97480831]]\n",
      "Loop 3463 Loss_Train:  [[ 13.20250646]] Loss_Validation:  [[ 10.97486358]]\n",
      "Loop 3464 Loss_Train:  [[ 13.20249571]] Loss_Validation:  [[ 10.97491882]]\n",
      "Loop 3465 Loss_Train:  [[ 13.20248497]] Loss_Validation:  [[ 10.974974]]\n",
      "Loop 3466 Loss_Train:  [[ 13.20247425]] Loss_Validation:  [[ 10.97502915]]\n",
      "Loop 3467 Loss_Train:  [[ 13.20246355]] Loss_Validation:  [[ 10.97508425]]\n",
      "Loop 3468 Loss_Train:  [[ 13.20245286]] Loss_Validation:  [[ 10.97513931]]\n",
      "Loop 3469 Loss_Train:  [[ 13.20244219]] Loss_Validation:  [[ 10.97519433]]\n",
      "Loop 3470 Loss_Train:  [[ 13.20243153]] Loss_Validation:  [[ 10.97524931]]\n",
      "Loop 3471 Loss_Train:  [[ 13.20242089]] Loss_Validation:  [[ 10.97530424]]\n",
      "Loop 3472 Loss_Train:  [[ 13.20241027]] Loss_Validation:  [[ 10.97535914]]\n",
      "Loop 3473 Loss_Train:  [[ 13.20239966]] Loss_Validation:  [[ 10.97541399]]\n",
      "Loop 3474 Loss_Train:  [[ 13.20238906]] Loss_Validation:  [[ 10.9754688]]\n",
      "Loop 3475 Loss_Train:  [[ 13.20237849]] Loss_Validation:  [[ 10.97552356]]\n",
      "Loop 3476 Loss_Train:  [[ 13.20236793]] Loss_Validation:  [[ 10.97557829]]\n",
      "Loop 3477 Loss_Train:  [[ 13.20235738]] Loss_Validation:  [[ 10.97563297]]\n",
      "Loop 3478 Loss_Train:  [[ 13.20234685]] Loss_Validation:  [[ 10.97568761]]\n",
      "Loop 3479 Loss_Train:  [[ 13.20233634]] Loss_Validation:  [[ 10.97574221]]\n",
      "Loop 3480 Loss_Train:  [[ 13.20232584]] Loss_Validation:  [[ 10.97579677]]\n",
      "Loop 3481 Loss_Train:  [[ 13.20231536]] Loss_Validation:  [[ 10.97585128]]\n",
      "Loop 3482 Loss_Train:  [[ 13.20230489]] Loss_Validation:  [[ 10.97590576]]\n",
      "Loop 3483 Loss_Train:  [[ 13.20229444]] Loss_Validation:  [[ 10.97596019]]\n",
      "Loop 3484 Loss_Train:  [[ 13.20228401]] Loss_Validation:  [[ 10.97601458]]\n",
      "Loop 3485 Loss_Train:  [[ 13.20227359]] Loss_Validation:  [[ 10.97606893]]\n",
      "Loop 3486 Loss_Train:  [[ 13.20226319]] Loss_Validation:  [[ 10.97612323]]\n",
      "Loop 3487 Loss_Train:  [[ 13.2022528]] Loss_Validation:  [[ 10.9761775]]\n",
      "Loop 3488 Loss_Train:  [[ 13.20224243]] Loss_Validation:  [[ 10.97623172]]\n",
      "Loop 3489 Loss_Train:  [[ 13.20223207]] Loss_Validation:  [[ 10.97628591]]\n",
      "Loop 3490 Loss_Train:  [[ 13.20222173]] Loss_Validation:  [[ 10.97634005]]\n",
      "Loop 3491 Loss_Train:  [[ 13.2022114]] Loss_Validation:  [[ 10.97639415]]\n",
      "Loop 3492 Loss_Train:  [[ 13.20220109]] Loss_Validation:  [[ 10.97644821]]\n",
      "Loop 3493 Loss_Train:  [[ 13.2021908]] Loss_Validation:  [[ 10.97650223]]\n",
      "Loop 3494 Loss_Train:  [[ 13.20218052]] Loss_Validation:  [[ 10.9765562]]\n",
      "Loop 3495 Loss_Train:  [[ 13.20217025]] Loss_Validation:  [[ 10.97661014]]\n",
      "Loop 3496 Loss_Train:  [[ 13.20216001]] Loss_Validation:  [[ 10.97666403]]\n",
      "Loop 3497 Loss_Train:  [[ 13.20214977]] Loss_Validation:  [[ 10.97671788]]\n",
      "Loop 3498 Loss_Train:  [[ 13.20213955]] Loss_Validation:  [[ 10.97677169]]\n",
      "Loop 3499 Loss_Train:  [[ 13.20212935]] Loss_Validation:  [[ 10.97682546]]\n",
      "Loop 3500 Loss_Train:  [[ 13.20211917]] Loss_Validation:  [[ 10.97687919]]\n",
      "Loop 3501 Loss_Train:  [[ 13.20210899]] Loss_Validation:  [[ 10.97693288]]\n",
      "Loop 3502 Loss_Train:  [[ 13.20209884]] Loss_Validation:  [[ 10.97698653]]\n",
      "Loop 3503 Loss_Train:  [[ 13.2020887]] Loss_Validation:  [[ 10.97704014]]\n",
      "Loop 3504 Loss_Train:  [[ 13.20207857]] Loss_Validation:  [[ 10.9770937]]\n",
      "Loop 3505 Loss_Train:  [[ 13.20206846]] Loss_Validation:  [[ 10.97714723]]\n",
      "Loop 3506 Loss_Train:  [[ 13.20205836]] Loss_Validation:  [[ 10.97720071]]\n",
      "Loop 3507 Loss_Train:  [[ 13.20204828]] Loss_Validation:  [[ 10.97725415]]\n",
      "Loop 3508 Loss_Train:  [[ 13.20203822]] Loss_Validation:  [[ 10.97730755]]\n",
      "Loop 3509 Loss_Train:  [[ 13.20202817]] Loss_Validation:  [[ 10.97736092]]\n",
      "Loop 3510 Loss_Train:  [[ 13.20201813]] Loss_Validation:  [[ 10.97741424]]\n",
      "Loop 3511 Loss_Train:  [[ 13.20200811]] Loss_Validation:  [[ 10.97746752]]\n",
      "Loop 3512 Loss_Train:  [[ 13.2019981]] Loss_Validation:  [[ 10.97752076]]\n",
      "Loop 3513 Loss_Train:  [[ 13.20198811]] Loss_Validation:  [[ 10.97757395]]\n",
      "Loop 3514 Loss_Train:  [[ 13.20197814]] Loss_Validation:  [[ 10.97762711]]\n",
      "Loop 3515 Loss_Train:  [[ 13.20196818]] Loss_Validation:  [[ 10.97768023]]\n",
      "Loop 3516 Loss_Train:  [[ 13.20195823]] Loss_Validation:  [[ 10.97773331]]\n",
      "Loop 3517 Loss_Train:  [[ 13.2019483]] Loss_Validation:  [[ 10.97778634]]\n",
      "Loop 3518 Loss_Train:  [[ 13.20193839]] Loss_Validation:  [[ 10.97783934]]\n",
      "Loop 3519 Loss_Train:  [[ 13.20192849]] Loss_Validation:  [[ 10.9778923]]\n",
      "Loop 3520 Loss_Train:  [[ 13.2019186]] Loss_Validation:  [[ 10.97794521]]\n",
      "Loop 3521 Loss_Train:  [[ 13.20190873]] Loss_Validation:  [[ 10.97799809]]\n",
      "Loop 3522 Loss_Train:  [[ 13.20189887]] Loss_Validation:  [[ 10.97805092]]\n",
      "Loop 3523 Loss_Train:  [[ 13.20188903]] Loss_Validation:  [[ 10.97810372]]\n",
      "Loop 3524 Loss_Train:  [[ 13.2018792]] Loss_Validation:  [[ 10.97815647]]\n",
      "Loop 3525 Loss_Train:  [[ 13.20186939]] Loss_Validation:  [[ 10.97820919]]\n",
      "Loop 3526 Loss_Train:  [[ 13.20185959]] Loss_Validation:  [[ 10.97826186]]\n",
      "Loop 3527 Loss_Train:  [[ 13.20184981]] Loss_Validation:  [[ 10.9783145]]\n",
      "Loop 3528 Loss_Train:  [[ 13.20184004]] Loss_Validation:  [[ 10.97836709]]\n",
      "Loop 3529 Loss_Train:  [[ 13.20183029]] Loss_Validation:  [[ 10.97841965]]\n",
      "Loop 3530 Loss_Train:  [[ 13.20182055]] Loss_Validation:  [[ 10.97847216]]\n",
      "Loop 3531 Loss_Train:  [[ 13.20181083]] Loss_Validation:  [[ 10.97852463]]\n",
      "Loop 3532 Loss_Train:  [[ 13.20180112]] Loss_Validation:  [[ 10.97857707]]\n",
      "Loop 3533 Loss_Train:  [[ 13.20179142]] Loss_Validation:  [[ 10.97862946]]\n",
      "Loop 3534 Loss_Train:  [[ 13.20178174]] Loss_Validation:  [[ 10.97868182]]\n",
      "Loop 3535 Loss_Train:  [[ 13.20177207]] Loss_Validation:  [[ 10.97873413]]\n",
      "Loop 3536 Loss_Train:  [[ 13.20176242]] Loss_Validation:  [[ 10.97878641]]\n",
      "Loop 3537 Loss_Train:  [[ 13.20175278]] Loss_Validation:  [[ 10.97883864]]\n",
      "Loop 3538 Loss_Train:  [[ 13.20174316]] Loss_Validation:  [[ 10.97889084]]\n",
      "Loop 3539 Loss_Train:  [[ 13.20173355]] Loss_Validation:  [[ 10.978943]]\n",
      "Loop 3540 Loss_Train:  [[ 13.20172396]] Loss_Validation:  [[ 10.97899511]]\n",
      "Loop 3541 Loss_Train:  [[ 13.20171438]] Loss_Validation:  [[ 10.97904719]]\n",
      "Loop 3542 Loss_Train:  [[ 13.20170481]] Loss_Validation:  [[ 10.97909923]]\n",
      "Loop 3543 Loss_Train:  [[ 13.20169526]] Loss_Validation:  [[ 10.97915122]]\n",
      "Loop 3544 Loss_Train:  [[ 13.20168573]] Loss_Validation:  [[ 10.97920318]]\n",
      "Loop 3545 Loss_Train:  [[ 13.2016762]] Loss_Validation:  [[ 10.9792551]]\n",
      "Loop 3546 Loss_Train:  [[ 13.2016667]] Loss_Validation:  [[ 10.97930698]]\n",
      "Loop 3547 Loss_Train:  [[ 13.2016572]] Loss_Validation:  [[ 10.97935882]]\n",
      "Loop 3548 Loss_Train:  [[ 13.20164772]] Loss_Validation:  [[ 10.97941062]]\n",
      "Loop 3549 Loss_Train:  [[ 13.20163826]] Loss_Validation:  [[ 10.97946238]]\n",
      "Loop 3550 Loss_Train:  [[ 13.20162881]] Loss_Validation:  [[ 10.97951411]]\n",
      "Loop 3551 Loss_Train:  [[ 13.20161937]] Loss_Validation:  [[ 10.97956579]]\n",
      "Loop 3552 Loss_Train:  [[ 13.20160995]] Loss_Validation:  [[ 10.97961743]]\n",
      "Loop 3553 Loss_Train:  [[ 13.20160054]] Loss_Validation:  [[ 10.97966904]]\n",
      "Loop 3554 Loss_Train:  [[ 13.20159114]] Loss_Validation:  [[ 10.9797206]]\n",
      "Loop 3555 Loss_Train:  [[ 13.20158176]] Loss_Validation:  [[ 10.97977213]]\n",
      "Loop 3556 Loss_Train:  [[ 13.20157239]] Loss_Validation:  [[ 10.97982361]]\n",
      "Loop 3557 Loss_Train:  [[ 13.20156304]] Loss_Validation:  [[ 10.97987506]]\n",
      "Loop 3558 Loss_Train:  [[ 13.2015537]] Loss_Validation:  [[ 10.97992647]]\n",
      "Loop 3559 Loss_Train:  [[ 13.20154438]] Loss_Validation:  [[ 10.97997784]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3560 Loss_Train:  [[ 13.20153507]] Loss_Validation:  [[ 10.98002917]]\n",
      "Loop 3561 Loss_Train:  [[ 13.20152577]] Loss_Validation:  [[ 10.98008046]]\n",
      "Loop 3562 Loss_Train:  [[ 13.20151649]] Loss_Validation:  [[ 10.98013172]]\n",
      "Loop 3563 Loss_Train:  [[ 13.20150722]] Loss_Validation:  [[ 10.98018293]]\n",
      "Loop 3564 Loss_Train:  [[ 13.20149796]] Loss_Validation:  [[ 10.98023411]]\n",
      "Loop 3565 Loss_Train:  [[ 13.20148872]] Loss_Validation:  [[ 10.98028525]]\n",
      "Loop 3566 Loss_Train:  [[ 13.20147949]] Loss_Validation:  [[ 10.98033634]]\n",
      "Loop 3567 Loss_Train:  [[ 13.20147028]] Loss_Validation:  [[ 10.9803874]]\n",
      "Loop 3568 Loss_Train:  [[ 13.20146108]] Loss_Validation:  [[ 10.98043842]]\n",
      "Loop 3569 Loss_Train:  [[ 13.20145189]] Loss_Validation:  [[ 10.98048941]]\n",
      "Loop 3570 Loss_Train:  [[ 13.20144272]] Loss_Validation:  [[ 10.98054035]]\n",
      "Loop 3571 Loss_Train:  [[ 13.20143356]] Loss_Validation:  [[ 10.98059125]]\n",
      "Loop 3572 Loss_Train:  [[ 13.20142442]] Loss_Validation:  [[ 10.98064212]]\n",
      "Loop 3573 Loss_Train:  [[ 13.20141529]] Loss_Validation:  [[ 10.98069295]]\n",
      "Loop 3574 Loss_Train:  [[ 13.20140617]] Loss_Validation:  [[ 10.98074374]]\n",
      "Loop 3575 Loss_Train:  [[ 13.20139707]] Loss_Validation:  [[ 10.98079449]]\n",
      "Loop 3576 Loss_Train:  [[ 13.20138798]] Loss_Validation:  [[ 10.9808452]]\n",
      "Loop 3577 Loss_Train:  [[ 13.2013789]] Loss_Validation:  [[ 10.98089588]]\n",
      "Loop 3578 Loss_Train:  [[ 13.20136984]] Loss_Validation:  [[ 10.98094651]]\n",
      "Loop 3579 Loss_Train:  [[ 13.20136079]] Loss_Validation:  [[ 10.98099711]]\n",
      "Loop 3580 Loss_Train:  [[ 13.20135175]] Loss_Validation:  [[ 10.98104767]]\n",
      "Loop 3581 Loss_Train:  [[ 13.20134273]] Loss_Validation:  [[ 10.98109819]]\n",
      "Loop 3582 Loss_Train:  [[ 13.20133372]] Loss_Validation:  [[ 10.98114867]]\n",
      "Loop 3583 Loss_Train:  [[ 13.20132472]] Loss_Validation:  [[ 10.98119912]]\n",
      "Loop 3584 Loss_Train:  [[ 13.20131574]] Loss_Validation:  [[ 10.98124952]]\n",
      "Loop 3585 Loss_Train:  [[ 13.20130677]] Loss_Validation:  [[ 10.98129989]]\n",
      "Loop 3586 Loss_Train:  [[ 13.20129782]] Loss_Validation:  [[ 10.98135022]]\n",
      "Loop 3587 Loss_Train:  [[ 13.20128888]] Loss_Validation:  [[ 10.98140051]]\n",
      "Loop 3588 Loss_Train:  [[ 13.20127995]] Loss_Validation:  [[ 10.98145077]]\n",
      "Loop 3589 Loss_Train:  [[ 13.20127103]] Loss_Validation:  [[ 10.98150098]]\n",
      "Loop 3590 Loss_Train:  [[ 13.20126213]] Loss_Validation:  [[ 10.98155116]]\n",
      "Loop 3591 Loss_Train:  [[ 13.20125324]] Loss_Validation:  [[ 10.9816013]]\n",
      "Loop 3592 Loss_Train:  [[ 13.20124437]] Loss_Validation:  [[ 10.98165141]]\n",
      "Loop 3593 Loss_Train:  [[ 13.2012355]] Loss_Validation:  [[ 10.98170147]]\n",
      "Loop 3594 Loss_Train:  [[ 13.20122666]] Loss_Validation:  [[ 10.9817515]]\n",
      "Loop 3595 Loss_Train:  [[ 13.20121782]] Loss_Validation:  [[ 10.98180149]]\n",
      "Loop 3596 Loss_Train:  [[ 13.201209]] Loss_Validation:  [[ 10.98185144]]\n",
      "Loop 3597 Loss_Train:  [[ 13.20120019]] Loss_Validation:  [[ 10.98190135]]\n",
      "Loop 3598 Loss_Train:  [[ 13.20119139]] Loss_Validation:  [[ 10.98195123]]\n",
      "Loop 3599 Loss_Train:  [[ 13.20118261]] Loss_Validation:  [[ 10.98200107]]\n",
      "Loop 3600 Loss_Train:  [[ 13.20117384]] Loss_Validation:  [[ 10.98205087]]\n",
      "Loop 3601 Loss_Train:  [[ 13.20116508]] Loss_Validation:  [[ 10.98210063]]\n",
      "Loop 3602 Loss_Train:  [[ 13.20115634]] Loss_Validation:  [[ 10.98215036]]\n",
      "Loop 3603 Loss_Train:  [[ 13.20114761]] Loss_Validation:  [[ 10.98220004]]\n",
      "Loop 3604 Loss_Train:  [[ 13.20113889]] Loss_Validation:  [[ 10.98224969]]\n",
      "Loop 3605 Loss_Train:  [[ 13.20113019]] Loss_Validation:  [[ 10.98229931]]\n",
      "Loop 3606 Loss_Train:  [[ 13.2011215]] Loss_Validation:  [[ 10.98234888]]\n",
      "Loop 3607 Loss_Train:  [[ 13.20111282]] Loss_Validation:  [[ 10.98239842]]\n",
      "Loop 3608 Loss_Train:  [[ 13.20110416]] Loss_Validation:  [[ 10.98244792]]\n",
      "Loop 3609 Loss_Train:  [[ 13.2010955]] Loss_Validation:  [[ 10.98249739]]\n",
      "Loop 3610 Loss_Train:  [[ 13.20108686]] Loss_Validation:  [[ 10.98254681]]\n",
      "Loop 3611 Loss_Train:  [[ 13.20107824]] Loss_Validation:  [[ 10.9825962]]\n",
      "Loop 3612 Loss_Train:  [[ 13.20106962]] Loss_Validation:  [[ 10.98264555]]\n",
      "Loop 3613 Loss_Train:  [[ 13.20106102]] Loss_Validation:  [[ 10.98269487]]\n",
      "Loop 3614 Loss_Train:  [[ 13.20105244]] Loss_Validation:  [[ 10.98274415]]\n",
      "Loop 3615 Loss_Train:  [[ 13.20104386]] Loss_Validation:  [[ 10.98279339]]\n",
      "Loop 3616 Loss_Train:  [[ 13.2010353]] Loss_Validation:  [[ 10.98284259]]\n",
      "Loop 3617 Loss_Train:  [[ 13.20102675]] Loss_Validation:  [[ 10.98289176]]\n",
      "Loop 3618 Loss_Train:  [[ 13.20101821]] Loss_Validation:  [[ 10.98294089]]\n",
      "Loop 3619 Loss_Train:  [[ 13.20100969]] Loss_Validation:  [[ 10.98298998]]\n",
      "Loop 3620 Loss_Train:  [[ 13.20100118]] Loss_Validation:  [[ 10.98303903]]\n",
      "Loop 3621 Loss_Train:  [[ 13.20099268]] Loss_Validation:  [[ 10.98308805]]\n",
      "Loop 3622 Loss_Train:  [[ 13.20098419]] Loss_Validation:  [[ 10.98313703]]\n",
      "Loop 3623 Loss_Train:  [[ 13.20097572]] Loss_Validation:  [[ 10.98318598]]\n",
      "Loop 3624 Loss_Train:  [[ 13.20096726]] Loss_Validation:  [[ 10.98323488]]\n",
      "Loop 3625 Loss_Train:  [[ 13.20095881]] Loss_Validation:  [[ 10.98328376]]\n",
      "Loop 3626 Loss_Train:  [[ 13.20095038]] Loss_Validation:  [[ 10.98333259]]\n",
      "Loop 3627 Loss_Train:  [[ 13.20094196]] Loss_Validation:  [[ 10.98338139]]\n",
      "Loop 3628 Loss_Train:  [[ 13.20093355]] Loss_Validation:  [[ 10.98343015]]\n",
      "Loop 3629 Loss_Train:  [[ 13.20092515]] Loss_Validation:  [[ 10.98347887]]\n",
      "Loop 3630 Loss_Train:  [[ 13.20091676]] Loss_Validation:  [[ 10.98352756]]\n",
      "Loop 3631 Loss_Train:  [[ 13.20090839]] Loss_Validation:  [[ 10.98357621]]\n",
      "Loop 3632 Loss_Train:  [[ 13.20090003]] Loss_Validation:  [[ 10.98362482]]\n",
      "Loop 3633 Loss_Train:  [[ 13.20089168]] Loss_Validation:  [[ 10.9836734]]\n",
      "Loop 3634 Loss_Train:  [[ 13.20088335]] Loss_Validation:  [[ 10.98372194]]\n",
      "Loop 3635 Loss_Train:  [[ 13.20087503]] Loss_Validation:  [[ 10.98377045]]\n",
      "Loop 3636 Loss_Train:  [[ 13.20086672]] Loss_Validation:  [[ 10.98381892]]\n",
      "Loop 3637 Loss_Train:  [[ 13.20085842]] Loss_Validation:  [[ 10.98386735]]\n",
      "Loop 3638 Loss_Train:  [[ 13.20085014]] Loss_Validation:  [[ 10.98391574]]\n",
      "Loop 3639 Loss_Train:  [[ 13.20084186]] Loss_Validation:  [[ 10.9839641]]\n",
      "Loop 3640 Loss_Train:  [[ 13.2008336]] Loss_Validation:  [[ 10.98401242]]\n",
      "Loop 3641 Loss_Train:  [[ 13.20082535]] Loss_Validation:  [[ 10.98406071]]\n",
      "Loop 3642 Loss_Train:  [[ 13.20081712]] Loss_Validation:  [[ 10.98410896]]\n",
      "Loop 3643 Loss_Train:  [[ 13.2008089]] Loss_Validation:  [[ 10.98415717]]\n",
      "Loop 3644 Loss_Train:  [[ 13.20080068]] Loss_Validation:  [[ 10.98420535]]\n",
      "Loop 3645 Loss_Train:  [[ 13.20079249]] Loss_Validation:  [[ 10.98425349]]\n",
      "Loop 3646 Loss_Train:  [[ 13.2007843]] Loss_Validation:  [[ 10.9843016]]\n",
      "Loop 3647 Loss_Train:  [[ 13.20077613]] Loss_Validation:  [[ 10.98434967]]\n",
      "Loop 3648 Loss_Train:  [[ 13.20076796]] Loss_Validation:  [[ 10.9843977]]\n",
      "Loop 3649 Loss_Train:  [[ 13.20075981]] Loss_Validation:  [[ 10.9844457]]\n",
      "Loop 3650 Loss_Train:  [[ 13.20075168]] Loss_Validation:  [[ 10.98449366]]\n",
      "Loop 3651 Loss_Train:  [[ 13.20074355]] Loss_Validation:  [[ 10.98454158]]\n",
      "Loop 3652 Loss_Train:  [[ 13.20073544]] Loss_Validation:  [[ 10.98458947]]\n",
      "Loop 3653 Loss_Train:  [[ 13.20072734]] Loss_Validation:  [[ 10.98463732]]\n",
      "Loop 3654 Loss_Train:  [[ 13.20071925]] Loss_Validation:  [[ 10.98468514]]\n",
      "Loop 3655 Loss_Train:  [[ 13.20071117]] Loss_Validation:  [[ 10.98473292]]\n",
      "Loop 3656 Loss_Train:  [[ 13.2007031]] Loss_Validation:  [[ 10.98478067]]\n",
      "Loop 3657 Loss_Train:  [[ 13.20069505]] Loss_Validation:  [[ 10.98482838]]\n",
      "Loop 3658 Loss_Train:  [[ 13.20068701]] Loss_Validation:  [[ 10.98487605]]\n",
      "Loop 3659 Loss_Train:  [[ 13.20067898]] Loss_Validation:  [[ 10.98492369]]\n",
      "Loop 3660 Loss_Train:  [[ 13.20067096]] Loss_Validation:  [[ 10.98497129]]\n",
      "Loop 3661 Loss_Train:  [[ 13.20066296]] Loss_Validation:  [[ 10.98501886]]\n",
      "Loop 3662 Loss_Train:  [[ 13.20065497]] Loss_Validation:  [[ 10.98506639]]\n",
      "Loop 3663 Loss_Train:  [[ 13.20064698]] Loss_Validation:  [[ 10.98511388]]\n",
      "Loop 3664 Loss_Train:  [[ 13.20063902]] Loss_Validation:  [[ 10.98516134]]\n",
      "Loop 3665 Loss_Train:  [[ 13.20063106]] Loss_Validation:  [[ 10.98520877]]\n",
      "Loop 3666 Loss_Train:  [[ 13.20062311]] Loss_Validation:  [[ 10.98525616]]\n",
      "Loop 3667 Loss_Train:  [[ 13.20061518]] Loss_Validation:  [[ 10.98530351]]\n",
      "Loop 3668 Loss_Train:  [[ 13.20060726]] Loss_Validation:  [[ 10.98535083]]\n",
      "Loop 3669 Loss_Train:  [[ 13.20059935]] Loss_Validation:  [[ 10.98539811]]\n",
      "Loop 3670 Loss_Train:  [[ 13.20059145]] Loss_Validation:  [[ 10.98544536]]\n",
      "Loop 3671 Loss_Train:  [[ 13.20058356]] Loss_Validation:  [[ 10.98549257]]\n",
      "Loop 3672 Loss_Train:  [[ 13.20057569]] Loss_Validation:  [[ 10.98553974]]\n",
      "Loop 3673 Loss_Train:  [[ 13.20056783]] Loss_Validation:  [[ 10.98558689]]\n",
      "Loop 3674 Loss_Train:  [[ 13.20055997]] Loss_Validation:  [[ 10.98563399]]\n",
      "Loop 3675 Loss_Train:  [[ 13.20055213]] Loss_Validation:  [[ 10.98568106]]\n",
      "Loop 3676 Loss_Train:  [[ 13.20054431]] Loss_Validation:  [[ 10.9857281]]\n",
      "Loop 3677 Loss_Train:  [[ 13.20053649]] Loss_Validation:  [[ 10.9857751]]\n",
      "Loop 3678 Loss_Train:  [[ 13.20052869]] Loss_Validation:  [[ 10.98582206]]\n",
      "Loop 3679 Loss_Train:  [[ 13.20052089]] Loss_Validation:  [[ 10.98586899]]\n",
      "Loop 3680 Loss_Train:  [[ 13.20051311]] Loss_Validation:  [[ 10.98591588]]\n",
      "Loop 3681 Loss_Train:  [[ 13.20050534]] Loss_Validation:  [[ 10.98596274]]\n",
      "Loop 3682 Loss_Train:  [[ 13.20049759]] Loss_Validation:  [[ 10.98600957]]\n",
      "Loop 3683 Loss_Train:  [[ 13.20048984]] Loss_Validation:  [[ 10.98605636]]\n",
      "Loop 3684 Loss_Train:  [[ 13.2004821]] Loss_Validation:  [[ 10.98610311]]\n",
      "Loop 3685 Loss_Train:  [[ 13.20047438]] Loss_Validation:  [[ 10.98614983]]\n",
      "Loop 3686 Loss_Train:  [[ 13.20046667]] Loss_Validation:  [[ 10.98619651]]\n",
      "Loop 3687 Loss_Train:  [[ 13.20045897]] Loss_Validation:  [[ 10.98624316]]\n",
      "Loop 3688 Loss_Train:  [[ 13.20045128]] Loss_Validation:  [[ 10.98628978]]\n",
      "Loop 3689 Loss_Train:  [[ 13.2004436]] Loss_Validation:  [[ 10.98633636]]\n",
      "Loop 3690 Loss_Train:  [[ 13.20043594]] Loss_Validation:  [[ 10.9863829]]\n",
      "Loop 3691 Loss_Train:  [[ 13.20042828]] Loss_Validation:  [[ 10.98642941]]\n",
      "Loop 3692 Loss_Train:  [[ 13.20042064]] Loss_Validation:  [[ 10.98647589]]\n",
      "Loop 3693 Loss_Train:  [[ 13.20041301]] Loss_Validation:  [[ 10.98652233]]\n",
      "Loop 3694 Loss_Train:  [[ 13.20040539]] Loss_Validation:  [[ 10.98656873]]\n",
      "Loop 3695 Loss_Train:  [[ 13.20039778]] Loss_Validation:  [[ 10.98661511]]\n",
      "Loop 3696 Loss_Train:  [[ 13.20039018]] Loss_Validation:  [[ 10.98666144]]\n",
      "Loop 3697 Loss_Train:  [[ 13.2003826]] Loss_Validation:  [[ 10.98670774]]\n",
      "Loop 3698 Loss_Train:  [[ 13.20037502]] Loss_Validation:  [[ 10.98675401]]\n",
      "Loop 3699 Loss_Train:  [[ 13.20036746]] Loss_Validation:  [[ 10.98680024]]\n",
      "Loop 3700 Loss_Train:  [[ 13.20035991]] Loss_Validation:  [[ 10.98684644]]\n",
      "Loop 3701 Loss_Train:  [[ 13.20035237]] Loss_Validation:  [[ 10.98689261]]\n",
      "Loop 3702 Loss_Train:  [[ 13.20034484]] Loss_Validation:  [[ 10.98693874]]\n",
      "Loop 3703 Loss_Train:  [[ 13.20033732]] Loss_Validation:  [[ 10.98698483]]\n",
      "Loop 3704 Loss_Train:  [[ 13.20032981]] Loss_Validation:  [[ 10.98703089]]\n",
      "Loop 3705 Loss_Train:  [[ 13.20032232]] Loss_Validation:  [[ 10.98707692]]\n",
      "Loop 3706 Loss_Train:  [[ 13.20031483]] Loss_Validation:  [[ 10.98712291]]\n",
      "Loop 3707 Loss_Train:  [[ 13.20030736]] Loss_Validation:  [[ 10.98716887]]\n",
      "Loop 3708 Loss_Train:  [[ 13.20029989]] Loss_Validation:  [[ 10.98721479]]\n",
      "Loop 3709 Loss_Train:  [[ 13.20029244]] Loss_Validation:  [[ 10.98726068]]\n",
      "Loop 3710 Loss_Train:  [[ 13.200285]] Loss_Validation:  [[ 10.98730653]]\n",
      "Loop 3711 Loss_Train:  [[ 13.20027757]] Loss_Validation:  [[ 10.98735235]]\n",
      "Loop 3712 Loss_Train:  [[ 13.20027016]] Loss_Validation:  [[ 10.98739814]]\n",
      "Loop 3713 Loss_Train:  [[ 13.20026275]] Loss_Validation:  [[ 10.98744389]]\n",
      "Loop 3714 Loss_Train:  [[ 13.20025535]] Loss_Validation:  [[ 10.98748961]]\n",
      "Loop 3715 Loss_Train:  [[ 13.20024797]] Loss_Validation:  [[ 10.9875353]]\n",
      "Loop 3716 Loss_Train:  [[ 13.20024059]] Loss_Validation:  [[ 10.98758095]]\n",
      "Loop 3717 Loss_Train:  [[ 13.20023323]] Loss_Validation:  [[ 10.98762656]]\n",
      "Loop 3718 Loss_Train:  [[ 13.20022588]] Loss_Validation:  [[ 10.98767214]]\n",
      "Loop 3719 Loss_Train:  [[ 13.20021854]] Loss_Validation:  [[ 10.98771769]]\n",
      "Loop 3720 Loss_Train:  [[ 13.20021121]] Loss_Validation:  [[ 10.98776321]]\n",
      "Loop 3721 Loss_Train:  [[ 13.20020389]] Loss_Validation:  [[ 10.98780869]]\n",
      "Loop 3722 Loss_Train:  [[ 13.20019658]] Loss_Validation:  [[ 10.98785413]]\n",
      "Loop 3723 Loss_Train:  [[ 13.20018928]] Loss_Validation:  [[ 10.98789954]]\n",
      "Loop 3724 Loss_Train:  [[ 13.200182]] Loss_Validation:  [[ 10.98794492]]\n",
      "Loop 3725 Loss_Train:  [[ 13.20017472]] Loss_Validation:  [[ 10.98799027]]\n",
      "Loop 3726 Loss_Train:  [[ 13.20016746]] Loss_Validation:  [[ 10.98803558]]\n",
      "Loop 3727 Loss_Train:  [[ 13.2001602]] Loss_Validation:  [[ 10.98808086]]\n",
      "Loop 3728 Loss_Train:  [[ 13.20015296]] Loss_Validation:  [[ 10.9881261]]\n",
      "Loop 3729 Loss_Train:  [[ 13.20014573]] Loss_Validation:  [[ 10.98817131]]\n",
      "Loop 3730 Loss_Train:  [[ 13.20013851]] Loss_Validation:  [[ 10.98821649]]\n",
      "Loop 3731 Loss_Train:  [[ 13.20013129]] Loss_Validation:  [[ 10.98826163]]\n",
      "Loop 3732 Loss_Train:  [[ 13.20012409]] Loss_Validation:  [[ 10.98830674]]\n",
      "Loop 3733 Loss_Train:  [[ 13.20011691]] Loss_Validation:  [[ 10.98835181]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3734 Loss_Train:  [[ 13.20010973]] Loss_Validation:  [[ 10.98839685]]\n",
      "Loop 3735 Loss_Train:  [[ 13.20010256]] Loss_Validation:  [[ 10.98844186]]\n",
      "Loop 3736 Loss_Train:  [[ 13.2000954]] Loss_Validation:  [[ 10.98848684]]\n",
      "Loop 3737 Loss_Train:  [[ 13.20008826]] Loss_Validation:  [[ 10.98853178]]\n",
      "Loop 3738 Loss_Train:  [[ 13.20008112]] Loss_Validation:  [[ 10.98857669]]\n",
      "Loop 3739 Loss_Train:  [[ 13.20007399]] Loss_Validation:  [[ 10.98862156]]\n",
      "Loop 3740 Loss_Train:  [[ 13.20006688]] Loss_Validation:  [[ 10.9886664]]\n",
      "Loop 3741 Loss_Train:  [[ 13.20005978]] Loss_Validation:  [[ 10.98871121]]\n",
      "Loop 3742 Loss_Train:  [[ 13.20005268]] Loss_Validation:  [[ 10.98875599]]\n",
      "Loop 3743 Loss_Train:  [[ 13.2000456]] Loss_Validation:  [[ 10.98880073]]\n",
      "Loop 3744 Loss_Train:  [[ 13.20003853]] Loss_Validation:  [[ 10.98884543]]\n",
      "Loop 3745 Loss_Train:  [[ 13.20003147]] Loss_Validation:  [[ 10.98889011]]\n",
      "Loop 3746 Loss_Train:  [[ 13.20002441]] Loss_Validation:  [[ 10.98893475]]\n",
      "Loop 3747 Loss_Train:  [[ 13.20001737]] Loss_Validation:  [[ 10.98897936]]\n",
      "Loop 3748 Loss_Train:  [[ 13.20001034]] Loss_Validation:  [[ 10.98902394]]\n",
      "Loop 3749 Loss_Train:  [[ 13.20000332]] Loss_Validation:  [[ 10.98906848]]\n",
      "Loop 3750 Loss_Train:  [[ 13.19999631]] Loss_Validation:  [[ 10.98911299]]\n",
      "Loop 3751 Loss_Train:  [[ 13.19998932]] Loss_Validation:  [[ 10.98915746]]\n",
      "Loop 3752 Loss_Train:  [[ 13.19998233]] Loss_Validation:  [[ 10.98920191]]\n",
      "Loop 3753 Loss_Train:  [[ 13.19997535]] Loss_Validation:  [[ 10.98924632]]\n",
      "Loop 3754 Loss_Train:  [[ 13.19996838]] Loss_Validation:  [[ 10.98929069]]\n",
      "Loop 3755 Loss_Train:  [[ 13.19996142]] Loss_Validation:  [[ 10.98933504]]\n",
      "Loop 3756 Loss_Train:  [[ 13.19995448]] Loss_Validation:  [[ 10.98937935]]\n",
      "Loop 3757 Loss_Train:  [[ 13.19994754]] Loss_Validation:  [[ 10.98942363]]\n",
      "Loop 3758 Loss_Train:  [[ 13.19994061]] Loss_Validation:  [[ 10.98946787]]\n",
      "Loop 3759 Loss_Train:  [[ 13.1999337]] Loss_Validation:  [[ 10.98951208]]\n",
      "Loop 3760 Loss_Train:  [[ 13.19992679]] Loss_Validation:  [[ 10.98955626]]\n",
      "Loop 3761 Loss_Train:  [[ 13.1999199]] Loss_Validation:  [[ 10.98960041]]\n",
      "Loop 3762 Loss_Train:  [[ 13.19991301]] Loss_Validation:  [[ 10.98964453]]\n",
      "Loop 3763 Loss_Train:  [[ 13.19990614]] Loss_Validation:  [[ 10.98968861]]\n",
      "Loop 3764 Loss_Train:  [[ 13.19989927]] Loss_Validation:  [[ 10.98973266]]\n",
      "Loop 3765 Loss_Train:  [[ 13.19989242]] Loss_Validation:  [[ 10.98977667]]\n",
      "Loop 3766 Loss_Train:  [[ 13.19988558]] Loss_Validation:  [[ 10.98982065]]\n",
      "Loop 3767 Loss_Train:  [[ 13.19987874]] Loss_Validation:  [[ 10.98986461]]\n",
      "Loop 3768 Loss_Train:  [[ 13.19987192]] Loss_Validation:  [[ 10.98990852]]\n",
      "Loop 3769 Loss_Train:  [[ 13.1998651]] Loss_Validation:  [[ 10.98995241]]\n",
      "Loop 3770 Loss_Train:  [[ 13.1998583]] Loss_Validation:  [[ 10.98999626]]\n",
      "Loop 3771 Loss_Train:  [[ 13.19985151]] Loss_Validation:  [[ 10.99004008]]\n",
      "Loop 3772 Loss_Train:  [[ 13.19984472]] Loss_Validation:  [[ 10.99008387]]\n",
      "Loop 3773 Loss_Train:  [[ 13.19983795]] Loss_Validation:  [[ 10.99012763]]\n",
      "Loop 3774 Loss_Train:  [[ 13.19983119]] Loss_Validation:  [[ 10.99017135]]\n",
      "Loop 3775 Loss_Train:  [[ 13.19982444]] Loss_Validation:  [[ 10.99021504]]\n",
      "Loop 3776 Loss_Train:  [[ 13.19981769]] Loss_Validation:  [[ 10.9902587]]\n",
      "Loop 3777 Loss_Train:  [[ 13.19981096]] Loss_Validation:  [[ 10.99030233]]\n",
      "Loop 3778 Loss_Train:  [[ 13.19980424]] Loss_Validation:  [[ 10.99034592]]\n",
      "Loop 3779 Loss_Train:  [[ 13.19979752]] Loss_Validation:  [[ 10.99038948]]\n",
      "Loop 3780 Loss_Train:  [[ 13.19979082]] Loss_Validation:  [[ 10.99043301]]\n",
      "Loop 3781 Loss_Train:  [[ 13.19978413]] Loss_Validation:  [[ 10.99047651]]\n",
      "Loop 3782 Loss_Train:  [[ 13.19977745]] Loss_Validation:  [[ 10.99051997]]\n",
      "Loop 3783 Loss_Train:  [[ 13.19977077]] Loss_Validation:  [[ 10.9905634]]\n",
      "Loop 3784 Loss_Train:  [[ 13.19976411]] Loss_Validation:  [[ 10.99060681]]\n",
      "Loop 3785 Loss_Train:  [[ 13.19975746]] Loss_Validation:  [[ 10.99065017]]\n",
      "Loop 3786 Loss_Train:  [[ 13.19975081]] Loss_Validation:  [[ 10.99069351]]\n",
      "Loop 3787 Loss_Train:  [[ 13.19974418]] Loss_Validation:  [[ 10.99073681]]\n",
      "Loop 3788 Loss_Train:  [[ 13.19973756]] Loss_Validation:  [[ 10.99078009]]\n",
      "Loop 3789 Loss_Train:  [[ 13.19973094]] Loss_Validation:  [[ 10.99082333]]\n",
      "Loop 3790 Loss_Train:  [[ 13.19972434]] Loss_Validation:  [[ 10.99086653]]\n",
      "Loop 3791 Loss_Train:  [[ 13.19971775]] Loss_Validation:  [[ 10.99090971]]\n",
      "Loop 3792 Loss_Train:  [[ 13.19971116]] Loss_Validation:  [[ 10.99095285]]\n",
      "Loop 3793 Loss_Train:  [[ 13.19970459]] Loss_Validation:  [[ 10.99099597]]\n",
      "Loop 3794 Loss_Train:  [[ 13.19969802]] Loss_Validation:  [[ 10.99103905]]\n",
      "Loop 3795 Loss_Train:  [[ 13.19969147]] Loss_Validation:  [[ 10.9910821]]\n",
      "Loop 3796 Loss_Train:  [[ 13.19968492]] Loss_Validation:  [[ 10.99112511]]\n",
      "Loop 3797 Loss_Train:  [[ 13.19967839]] Loss_Validation:  [[ 10.9911681]]\n",
      "Loop 3798 Loss_Train:  [[ 13.19967186]] Loss_Validation:  [[ 10.99121105]]\n",
      "Loop 3799 Loss_Train:  [[ 13.19966535]] Loss_Validation:  [[ 10.99125397]]\n",
      "Loop 3800 Loss_Train:  [[ 13.19965884]] Loss_Validation:  [[ 10.99129686]]\n",
      "Loop 3801 Loss_Train:  [[ 13.19965235]] Loss_Validation:  [[ 10.99133972]]\n",
      "Loop 3802 Loss_Train:  [[ 13.19964586]] Loss_Validation:  [[ 10.99138255]]\n",
      "Loop 3803 Loss_Train:  [[ 13.19963938]] Loss_Validation:  [[ 10.99142534]]\n",
      "Loop 3804 Loss_Train:  [[ 13.19963291]] Loss_Validation:  [[ 10.9914681]]\n",
      "Loop 3805 Loss_Train:  [[ 13.19962646]] Loss_Validation:  [[ 10.99151083]]\n",
      "Loop 3806 Loss_Train:  [[ 13.19962001]] Loss_Validation:  [[ 10.99155353]]\n",
      "Loop 3807 Loss_Train:  [[ 13.19961357]] Loss_Validation:  [[ 10.9915962]]\n",
      "Loop 3808 Loss_Train:  [[ 13.19960714]] Loss_Validation:  [[ 10.99163884]]\n",
      "Loop 3809 Loss_Train:  [[ 13.19960072]] Loss_Validation:  [[ 10.99168144]]\n",
      "Loop 3810 Loss_Train:  [[ 13.19959431]] Loss_Validation:  [[ 10.99172402]]\n",
      "Loop 3811 Loss_Train:  [[ 13.19958791]] Loss_Validation:  [[ 10.99176656]]\n",
      "Loop 3812 Loss_Train:  [[ 13.19958152]] Loss_Validation:  [[ 10.99180907]]\n",
      "Loop 3813 Loss_Train:  [[ 13.19957514]] Loss_Validation:  [[ 10.99185155]]\n",
      "Loop 3814 Loss_Train:  [[ 13.19956877]] Loss_Validation:  [[ 10.991894]]\n",
      "Loop 3815 Loss_Train:  [[ 13.1995624]] Loss_Validation:  [[ 10.99193642]]\n",
      "Loop 3816 Loss_Train:  [[ 13.19955605]] Loss_Validation:  [[ 10.9919788]]\n",
      "Loop 3817 Loss_Train:  [[ 13.19954971]] Loss_Validation:  [[ 10.99202115]]\n",
      "Loop 3818 Loss_Train:  [[ 13.19954337]] Loss_Validation:  [[ 10.99206348]]\n",
      "Loop 3819 Loss_Train:  [[ 13.19953705]] Loss_Validation:  [[ 10.99210577]]\n",
      "Loop 3820 Loss_Train:  [[ 13.19953073]] Loss_Validation:  [[ 10.99214803]]\n",
      "Loop 3821 Loss_Train:  [[ 13.19952443]] Loss_Validation:  [[ 10.99219026]]\n",
      "Loop 3822 Loss_Train:  [[ 13.19951813]] Loss_Validation:  [[ 10.99223246]]\n",
      "Loop 3823 Loss_Train:  [[ 13.19951185]] Loss_Validation:  [[ 10.99227462]]\n",
      "Loop 3824 Loss_Train:  [[ 13.19950557]] Loss_Validation:  [[ 10.99231676]]\n",
      "Loop 3825 Loss_Train:  [[ 13.1994993]] Loss_Validation:  [[ 10.99235887]]\n",
      "Loop 3826 Loss_Train:  [[ 13.19949304]] Loss_Validation:  [[ 10.99240094]]\n",
      "Loop 3827 Loss_Train:  [[ 13.19948679]] Loss_Validation:  [[ 10.99244298]]\n",
      "Loop 3828 Loss_Train:  [[ 13.19948055]] Loss_Validation:  [[ 10.99248499]]\n",
      "Loop 3829 Loss_Train:  [[ 13.19947432]] Loss_Validation:  [[ 10.99252697]]\n",
      "Loop 3830 Loss_Train:  [[ 13.1994681]] Loss_Validation:  [[ 10.99256892]]\n",
      "Loop 3831 Loss_Train:  [[ 13.19946189]] Loss_Validation:  [[ 10.99261084]]\n",
      "Loop 3832 Loss_Train:  [[ 13.19945568]] Loss_Validation:  [[ 10.99265273]]\n",
      "Loop 3833 Loss_Train:  [[ 13.19944949]] Loss_Validation:  [[ 10.99269459]]\n",
      "Loop 3834 Loss_Train:  [[ 13.1994433]] Loss_Validation:  [[ 10.99273641]]\n",
      "Loop 3835 Loss_Train:  [[ 13.19943713]] Loss_Validation:  [[ 10.99277821]]\n",
      "Loop 3836 Loss_Train:  [[ 13.19943096]] Loss_Validation:  [[ 10.99281997]]\n",
      "Loop 3837 Loss_Train:  [[ 13.1994248]] Loss_Validation:  [[ 10.99286171]]\n",
      "Loop 3838 Loss_Train:  [[ 13.19941866]] Loss_Validation:  [[ 10.99290341]]\n",
      "Loop 3839 Loss_Train:  [[ 13.19941252]] Loss_Validation:  [[ 10.99294508]]\n",
      "Loop 3840 Loss_Train:  [[ 13.19940639]] Loss_Validation:  [[ 10.99298673]]\n",
      "Loop 3841 Loss_Train:  [[ 13.19940027]] Loss_Validation:  [[ 10.99302834]]\n",
      "Loop 3842 Loss_Train:  [[ 13.19939415]] Loss_Validation:  [[ 10.99306992]]\n",
      "Loop 3843 Loss_Train:  [[ 13.19938805]] Loss_Validation:  [[ 10.99311147]]\n",
      "Loop 3844 Loss_Train:  [[ 13.19938196]] Loss_Validation:  [[ 10.99315299]]\n",
      "Loop 3845 Loss_Train:  [[ 13.19937587]] Loss_Validation:  [[ 10.99319448]]\n",
      "Loop 3846 Loss_Train:  [[ 13.1993698]] Loss_Validation:  [[ 10.99323593]]\n",
      "Loop 3847 Loss_Train:  [[ 13.19936373]] Loss_Validation:  [[ 10.99327736]]\n",
      "Loop 3848 Loss_Train:  [[ 13.19935767]] Loss_Validation:  [[ 10.99331876]]\n",
      "Loop 3849 Loss_Train:  [[ 13.19935163]] Loss_Validation:  [[ 10.99336013]]\n",
      "Loop 3850 Loss_Train:  [[ 13.19934559]] Loss_Validation:  [[ 10.99340146]]\n",
      "Loop 3851 Loss_Train:  [[ 13.19933956]] Loss_Validation:  [[ 10.99344277]]\n",
      "Loop 3852 Loss_Train:  [[ 13.19933353]] Loss_Validation:  [[ 10.99348404]]\n",
      "Loop 3853 Loss_Train:  [[ 13.19932752]] Loss_Validation:  [[ 10.99352529]]\n",
      "Loop 3854 Loss_Train:  [[ 13.19932152]] Loss_Validation:  [[ 10.9935665]]\n",
      "Loop 3855 Loss_Train:  [[ 13.19931552]] Loss_Validation:  [[ 10.99360769]]\n",
      "Loop 3856 Loss_Train:  [[ 13.19930954]] Loss_Validation:  [[ 10.99364884]]\n",
      "Loop 3857 Loss_Train:  [[ 13.19930356]] Loss_Validation:  [[ 10.99368997]]\n",
      "Loop 3858 Loss_Train:  [[ 13.19929759]] Loss_Validation:  [[ 10.99373106]]\n",
      "Loop 3859 Loss_Train:  [[ 13.19929163]] Loss_Validation:  [[ 10.99377212]]\n",
      "Loop 3860 Loss_Train:  [[ 13.19928568]] Loss_Validation:  [[ 10.99381316]]\n",
      "Loop 3861 Loss_Train:  [[ 13.19927974]] Loss_Validation:  [[ 10.99385416]]\n",
      "Loop 3862 Loss_Train:  [[ 13.19927381]] Loss_Validation:  [[ 10.99389513]]\n",
      "Loop 3863 Loss_Train:  [[ 13.19926789]] Loss_Validation:  [[ 10.99393607]]\n",
      "Loop 3864 Loss_Train:  [[ 13.19926197]] Loss_Validation:  [[ 10.99397699]]\n",
      "Loop 3865 Loss_Train:  [[ 13.19925606]] Loss_Validation:  [[ 10.99401787]]\n",
      "Loop 3866 Loss_Train:  [[ 13.19925017]] Loss_Validation:  [[ 10.99405872]]\n",
      "Loop 3867 Loss_Train:  [[ 13.19924428]] Loss_Validation:  [[ 10.99409954]]\n",
      "Loop 3868 Loss_Train:  [[ 13.1992384]] Loss_Validation:  [[ 10.99414034]]\n",
      "Loop 3869 Loss_Train:  [[ 13.19923253]] Loss_Validation:  [[ 10.9941811]]\n",
      "Loop 3870 Loss_Train:  [[ 13.19922667]] Loss_Validation:  [[ 10.99422183]]\n",
      "Loop 3871 Loss_Train:  [[ 13.19922081]] Loss_Validation:  [[ 10.99426254]]\n",
      "Loop 3872 Loss_Train:  [[ 13.19921497]] Loss_Validation:  [[ 10.99430321]]\n",
      "Loop 3873 Loss_Train:  [[ 13.19920913]] Loss_Validation:  [[ 10.99434385]]\n",
      "Loop 3874 Loss_Train:  [[ 13.1992033]] Loss_Validation:  [[ 10.99438446]]\n",
      "Loop 3875 Loss_Train:  [[ 13.19919748]] Loss_Validation:  [[ 10.99442505]]\n",
      "Loop 3876 Loss_Train:  [[ 13.19919167]] Loss_Validation:  [[ 10.9944656]]\n",
      "Loop 3877 Loss_Train:  [[ 13.19918587]] Loss_Validation:  [[ 10.99450613]]\n",
      "Loop 3878 Loss_Train:  [[ 13.19918008]] Loss_Validation:  [[ 10.99454662]]\n",
      "Loop 3879 Loss_Train:  [[ 13.19917429]] Loss_Validation:  [[ 10.99458708]]\n",
      "Loop 3880 Loss_Train:  [[ 13.19916852]] Loss_Validation:  [[ 10.99462752]]\n",
      "Loop 3881 Loss_Train:  [[ 13.19916275]] Loss_Validation:  [[ 10.99466792]]\n",
      "Loop 3882 Loss_Train:  [[ 13.19915699]] Loss_Validation:  [[ 10.9947083]]\n",
      "Loop 3883 Loss_Train:  [[ 13.19915124]] Loss_Validation:  [[ 10.99474864]]\n",
      "Loop 3884 Loss_Train:  [[ 13.1991455]] Loss_Validation:  [[ 10.99478896]]\n",
      "Loop 3885 Loss_Train:  [[ 13.19913977]] Loss_Validation:  [[ 10.99482925]]\n",
      "Loop 3886 Loss_Train:  [[ 13.19913404]] Loss_Validation:  [[ 10.9948695]]\n",
      "Loop 3887 Loss_Train:  [[ 13.19912833]] Loss_Validation:  [[ 10.99490973]]\n",
      "Loop 3888 Loss_Train:  [[ 13.19912262]] Loss_Validation:  [[ 10.99494993]]\n",
      "Loop 3889 Loss_Train:  [[ 13.19911692]] Loss_Validation:  [[ 10.9949901]]\n",
      "Loop 3890 Loss_Train:  [[ 13.19911123]] Loss_Validation:  [[ 10.99503024]]\n",
      "Loop 3891 Loss_Train:  [[ 13.19910555]] Loss_Validation:  [[ 10.99507035]]\n",
      "Loop 3892 Loss_Train:  [[ 13.19909987]] Loss_Validation:  [[ 10.99511043]]\n",
      "Loop 3893 Loss_Train:  [[ 13.19909421]] Loss_Validation:  [[ 10.99515048]]\n",
      "Loop 3894 Loss_Train:  [[ 13.19908855]] Loss_Validation:  [[ 10.9951905]]\n",
      "Loop 3895 Loss_Train:  [[ 13.1990829]] Loss_Validation:  [[ 10.99523049]]\n",
      "Loop 3896 Loss_Train:  [[ 13.19907726]] Loss_Validation:  [[ 10.99527045]]\n",
      "Loop 3897 Loss_Train:  [[ 13.19907163]] Loss_Validation:  [[ 10.99531039]]\n",
      "Loop 3898 Loss_Train:  [[ 13.19906601]] Loss_Validation:  [[ 10.99535029]]\n",
      "Loop 3899 Loss_Train:  [[ 13.19906039]] Loss_Validation:  [[ 10.99539017]]\n",
      "Loop 3900 Loss_Train:  [[ 13.19905479]] Loss_Validation:  [[ 10.99543001]]\n",
      "Loop 3901 Loss_Train:  [[ 13.19904919]] Loss_Validation:  [[ 10.99546983]]\n",
      "Loop 3902 Loss_Train:  [[ 13.1990436]] Loss_Validation:  [[ 10.99550962]]\n",
      "Loop 3903 Loss_Train:  [[ 13.19903802]] Loss_Validation:  [[ 10.99554938]]\n",
      "Loop 3904 Loss_Train:  [[ 13.19903244]] Loss_Validation:  [[ 10.99558911]]\n",
      "Loop 3905 Loss_Train:  [[ 13.19902688]] Loss_Validation:  [[ 10.99562881]]\n",
      "Loop 3906 Loss_Train:  [[ 13.19902132]] Loss_Validation:  [[ 10.99566848]]\n",
      "Loop 3907 Loss_Train:  [[ 13.19901577]] Loss_Validation:  [[ 10.99570812]]\n",
      "Loop 3908 Loss_Train:  [[ 13.19901023]] Loss_Validation:  [[ 10.99574773]]\n",
      "Loop 3909 Loss_Train:  [[ 13.1990047]] Loss_Validation:  [[ 10.99578732]]\n",
      "Loop 3910 Loss_Train:  [[ 13.19899918]] Loss_Validation:  [[ 10.99582687]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3911 Loss_Train:  [[ 13.19899366]] Loss_Validation:  [[ 10.9958664]]\n",
      "Loop 3912 Loss_Train:  [[ 13.19898815]] Loss_Validation:  [[ 10.99590589]]\n",
      "Loop 3913 Loss_Train:  [[ 13.19898265]] Loss_Validation:  [[ 10.99594536]]\n",
      "Loop 3914 Loss_Train:  [[ 13.19897716]] Loss_Validation:  [[ 10.9959848]]\n",
      "Loop 3915 Loss_Train:  [[ 13.19897168]] Loss_Validation:  [[ 10.99602421]]\n",
      "Loop 3916 Loss_Train:  [[ 13.1989662]] Loss_Validation:  [[ 10.99606359]]\n",
      "Loop 3917 Loss_Train:  [[ 13.19896074]] Loss_Validation:  [[ 10.99610295]]\n",
      "Loop 3918 Loss_Train:  [[ 13.19895528]] Loss_Validation:  [[ 10.99614227]]\n",
      "Loop 3919 Loss_Train:  [[ 13.19894983]] Loss_Validation:  [[ 10.99618157]]\n",
      "Loop 3920 Loss_Train:  [[ 13.19894439]] Loss_Validation:  [[ 10.99622083]]\n",
      "Loop 3921 Loss_Train:  [[ 13.19893895]] Loss_Validation:  [[ 10.99626007]]\n",
      "Loop 3922 Loss_Train:  [[ 13.19893352]] Loss_Validation:  [[ 10.99629928]]\n",
      "Loop 3923 Loss_Train:  [[ 13.19892811]] Loss_Validation:  [[ 10.99633846]]\n",
      "Loop 3924 Loss_Train:  [[ 13.1989227]] Loss_Validation:  [[ 10.99637761]]\n",
      "Loop 3925 Loss_Train:  [[ 13.19891729]] Loss_Validation:  [[ 10.99641674]]\n",
      "Loop 3926 Loss_Train:  [[ 13.1989119]] Loss_Validation:  [[ 10.99645583]]\n",
      "Loop 3927 Loss_Train:  [[ 13.19890651]] Loss_Validation:  [[ 10.9964949]]\n",
      "Loop 3928 Loss_Train:  [[ 13.19890114]] Loss_Validation:  [[ 10.99653393]]\n",
      "Loop 3929 Loss_Train:  [[ 13.19889576]] Loss_Validation:  [[ 10.99657294]]\n",
      "Loop 3930 Loss_Train:  [[ 13.1988904]] Loss_Validation:  [[ 10.99661192]]\n",
      "Loop 3931 Loss_Train:  [[ 13.19888505]] Loss_Validation:  [[ 10.99665088]]\n",
      "Loop 3932 Loss_Train:  [[ 13.1988797]] Loss_Validation:  [[ 10.9966898]]\n",
      "Loop 3933 Loss_Train:  [[ 13.19887436]] Loss_Validation:  [[ 10.99672869]]\n",
      "Loop 3934 Loss_Train:  [[ 13.19886903]] Loss_Validation:  [[ 10.99676756]]\n",
      "Loop 3935 Loss_Train:  [[ 13.19886371]] Loss_Validation:  [[ 10.9968064]]\n",
      "Loop 3936 Loss_Train:  [[ 13.1988584]] Loss_Validation:  [[ 10.99684521]]\n",
      "Loop 3937 Loss_Train:  [[ 13.19885309]] Loss_Validation:  [[ 10.99688399]]\n",
      "Loop 3938 Loss_Train:  [[ 13.19884779]] Loss_Validation:  [[ 10.99692275]]\n",
      "Loop 3939 Loss_Train:  [[ 13.1988425]] Loss_Validation:  [[ 10.99696147]]\n",
      "Loop 3940 Loss_Train:  [[ 13.19883722]] Loss_Validation:  [[ 10.99700017]]\n",
      "Loop 3941 Loss_Train:  [[ 13.19883194]] Loss_Validation:  [[ 10.99703884]]\n",
      "Loop 3942 Loss_Train:  [[ 13.19882667]] Loss_Validation:  [[ 10.99707748]]\n",
      "Loop 3943 Loss_Train:  [[ 13.19882141]] Loss_Validation:  [[ 10.99711609]]\n",
      "Loop 3944 Loss_Train:  [[ 13.19881616]] Loss_Validation:  [[ 10.99715467]]\n",
      "Loop 3945 Loss_Train:  [[ 13.19881092]] Loss_Validation:  [[ 10.99719323]]\n",
      "Loop 3946 Loss_Train:  [[ 13.19880568]] Loss_Validation:  [[ 10.99723176]]\n",
      "Loop 3947 Loss_Train:  [[ 13.19880045]] Loss_Validation:  [[ 10.99727025]]\n",
      "Loop 3948 Loss_Train:  [[ 13.19879523]] Loss_Validation:  [[ 10.99730873]]\n",
      "Loop 3949 Loss_Train:  [[ 13.19879002]] Loss_Validation:  [[ 10.99734717]]\n",
      "Loop 3950 Loss_Train:  [[ 13.19878481]] Loss_Validation:  [[ 10.99738559]]\n",
      "Loop 3951 Loss_Train:  [[ 13.19877962]] Loss_Validation:  [[ 10.99742397]]\n",
      "Loop 3952 Loss_Train:  [[ 13.19877443]] Loss_Validation:  [[ 10.99746233]]\n",
      "Loop 3953 Loss_Train:  [[ 13.19876924]] Loss_Validation:  [[ 10.99750066]]\n",
      "Loop 3954 Loss_Train:  [[ 13.19876407]] Loss_Validation:  [[ 10.99753897]]\n",
      "Loop 3955 Loss_Train:  [[ 13.1987589]] Loss_Validation:  [[ 10.99757724]]\n",
      "Loop 3956 Loss_Train:  [[ 13.19875374]] Loss_Validation:  [[ 10.99761549]]\n",
      "Loop 3957 Loss_Train:  [[ 13.19874859]] Loss_Validation:  [[ 10.99765371]]\n",
      "Loop 3958 Loss_Train:  [[ 13.19874345]] Loss_Validation:  [[ 10.9976919]]\n",
      "Loop 3959 Loss_Train:  [[ 13.19873831]] Loss_Validation:  [[ 10.99773007]]\n",
      "Loop 3960 Loss_Train:  [[ 13.19873318]] Loss_Validation:  [[ 10.9977682]]\n",
      "Loop 3961 Loss_Train:  [[ 13.19872806]] Loss_Validation:  [[ 10.99780631]]\n",
      "Loop 3962 Loss_Train:  [[ 13.19872295]] Loss_Validation:  [[ 10.99784439]]\n",
      "Loop 3963 Loss_Train:  [[ 13.19871784]] Loss_Validation:  [[ 10.99788244]]\n",
      "Loop 3964 Loss_Train:  [[ 13.19871274]] Loss_Validation:  [[ 10.99792047]]\n",
      "Loop 3965 Loss_Train:  [[ 13.19870765]] Loss_Validation:  [[ 10.99795847]]\n",
      "Loop 3966 Loss_Train:  [[ 13.19870257]] Loss_Validation:  [[ 10.99799644]]\n",
      "Loop 3967 Loss_Train:  [[ 13.19869749]] Loss_Validation:  [[ 10.99803438]]\n",
      "Loop 3968 Loss_Train:  [[ 13.19869243]] Loss_Validation:  [[ 10.99807229]]\n",
      "Loop 3969 Loss_Train:  [[ 13.19868737]] Loss_Validation:  [[ 10.99811018]]\n",
      "Loop 3970 Loss_Train:  [[ 13.19868231]] Loss_Validation:  [[ 10.99814804]]\n",
      "Loop 3971 Loss_Train:  [[ 13.19867727]] Loss_Validation:  [[ 10.99818587]]\n",
      "Loop 3972 Loss_Train:  [[ 13.19867223]] Loss_Validation:  [[ 10.99822367]]\n",
      "Loop 3973 Loss_Train:  [[ 13.1986672]] Loss_Validation:  [[ 10.99826145]]\n",
      "Loop 3974 Loss_Train:  [[ 13.19866218]] Loss_Validation:  [[ 10.9982992]]\n",
      "Loop 3975 Loss_Train:  [[ 13.19865716]] Loss_Validation:  [[ 10.99833692]]\n",
      "Loop 3976 Loss_Train:  [[ 13.19865215]] Loss_Validation:  [[ 10.99837462]]\n",
      "Loop 3977 Loss_Train:  [[ 13.19864715]] Loss_Validation:  [[ 10.99841228]]\n",
      "Loop 3978 Loss_Train:  [[ 13.19864216]] Loss_Validation:  [[ 10.99844992]]\n",
      "Loop 3979 Loss_Train:  [[ 13.19863717]] Loss_Validation:  [[ 10.99848753]]\n",
      "Loop 3980 Loss_Train:  [[ 13.19863219]] Loss_Validation:  [[ 10.99852512]]\n",
      "Loop 3981 Loss_Train:  [[ 13.19862722]] Loss_Validation:  [[ 10.99856268]]\n",
      "Loop 3982 Loss_Train:  [[ 13.19862226]] Loss_Validation:  [[ 10.99860021]]\n",
      "Loop 3983 Loss_Train:  [[ 13.1986173]] Loss_Validation:  [[ 10.99863771]]\n",
      "Loop 3984 Loss_Train:  [[ 13.19861235]] Loss_Validation:  [[ 10.99867518]]\n",
      "Loop 3985 Loss_Train:  [[ 13.19860741]] Loss_Validation:  [[ 10.99871263]]\n",
      "Loop 3986 Loss_Train:  [[ 13.19860248]] Loss_Validation:  [[ 10.99875005]]\n",
      "Loop 3987 Loss_Train:  [[ 13.19859755]] Loss_Validation:  [[ 10.99878745]]\n",
      "Loop 3988 Loss_Train:  [[ 13.19859263]] Loss_Validation:  [[ 10.99882481]]\n",
      "Loop 3989 Loss_Train:  [[ 13.19858772]] Loss_Validation:  [[ 10.99886215]]\n",
      "Loop 3990 Loss_Train:  [[ 13.19858281]] Loss_Validation:  [[ 10.99889946]]\n",
      "Loop 3991 Loss_Train:  [[ 13.19857791]] Loss_Validation:  [[ 10.99893675]]\n",
      "Loop 3992 Loss_Train:  [[ 13.19857302]] Loss_Validation:  [[ 10.99897401]]\n",
      "Loop 3993 Loss_Train:  [[ 13.19856814]] Loss_Validation:  [[ 10.99901124]]\n",
      "Loop 3994 Loss_Train:  [[ 13.19856326]] Loss_Validation:  [[ 10.99904844]]\n",
      "Loop 3995 Loss_Train:  [[ 13.19855839]] Loss_Validation:  [[ 10.99908562]]\n",
      "Loop 3996 Loss_Train:  [[ 13.19855353]] Loss_Validation:  [[ 10.99912277]]\n",
      "Loop 3997 Loss_Train:  [[ 13.19854868]] Loss_Validation:  [[ 10.99915989]]\n",
      "Loop 3998 Loss_Train:  [[ 13.19854383]] Loss_Validation:  [[ 10.99919699]]\n",
      "Loop 3999 Loss_Train:  [[ 13.19853899]] Loss_Validation:  [[ 10.99923405]]\n",
      "Loop 4000 Loss_Train:  [[ 13.19853416]] Loss_Validation:  [[ 10.9992711]]\n",
      "Loop 4001 Loss_Train:  [[ 13.19852933]] Loss_Validation:  [[ 10.99930811]]\n",
      "Loop 4002 Loss_Train:  [[ 13.19852451]] Loss_Validation:  [[ 10.9993451]]\n",
      "Loop 4003 Loss_Train:  [[ 13.1985197]] Loss_Validation:  [[ 10.99938206]]\n",
      "Loop 4004 Loss_Train:  [[ 13.19851489]] Loss_Validation:  [[ 10.99941899]]\n",
      "Loop 4005 Loss_Train:  [[ 13.1985101]] Loss_Validation:  [[ 10.9994559]]\n",
      "Loop 4006 Loss_Train:  [[ 13.19850531]] Loss_Validation:  [[ 10.99949278]]\n",
      "Loop 4007 Loss_Train:  [[ 13.19850052]] Loss_Validation:  [[ 10.99952964]]\n",
      "Loop 4008 Loss_Train:  [[ 13.19849575]] Loss_Validation:  [[ 10.99956646]]\n",
      "Loop 4009 Loss_Train:  [[ 13.19849098]] Loss_Validation:  [[ 10.99960326]]\n",
      "Loop 4010 Loss_Train:  [[ 13.19848622]] Loss_Validation:  [[ 10.99964004]]\n",
      "Loop 4011 Loss_Train:  [[ 13.19848146]] Loss_Validation:  [[ 10.99967679]]\n",
      "Loop 4012 Loss_Train:  [[ 13.19847671]] Loss_Validation:  [[ 10.99971351]]\n",
      "Loop 4013 Loss_Train:  [[ 13.19847197]] Loss_Validation:  [[ 10.9997502]]\n",
      "Loop 4014 Loss_Train:  [[ 13.19846724]] Loss_Validation:  [[ 10.99978687]]\n",
      "Loop 4015 Loss_Train:  [[ 13.19846251]] Loss_Validation:  [[ 10.99982351]]\n",
      "Loop 4016 Loss_Train:  [[ 13.19845779]] Loss_Validation:  [[ 10.99986012]]\n",
      "Loop 4017 Loss_Train:  [[ 13.19845308]] Loss_Validation:  [[ 10.99989671]]\n",
      "Loop 4018 Loss_Train:  [[ 13.19844837]] Loss_Validation:  [[ 10.99993327]]\n",
      "Loop 4019 Loss_Train:  [[ 13.19844368]] Loss_Validation:  [[ 10.9999698]]\n",
      "Loop 4020 Loss_Train:  [[ 13.19843898]] Loss_Validation:  [[ 11.00000631]]\n",
      "Loop 4021 Loss_Train:  [[ 13.1984343]] Loss_Validation:  [[ 11.00004279]]\n",
      "Loop 4022 Loss_Train:  [[ 13.19842962]] Loss_Validation:  [[ 11.00007925]]\n",
      "Loop 4023 Loss_Train:  [[ 13.19842495]] Loss_Validation:  [[ 11.00011568]]\n",
      "Loop 4024 Loss_Train:  [[ 13.19842029]] Loss_Validation:  [[ 11.00015208]]\n",
      "Loop 4025 Loss_Train:  [[ 13.19841563]] Loss_Validation:  [[ 11.00018845]]\n",
      "Loop 4026 Loss_Train:  [[ 13.19841098]] Loss_Validation:  [[ 11.0002248]]\n",
      "Loop 4027 Loss_Train:  [[ 13.19840634]] Loss_Validation:  [[ 11.00026113]]\n",
      "Loop 4028 Loss_Train:  [[ 13.1984017]] Loss_Validation:  [[ 11.00029742]]\n",
      "Loop 4029 Loss_Train:  [[ 13.19839707]] Loss_Validation:  [[ 11.00033369]]\n",
      "Loop 4030 Loss_Train:  [[ 13.19839245]] Loss_Validation:  [[ 11.00036994]]\n",
      "Loop 4031 Loss_Train:  [[ 13.19838783]] Loss_Validation:  [[ 11.00040615]]\n",
      "Loop 4032 Loss_Train:  [[ 13.19838322]] Loss_Validation:  [[ 11.00044235]]\n",
      "Loop 4033 Loss_Train:  [[ 13.19837862]] Loss_Validation:  [[ 11.00047851]]\n",
      "Loop 4034 Loss_Train:  [[ 13.19837402]] Loss_Validation:  [[ 11.00051465]]\n",
      "Loop 4035 Loss_Train:  [[ 13.19836944]] Loss_Validation:  [[ 11.00055076]]\n",
      "Loop 4036 Loss_Train:  [[ 13.19836485]] Loss_Validation:  [[ 11.00058685]]\n",
      "Loop 4037 Loss_Train:  [[ 13.19836028]] Loss_Validation:  [[ 11.00062291]]\n",
      "Loop 4038 Loss_Train:  [[ 13.19835571]] Loss_Validation:  [[ 11.00065894]]\n",
      "Loop 4039 Loss_Train:  [[ 13.19835115]] Loss_Validation:  [[ 11.00069495]]\n",
      "Loop 4040 Loss_Train:  [[ 13.19834659]] Loss_Validation:  [[ 11.00073093]]\n",
      "Loop 4041 Loss_Train:  [[ 13.19834205]] Loss_Validation:  [[ 11.00076689]]\n",
      "Loop 4042 Loss_Train:  [[ 13.1983375]] Loss_Validation:  [[ 11.00080282]]\n",
      "Loop 4043 Loss_Train:  [[ 13.19833297]] Loss_Validation:  [[ 11.00083872]]\n",
      "Loop 4044 Loss_Train:  [[ 13.19832844]] Loss_Validation:  [[ 11.0008746]]\n",
      "Loop 4045 Loss_Train:  [[ 13.19832392]] Loss_Validation:  [[ 11.00091046]]\n",
      "Loop 4046 Loss_Train:  [[ 13.19831941]] Loss_Validation:  [[ 11.00094628]]\n",
      "Loop 4047 Loss_Train:  [[ 13.1983149]] Loss_Validation:  [[ 11.00098208]]\n",
      "Loop 4048 Loss_Train:  [[ 13.1983104]] Loss_Validation:  [[ 11.00101786]]\n",
      "Loop 4049 Loss_Train:  [[ 13.1983059]] Loss_Validation:  [[ 11.0010536]]\n",
      "Loop 4050 Loss_Train:  [[ 13.19830142]] Loss_Validation:  [[ 11.00108933]]\n",
      "Loop 4051 Loss_Train:  [[ 13.19829693]] Loss_Validation:  [[ 11.00112502]]\n",
      "Loop 4052 Loss_Train:  [[ 13.19829246]] Loss_Validation:  [[ 11.00116069]]\n",
      "Loop 4053 Loss_Train:  [[ 13.19828799]] Loss_Validation:  [[ 11.00119634]]\n",
      "Loop 4054 Loss_Train:  [[ 13.19828353]] Loss_Validation:  [[ 11.00123196]]\n",
      "Loop 4055 Loss_Train:  [[ 13.19827908]] Loss_Validation:  [[ 11.00126755]]\n",
      "Loop 4056 Loss_Train:  [[ 13.19827463]] Loss_Validation:  [[ 11.00130312]]\n",
      "Loop 4057 Loss_Train:  [[ 13.19827019]] Loss_Validation:  [[ 11.00133866]]\n",
      "Loop 4058 Loss_Train:  [[ 13.19826575]] Loss_Validation:  [[ 11.00137418]]\n",
      "Loop 4059 Loss_Train:  [[ 13.19826132]] Loss_Validation:  [[ 11.00140967]]\n",
      "Loop 4060 Loss_Train:  [[ 13.1982569]] Loss_Validation:  [[ 11.00144513]]\n",
      "Loop 4061 Loss_Train:  [[ 13.19825249]] Loss_Validation:  [[ 11.00148057]]\n",
      "Loop 4062 Loss_Train:  [[ 13.19824808]] Loss_Validation:  [[ 11.00151599]]\n",
      "Loop 4063 Loss_Train:  [[ 13.19824368]] Loss_Validation:  [[ 11.00155138]]\n",
      "Loop 4064 Loss_Train:  [[ 13.19823928]] Loss_Validation:  [[ 11.00158674]]\n",
      "Loop 4065 Loss_Train:  [[ 13.19823489]] Loss_Validation:  [[ 11.00162208]]\n",
      "Loop 4066 Loss_Train:  [[ 13.19823051]] Loss_Validation:  [[ 11.00165739]]\n",
      "Loop 4067 Loss_Train:  [[ 13.19822613]] Loss_Validation:  [[ 11.00169267]]\n",
      "Loop 4068 Loss_Train:  [[ 13.19822176]] Loss_Validation:  [[ 11.00172793]]\n",
      "Loop 4069 Loss_Train:  [[ 13.1982174]] Loss_Validation:  [[ 11.00176317]]\n",
      "Loop 4070 Loss_Train:  [[ 13.19821304]] Loss_Validation:  [[ 11.00179838]]\n",
      "Loop 4071 Loss_Train:  [[ 13.19820869]] Loss_Validation:  [[ 11.00183356]]\n",
      "Loop 4072 Loss_Train:  [[ 13.19820435]] Loss_Validation:  [[ 11.00186872]]\n",
      "Loop 4073 Loss_Train:  [[ 13.19820001]] Loss_Validation:  [[ 11.00190385]]\n",
      "Loop 4074 Loss_Train:  [[ 13.19819568]] Loss_Validation:  [[ 11.00193896]]\n",
      "Loop 4075 Loss_Train:  [[ 13.19819136]] Loss_Validation:  [[ 11.00197404]]\n",
      "Loop 4076 Loss_Train:  [[ 13.19818704]] Loss_Validation:  [[ 11.0020091]]\n",
      "Loop 4077 Loss_Train:  [[ 13.19818273]] Loss_Validation:  [[ 11.00204413]]\n",
      "Loop 4078 Loss_Train:  [[ 13.19817842]] Loss_Validation:  [[ 11.00207914]]\n",
      "Loop 4079 Loss_Train:  [[ 13.19817412]] Loss_Validation:  [[ 11.00211412]]\n",
      "Loop 4080 Loss_Train:  [[ 13.19816983]] Loss_Validation:  [[ 11.00214908]]\n",
      "Loop 4081 Loss_Train:  [[ 13.19816554]] Loss_Validation:  [[ 11.00218401]]\n",
      "Loop 4082 Loss_Train:  [[ 13.19816126]] Loss_Validation:  [[ 11.00221891]]\n",
      "Loop 4083 Loss_Train:  [[ 13.19815699]] Loss_Validation:  [[ 11.00225379]]\n",
      "Loop 4084 Loss_Train:  [[ 13.19815272]] Loss_Validation:  [[ 11.00228865]]\n",
      "Loop 4085 Loss_Train:  [[ 13.19814846]] Loss_Validation:  [[ 11.00232348]]\n",
      "Loop 4086 Loss_Train:  [[ 13.19814421]] Loss_Validation:  [[ 11.00235828]]\n",
      "Loop 4087 Loss_Train:  [[ 13.19813996]] Loss_Validation:  [[ 11.00239306]]\n",
      "Loop 4088 Loss_Train:  [[ 13.19813572]] Loss_Validation:  [[ 11.00242782]]\n",
      "Loop 4089 Loss_Train:  [[ 13.19813148]] Loss_Validation:  [[ 11.00246255]]\n",
      "Loop 4090 Loss_Train:  [[ 13.19812725]] Loss_Validation:  [[ 11.00249725]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 4091 Loss_Train:  [[ 13.19812303]] Loss_Validation:  [[ 11.00253193]]\n",
      "Loop 4092 Loss_Train:  [[ 13.19811881]] Loss_Validation:  [[ 11.00256659]]\n",
      "Loop 4093 Loss_Train:  [[ 13.1981146]] Loss_Validation:  [[ 11.00260122]]\n",
      "Loop 4094 Loss_Train:  [[ 13.19811039]] Loss_Validation:  [[ 11.00263582]]\n",
      "Loop 4095 Loss_Train:  [[ 13.1981062]] Loss_Validation:  [[ 11.0026704]]\n",
      "Loop 4096 Loss_Train:  [[ 13.198102]] Loss_Validation:  [[ 11.00270496]]\n",
      "Loop 4097 Loss_Train:  [[ 13.19809782]] Loss_Validation:  [[ 11.00273948]]\n",
      "Loop 4098 Loss_Train:  [[ 13.19809364]] Loss_Validation:  [[ 11.00277399]]\n",
      "Loop 4099 Loss_Train:  [[ 13.19808946]] Loss_Validation:  [[ 11.00280847]]\n",
      "Loop 4100 Loss_Train:  [[ 13.1980853]] Loss_Validation:  [[ 11.00284292]]\n",
      "Loop 4101 Loss_Train:  [[ 13.19808114]] Loss_Validation:  [[ 11.00287735]]\n",
      "Loop 4102 Loss_Train:  [[ 13.19807698]] Loss_Validation:  [[ 11.00291176]]\n",
      "Loop 4103 Loss_Train:  [[ 13.19807283]] Loss_Validation:  [[ 11.00294614]]\n",
      "Loop 4104 Loss_Train:  [[ 13.19806869]] Loss_Validation:  [[ 11.0029805]]\n",
      "Loop 4105 Loss_Train:  [[ 13.19806455]] Loss_Validation:  [[ 11.00301483]]\n",
      "Loop 4106 Loss_Train:  [[ 13.19806042]] Loss_Validation:  [[ 11.00304913]]\n",
      "Loop 4107 Loss_Train:  [[ 13.1980563]] Loss_Validation:  [[ 11.00308342]]\n",
      "Loop 4108 Loss_Train:  [[ 13.19805218]] Loss_Validation:  [[ 11.00311767]]\n",
      "Loop 4109 Loss_Train:  [[ 13.19804807]] Loss_Validation:  [[ 11.0031519]]\n",
      "Loop 4110 Loss_Train:  [[ 13.19804396]] Loss_Validation:  [[ 11.00318611]]\n",
      "Loop 4111 Loss_Train:  [[ 13.19803986]] Loss_Validation:  [[ 11.0032203]]\n",
      "Loop 4112 Loss_Train:  [[ 13.19803577]] Loss_Validation:  [[ 11.00325445]]\n",
      "Loop 4113 Loss_Train:  [[ 13.19803168]] Loss_Validation:  [[ 11.00328859]]\n",
      "Loop 4114 Loss_Train:  [[ 13.1980276]] Loss_Validation:  [[ 11.0033227]]\n",
      "Loop 4115 Loss_Train:  [[ 13.19802352]] Loss_Validation:  [[ 11.00335678]]\n",
      "Loop 4116 Loss_Train:  [[ 13.19801945]] Loss_Validation:  [[ 11.00339084]]\n",
      "Loop 4117 Loss_Train:  [[ 13.19801539]] Loss_Validation:  [[ 11.00342488]]\n",
      "Loop 4118 Loss_Train:  [[ 13.19801133]] Loss_Validation:  [[ 11.00345889]]\n",
      "Loop 4119 Loss_Train:  [[ 13.19800728]] Loss_Validation:  [[ 11.00349287]]\n",
      "Loop 4120 Loss_Train:  [[ 13.19800323]] Loss_Validation:  [[ 11.00352684]]\n",
      "Loop 4121 Loss_Train:  [[ 13.19799919]] Loss_Validation:  [[ 11.00356077]]\n",
      "Loop 4122 Loss_Train:  [[ 13.19799516]] Loss_Validation:  [[ 11.00359469]]\n",
      "Loop 4123 Loss_Train:  [[ 13.19799113]] Loss_Validation:  [[ 11.00362858]]\n",
      "Loop 4124 Loss_Train:  [[ 13.19798711]] Loss_Validation:  [[ 11.00366244]]\n",
      "Loop 4125 Loss_Train:  [[ 13.19798309]] Loss_Validation:  [[ 11.00369628]]\n",
      "Loop 4126 Loss_Train:  [[ 13.19797908]] Loss_Validation:  [[ 11.00373009]]\n",
      "Loop 4127 Loss_Train:  [[ 13.19797508]] Loss_Validation:  [[ 11.00376389]]\n",
      "Loop 4128 Loss_Train:  [[ 13.19797108]] Loss_Validation:  [[ 11.00379765]]\n",
      "Loop 4129 Loss_Train:  [[ 13.19796709]] Loss_Validation:  [[ 11.0038314]]\n",
      "Loop 4130 Loss_Train:  [[ 13.1979631]] Loss_Validation:  [[ 11.00386511]]\n",
      "Loop 4131 Loss_Train:  [[ 13.19795912]] Loss_Validation:  [[ 11.00389881]]\n",
      "Loop 4132 Loss_Train:  [[ 13.19795515]] Loss_Validation:  [[ 11.00393248]]\n",
      "Loop 4133 Loss_Train:  [[ 13.19795118]] Loss_Validation:  [[ 11.00396612]]\n",
      "Loop 4134 Loss_Train:  [[ 13.19794721]] Loss_Validation:  [[ 11.00399975]]\n",
      "Loop 4135 Loss_Train:  [[ 13.19794326]] Loss_Validation:  [[ 11.00403334]]\n",
      "Loop 4136 Loss_Train:  [[ 13.19793931]] Loss_Validation:  [[ 11.00406692]]\n",
      "Loop 4137 Loss_Train:  [[ 13.19793536]] Loss_Validation:  [[ 11.00410046]]\n",
      "Loop 4138 Loss_Train:  [[ 13.19793142]] Loss_Validation:  [[ 11.00413399]]\n",
      "Loop 4139 Loss_Train:  [[ 13.19792749]] Loss_Validation:  [[ 11.00416749]]\n",
      "Loop 4140 Loss_Train:  [[ 13.19792356]] Loss_Validation:  [[ 11.00420097]]\n",
      "Loop 4141 Loss_Train:  [[ 13.19791964]] Loss_Validation:  [[ 11.00423442]]\n",
      "Loop 4142 Loss_Train:  [[ 13.19791572]] Loss_Validation:  [[ 11.00426785]]\n",
      "Loop 4143 Loss_Train:  [[ 13.19791181]] Loss_Validation:  [[ 11.00430125]]\n",
      "Loop 4144 Loss_Train:  [[ 13.19790791]] Loss_Validation:  [[ 11.00433463]]\n",
      "Loop 4145 Loss_Train:  [[ 13.19790401]] Loss_Validation:  [[ 11.00436799]]\n",
      "Loop 4146 Loss_Train:  [[ 13.19790011]] Loss_Validation:  [[ 11.00440132]]\n",
      "Loop 4147 Loss_Train:  [[ 13.19789623]] Loss_Validation:  [[ 11.00443463]]\n",
      "Loop 4148 Loss_Train:  [[ 13.19789235]] Loss_Validation:  [[ 11.00446792]]\n",
      "Loop 4149 Loss_Train:  [[ 13.19788847]] Loss_Validation:  [[ 11.00450118]]\n",
      "Loop 4150 Loss_Train:  [[ 13.1978846]] Loss_Validation:  [[ 11.00453441]]\n",
      "Loop 4151 Loss_Train:  [[ 13.19788074]] Loss_Validation:  [[ 11.00456763]]\n",
      "Loop 4152 Loss_Train:  [[ 13.19787688]] Loss_Validation:  [[ 11.00460082]]\n",
      "Loop 4153 Loss_Train:  [[ 13.19787302]] Loss_Validation:  [[ 11.00463398]]\n",
      "Loop 4154 Loss_Train:  [[ 13.19786918]] Loss_Validation:  [[ 11.00466712]]\n",
      "Loop 4155 Loss_Train:  [[ 13.19786533]] Loss_Validation:  [[ 11.00470024]]\n",
      "Loop 4156 Loss_Train:  [[ 13.1978615]] Loss_Validation:  [[ 11.00473333]]\n",
      "Loop 4157 Loss_Train:  [[ 13.19785767]] Loss_Validation:  [[ 11.0047664]]\n",
      "Loop 4158 Loss_Train:  [[ 13.19785384]] Loss_Validation:  [[ 11.00479945]]\n",
      "Loop 4159 Loss_Train:  [[ 13.19785002]] Loss_Validation:  [[ 11.00483247]]\n",
      "Loop 4160 Loss_Train:  [[ 13.19784621]] Loss_Validation:  [[ 11.00486547]]\n",
      "Loop 4161 Loss_Train:  [[ 13.1978424]] Loss_Validation:  [[ 11.00489845]]\n",
      "Loop 4162 Loss_Train:  [[ 13.1978386]] Loss_Validation:  [[ 11.0049314]]\n",
      "Loop 4163 Loss_Train:  [[ 13.19783481]] Loss_Validation:  [[ 11.00496433]]\n",
      "Loop 4164 Loss_Train:  [[ 13.19783101]] Loss_Validation:  [[ 11.00499723]]\n",
      "Loop 4165 Loss_Train:  [[ 13.19782723]] Loss_Validation:  [[ 11.00503011]]\n",
      "Loop 4166 Loss_Train:  [[ 13.19782345]] Loss_Validation:  [[ 11.00506297]]\n",
      "Loop 4167 Loss_Train:  [[ 13.19781968]] Loss_Validation:  [[ 11.0050958]]\n",
      "Loop 4168 Loss_Train:  [[ 13.19781591]] Loss_Validation:  [[ 11.00512861]]\n",
      "Loop 4169 Loss_Train:  [[ 13.19781214]] Loss_Validation:  [[ 11.0051614]]\n",
      "Loop 4170 Loss_Train:  [[ 13.19780839]] Loss_Validation:  [[ 11.00519416]]\n",
      "Loop 4171 Loss_Train:  [[ 13.19780464]] Loss_Validation:  [[ 11.0052269]]\n",
      "Loop 4172 Loss_Train:  [[ 13.19780089]] Loss_Validation:  [[ 11.00525962]]\n",
      "Loop 4173 Loss_Train:  [[ 13.19779715]] Loss_Validation:  [[ 11.00529231]]\n",
      "Loop 4174 Loss_Train:  [[ 13.19779341]] Loss_Validation:  [[ 11.00532498]]\n",
      "Loop 4175 Loss_Train:  [[ 13.19778968]] Loss_Validation:  [[ 11.00535762]]\n",
      "Loop 4176 Loss_Train:  [[ 13.19778596]] Loss_Validation:  [[ 11.00539025]]\n",
      "Loop 4177 Loss_Train:  [[ 13.19778224]] Loss_Validation:  [[ 11.00542284]]\n",
      "Loop 4178 Loss_Train:  [[ 13.19777853]] Loss_Validation:  [[ 11.00545542]]\n",
      "Loop 4179 Loss_Train:  [[ 13.19777482]] Loss_Validation:  [[ 11.00548797]]\n",
      "Loop 4180 Loss_Train:  [[ 13.19777112]] Loss_Validation:  [[ 11.0055205]]\n",
      "Loop 4181 Loss_Train:  [[ 13.19776742]] Loss_Validation:  [[ 11.00555301]]\n",
      "Loop 4182 Loss_Train:  [[ 13.19776373]] Loss_Validation:  [[ 11.00558549]]\n",
      "Loop 4183 Loss_Train:  [[ 13.19776004]] Loss_Validation:  [[ 11.00561795]]\n",
      "Loop 4184 Loss_Train:  [[ 13.19775636]] Loss_Validation:  [[ 11.00565038]]\n",
      "Loop 4185 Loss_Train:  [[ 13.19775269]] Loss_Validation:  [[ 11.00568279]]\n",
      "Loop 4186 Loss_Train:  [[ 13.19774902]] Loss_Validation:  [[ 11.00571518]]\n",
      "Loop 4187 Loss_Train:  [[ 13.19774536]] Loss_Validation:  [[ 11.00574755]]\n",
      "Loop 4188 Loss_Train:  [[ 13.1977417]] Loss_Validation:  [[ 11.00577989]]\n",
      "Loop 4189 Loss_Train:  [[ 13.19773804]] Loss_Validation:  [[ 11.00581221]]\n",
      "Loop 4190 Loss_Train:  [[ 13.1977344]] Loss_Validation:  [[ 11.00584451]]\n",
      "Loop 4191 Loss_Train:  [[ 13.19773075]] Loss_Validation:  [[ 11.00587678]]\n",
      "Loop 4192 Loss_Train:  [[ 13.19772712]] Loss_Validation:  [[ 11.00590903]]\n",
      "Loop 4193 Loss_Train:  [[ 13.19772348]] Loss_Validation:  [[ 11.00594126]]\n",
      "Loop 4194 Loss_Train:  [[ 13.19771986]] Loss_Validation:  [[ 11.00597346]]\n",
      "Loop 4195 Loss_Train:  [[ 13.19771624]] Loss_Validation:  [[ 11.00600564]]\n",
      "Loop 4196 Loss_Train:  [[ 13.19771262]] Loss_Validation:  [[ 11.0060378]]\n",
      "Loop 4197 Loss_Train:  [[ 13.19770901]] Loss_Validation:  [[ 11.00606993]]\n",
      "Loop 4198 Loss_Train:  [[ 13.19770541]] Loss_Validation:  [[ 11.00610205]]\n",
      "Loop 4199 Loss_Train:  [[ 13.19770181]] Loss_Validation:  [[ 11.00613413]]\n",
      "Loop 4200 Loss_Train:  [[ 13.19769821]] Loss_Validation:  [[ 11.0061662]]\n",
      "Loop 4201 Loss_Train:  [[ 13.19769462]] Loss_Validation:  [[ 11.00619824]]\n",
      "Loop 4202 Loss_Train:  [[ 13.19769104]] Loss_Validation:  [[ 11.00623026]]\n",
      "Loop 4203 Loss_Train:  [[ 13.19768746]] Loss_Validation:  [[ 11.00626226]]\n",
      "Loop 4204 Loss_Train:  [[ 13.19768389]] Loss_Validation:  [[ 11.00629423]]\n",
      "Loop 4205 Loss_Train:  [[ 13.19768032]] Loss_Validation:  [[ 11.00632618]]\n",
      "Loop 4206 Loss_Train:  [[ 13.19767676]] Loss_Validation:  [[ 11.00635811]]\n",
      "Loop 4207 Loss_Train:  [[ 13.1976732]] Loss_Validation:  [[ 11.00639002]]\n",
      "Loop 4208 Loss_Train:  [[ 13.19766965]] Loss_Validation:  [[ 11.0064219]]\n",
      "Loop 4209 Loss_Train:  [[ 13.1976661]] Loss_Validation:  [[ 11.00645376]]\n",
      "Loop 4210 Loss_Train:  [[ 13.19766256]] Loss_Validation:  [[ 11.0064856]]\n",
      "Loop 4211 Loss_Train:  [[ 13.19765902]] Loss_Validation:  [[ 11.00651741]]\n",
      "Loop 4212 Loss_Train:  [[ 13.19765549]] Loss_Validation:  [[ 11.0065492]]\n",
      "Loop 4213 Loss_Train:  [[ 13.19765197]] Loss_Validation:  [[ 11.00658097]]\n",
      "Loop 4214 Loss_Train:  [[ 13.19764845]] Loss_Validation:  [[ 11.00661272]]\n",
      "Loop 4215 Loss_Train:  [[ 13.19764493]] Loss_Validation:  [[ 11.00664444]]\n",
      "Loop 4216 Loss_Train:  [[ 13.19764142]] Loss_Validation:  [[ 11.00667614]]\n",
      "Loop 4217 Loss_Train:  [[ 13.19763791]] Loss_Validation:  [[ 11.00670782]]\n",
      "Loop 4218 Loss_Train:  [[ 13.19763441]] Loss_Validation:  [[ 11.00673947]]\n",
      "Loop 4219 Loss_Train:  [[ 13.19763092]] Loss_Validation:  [[ 11.00677111]]\n",
      "Loop 4220 Loss_Train:  [[ 13.19762743]] Loss_Validation:  [[ 11.00680272]]\n",
      "Loop 4221 Loss_Train:  [[ 13.19762395]] Loss_Validation:  [[ 11.0068343]]\n",
      "Loop 4222 Loss_Train:  [[ 13.19762047]] Loss_Validation:  [[ 11.00686587]]\n",
      "Loop 4223 Loss_Train:  [[ 13.19761699]] Loss_Validation:  [[ 11.00689741]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 4224 Loss_Train:  [[ 13.19761352]] Loss_Validation:  [[ 11.00692893]]\n",
      "Loop 4225 Loss_Train:  [[ 13.19761006]] Loss_Validation:  [[ 11.00696043]]\n",
      "Loop 4226 Loss_Train:  [[ 13.1976066]] Loss_Validation:  [[ 11.0069919]]\n",
      "Loop 4227 Loss_Train:  [[ 13.19760315]] Loss_Validation:  [[ 11.00702335]]\n",
      "Loop 4228 Loss_Train:  [[ 13.1975997]] Loss_Validation:  [[ 11.00705478]]\n",
      "Loop 4229 Loss_Train:  [[ 13.19759625]] Loss_Validation:  [[ 11.00708619]]\n",
      "Loop 4230 Loss_Train:  [[ 13.19759282]] Loss_Validation:  [[ 11.00711757]]\n",
      "Loop 4231 Loss_Train:  [[ 13.19758938]] Loss_Validation:  [[ 11.00714894]]\n",
      "Loop 4232 Loss_Train:  [[ 13.19758595]] Loss_Validation:  [[ 11.00718028]]\n",
      "Loop 4233 Loss_Train:  [[ 13.19758253]] Loss_Validation:  [[ 11.00721159]]\n",
      "Loop 4234 Loss_Train:  [[ 13.19757911]] Loss_Validation:  [[ 11.00724289]]\n",
      "Loop 4235 Loss_Train:  [[ 13.1975757]] Loss_Validation:  [[ 11.00727416]]\n",
      "Loop 4236 Loss_Train:  [[ 13.19757229]] Loss_Validation:  [[ 11.00730541]]\n",
      "Loop 4237 Loss_Train:  [[ 13.19756889]] Loss_Validation:  [[ 11.00733664]]\n",
      "Loop 4238 Loss_Train:  [[ 13.19756549]] Loss_Validation:  [[ 11.00736784]]\n",
      "Loop 4239 Loss_Train:  [[ 13.1975621]] Loss_Validation:  [[ 11.00739903]]\n",
      "Loop 4240 Loss_Train:  [[ 13.19755871]] Loss_Validation:  [[ 11.00743019]]\n",
      "Loop 4241 Loss_Train:  [[ 13.19755533]] Loss_Validation:  [[ 11.00746133]]\n",
      "Loop 4242 Loss_Train:  [[ 13.19755195]] Loss_Validation:  [[ 11.00749244]]\n",
      "Loop 4243 Loss_Train:  [[ 13.19754857]] Loss_Validation:  [[ 11.00752354]]\n",
      "Loop 4244 Loss_Train:  [[ 13.19754521]] Loss_Validation:  [[ 11.00755461]]\n",
      "Loop 4245 Loss_Train:  [[ 13.19754184]] Loss_Validation:  [[ 11.00758566]]\n",
      "Loop 4246 Loss_Train:  [[ 13.19753849]] Loss_Validation:  [[ 11.00761669]]\n",
      "Loop 4247 Loss_Train:  [[ 13.19753513]] Loss_Validation:  [[ 11.0076477]]\n",
      "Loop 4248 Loss_Train:  [[ 13.19753178]] Loss_Validation:  [[ 11.00767868]]\n",
      "Loop 4249 Loss_Train:  [[ 13.19752844]] Loss_Validation:  [[ 11.00770964]]\n",
      "Loop 4250 Loss_Train:  [[ 13.1975251]] Loss_Validation:  [[ 11.00774058]]\n",
      "Loop 4251 Loss_Train:  [[ 13.19752177]] Loss_Validation:  [[ 11.0077715]]\n",
      "Loop 4252 Loss_Train:  [[ 13.19751844]] Loss_Validation:  [[ 11.00780239]]\n",
      "Loop 4253 Loss_Train:  [[ 13.19751512]] Loss_Validation:  [[ 11.00783327]]\n",
      "Loop 4254 Loss_Train:  [[ 13.1975118]] Loss_Validation:  [[ 11.00786412]]\n",
      "Loop 4255 Loss_Train:  [[ 13.19750848]] Loss_Validation:  [[ 11.00789495]]\n",
      "Loop 4256 Loss_Train:  [[ 13.19750518]] Loss_Validation:  [[ 11.00792575]]\n",
      "Loop 4257 Loss_Train:  [[ 13.19750187]] Loss_Validation:  [[ 11.00795654]]\n",
      "Loop 4258 Loss_Train:  [[ 13.19749857]] Loss_Validation:  [[ 11.0079873]]\n",
      "Loop 4259 Loss_Train:  [[ 13.19749528]] Loss_Validation:  [[ 11.00801804]]\n",
      "Loop 4260 Loss_Train:  [[ 13.19749199]] Loss_Validation:  [[ 11.00804876]]\n",
      "Loop 4261 Loss_Train:  [[ 13.1974887]] Loss_Validation:  [[ 11.00807946]]\n",
      "Loop 4262 Loss_Train:  [[ 13.19748542]] Loss_Validation:  [[ 11.00811013]]\n",
      "Loop 4263 Loss_Train:  [[ 13.19748215]] Loss_Validation:  [[ 11.00814079]]\n",
      "Loop 4264 Loss_Train:  [[ 13.19747888]] Loss_Validation:  [[ 11.00817142]]\n",
      "Loop 4265 Loss_Train:  [[ 13.19747561]] Loss_Validation:  [[ 11.00820203]]\n",
      "Loop 4266 Loss_Train:  [[ 13.19747235]] Loss_Validation:  [[ 11.00823262]]\n",
      "Loop 4267 Loss_Train:  [[ 13.1974691]] Loss_Validation:  [[ 11.00826318]]\n",
      "Loop 4268 Loss_Train:  [[ 13.19746585]] Loss_Validation:  [[ 11.00829373]]\n",
      "Loop 4269 Loss_Train:  [[ 13.1974626]] Loss_Validation:  [[ 11.00832425]]\n",
      "Loop 4270 Loss_Train:  [[ 13.19745936]] Loss_Validation:  [[ 11.00835475]]\n",
      "Loop 4271 Loss_Train:  [[ 13.19745612]] Loss_Validation:  [[ 11.00838523]]\n",
      "Loop 4272 Loss_Train:  [[ 13.19745289]] Loss_Validation:  [[ 11.00841569]]\n",
      "Loop 4273 Loss_Train:  [[ 13.19744966]] Loss_Validation:  [[ 11.00844613]]\n",
      "Loop 4274 Loss_Train:  [[ 13.19744644]] Loss_Validation:  [[ 11.00847654]]\n",
      "Loop 4275 Loss_Train:  [[ 13.19744323]] Loss_Validation:  [[ 11.00850693]]\n",
      "Loop 4276 Loss_Train:  [[ 13.19744001]] Loss_Validation:  [[ 11.0085373]]\n",
      "Loop 4277 Loss_Train:  [[ 13.1974368]] Loss_Validation:  [[ 11.00856765]]\n",
      "Loop 4278 Loss_Train:  [[ 13.1974336]] Loss_Validation:  [[ 11.00859798]]\n",
      "Loop 4279 Loss_Train:  [[ 13.1974304]] Loss_Validation:  [[ 11.00862828]]\n",
      "Loop 4280 Loss_Train:  [[ 13.19742721]] Loss_Validation:  [[ 11.00865857]]\n",
      "Loop 4281 Loss_Train:  [[ 13.19742402]] Loss_Validation:  [[ 11.00868883]]\n",
      "Loop 4282 Loss_Train:  [[ 13.19742084]] Loss_Validation:  [[ 11.00871907]]\n",
      "Loop 4283 Loss_Train:  [[ 13.19741766]] Loss_Validation:  [[ 11.00874929]]\n",
      "Loop 4284 Loss_Train:  [[ 13.19741448]] Loss_Validation:  [[ 11.00877949]]\n",
      "Loop 4285 Loss_Train:  [[ 13.19741131]] Loss_Validation:  [[ 11.00880967]]\n",
      "Loop 4286 Loss_Train:  [[ 13.19740815]] Loss_Validation:  [[ 11.00883982]]\n",
      "Loop 4287 Loss_Train:  [[ 13.19740499]] Loss_Validation:  [[ 11.00886996]]\n",
      "Loop 4288 Loss_Train:  [[ 13.19740183]] Loss_Validation:  [[ 11.00890007]]\n",
      "Loop 4289 Loss_Train:  [[ 13.19739868]] Loss_Validation:  [[ 11.00893016]]\n",
      "Loop 4290 Loss_Train:  [[ 13.19739553]] Loss_Validation:  [[ 11.00896023]]\n",
      "Loop 4291 Loss_Train:  [[ 13.19739239]] Loss_Validation:  [[ 11.00899028]]\n",
      "Loop 4292 Loss_Train:  [[ 13.19738925]] Loss_Validation:  [[ 11.0090203]]\n",
      "Loop 4293 Loss_Train:  [[ 13.19738612]] Loss_Validation:  [[ 11.00905031]]\n",
      "Loop 4294 Loss_Train:  [[ 13.19738299]] Loss_Validation:  [[ 11.00908029]]\n",
      "Loop 4295 Loss_Train:  [[ 13.19737987]] Loss_Validation:  [[ 11.00911025]]\n",
      "Loop 4296 Loss_Train:  [[ 13.19737675]] Loss_Validation:  [[ 11.0091402]]\n",
      "Loop 4297 Loss_Train:  [[ 13.19737363]] Loss_Validation:  [[ 11.00917011]]\n",
      "Loop 4298 Loss_Train:  [[ 13.19737052]] Loss_Validation:  [[ 11.00920001]]\n",
      "Loop 4299 Loss_Train:  [[ 13.19736742]] Loss_Validation:  [[ 11.00922989]]\n",
      "Loop 4300 Loss_Train:  [[ 13.19736432]] Loss_Validation:  [[ 11.00925975]]\n",
      "Loop 4301 Loss_Train:  [[ 13.19736122]] Loss_Validation:  [[ 11.00928958]]\n",
      "Loop 4302 Loss_Train:  [[ 13.19735813]] Loss_Validation:  [[ 11.00931939]]\n",
      "Loop 4303 Loss_Train:  [[ 13.19735504]] Loss_Validation:  [[ 11.00934919]]\n",
      "Loop 4304 Loss_Train:  [[ 13.19735196]] Loss_Validation:  [[ 11.00937896]]\n",
      "Loop 4305 Loss_Train:  [[ 13.19734888]] Loss_Validation:  [[ 11.00940871]]\n",
      "Loop 4306 Loss_Train:  [[ 13.19734581]] Loss_Validation:  [[ 11.00943844]]\n",
      "Loop 4307 Loss_Train:  [[ 13.19734274]] Loss_Validation:  [[ 11.00946814]]\n",
      "Loop 4308 Loss_Train:  [[ 13.19733967]] Loss_Validation:  [[ 11.00949783]]\n",
      "Loop 4309 Loss_Train:  [[ 13.19733661]] Loss_Validation:  [[ 11.0095275]]\n",
      "Loop 4310 Loss_Train:  [[ 13.19733356]] Loss_Validation:  [[ 11.00955714]]\n",
      "Loop 4311 Loss_Train:  [[ 13.19733051]] Loss_Validation:  [[ 11.00958676]]\n",
      "Loop 4312 Loss_Train:  [[ 13.19732746]] Loss_Validation:  [[ 11.00961637]]\n",
      "Loop 4313 Loss_Train:  [[ 13.19732442]] Loss_Validation:  [[ 11.00964595]]\n",
      "Loop 4314 Loss_Train:  [[ 13.19732138]] Loss_Validation:  [[ 11.00967551]]\n",
      "Loop 4315 Loss_Train:  [[ 13.19731835]] Loss_Validation:  [[ 11.00970505]]\n",
      "Loop 4316 Loss_Train:  [[ 13.19731532]] Loss_Validation:  [[ 11.00973456]]\n",
      "Loop 4317 Loss_Train:  [[ 13.1973123]] Loss_Validation:  [[ 11.00976406]]\n",
      "Loop 4318 Loss_Train:  [[ 13.19730928]] Loss_Validation:  [[ 11.00979354]]\n",
      "Loop 4319 Loss_Train:  [[ 13.19730626]] Loss_Validation:  [[ 11.00982299]]\n",
      "Loop 4320 Loss_Train:  [[ 13.19730325]] Loss_Validation:  [[ 11.00985243]]\n",
      "Loop 4321 Loss_Train:  [[ 13.19730024]] Loss_Validation:  [[ 11.00988184]]\n",
      "Loop 4322 Loss_Train:  [[ 13.19729724]] Loss_Validation:  [[ 11.00991123]]\n",
      "Loop 4323 Loss_Train:  [[ 13.19729425]] Loss_Validation:  [[ 11.0099406]]\n",
      "Loop 4324 Loss_Train:  [[ 13.19729125]] Loss_Validation:  [[ 11.00996995]]\n",
      "Loop 4325 Loss_Train:  [[ 13.19728826]] Loss_Validation:  [[ 11.00999928]]\n",
      "Loop 4326 Loss_Train:  [[ 13.19728528]] Loss_Validation:  [[ 11.01002859]]\n",
      "Loop 4327 Loss_Train:  [[ 13.1972823]] Loss_Validation:  [[ 11.01005788]]\n",
      "Loop 4328 Loss_Train:  [[ 13.19727932]] Loss_Validation:  [[ 11.01008715]]\n",
      "Loop 4329 Loss_Train:  [[ 13.19727635]] Loss_Validation:  [[ 11.01011639]]\n",
      "Loop 4330 Loss_Train:  [[ 13.19727339]] Loss_Validation:  [[ 11.01014562]]\n",
      "Loop 4331 Loss_Train:  [[ 13.19727042]] Loss_Validation:  [[ 11.01017482]]\n",
      "Loop 4332 Loss_Train:  [[ 13.19726747]] Loss_Validation:  [[ 11.01020401]]\n",
      "Loop 4333 Loss_Train:  [[ 13.19726451]] Loss_Validation:  [[ 11.01023317]]\n",
      "Loop 4334 Loss_Train:  [[ 13.19726156]] Loss_Validation:  [[ 11.01026231]]\n",
      "Loop 4335 Loss_Train:  [[ 13.19725862]] Loss_Validation:  [[ 11.01029144]]\n",
      "Loop 4336 Loss_Train:  [[ 13.19725568]] Loss_Validation:  [[ 11.01032054]]\n",
      "Loop 4337 Loss_Train:  [[ 13.19725274]] Loss_Validation:  [[ 11.01034962]]\n",
      "Loop 4338 Loss_Train:  [[ 13.19724981]] Loss_Validation:  [[ 11.01037868]]\n",
      "Loop 4339 Loss_Train:  [[ 13.19724688]] Loss_Validation:  [[ 11.01040772]]\n",
      "Loop 4340 Loss_Train:  [[ 13.19724396]] Loss_Validation:  [[ 11.01043674]]\n",
      "Loop 4341 Loss_Train:  [[ 13.19724104]] Loss_Validation:  [[ 11.01046573]]\n",
      "Loop 4342 Loss_Train:  [[ 13.19723813]] Loss_Validation:  [[ 11.01049471]]\n",
      "Loop 4343 Loss_Train:  [[ 13.19723522]] Loss_Validation:  [[ 11.01052367]]\n",
      "Loop 4344 Loss_Train:  [[ 13.19723231]] Loss_Validation:  [[ 11.01055261]]\n",
      "Loop 4345 Loss_Train:  [[ 13.19722941]] Loss_Validation:  [[ 11.01058152]]\n",
      "Loop 4346 Loss_Train:  [[ 13.19722651]] Loss_Validation:  [[ 11.01061042]]\n",
      "Loop 4347 Loss_Train:  [[ 13.19722362]] Loss_Validation:  [[ 11.01063929]]\n",
      "Loop 4348 Loss_Train:  [[ 13.19722073]] Loss_Validation:  [[ 11.01066815]]\n",
      "Loop 4349 Loss_Train:  [[ 13.19721785]] Loss_Validation:  [[ 11.01069698]]\n",
      "Loop 4350 Loss_Train:  [[ 13.19721497]] Loss_Validation:  [[ 11.01072579]]\n",
      "Loop 4351 Loss_Train:  [[ 13.19721209]] Loss_Validation:  [[ 11.01075459]]\n",
      "Loop 4352 Loss_Train:  [[ 13.19720922]] Loss_Validation:  [[ 11.01078336]]\n",
      "Loop 4353 Loss_Train:  [[ 13.19720635]] Loss_Validation:  [[ 11.01081211]]\n",
      "Loop 4354 Loss_Train:  [[ 13.19720349]] Loss_Validation:  [[ 11.01084084]]\n",
      "Loop 4355 Loss_Train:  [[ 13.19720063]] Loss_Validation:  [[ 11.01086955]]\n",
      "Loop 4356 Loss_Train:  [[ 13.19719777]] Loss_Validation:  [[ 11.01089825]]\n",
      "Loop 4357 Loss_Train:  [[ 13.19719492]] Loss_Validation:  [[ 11.01092692]]\n",
      "Loop 4358 Loss_Train:  [[ 13.19719208]] Loss_Validation:  [[ 11.01095557]]\n",
      "Loop 4359 Loss_Train:  [[ 13.19718923]] Loss_Validation:  [[ 11.0109842]]\n",
      "Loop 4360 Loss_Train:  [[ 13.19718639]] Loss_Validation:  [[ 11.01101281]]\n",
      "Loop 4361 Loss_Train:  [[ 13.19718356]] Loss_Validation:  [[ 11.0110414]]\n",
      "Loop 4362 Loss_Train:  [[ 13.19718073]] Loss_Validation:  [[ 11.01106996]]\n",
      "Loop 4363 Loss_Train:  [[ 13.19717791]] Loss_Validation:  [[ 11.01109851]]\n",
      "Loop 4364 Loss_Train:  [[ 13.19717508]] Loss_Validation:  [[ 11.01112704]]\n",
      "Loop 4365 Loss_Train:  [[ 13.19717227]] Loss_Validation:  [[ 11.01115555]]\n",
      "Loop 4366 Loss_Train:  [[ 13.19716945]] Loss_Validation:  [[ 11.01118404]]\n",
      "Loop 4367 Loss_Train:  [[ 13.19716664]] Loss_Validation:  [[ 11.01121251]]\n",
      "Loop 4368 Loss_Train:  [[ 13.19716384]] Loss_Validation:  [[ 11.01124095]]\n",
      "Loop 4369 Loss_Train:  [[ 13.19716104]] Loss_Validation:  [[ 11.01126938]]\n",
      "Loop 4370 Loss_Train:  [[ 13.19715824]] Loss_Validation:  [[ 11.01129779]]\n",
      "Loop 4371 Loss_Train:  [[ 13.19715545]] Loss_Validation:  [[ 11.01132618]]\n",
      "Loop 4372 Loss_Train:  [[ 13.19715266]] Loss_Validation:  [[ 11.01135454]]\n",
      "Loop 4373 Loss_Train:  [[ 13.19714988]] Loss_Validation:  [[ 11.01138289]]\n",
      "Loop 4374 Loss_Train:  [[ 13.1971471]] Loss_Validation:  [[ 11.01141122]]\n",
      "Loop 4375 Loss_Train:  [[ 13.19714432]] Loss_Validation:  [[ 11.01143953]]\n",
      "Loop 4376 Loss_Train:  [[ 13.19714155]] Loss_Validation:  [[ 11.01146781]]\n",
      "Loop 4377 Loss_Train:  [[ 13.19713878]] Loss_Validation:  [[ 11.01149608]]\n",
      "Loop 4378 Loss_Train:  [[ 13.19713602]] Loss_Validation:  [[ 11.01152433]]\n",
      "Loop 4379 Loss_Train:  [[ 13.19713326]] Loss_Validation:  [[ 11.01155255]]\n",
      "Loop 4380 Loss_Train:  [[ 13.1971305]] Loss_Validation:  [[ 11.01158076]]\n",
      "Loop 4381 Loss_Train:  [[ 13.19712775]] Loss_Validation:  [[ 11.01160895]]\n",
      "Loop 4382 Loss_Train:  [[ 13.197125]] Loss_Validation:  [[ 11.01163711]]\n",
      "Loop 4383 Loss_Train:  [[ 13.19712226]] Loss_Validation:  [[ 11.01166526]]\n",
      "Loop 4384 Loss_Train:  [[ 13.19711952]] Loss_Validation:  [[ 11.01169339]]\n",
      "Loop 4385 Loss_Train:  [[ 13.19711678]] Loss_Validation:  [[ 11.0117215]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 4386 Loss_Train:  [[ 13.19711405]] Loss_Validation:  [[ 11.01174958]]\n",
      "Loop 4387 Loss_Train:  [[ 13.19711132]] Loss_Validation:  [[ 11.01177765]]\n",
      "Loop 4388 Loss_Train:  [[ 13.1971086]] Loss_Validation:  [[ 11.0118057]]\n",
      "Loop 4389 Loss_Train:  [[ 13.19710588]] Loss_Validation:  [[ 11.01183372]]\n",
      "Loop 4390 Loss_Train:  [[ 13.19710317]] Loss_Validation:  [[ 11.01186173]]\n",
      "Loop 4391 Loss_Train:  [[ 13.19710046]] Loss_Validation:  [[ 11.01188972]]\n",
      "Loop 4392 Loss_Train:  [[ 13.19709775]] Loss_Validation:  [[ 11.01191769]]\n",
      "Loop 4393 Loss_Train:  [[ 13.19709504]] Loss_Validation:  [[ 11.01194564]]\n",
      "Loop 4394 Loss_Train:  [[ 13.19709235]] Loss_Validation:  [[ 11.01197357]]\n",
      "Loop 4395 Loss_Train:  [[ 13.19708965]] Loss_Validation:  [[ 11.01200147]]\n",
      "Loop 4396 Loss_Train:  [[ 13.19708696]] Loss_Validation:  [[ 11.01202936]]\n",
      "Loop 4397 Loss_Train:  [[ 13.19708427]] Loss_Validation:  [[ 11.01205723]]\n",
      "Loop 4398 Loss_Train:  [[ 13.19708159]] Loss_Validation:  [[ 11.01208508]]\n",
      "Loop 4399 Loss_Train:  [[ 13.19707891]] Loss_Validation:  [[ 11.01211291]]\n",
      "Loop 4400 Loss_Train:  [[ 13.19707623]] Loss_Validation:  [[ 11.01214072]]\n",
      "Loop 4401 Loss_Train:  [[ 13.19707356]] Loss_Validation:  [[ 11.01216851]]\n",
      "Loop 4402 Loss_Train:  [[ 13.19707089]] Loss_Validation:  [[ 11.01219628]]\n",
      "Loop 4403 Loss_Train:  [[ 13.19706823]] Loss_Validation:  [[ 11.01222403]]\n",
      "Loop 4404 Loss_Train:  [[ 13.19706557]] Loss_Validation:  [[ 11.01225177]]\n",
      "Loop 4405 Loss_Train:  [[ 13.19706291]] Loss_Validation:  [[ 11.01227948]]\n",
      "Loop 4406 Loss_Train:  [[ 13.19706026]] Loss_Validation:  [[ 11.01230717]]\n",
      "Loop 4407 Loss_Train:  [[ 13.19705761]] Loss_Validation:  [[ 11.01233484]]\n",
      "Loop 4408 Loss_Train:  [[ 13.19705497]] Loss_Validation:  [[ 11.0123625]]\n",
      "Loop 4409 Loss_Train:  [[ 13.19705233]] Loss_Validation:  [[ 11.01239013]]\n",
      "Loop 4410 Loss_Train:  [[ 13.19704969]] Loss_Validation:  [[ 11.01241774]]\n",
      "Loop 4411 Loss_Train:  [[ 13.19704706]] Loss_Validation:  [[ 11.01244534]]\n",
      "Loop 4412 Loss_Train:  [[ 13.19704443]] Loss_Validation:  [[ 11.01247291]]\n",
      "Loop 4413 Loss_Train:  [[ 13.1970418]] Loss_Validation:  [[ 11.01250047]]\n",
      "Loop 4414 Loss_Train:  [[ 13.19703918]] Loss_Validation:  [[ 11.012528]]\n",
      "Loop 4415 Loss_Train:  [[ 13.19703657]] Loss_Validation:  [[ 11.01255552]]\n",
      "Loop 4416 Loss_Train:  [[ 13.19703395]] Loss_Validation:  [[ 11.01258302]]\n",
      "Loop 4417 Loss_Train:  [[ 13.19703134]] Loss_Validation:  [[ 11.0126105]]\n",
      "Loop 4418 Loss_Train:  [[ 13.19702874]] Loss_Validation:  [[ 11.01263795]]\n",
      "Loop 4419 Loss_Train:  [[ 13.19702614]] Loss_Validation:  [[ 11.01266539]]\n",
      "Loop 4420 Loss_Train:  [[ 13.19702354]] Loss_Validation:  [[ 11.01269281]]\n",
      "Loop 4421 Loss_Train:  [[ 13.19702094]] Loss_Validation:  [[ 11.01272021]]\n",
      "Loop 4422 Loss_Train:  [[ 13.19701835]] Loss_Validation:  [[ 11.01274759]]\n",
      "Loop 4423 Loss_Train:  [[ 13.19701577]] Loss_Validation:  [[ 11.01277495]]\n",
      "Loop 4424 Loss_Train:  [[ 13.19701318]] Loss_Validation:  [[ 11.0128023]]\n",
      "Loop 4425 Loss_Train:  [[ 13.19701061]] Loss_Validation:  [[ 11.01282962]]\n",
      "Loop 4426 Loss_Train:  [[ 13.19700803]] Loss_Validation:  [[ 11.01285692]]\n",
      "Loop 4427 Loss_Train:  [[ 13.19700546]] Loss_Validation:  [[ 11.01288421]]\n",
      "Loop 4428 Loss_Train:  [[ 13.19700289]] Loss_Validation:  [[ 11.01291147]]\n",
      "Loop 4429 Loss_Train:  [[ 13.19700033]] Loss_Validation:  [[ 11.01293872]]\n",
      "Loop 4430 Loss_Train:  [[ 13.19699777]] Loss_Validation:  [[ 11.01296594]]\n",
      "Loop 4431 Loss_Train:  [[ 13.19699521]] Loss_Validation:  [[ 11.01299315]]\n",
      "Loop 4432 Loss_Train:  [[ 13.19699266]] Loss_Validation:  [[ 11.01302034]]\n",
      "Loop 4433 Loss_Train:  [[ 13.19699011]] Loss_Validation:  [[ 11.0130475]]\n",
      "Loop 4434 Loss_Train:  [[ 13.19698757]] Loss_Validation:  [[ 11.01307465]]\n",
      "Loop 4435 Loss_Train:  [[ 13.19698502]] Loss_Validation:  [[ 11.01310178]]\n",
      "Loop 4436 Loss_Train:  [[ 13.19698249]] Loss_Validation:  [[ 11.0131289]]\n",
      "Loop 4437 Loss_Train:  [[ 13.19697995]] Loss_Validation:  [[ 11.01315599]]\n",
      "Loop 4438 Loss_Train:  [[ 13.19697742]] Loss_Validation:  [[ 11.01318306]]\n",
      "Loop 4439 Loss_Train:  [[ 13.1969749]] Loss_Validation:  [[ 11.01321011]]\n",
      "Loop 4440 Loss_Train:  [[ 13.19697237]] Loss_Validation:  [[ 11.01323715]]\n",
      "Loop 4441 Loss_Train:  [[ 13.19696986]] Loss_Validation:  [[ 11.01326416]]\n",
      "Loop 4442 Loss_Train:  [[ 13.19696734]] Loss_Validation:  [[ 11.01329116]]\n",
      "Loop 4443 Loss_Train:  [[ 13.19696483]] Loss_Validation:  [[ 11.01331814]]\n",
      "Loop 4444 Loss_Train:  [[ 13.19696232]] Loss_Validation:  [[ 11.0133451]]\n",
      "Loop 4445 Loss_Train:  [[ 13.19695982]] Loss_Validation:  [[ 11.01337203]]\n",
      "Loop 4446 Loss_Train:  [[ 13.19695732]] Loss_Validation:  [[ 11.01339895]]\n",
      "Loop 4447 Loss_Train:  [[ 13.19695482]] Loss_Validation:  [[ 11.01342586]]\n",
      "Loop 4448 Loss_Train:  [[ 13.19695233]] Loss_Validation:  [[ 11.01345274]]\n",
      "Loop 4449 Loss_Train:  [[ 13.19694984]] Loss_Validation:  [[ 11.0134796]]\n",
      "Loop 4450 Loss_Train:  [[ 13.19694735]] Loss_Validation:  [[ 11.01350645]]\n",
      "Loop 4451 Loss_Train:  [[ 13.19694487]] Loss_Validation:  [[ 11.01353327]]\n",
      "Loop 4452 Loss_Train:  [[ 13.19694239]] Loss_Validation:  [[ 11.01356008]]\n",
      "Loop 4453 Loss_Train:  [[ 13.19693992]] Loss_Validation:  [[ 11.01358686]]\n",
      "Loop 4454 Loss_Train:  [[ 13.19693745]] Loss_Validation:  [[ 11.01361363]]\n",
      "Loop 4455 Loss_Train:  [[ 13.19693498]] Loss_Validation:  [[ 11.01364038]]\n",
      "Loop 4456 Loss_Train:  [[ 13.19693251]] Loss_Validation:  [[ 11.01366711]]\n",
      "Loop 4457 Loss_Train:  [[ 13.19693005]] Loss_Validation:  [[ 11.01369383]]\n",
      "Loop 4458 Loss_Train:  [[ 13.1969276]] Loss_Validation:  [[ 11.01372052]]\n",
      "Loop 4459 Loss_Train:  [[ 13.19692514]] Loss_Validation:  [[ 11.01374719]]\n",
      "Loop 4460 Loss_Train:  [[ 13.1969227]] Loss_Validation:  [[ 11.01377385]]\n",
      "Loop 4461 Loss_Train:  [[ 13.19692025]] Loss_Validation:  [[ 11.01380048]]\n",
      "Loop 4462 Loss_Train:  [[ 13.19691781]] Loss_Validation:  [[ 11.0138271]]\n",
      "Loop 4463 Loss_Train:  [[ 13.19691537]] Loss_Validation:  [[ 11.0138537]]\n",
      "Loop 4464 Loss_Train:  [[ 13.19691293]] Loss_Validation:  [[ 11.01388028]]\n",
      "Loop 4465 Loss_Train:  [[ 13.1969105]] Loss_Validation:  [[ 11.01390684]]\n",
      "Loop 4466 Loss_Train:  [[ 13.19690807]] Loss_Validation:  [[ 11.01393339]]\n",
      "Loop 4467 Loss_Train:  [[ 13.19690565]] Loss_Validation:  [[ 11.01395991]]\n",
      "Loop 4468 Loss_Train:  [[ 13.19690323]] Loss_Validation:  [[ 11.01398642]]\n",
      "Loop 4469 Loss_Train:  [[ 13.19690081]] Loss_Validation:  [[ 11.0140129]]\n",
      "Loop 4470 Loss_Train:  [[ 13.1968984]] Loss_Validation:  [[ 11.01403937]]\n",
      "Loop 4471 Loss_Train:  [[ 13.19689599]] Loss_Validation:  [[ 11.01406582]]\n",
      "Loop 4472 Loss_Train:  [[ 13.19689358]] Loss_Validation:  [[ 11.01409225]]\n",
      "Loop 4473 Loss_Train:  [[ 13.19689118]] Loss_Validation:  [[ 11.01411866]]\n",
      "Loop 4474 Loss_Train:  [[ 13.19688878]] Loss_Validation:  [[ 11.01414506]]\n",
      "Loop 4475 Loss_Train:  [[ 13.19688638]] Loss_Validation:  [[ 11.01417143]]\n",
      "Loop 4476 Loss_Train:  [[ 13.19688399]] Loss_Validation:  [[ 11.01419779]]\n",
      "Loop 4477 Loss_Train:  [[ 13.1968816]] Loss_Validation:  [[ 11.01422412]]\n",
      "Loop 4478 Loss_Train:  [[ 13.19687922]] Loss_Validation:  [[ 11.01425044]]\n",
      "Loop 4479 Loss_Train:  [[ 13.19687684]] Loss_Validation:  [[ 11.01427674]]\n",
      "Loop 4480 Loss_Train:  [[ 13.19687446]] Loss_Validation:  [[ 11.01430303]]\n",
      "Loop 4481 Loss_Train:  [[ 13.19687208]] Loss_Validation:  [[ 11.01432929]]\n",
      "Loop 4482 Loss_Train:  [[ 13.19686971]] Loss_Validation:  [[ 11.01435553]]\n",
      "Loop 4483 Loss_Train:  [[ 13.19686734]] Loss_Validation:  [[ 11.01438176]]\n",
      "Loop 4484 Loss_Train:  [[ 13.19686498]] Loss_Validation:  [[ 11.01440797]]\n",
      "Loop 4485 Loss_Train:  [[ 13.19686262]] Loss_Validation:  [[ 11.01443416]]\n",
      "Loop 4486 Loss_Train:  [[ 13.19686026]] Loss_Validation:  [[ 11.01446033]]\n",
      "Loop 4487 Loss_Train:  [[ 13.19685791]] Loss_Validation:  [[ 11.01448648]]\n",
      "Loop 4488 Loss_Train:  [[ 13.19685556]] Loss_Validation:  [[ 11.01451262]]\n",
      "Loop 4489 Loss_Train:  [[ 13.19685321]] Loss_Validation:  [[ 11.01453873]]\n",
      "Loop 4490 Loss_Train:  [[ 13.19685087]] Loss_Validation:  [[ 11.01456483]]\n",
      "Loop 4491 Loss_Train:  [[ 13.19684853]] Loss_Validation:  [[ 11.01459091]]\n",
      "Loop 4492 Loss_Train:  [[ 13.19684619]] Loss_Validation:  [[ 11.01461697]]\n",
      "Loop 4493 Loss_Train:  [[ 13.19684386]] Loss_Validation:  [[ 11.01464301]]\n",
      "Loop 4494 Loss_Train:  [[ 13.19684153]] Loss_Validation:  [[ 11.01466903]]\n",
      "Loop 4495 Loss_Train:  [[ 13.1968392]] Loss_Validation:  [[ 11.01469504]]\n",
      "Loop 4496 Loss_Train:  [[ 13.19683688]] Loss_Validation:  [[ 11.01472103]]\n",
      "Loop 4497 Loss_Train:  [[ 13.19683456]] Loss_Validation:  [[ 11.014747]]\n",
      "Loop 4498 Loss_Train:  [[ 13.19683224]] Loss_Validation:  [[ 11.01477295]]\n",
      "Loop 4499 Loss_Train:  [[ 13.19682993]] Loss_Validation:  [[ 11.01479888]]\n",
      "Loop 4500 Loss_Train:  [[ 13.19682762]] Loss_Validation:  [[ 11.01482479]]\n",
      "Loop 4501 Loss_Train:  [[ 13.19682531]] Loss_Validation:  [[ 11.01485069]]\n",
      "Loop 4502 Loss_Train:  [[ 13.19682301]] Loss_Validation:  [[ 11.01487657]]\n",
      "Loop 4503 Loss_Train:  [[ 13.19682071]] Loss_Validation:  [[ 11.01490243]]\n",
      "Loop 4504 Loss_Train:  [[ 13.19681842]] Loss_Validation:  [[ 11.01492827]]\n",
      "Loop 4505 Loss_Train:  [[ 13.19681612]] Loss_Validation:  [[ 11.01495409]]\n",
      "Loop 4506 Loss_Train:  [[ 13.19681384]] Loss_Validation:  [[ 11.0149799]]\n",
      "Loop 4507 Loss_Train:  [[ 13.19681155]] Loss_Validation:  [[ 11.01500568]]\n",
      "Loop 4508 Loss_Train:  [[ 13.19680927]] Loss_Validation:  [[ 11.01503145]]\n",
      "Loop 4509 Loss_Train:  [[ 13.19680699]] Loss_Validation:  [[ 11.0150572]]\n",
      "Loop 4510 Loss_Train:  [[ 13.19680471]] Loss_Validation:  [[ 11.01508293]]\n",
      "Loop 4511 Loss_Train:  [[ 13.19680244]] Loss_Validation:  [[ 11.01510865]]\n",
      "Loop 4512 Loss_Train:  [[ 13.19680017]] Loss_Validation:  [[ 11.01513434]]\n",
      "Loop 4513 Loss_Train:  [[ 13.19679791]] Loss_Validation:  [[ 11.01516002]]\n",
      "Loop 4514 Loss_Train:  [[ 13.19679564]] Loss_Validation:  [[ 11.01518568]]\n",
      "Loop 4515 Loss_Train:  [[ 13.19679339]] Loss_Validation:  [[ 11.01521132]]\n",
      "Loop 4516 Loss_Train:  [[ 13.19679113]] Loss_Validation:  [[ 11.01523695]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 4517 Loss_Train:  [[ 13.19678888]] Loss_Validation:  [[ 11.01526255]]\n",
      "Loop 4518 Loss_Train:  [[ 13.19678663]] Loss_Validation:  [[ 11.01528814]]\n",
      "Loop 4519 Loss_Train:  [[ 13.19678438]] Loss_Validation:  [[ 11.01531371]]\n",
      "Loop 4520 Loss_Train:  [[ 13.19678214]] Loss_Validation:  [[ 11.01533926]]\n",
      "Loop 4521 Loss_Train:  [[ 13.1967799]] Loss_Validation:  [[ 11.0153648]]\n",
      "Loop 4522 Loss_Train:  [[ 13.19677767]] Loss_Validation:  [[ 11.01539031]]\n",
      "Loop 4523 Loss_Train:  [[ 13.19677543]] Loss_Validation:  [[ 11.01541581]]\n",
      "Loop 4524 Loss_Train:  [[ 13.1967732]] Loss_Validation:  [[ 11.01544129]]\n",
      "Loop 4525 Loss_Train:  [[ 13.19677098]] Loss_Validation:  [[ 11.01546675]]\n",
      "Loop 4526 Loss_Train:  [[ 13.19676876]] Loss_Validation:  [[ 11.0154922]]\n",
      "Loop 4527 Loss_Train:  [[ 13.19676654]] Loss_Validation:  [[ 11.01551762]]\n",
      "Loop 4528 Loss_Train:  [[ 13.19676432]] Loss_Validation:  [[ 11.01554303]]\n",
      "Loop 4529 Loss_Train:  [[ 13.19676211]] Loss_Validation:  [[ 11.01556842]]\n",
      "Loop 4530 Loss_Train:  [[ 13.1967599]] Loss_Validation:  [[ 11.01559379]]\n",
      "Loop 4531 Loss_Train:  [[ 13.19675769]] Loss_Validation:  [[ 11.01561915]]\n",
      "Loop 4532 Loss_Train:  [[ 13.19675549]] Loss_Validation:  [[ 11.01564449]]\n",
      "Loop 4533 Loss_Train:  [[ 13.19675329]] Loss_Validation:  [[ 11.01566981]]\n",
      "Loop 4534 Loss_Train:  [[ 13.19675109]] Loss_Validation:  [[ 11.01569511]]\n",
      "Loop 4535 Loss_Train:  [[ 13.1967489]] Loss_Validation:  [[ 11.01572039]]\n",
      "Loop 4536 Loss_Train:  [[ 13.19674671]] Loss_Validation:  [[ 11.01574566]]\n",
      "Loop 4537 Loss_Train:  [[ 13.19674452]] Loss_Validation:  [[ 11.0157709]]\n",
      "Loop 4538 Loss_Train:  [[ 13.19674234]] Loss_Validation:  [[ 11.01579613]]\n",
      "Loop 4539 Loss_Train:  [[ 13.19674016]] Loss_Validation:  [[ 11.01582135]]\n",
      "Loop 4540 Loss_Train:  [[ 13.19673798]] Loss_Validation:  [[ 11.01584654]]\n",
      "Loop 4541 Loss_Train:  [[ 13.19673581]] Loss_Validation:  [[ 11.01587172]]\n",
      "Loop 4542 Loss_Train:  [[ 13.19673363]] Loss_Validation:  [[ 11.01589688]]\n",
      "Loop 4543 Loss_Train:  [[ 13.19673147]] Loss_Validation:  [[ 11.01592202]]\n",
      "Loop 4544 Loss_Train:  [[ 13.1967293]] Loss_Validation:  [[ 11.01594714]]\n",
      "Loop 4545 Loss_Train:  [[ 13.19672714]] Loss_Validation:  [[ 11.01597225]]\n",
      "Loop 4546 Loss_Train:  [[ 13.19672498]] Loss_Validation:  [[ 11.01599734]]\n",
      "Loop 4547 Loss_Train:  [[ 13.19672283]] Loss_Validation:  [[ 11.01602241]]\n",
      "Loop 4548 Loss_Train:  [[ 13.19672068]] Loss_Validation:  [[ 11.01604746]]\n",
      "Loop 4549 Loss_Train:  [[ 13.19671853]] Loss_Validation:  [[ 11.0160725]]\n",
      "Loop 4550 Loss_Train:  [[ 13.19671638]] Loss_Validation:  [[ 11.01609752]]\n",
      "Loop 4551 Loss_Train:  [[ 13.19671424]] Loss_Validation:  [[ 11.01612252]]\n",
      "Loop 4552 Loss_Train:  [[ 13.1967121]] Loss_Validation:  [[ 11.0161475]]\n",
      "Loop 4553 Loss_Train:  [[ 13.19670996]] Loss_Validation:  [[ 11.01617247]]\n",
      "Loop 4554 Loss_Train:  [[ 13.19670783]] Loss_Validation:  [[ 11.01619742]]\n",
      "Loop 4555 Loss_Train:  [[ 13.1967057]] Loss_Validation:  [[ 11.01622235]]\n",
      "Loop 4556 Loss_Train:  [[ 13.19670357]] Loss_Validation:  [[ 11.01624726]]\n",
      "Loop 4557 Loss_Train:  [[ 13.19670145]] Loss_Validation:  [[ 11.01627216]]\n",
      "Loop 4558 Loss_Train:  [[ 13.19669933]] Loss_Validation:  [[ 11.01629703]]\n",
      "Loop 4559 Loss_Train:  [[ 13.19669721]] Loss_Validation:  [[ 11.01632189]]\n",
      "Loop 4560 Loss_Train:  [[ 13.1966951]] Loss_Validation:  [[ 11.01634674]]\n",
      "Loop 4561 Loss_Train:  [[ 13.19669299]] Loss_Validation:  [[ 11.01637156]]\n",
      "Loop 4562 Loss_Train:  [[ 13.19669088]] Loss_Validation:  [[ 11.01639637]]\n",
      "Loop 4563 Loss_Train:  [[ 13.19668877]] Loss_Validation:  [[ 11.01642116]]\n",
      "Loop 4564 Loss_Train:  [[ 13.19668667]] Loss_Validation:  [[ 11.01644594]]\n",
      "Loop 4565 Loss_Train:  [[ 13.19668457]] Loss_Validation:  [[ 11.01647069]]\n",
      "Loop 4566 Loss_Train:  [[ 13.19668248]] Loss_Validation:  [[ 11.01649543]]\n",
      "Loop 4567 Loss_Train:  [[ 13.19668039]] Loss_Validation:  [[ 11.01652015]]\n",
      "Loop 4568 Loss_Train:  [[ 13.1966783]] Loss_Validation:  [[ 11.01654486]]\n",
      "Loop 4569 Loss_Train:  [[ 13.19667621]] Loss_Validation:  [[ 11.01656954]]\n",
      "Loop 4570 Loss_Train:  [[ 13.19667413]] Loss_Validation:  [[ 11.01659421]]\n",
      "Loop 4571 Loss_Train:  [[ 13.19667205]] Loss_Validation:  [[ 11.01661886]]\n",
      "Loop 4572 Loss_Train:  [[ 13.19666997]] Loss_Validation:  [[ 11.0166435]]\n",
      "Loop 4573 Loss_Train:  [[ 13.19666789]] Loss_Validation:  [[ 11.01666812]]\n",
      "Loop 4574 Loss_Train:  [[ 13.19666582]] Loss_Validation:  [[ 11.01669272]]\n",
      "Loop 4575 Loss_Train:  [[ 13.19666376]] Loss_Validation:  [[ 11.0167173]]\n",
      "Loop 4576 Loss_Train:  [[ 13.19666169]] Loss_Validation:  [[ 11.01674186]]\n",
      "Loop 4577 Loss_Train:  [[ 13.19665963]] Loss_Validation:  [[ 11.01676641]]\n",
      "Loop 4578 Loss_Train:  [[ 13.19665757]] Loss_Validation:  [[ 11.01679094]]\n",
      "Loop 4579 Loss_Train:  [[ 13.19665551]] Loss_Validation:  [[ 11.01681546]]\n",
      "Loop 4580 Loss_Train:  [[ 13.19665346]] Loss_Validation:  [[ 11.01683995]]\n",
      "Loop 4581 Loss_Train:  [[ 13.19665141]] Loss_Validation:  [[ 11.01686443]]\n",
      "Loop 4582 Loss_Train:  [[ 13.19664936]] Loss_Validation:  [[ 11.0168889]]\n",
      "Loop 4583 Loss_Train:  [[ 13.19664732]] Loss_Validation:  [[ 11.01691334]]\n",
      "Loop 4584 Loss_Train:  [[ 13.19664528]] Loss_Validation:  [[ 11.01693777]]\n",
      "Loop 4585 Loss_Train:  [[ 13.19664324]] Loss_Validation:  [[ 11.01696218]]\n",
      "Loop 4586 Loss_Train:  [[ 13.19664121]] Loss_Validation:  [[ 11.01698657]]\n",
      "Loop 4587 Loss_Train:  [[ 13.19663917]] Loss_Validation:  [[ 11.01701095]]\n",
      "Loop 4588 Loss_Train:  [[ 13.19663715]] Loss_Validation:  [[ 11.01703531]]\n",
      "Loop 4589 Loss_Train:  [[ 13.19663512]] Loss_Validation:  [[ 11.01705965]]\n",
      "Loop 4590 Loss_Train:  [[ 13.1966331]] Loss_Validation:  [[ 11.01708398]]\n",
      "Loop 4591 Loss_Train:  [[ 13.19663108]] Loss_Validation:  [[ 11.01710829]]\n",
      "Loop 4592 Loss_Train:  [[ 13.19662906]] Loss_Validation:  [[ 11.01713258]]\n",
      "Loop 4593 Loss_Train:  [[ 13.19662704]] Loss_Validation:  [[ 11.01715685]]\n",
      "Loop 4594 Loss_Train:  [[ 13.19662503]] Loss_Validation:  [[ 11.01718111]]\n",
      "Loop 4595 Loss_Train:  [[ 13.19662303]] Loss_Validation:  [[ 11.01720535]]\n",
      "Loop 4596 Loss_Train:  [[ 13.19662102]] Loss_Validation:  [[ 11.01722957]]\n",
      "Loop 4597 Loss_Train:  [[ 13.19661902]] Loss_Validation:  [[ 11.01725378]]\n",
      "Loop 4598 Loss_Train:  [[ 13.19661702]] Loss_Validation:  [[ 11.01727797]]\n",
      "Loop 4599 Loss_Train:  [[ 13.19661502]] Loss_Validation:  [[ 11.01730214]]\n",
      "Loop 4600 Loss_Train:  [[ 13.19661303]] Loss_Validation:  [[ 11.0173263]]\n",
      "Loop 4601 Loss_Train:  [[ 13.19661104]] Loss_Validation:  [[ 11.01735044]]\n",
      "Loop 4602 Loss_Train:  [[ 13.19660905]] Loss_Validation:  [[ 11.01737456]]\n",
      "Loop 4603 Loss_Train:  [[ 13.19660707]] Loss_Validation:  [[ 11.01739866]]\n",
      "Loop 4604 Loss_Train:  [[ 13.19660508]] Loss_Validation:  [[ 11.01742275]]\n",
      "Loop 4605 Loss_Train:  [[ 13.1966031]] Loss_Validation:  [[ 11.01744682]]\n",
      "Loop 4606 Loss_Train:  [[ 13.19660113]] Loss_Validation:  [[ 11.01747087]]\n",
      "Loop 4607 Loss_Train:  [[ 13.19659916]] Loss_Validation:  [[ 11.01749491]]\n",
      "Loop 4608 Loss_Train:  [[ 13.19659719]] Loss_Validation:  [[ 11.01751893]]\n",
      "Loop 4609 Loss_Train:  [[ 13.19659522]] Loss_Validation:  [[ 11.01754293]]\n",
      "Loop 4610 Loss_Train:  [[ 13.19659325]] Loss_Validation:  [[ 11.01756692]]\n",
      "Loop 4611 Loss_Train:  [[ 13.19659129]] Loss_Validation:  [[ 11.01759089]]\n",
      "Loop 4612 Loss_Train:  [[ 13.19658933]] Loss_Validation:  [[ 11.01761484]]\n",
      "Loop 4613 Loss_Train:  [[ 13.19658738]] Loss_Validation:  [[ 11.01763878]]\n",
      "Loop 4614 Loss_Train:  [[ 13.19658543]] Loss_Validation:  [[ 11.0176627]]\n",
      "Loop 4615 Loss_Train:  [[ 13.19658347]] Loss_Validation:  [[ 11.0176866]]\n",
      "Loop 4616 Loss_Train:  [[ 13.19658153]] Loss_Validation:  [[ 11.01771049]]\n",
      "Loop 4617 Loss_Train:  [[ 13.19657958]] Loss_Validation:  [[ 11.01773436]]\n",
      "Loop 4618 Loss_Train:  [[ 13.19657764]] Loss_Validation:  [[ 11.01775821]]\n",
      "Loop 4619 Loss_Train:  [[ 13.1965757]] Loss_Validation:  [[ 11.01778205]]\n",
      "Loop 4620 Loss_Train:  [[ 13.19657377]] Loss_Validation:  [[ 11.01780587]]\n",
      "Loop 4621 Loss_Train:  [[ 13.19657183]] Loss_Validation:  [[ 11.01782967]]\n",
      "Loop 4622 Loss_Train:  [[ 13.1965699]] Loss_Validation:  [[ 11.01785345]]\n",
      "Loop 4623 Loss_Train:  [[ 13.19656798]] Loss_Validation:  [[ 11.01787722]]\n",
      "Loop 4624 Loss_Train:  [[ 13.19656605]] Loss_Validation:  [[ 11.01790098]]\n",
      "Loop 4625 Loss_Train:  [[ 13.19656413]] Loss_Validation:  [[ 11.01792471]]\n",
      "Loop 4626 Loss_Train:  [[ 13.19656221]] Loss_Validation:  [[ 11.01794843]]\n",
      "Loop 4627 Loss_Train:  [[ 13.1965603]] Loss_Validation:  [[ 11.01797213]]\n",
      "Loop 4628 Loss_Train:  [[ 13.19655838]] Loss_Validation:  [[ 11.01799582]]\n",
      "Loop 4629 Loss_Train:  [[ 13.19655647]] Loss_Validation:  [[ 11.01801949]]\n",
      "Loop 4630 Loss_Train:  [[ 13.19655457]] Loss_Validation:  [[ 11.01804314]]\n",
      "Loop 4631 Loss_Train:  [[ 13.19655266]] Loss_Validation:  [[ 11.01806678]]\n",
      "Loop 4632 Loss_Train:  [[ 13.19655076]] Loss_Validation:  [[ 11.0180904]]\n",
      "Loop 4633 Loss_Train:  [[ 13.19654886]] Loss_Validation:  [[ 11.018114]]\n",
      "Loop 4634 Loss_Train:  [[ 13.19654696]] Loss_Validation:  [[ 11.01813759]]\n",
      "Loop 4635 Loss_Train:  [[ 13.19654507]] Loss_Validation:  [[ 11.01816116]]\n",
      "Loop 4636 Loss_Train:  [[ 13.19654318]] Loss_Validation:  [[ 11.01818471]]\n",
      "Loop 4637 Loss_Train:  [[ 13.19654129]] Loss_Validation:  [[ 11.01820825]]\n",
      "Loop 4638 Loss_Train:  [[ 13.19653941]] Loss_Validation:  [[ 11.01823177]]\n",
      "Loop 4639 Loss_Train:  [[ 13.19653752]] Loss_Validation:  [[ 11.01825527]]\n",
      "Loop 4640 Loss_Train:  [[ 13.19653564]] Loss_Validation:  [[ 11.01827876]]\n",
      "Loop 4641 Loss_Train:  [[ 13.19653377]] Loss_Validation:  [[ 11.01830223]]\n",
      "Loop 4642 Loss_Train:  [[ 13.19653189]] Loss_Validation:  [[ 11.01832569]]\n",
      "Loop 4643 Loss_Train:  [[ 13.19653002]] Loss_Validation:  [[ 11.01834912]]\n",
      "Loop 4644 Loss_Train:  [[ 13.19652815]] Loss_Validation:  [[ 11.01837255]]\n",
      "Loop 4645 Loss_Train:  [[ 13.19652629]] Loss_Validation:  [[ 11.01839595]]\n",
      "Loop 4646 Loss_Train:  [[ 13.19652442]] Loss_Validation:  [[ 11.01841934]]\n",
      "Loop 4647 Loss_Train:  [[ 13.19652256]] Loss_Validation:  [[ 11.01844271]]\n",
      "Loop 4648 Loss_Train:  [[ 13.1965207]] Loss_Validation:  [[ 11.01846607]]\n",
      "Loop 4649 Loss_Train:  [[ 13.19651885]] Loss_Validation:  [[ 11.01848941]]\n",
      "Loop 4650 Loss_Train:  [[ 13.196517]] Loss_Validation:  [[ 11.01851274]]\n",
      "Loop 4651 Loss_Train:  [[ 13.19651515]] Loss_Validation:  [[ 11.01853604]]\n",
      "Loop 4652 Loss_Train:  [[ 13.1965133]] Loss_Validation:  [[ 11.01855933]]\n",
      "Loop 4653 Loss_Train:  [[ 13.19651146]] Loss_Validation:  [[ 11.01858261]]\n",
      "Loop 4654 Loss_Train:  [[ 13.19650962]] Loss_Validation:  [[ 11.01860587]]\n",
      "Loop 4655 Loss_Train:  [[ 13.19650778]] Loss_Validation:  [[ 11.01862911]]\n",
      "Loop 4656 Loss_Train:  [[ 13.19650594]] Loss_Validation:  [[ 11.01865234]]\n",
      "Loop 4657 Loss_Train:  [[ 13.19650411]] Loss_Validation:  [[ 11.01867555]]\n",
      "Loop 4658 Loss_Train:  [[ 13.19650228]] Loss_Validation:  [[ 11.01869874]]\n",
      "Loop 4659 Loss_Train:  [[ 13.19650045]] Loss_Validation:  [[ 11.01872192]]\n",
      "Loop 4660 Loss_Train:  [[ 13.19649862]] Loss_Validation:  [[ 11.01874508]]\n",
      "Loop 4661 Loss_Train:  [[ 13.1964968]] Loss_Validation:  [[ 11.01876822]]\n",
      "Loop 4662 Loss_Train:  [[ 13.19649498]] Loss_Validation:  [[ 11.01879135]]\n",
      "Loop 4663 Loss_Train:  [[ 13.19649316]] Loss_Validation:  [[ 11.01881447]]\n",
      "Loop 4664 Loss_Train:  [[ 13.19649135]] Loss_Validation:  [[ 11.01883756]]\n",
      "Loop 4665 Loss_Train:  [[ 13.19648954]] Loss_Validation:  [[ 11.01886064]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 4666 Loss_Train:  [[ 13.19648773]] Loss_Validation:  [[ 11.01888371]]\n",
      "Loop 4667 Loss_Train:  [[ 13.19648592]] Loss_Validation:  [[ 11.01890676]]\n",
      "Loop 4668 Loss_Train:  [[ 13.19648412]] Loss_Validation:  [[ 11.01892979]]\n",
      "Loop 4669 Loss_Train:  [[ 13.19648232]] Loss_Validation:  [[ 11.0189528]]\n",
      "Loop 4670 Loss_Train:  [[ 13.19648052]] Loss_Validation:  [[ 11.0189758]]\n",
      "Loop 4671 Loss_Train:  [[ 13.19647872]] Loss_Validation:  [[ 11.01899879]]\n",
      "Loop 4672 Loss_Train:  [[ 13.19647693]] Loss_Validation:  [[ 11.01902175]]\n",
      "Loop 4673 Loss_Train:  [[ 13.19647514]] Loss_Validation:  [[ 11.01904471]]\n",
      "Loop 4674 Loss_Train:  [[ 13.19647335]] Loss_Validation:  [[ 11.01906764]]\n",
      "Loop 4675 Loss_Train:  [[ 13.19647156]] Loss_Validation:  [[ 11.01909056]]\n",
      "Loop 4676 Loss_Train:  [[ 13.19646978]] Loss_Validation:  [[ 11.01911347]]\n",
      "Loop 4677 Loss_Train:  [[ 13.196468]] Loss_Validation:  [[ 11.01913635]]\n",
      "Loop 4678 Loss_Train:  [[ 13.19646622]] Loss_Validation:  [[ 11.01915922]]\n",
      "Loop 4679 Loss_Train:  [[ 13.19646445]] Loss_Validation:  [[ 11.01918208]]\n",
      "Loop 4680 Loss_Train:  [[ 13.19646267]] Loss_Validation:  [[ 11.01920492]]\n",
      "Loop 4681 Loss_Train:  [[ 13.1964609]] Loss_Validation:  [[ 11.01922774]]\n",
      "Loop 4682 Loss_Train:  [[ 13.19645914]] Loss_Validation:  [[ 11.01925055]]\n",
      "Loop 4683 Loss_Train:  [[ 13.19645737]] Loss_Validation:  [[ 11.01927334]]\n",
      "Loop 4684 Loss_Train:  [[ 13.19645561]] Loss_Validation:  [[ 11.01929612]]\n",
      "Loop 4685 Loss_Train:  [[ 13.19645385]] Loss_Validation:  [[ 11.01931888]]\n",
      "Loop 4686 Loss_Train:  [[ 13.19645209]] Loss_Validation:  [[ 11.01934162]]\n",
      "Loop 4687 Loss_Train:  [[ 13.19645034]] Loss_Validation:  [[ 11.01936435]]\n",
      "Loop 4688 Loss_Train:  [[ 13.19644859]] Loss_Validation:  [[ 11.01938706]]\n",
      "Loop 4689 Loss_Train:  [[ 13.19644684]] Loss_Validation:  [[ 11.01940976]]\n",
      "Loop 4690 Loss_Train:  [[ 13.19644509]] Loss_Validation:  [[ 11.01943244]]\n",
      "Loop 4691 Loss_Train:  [[ 13.19644335]] Loss_Validation:  [[ 11.0194551]]\n",
      "Loop 4692 Loss_Train:  [[ 13.19644161]] Loss_Validation:  [[ 11.01947775]]\n",
      "Loop 4693 Loss_Train:  [[ 13.19643987]] Loss_Validation:  [[ 11.01950039]]\n",
      "Loop 4694 Loss_Train:  [[ 13.19643813]] Loss_Validation:  [[ 11.019523]]\n",
      "Loop 4695 Loss_Train:  [[ 13.1964364]] Loss_Validation:  [[ 11.0195456]]\n",
      "Loop 4696 Loss_Train:  [[ 13.19643467]] Loss_Validation:  [[ 11.01956819]]\n",
      "Loop 4697 Loss_Train:  [[ 13.19643294]] Loss_Validation:  [[ 11.01959076]]\n",
      "Loop 4698 Loss_Train:  [[ 13.19643121]] Loss_Validation:  [[ 11.01961331]]\n",
      "Loop 4699 Loss_Train:  [[ 13.19642949]] Loss_Validation:  [[ 11.01963585]]\n",
      "Loop 4700 Loss_Train:  [[ 13.19642777]] Loss_Validation:  [[ 11.01965837]]\n",
      "Loop 4701 Loss_Train:  [[ 13.19642605]] Loss_Validation:  [[ 11.01968088]]\n",
      "Loop 4702 Loss_Train:  [[ 13.19642433]] Loss_Validation:  [[ 11.01970337]]\n",
      "Loop 4703 Loss_Train:  [[ 13.19642262]] Loss_Validation:  [[ 11.01972585]]\n",
      "Loop 4704 Loss_Train:  [[ 13.19642091]] Loss_Validation:  [[ 11.01974831]]\n",
      "Loop 4705 Loss_Train:  [[ 13.1964192]] Loss_Validation:  [[ 11.01977075]]\n",
      "Loop 4706 Loss_Train:  [[ 13.19641749]] Loss_Validation:  [[ 11.01979318]]\n",
      "Loop 4707 Loss_Train:  [[ 13.19641579]] Loss_Validation:  [[ 11.01981559]]\n",
      "Loop 4708 Loss_Train:  [[ 13.19641409]] Loss_Validation:  [[ 11.01983799]]\n",
      "Loop 4709 Loss_Train:  [[ 13.19641239]] Loss_Validation:  [[ 11.01986037]]\n",
      "Loop 4710 Loss_Train:  [[ 13.19641069]] Loss_Validation:  [[ 11.01988274]]\n",
      "Loop 4711 Loss_Train:  [[ 13.196409]] Loss_Validation:  [[ 11.01990509]]\n",
      "Loop 4712 Loss_Train:  [[ 13.19640731]] Loss_Validation:  [[ 11.01992742]]\n",
      "Loop 4713 Loss_Train:  [[ 13.19640562]] Loss_Validation:  [[ 11.01994974]]\n",
      "Loop 4714 Loss_Train:  [[ 13.19640393]] Loss_Validation:  [[ 11.01997205]]\n",
      "Loop 4715 Loss_Train:  [[ 13.19640225]] Loss_Validation:  [[ 11.01999433]]\n",
      "Loop 4716 Loss_Train:  [[ 13.19640057]] Loss_Validation:  [[ 11.02001661]]\n",
      "Loop 4717 Loss_Train:  [[ 13.19639889]] Loss_Validation:  [[ 11.02003886]]\n",
      "Loop 4718 Loss_Train:  [[ 13.19639721]] Loss_Validation:  [[ 11.0200611]]\n",
      "Loop 4719 Loss_Train:  [[ 13.19639554]] Loss_Validation:  [[ 11.02008333]]\n",
      "Loop 4720 Loss_Train:  [[ 13.19639387]] Loss_Validation:  [[ 11.02010554]]\n",
      "Loop 4721 Loss_Train:  [[ 13.1963922]] Loss_Validation:  [[ 11.02012773]]\n",
      "Loop 4722 Loss_Train:  [[ 13.19639053]] Loss_Validation:  [[ 11.02014991]]\n",
      "Loop 4723 Loss_Train:  [[ 13.19638887]] Loss_Validation:  [[ 11.02017208]]\n",
      "Loop 4724 Loss_Train:  [[ 13.19638721]] Loss_Validation:  [[ 11.02019423]]\n",
      "Loop 4725 Loss_Train:  [[ 13.19638555]] Loss_Validation:  [[ 11.02021636]]\n",
      "Loop 4726 Loss_Train:  [[ 13.19638389]] Loss_Validation:  [[ 11.02023848]]\n",
      "Loop 4727 Loss_Train:  [[ 13.19638223]] Loss_Validation:  [[ 11.02026058]]\n",
      "Loop 4728 Loss_Train:  [[ 13.19638058]] Loss_Validation:  [[ 11.02028266]]\n",
      "Loop 4729 Loss_Train:  [[ 13.19637893]] Loss_Validation:  [[ 11.02030474]]\n",
      "Loop 4730 Loss_Train:  [[ 13.19637729]] Loss_Validation:  [[ 11.02032679]]\n",
      "Loop 4731 Loss_Train:  [[ 13.19637564]] Loss_Validation:  [[ 11.02034883]]\n",
      "Loop 4732 Loss_Train:  [[ 13.196374]] Loss_Validation:  [[ 11.02037086]]\n",
      "Loop 4733 Loss_Train:  [[ 13.19637236]] Loss_Validation:  [[ 11.02039287]]\n",
      "Loop 4734 Loss_Train:  [[ 13.19637072]] Loss_Validation:  [[ 11.02041486]]\n",
      "Loop 4735 Loss_Train:  [[ 13.19636909]] Loss_Validation:  [[ 11.02043684]]\n",
      "Loop 4736 Loss_Train:  [[ 13.19636745]] Loss_Validation:  [[ 11.0204588]]\n",
      "Loop 4737 Loss_Train:  [[ 13.19636582]] Loss_Validation:  [[ 11.02048075]]\n",
      "Loop 4738 Loss_Train:  [[ 13.1963642]] Loss_Validation:  [[ 11.02050268]]\n",
      "Loop 4739 Loss_Train:  [[ 13.19636257]] Loss_Validation:  [[ 11.0205246]]\n",
      "Loop 4740 Loss_Train:  [[ 13.19636095]] Loss_Validation:  [[ 11.0205465]]\n",
      "Loop 4741 Loss_Train:  [[ 13.19635933]] Loss_Validation:  [[ 11.02056839]]\n",
      "Loop 4742 Loss_Train:  [[ 13.19635771]] Loss_Validation:  [[ 11.02059026]]\n",
      "Loop 4743 Loss_Train:  [[ 13.19635609]] Loss_Validation:  [[ 11.02061212]]\n",
      "Loop 4744 Loss_Train:  [[ 13.19635448]] Loss_Validation:  [[ 11.02063396]]\n",
      "Loop 4745 Loss_Train:  [[ 13.19635287]] Loss_Validation:  [[ 11.02065579]]\n",
      "Loop 4746 Loss_Train:  [[ 13.19635126]] Loss_Validation:  [[ 11.0206776]]\n",
      "Loop 4747 Loss_Train:  [[ 13.19634965]] Loss_Validation:  [[ 11.02069939]]\n",
      "Loop 4748 Loss_Train:  [[ 13.19634805]] Loss_Validation:  [[ 11.02072117]]\n",
      "Loop 4749 Loss_Train:  [[ 13.19634645]] Loss_Validation:  [[ 11.02074294]]\n",
      "Loop 4750 Loss_Train:  [[ 13.19634485]] Loss_Validation:  [[ 11.02076469]]\n",
      "Loop 4751 Loss_Train:  [[ 13.19634325]] Loss_Validation:  [[ 11.02078643]]\n",
      "Loop 4752 Loss_Train:  [[ 13.19634166]] Loss_Validation:  [[ 11.02080815]]\n",
      "Loop 4753 Loss_Train:  [[ 13.19634006]] Loss_Validation:  [[ 11.02082985]]\n",
      "Loop 4754 Loss_Train:  [[ 13.19633847]] Loss_Validation:  [[ 11.02085154]]\n",
      "Loop 4755 Loss_Train:  [[ 13.19633689]] Loss_Validation:  [[ 11.02087321]]\n",
      "Loop 4756 Loss_Train:  [[ 13.1963353]] Loss_Validation:  [[ 11.02089487]]\n",
      "Loop 4757 Loss_Train:  [[ 13.19633372]] Loss_Validation:  [[ 11.02091652]]\n",
      "Loop 4758 Loss_Train:  [[ 13.19633214]] Loss_Validation:  [[ 11.02093815]]\n",
      "Loop 4759 Loss_Train:  [[ 13.19633056]] Loss_Validation:  [[ 11.02095976]]\n",
      "Loop 4760 Loss_Train:  [[ 13.19632898]] Loss_Validation:  [[ 11.02098136]]\n",
      "Loop 4761 Loss_Train:  [[ 13.19632741]] Loss_Validation:  [[ 11.02100294]]\n",
      "Loop 4762 Loss_Train:  [[ 13.19632584]] Loss_Validation:  [[ 11.02102451]]\n",
      "Loop 4763 Loss_Train:  [[ 13.19632427]] Loss_Validation:  [[ 11.02104607]]\n",
      "Loop 4764 Loss_Train:  [[ 13.1963227]] Loss_Validation:  [[ 11.02106761]]\n",
      "Loop 4765 Loss_Train:  [[ 13.19632113]] Loss_Validation:  [[ 11.02108913]]\n",
      "Loop 4766 Loss_Train:  [[ 13.19631957]] Loss_Validation:  [[ 11.02111064]]\n",
      "Loop 4767 Loss_Train:  [[ 13.19631801]] Loss_Validation:  [[ 11.02113213]]\n",
      "Loop 4768 Loss_Train:  [[ 13.19631645]] Loss_Validation:  [[ 11.02115361]]\n",
      "Loop 4769 Loss_Train:  [[ 13.1963149]] Loss_Validation:  [[ 11.02117508]]\n",
      "Loop 4770 Loss_Train:  [[ 13.19631335]] Loss_Validation:  [[ 11.02119653]]\n",
      "Loop 4771 Loss_Train:  [[ 13.19631179]] Loss_Validation:  [[ 11.02121796]]\n",
      "Loop 4772 Loss_Train:  [[ 13.19631025]] Loss_Validation:  [[ 11.02123938]]\n",
      "Loop 4773 Loss_Train:  [[ 13.1963087]] Loss_Validation:  [[ 11.02126078]]\n",
      "Loop 4774 Loss_Train:  [[ 13.19630716]] Loss_Validation:  [[ 11.02128217]]\n",
      "Loop 4775 Loss_Train:  [[ 13.19630561]] Loss_Validation:  [[ 11.02130355]]\n",
      "Loop 4776 Loss_Train:  [[ 13.19630407]] Loss_Validation:  [[ 11.02132491]]\n",
      "Loop 4777 Loss_Train:  [[ 13.19630254]] Loss_Validation:  [[ 11.02134625]]\n",
      "Loop 4778 Loss_Train:  [[ 13.196301]] Loss_Validation:  [[ 11.02136758]]\n",
      "Loop 4779 Loss_Train:  [[ 13.19629947]] Loss_Validation:  [[ 11.0213889]]\n",
      "Loop 4780 Loss_Train:  [[ 13.19629794]] Loss_Validation:  [[ 11.0214102]]\n",
      "Loop 4781 Loss_Train:  [[ 13.19629641]] Loss_Validation:  [[ 11.02143148]]\n",
      "Loop 4782 Loss_Train:  [[ 13.19629488]] Loss_Validation:  [[ 11.02145275]]\n",
      "Loop 4783 Loss_Train:  [[ 13.19629336]] Loss_Validation:  [[ 11.02147401]]\n",
      "Loop 4784 Loss_Train:  [[ 13.19629184]] Loss_Validation:  [[ 11.02149525]]\n",
      "Loop 4785 Loss_Train:  [[ 13.19629032]] Loss_Validation:  [[ 11.02151647]]\n",
      "Loop 4786 Loss_Train:  [[ 13.1962888]] Loss_Validation:  [[ 11.02153769]]\n",
      "Loop 4787 Loss_Train:  [[ 13.19628729]] Loss_Validation:  [[ 11.02155888]]\n",
      "Loop 4788 Loss_Train:  [[ 13.19628577]] Loss_Validation:  [[ 11.02158006]]\n",
      "Loop 4789 Loss_Train:  [[ 13.19628426]] Loss_Validation:  [[ 11.02160123]]\n",
      "Loop 4790 Loss_Train:  [[ 13.19628276]] Loss_Validation:  [[ 11.02162238]]\n",
      "Loop 4791 Loss_Train:  [[ 13.19628125]] Loss_Validation:  [[ 11.02164352]]\n",
      "Loop 4792 Loss_Train:  [[ 13.19627975]] Loss_Validation:  [[ 11.02166464]]\n",
      "Loop 4793 Loss_Train:  [[ 13.19627824]] Loss_Validation:  [[ 11.02168575]]\n",
      "Loop 4794 Loss_Train:  [[ 13.19627674]] Loss_Validation:  [[ 11.02170685]]\n",
      "Loop 4795 Loss_Train:  [[ 13.19627525]] Loss_Validation:  [[ 11.02172792]]\n",
      "Loop 4796 Loss_Train:  [[ 13.19627375]] Loss_Validation:  [[ 11.02174899]]\n",
      "Loop 4797 Loss_Train:  [[ 13.19627226]] Loss_Validation:  [[ 11.02177004]]\n",
      "Loop 4798 Loss_Train:  [[ 13.19627077]] Loss_Validation:  [[ 11.02179107]]\n",
      "Loop 4799 Loss_Train:  [[ 13.19626928]] Loss_Validation:  [[ 11.02181209]]\n",
      "Loop 4800 Loss_Train:  [[ 13.19626779]] Loss_Validation:  [[ 11.0218331]]\n",
      "Loop 4801 Loss_Train:  [[ 13.19626631]] Loss_Validation:  [[ 11.02185409]]\n",
      "Loop 4802 Loss_Train:  [[ 13.19626483]] Loss_Validation:  [[ 11.02187507]]\n",
      "Loop 4803 Loss_Train:  [[ 13.19626335]] Loss_Validation:  [[ 11.02189603]]\n",
      "Loop 4804 Loss_Train:  [[ 13.19626187]] Loss_Validation:  [[ 11.02191697]]\n",
      "Loop 4805 Loss_Train:  [[ 13.19626039]] Loss_Validation:  [[ 11.02193791]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 4806 Loss_Train:  [[ 13.19625892]] Loss_Validation:  [[ 11.02195883]]\n",
      "Loop 4807 Loss_Train:  [[ 13.19625745]] Loss_Validation:  [[ 11.02197973]]\n",
      "Loop 4808 Loss_Train:  [[ 13.19625598]] Loss_Validation:  [[ 11.02200062]]\n",
      "Loop 4809 Loss_Train:  [[ 13.19625451]] Loss_Validation:  [[ 11.02202149]]\n",
      "Loop 4810 Loss_Train:  [[ 13.19625305]] Loss_Validation:  [[ 11.02204235]]\n",
      "Loop 4811 Loss_Train:  [[ 13.19625159]] Loss_Validation:  [[ 11.0220632]]\n",
      "Loop 4812 Loss_Train:  [[ 13.19625013]] Loss_Validation:  [[ 11.02208403]]\n",
      "Loop 4813 Loss_Train:  [[ 13.19624867]] Loss_Validation:  [[ 11.02210484]]\n",
      "Loop 4814 Loss_Train:  [[ 13.19624721]] Loss_Validation:  [[ 11.02212565]]\n",
      "Loop 4815 Loss_Train:  [[ 13.19624576]] Loss_Validation:  [[ 11.02214643]]\n",
      "Loop 4816 Loss_Train:  [[ 13.1962443]] Loss_Validation:  [[ 11.02216721]]\n",
      "Loop 4817 Loss_Train:  [[ 13.19624286]] Loss_Validation:  [[ 11.02218796]]\n",
      "Loop 4818 Loss_Train:  [[ 13.19624141]] Loss_Validation:  [[ 11.02220871]]\n",
      "Loop 4819 Loss_Train:  [[ 13.19623996]] Loss_Validation:  [[ 11.02222944]]\n",
      "Loop 4820 Loss_Train:  [[ 13.19623852]] Loss_Validation:  [[ 11.02225015]]\n",
      "Loop 4821 Loss_Train:  [[ 13.19623708]] Loss_Validation:  [[ 11.02227085]]\n",
      "Loop 4822 Loss_Train:  [[ 13.19623564]] Loss_Validation:  [[ 11.02229154]]\n",
      "Loop 4823 Loss_Train:  [[ 13.1962342]] Loss_Validation:  [[ 11.02231221]]\n",
      "Loop 4824 Loss_Train:  [[ 13.19623277]] Loss_Validation:  [[ 11.02233287]]\n",
      "Loop 4825 Loss_Train:  [[ 13.19623133]] Loss_Validation:  [[ 11.02235351]]\n",
      "Loop 4826 Loss_Train:  [[ 13.1962299]] Loss_Validation:  [[ 11.02237414]]\n",
      "Loop 4827 Loss_Train:  [[ 13.19622847]] Loss_Validation:  [[ 11.02239476]]\n",
      "Loop 4828 Loss_Train:  [[ 13.19622705]] Loss_Validation:  [[ 11.02241536]]\n",
      "Loop 4829 Loss_Train:  [[ 13.19622562]] Loss_Validation:  [[ 11.02243594]]\n",
      "Loop 4830 Loss_Train:  [[ 13.1962242]] Loss_Validation:  [[ 11.02245652]]\n",
      "Loop 4831 Loss_Train:  [[ 13.19622278]] Loss_Validation:  [[ 11.02247707]]\n",
      "Loop 4832 Loss_Train:  [[ 13.19622136]] Loss_Validation:  [[ 11.02249762]]\n",
      "Loop 4833 Loss_Train:  [[ 13.19621994]] Loss_Validation:  [[ 11.02251814]]\n",
      "Loop 4834 Loss_Train:  [[ 13.19621853]] Loss_Validation:  [[ 11.02253866]]\n",
      "Loop 4835 Loss_Train:  [[ 13.19621712]] Loss_Validation:  [[ 11.02255916]]\n",
      "Loop 4836 Loss_Train:  [[ 13.19621571]] Loss_Validation:  [[ 11.02257964]]\n",
      "Loop 4837 Loss_Train:  [[ 13.1962143]] Loss_Validation:  [[ 11.02260012]]\n",
      "Loop 4838 Loss_Train:  [[ 13.1962129]] Loss_Validation:  [[ 11.02262057]]\n",
      "Loop 4839 Loss_Train:  [[ 13.19621149]] Loss_Validation:  [[ 11.02264102]]\n",
      "Loop 4840 Loss_Train:  [[ 13.19621009]] Loss_Validation:  [[ 11.02266145]]\n",
      "Loop 4841 Loss_Train:  [[ 13.19620869]] Loss_Validation:  [[ 11.02268186]]\n",
      "Loop 4842 Loss_Train:  [[ 13.19620729]] Loss_Validation:  [[ 11.02270226]]\n",
      "Loop 4843 Loss_Train:  [[ 13.1962059]] Loss_Validation:  [[ 11.02272265]]\n",
      "Loop 4844 Loss_Train:  [[ 13.1962045]] Loss_Validation:  [[ 11.02274302]]\n",
      "Loop 4845 Loss_Train:  [[ 13.19620311]] Loss_Validation:  [[ 11.02276338]]\n",
      "Loop 4846 Loss_Train:  [[ 13.19620172]] Loss_Validation:  [[ 11.02278372]]\n",
      "Loop 4847 Loss_Train:  [[ 13.19620033]] Loss_Validation:  [[ 11.02280405]]\n",
      "Loop 4848 Loss_Train:  [[ 13.19619895]] Loss_Validation:  [[ 11.02282437]]\n",
      "Loop 4849 Loss_Train:  [[ 13.19619757]] Loss_Validation:  [[ 11.02284467]]\n",
      "Loop 4850 Loss_Train:  [[ 13.19619618]] Loss_Validation:  [[ 11.02286496]]\n",
      "Loop 4851 Loss_Train:  [[ 13.19619481]] Loss_Validation:  [[ 11.02288523]]\n",
      "Loop 4852 Loss_Train:  [[ 13.19619343]] Loss_Validation:  [[ 11.02290549]]\n",
      "Loop 4853 Loss_Train:  [[ 13.19619205]] Loss_Validation:  [[ 11.02292574]]\n",
      "Loop 4854 Loss_Train:  [[ 13.19619068]] Loss_Validation:  [[ 11.02294597]]\n",
      "Loop 4855 Loss_Train:  [[ 13.19618931]] Loss_Validation:  [[ 11.02296618]]\n",
      "Loop 4856 Loss_Train:  [[ 13.19618794]] Loss_Validation:  [[ 11.02298639]]\n",
      "Loop 4857 Loss_Train:  [[ 13.19618657]] Loss_Validation:  [[ 11.02300658]]\n",
      "Loop 4858 Loss_Train:  [[ 13.19618521]] Loss_Validation:  [[ 11.02302675]]\n",
      "Loop 4859 Loss_Train:  [[ 13.19618384]] Loss_Validation:  [[ 11.02304691]]\n",
      "Loop 4860 Loss_Train:  [[ 13.19618248]] Loss_Validation:  [[ 11.02306706]]\n",
      "Loop 4861 Loss_Train:  [[ 13.19618112]] Loss_Validation:  [[ 11.02308719]]\n",
      "Loop 4862 Loss_Train:  [[ 13.19617977]] Loss_Validation:  [[ 11.02310731]]\n",
      "Loop 4863 Loss_Train:  [[ 13.19617841]] Loss_Validation:  [[ 11.02312742]]\n",
      "Loop 4864 Loss_Train:  [[ 13.19617706]] Loss_Validation:  [[ 11.02314751]]\n",
      "Loop 4865 Loss_Train:  [[ 13.19617571]] Loss_Validation:  [[ 11.02316758]]\n",
      "Loop 4866 Loss_Train:  [[ 13.19617436]] Loss_Validation:  [[ 11.02318765]]\n",
      "Loop 4867 Loss_Train:  [[ 13.19617301]] Loss_Validation:  [[ 11.0232077]]\n",
      "Loop 4868 Loss_Train:  [[ 13.19617166]] Loss_Validation:  [[ 11.02322773]]\n",
      "Loop 4869 Loss_Train:  [[ 13.19617032]] Loss_Validation:  [[ 11.02324775]]\n",
      "Loop 4870 Loss_Train:  [[ 13.19616898]] Loss_Validation:  [[ 11.02326776]]\n",
      "Loop 4871 Loss_Train:  [[ 13.19616764]] Loss_Validation:  [[ 11.02328775]]\n",
      "Loop 4872 Loss_Train:  [[ 13.1961663]] Loss_Validation:  [[ 11.02330773]]\n",
      "Loop 4873 Loss_Train:  [[ 13.19616497]] Loss_Validation:  [[ 11.0233277]]\n",
      "Loop 4874 Loss_Train:  [[ 13.19616363]] Loss_Validation:  [[ 11.02334765]]\n",
      "Loop 4875 Loss_Train:  [[ 13.1961623]] Loss_Validation:  [[ 11.02336759]]\n",
      "Loop 4876 Loss_Train:  [[ 13.19616097]] Loss_Validation:  [[ 11.02338751]]\n",
      "Loop 4877 Loss_Train:  [[ 13.19615964]] Loss_Validation:  [[ 11.02340743]]\n",
      "Loop 4878 Loss_Train:  [[ 13.19615832]] Loss_Validation:  [[ 11.02342732]]\n",
      "Loop 4879 Loss_Train:  [[ 13.19615699]] Loss_Validation:  [[ 11.0234472]]\n",
      "Loop 4880 Loss_Train:  [[ 13.19615567]] Loss_Validation:  [[ 11.02346707]]\n",
      "Loop 4881 Loss_Train:  [[ 13.19615435]] Loss_Validation:  [[ 11.02348693]]\n",
      "Loop 4882 Loss_Train:  [[ 13.19615303]] Loss_Validation:  [[ 11.02350677]]\n",
      "Loop 4883 Loss_Train:  [[ 13.19615172]] Loss_Validation:  [[ 11.0235266]]\n",
      "Loop 4884 Loss_Train:  [[ 13.1961504]] Loss_Validation:  [[ 11.02354641]]\n",
      "Loop 4885 Loss_Train:  [[ 13.19614909]] Loss_Validation:  [[ 11.02356621]]\n",
      "Loop 4886 Loss_Train:  [[ 13.19614778]] Loss_Validation:  [[ 11.023586]]\n",
      "Loop 4887 Loss_Train:  [[ 13.19614647]] Loss_Validation:  [[ 11.02360577]]\n",
      "Loop 4888 Loss_Train:  [[ 13.19614516]] Loss_Validation:  [[ 11.02362553]]\n",
      "Loop 4889 Loss_Train:  [[ 13.19614386]] Loss_Validation:  [[ 11.02364528]]\n",
      "Loop 4890 Loss_Train:  [[ 13.19614256]] Loss_Validation:  [[ 11.02366501]]\n",
      "Loop 4891 Loss_Train:  [[ 13.19614126]] Loss_Validation:  [[ 11.02368473]]\n",
      "Loop 4892 Loss_Train:  [[ 13.19613996]] Loss_Validation:  [[ 11.02370443]]\n",
      "Loop 4893 Loss_Train:  [[ 13.19613866]] Loss_Validation:  [[ 11.02372412]]\n",
      "Loop 4894 Loss_Train:  [[ 13.19613737]] Loss_Validation:  [[ 11.0237438]]\n",
      "Loop 4895 Loss_Train:  [[ 13.19613607]] Loss_Validation:  [[ 11.02376346]]\n",
      "Loop 4896 Loss_Train:  [[ 13.19613478]] Loss_Validation:  [[ 11.02378311]]\n",
      "Loop 4897 Loss_Train:  [[ 13.19613349]] Loss_Validation:  [[ 11.02380275]]\n",
      "Loop 4898 Loss_Train:  [[ 13.1961322]] Loss_Validation:  [[ 11.02382237]]\n",
      "Loop 4899 Loss_Train:  [[ 13.19613092]] Loss_Validation:  [[ 11.02384198]]\n",
      "Loop 4900 Loss_Train:  [[ 13.19612963]] Loss_Validation:  [[ 11.02386157]]\n",
      "Loop 4901 Loss_Train:  [[ 13.19612835]] Loss_Validation:  [[ 11.02388115]]\n",
      "Loop 4902 Loss_Train:  [[ 13.19612707]] Loss_Validation:  [[ 11.02390072]]\n",
      "Loop 4903 Loss_Train:  [[ 13.19612579]] Loss_Validation:  [[ 11.02392028]]\n",
      "Loop 4904 Loss_Train:  [[ 13.19612452]] Loss_Validation:  [[ 11.02393982]]\n",
      "Loop 4905 Loss_Train:  [[ 13.19612324]] Loss_Validation:  [[ 11.02395934]]\n",
      "Loop 4906 Loss_Train:  [[ 13.19612197]] Loss_Validation:  [[ 11.02397886]]\n",
      "Loop 4907 Loss_Train:  [[ 13.1961207]] Loss_Validation:  [[ 11.02399836]]\n",
      "Loop 4908 Loss_Train:  [[ 13.19611943]] Loss_Validation:  [[ 11.02401784]]\n",
      "Loop 4909 Loss_Train:  [[ 13.19611816]] Loss_Validation:  [[ 11.02403732]]\n",
      "Loop 4910 Loss_Train:  [[ 13.1961169]] Loss_Validation:  [[ 11.02405678]]\n",
      "Loop 4911 Loss_Train:  [[ 13.19611564]] Loss_Validation:  [[ 11.02407622]]\n",
      "Loop 4912 Loss_Train:  [[ 13.19611437]] Loss_Validation:  [[ 11.02409565]]\n",
      "Loop 4913 Loss_Train:  [[ 13.19611312]] Loss_Validation:  [[ 11.02411507]]\n",
      "Loop 4914 Loss_Train:  [[ 13.19611186]] Loss_Validation:  [[ 11.02413448]]\n",
      "Loop 4915 Loss_Train:  [[ 13.1961106]] Loss_Validation:  [[ 11.02415387]]\n",
      "Loop 4916 Loss_Train:  [[ 13.19610935]] Loss_Validation:  [[ 11.02417325]]\n",
      "Loop 4917 Loss_Train:  [[ 13.1961081]] Loss_Validation:  [[ 11.02419262]]\n",
      "Loop 4918 Loss_Train:  [[ 13.19610684]] Loss_Validation:  [[ 11.02421197]]\n",
      "Loop 4919 Loss_Train:  [[ 13.1961056]] Loss_Validation:  [[ 11.02423131]]\n",
      "Loop 4920 Loss_Train:  [[ 13.19610435]] Loss_Validation:  [[ 11.02425063]]\n",
      "Loop 4921 Loss_Train:  [[ 13.1961031]] Loss_Validation:  [[ 11.02426994]]\n",
      "Loop 4922 Loss_Train:  [[ 13.19610186]] Loss_Validation:  [[ 11.02428924]]\n",
      "Loop 4923 Loss_Train:  [[ 13.19610062]] Loss_Validation:  [[ 11.02430853]]\n",
      "Loop 4924 Loss_Train:  [[ 13.19609938]] Loss_Validation:  [[ 11.0243278]]\n",
      "Loop 4925 Loss_Train:  [[ 13.19609814]] Loss_Validation:  [[ 11.02434706]]\n",
      "Loop 4926 Loss_Train:  [[ 13.19609691]] Loss_Validation:  [[ 11.0243663]]\n",
      "Loop 4927 Loss_Train:  [[ 13.19609567]] Loss_Validation:  [[ 11.02438553]]\n",
      "Loop 4928 Loss_Train:  [[ 13.19609444]] Loss_Validation:  [[ 11.02440475]]\n",
      "Loop 4929 Loss_Train:  [[ 13.19609321]] Loss_Validation:  [[ 11.02442395]]\n",
      "Loop 4930 Loss_Train:  [[ 13.19609198]] Loss_Validation:  [[ 11.02444315]]\n",
      "Loop 4931 Loss_Train:  [[ 13.19609076]] Loss_Validation:  [[ 11.02446232]]\n",
      "Loop 4932 Loss_Train:  [[ 13.19608953]] Loss_Validation:  [[ 11.02448149]]\n",
      "Loop 4933 Loss_Train:  [[ 13.19608831]] Loss_Validation:  [[ 11.02450064]]\n",
      "Loop 4934 Loss_Train:  [[ 13.19608709]] Loss_Validation:  [[ 11.02451978]]\n",
      "Loop 4935 Loss_Train:  [[ 13.19608587]] Loss_Validation:  [[ 11.0245389]]\n",
      "Loop 4936 Loss_Train:  [[ 13.19608465]] Loss_Validation:  [[ 11.02455802]]\n",
      "Loop 4937 Loss_Train:  [[ 13.19608343]] Loss_Validation:  [[ 11.02457711]]\n",
      "Loop 4938 Loss_Train:  [[ 13.19608222]] Loss_Validation:  [[ 11.0245962]]\n",
      "Loop 4939 Loss_Train:  [[ 13.196081]] Loss_Validation:  [[ 11.02461527]]\n",
      "Loop 4940 Loss_Train:  [[ 13.19607979]] Loss_Validation:  [[ 11.02463433]]\n",
      "Loop 4941 Loss_Train:  [[ 13.19607859]] Loss_Validation:  [[ 11.02465338]]\n",
      "Loop 4942 Loss_Train:  [[ 13.19607738]] Loss_Validation:  [[ 11.02467241]]\n",
      "Loop 4943 Loss_Train:  [[ 13.19607617]] Loss_Validation:  [[ 11.02469143]]\n",
      "Loop 4944 Loss_Train:  [[ 13.19607497]] Loss_Validation:  [[ 11.02471043]]\n",
      "Loop 4945 Loss_Train:  [[ 13.19607377]] Loss_Validation:  [[ 11.02472943]]\n",
      "Loop 4946 Loss_Train:  [[ 13.19607257]] Loss_Validation:  [[ 11.02474841]]\n",
      "Loop 4947 Loss_Train:  [[ 13.19607137]] Loss_Validation:  [[ 11.02476737]]\n",
      "Loop 4948 Loss_Train:  [[ 13.19607017]] Loss_Validation:  [[ 11.02478633]]\n",
      "Loop 4949 Loss_Train:  [[ 13.19606898]] Loss_Validation:  [[ 11.02480527]]\n",
      "Loop 4950 Loss_Train:  [[ 13.19606778]] Loss_Validation:  [[ 11.02482419]]\n",
      "Loop 4951 Loss_Train:  [[ 13.19606659]] Loss_Validation:  [[ 11.02484311]]\n",
      "Loop 4952 Loss_Train:  [[ 13.1960654]] Loss_Validation:  [[ 11.02486201]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 4953 Loss_Train:  [[ 13.19606421]] Loss_Validation:  [[ 11.0248809]]\n",
      "Loop 4954 Loss_Train:  [[ 13.19606303]] Loss_Validation:  [[ 11.02489977]]\n",
      "Loop 4955 Loss_Train:  [[ 13.19606184]] Loss_Validation:  [[ 11.02491863]]\n",
      "Loop 4956 Loss_Train:  [[ 13.19606066]] Loss_Validation:  [[ 11.02493748]]\n",
      "Loop 4957 Loss_Train:  [[ 13.19605948]] Loss_Validation:  [[ 11.02495632]]\n",
      "Loop 4958 Loss_Train:  [[ 13.1960583]] Loss_Validation:  [[ 11.02497514]]\n",
      "Loop 4959 Loss_Train:  [[ 13.19605712]] Loss_Validation:  [[ 11.02499395]]\n",
      "Loop 4960 Loss_Train:  [[ 13.19605595]] Loss_Validation:  [[ 11.02501275]]\n",
      "Loop 4961 Loss_Train:  [[ 13.19605477]] Loss_Validation:  [[ 11.02503153]]\n",
      "Loop 4962 Loss_Train:  [[ 13.1960536]] Loss_Validation:  [[ 11.0250503]]\n",
      "Loop 4963 Loss_Train:  [[ 13.19605243]] Loss_Validation:  [[ 11.02506906]]\n",
      "Loop 4964 Loss_Train:  [[ 13.19605126]] Loss_Validation:  [[ 11.0250878]]\n",
      "Loop 4965 Loss_Train:  [[ 13.19605009]] Loss_Validation:  [[ 11.02510653]]\n",
      "Loop 4966 Loss_Train:  [[ 13.19604893]] Loss_Validation:  [[ 11.02512525]]\n",
      "Loop 4967 Loss_Train:  [[ 13.19604776]] Loss_Validation:  [[ 11.02514396]]\n",
      "Loop 4968 Loss_Train:  [[ 13.1960466]] Loss_Validation:  [[ 11.02516265]]\n",
      "Loop 4969 Loss_Train:  [[ 13.19604544]] Loss_Validation:  [[ 11.02518133]]\n",
      "Loop 4970 Loss_Train:  [[ 13.19604428]] Loss_Validation:  [[ 11.0252]]\n",
      "Loop 4971 Loss_Train:  [[ 13.19604313]] Loss_Validation:  [[ 11.02521865]]\n",
      "Loop 4972 Loss_Train:  [[ 13.19604197]] Loss_Validation:  [[ 11.02523729]]\n",
      "Loop 4973 Loss_Train:  [[ 13.19604082]] Loss_Validation:  [[ 11.02525592]]\n",
      "Loop 4974 Loss_Train:  [[ 13.19603966]] Loss_Validation:  [[ 11.02527453]]\n",
      "Loop 4975 Loss_Train:  [[ 13.19603851]] Loss_Validation:  [[ 11.02529314]]\n",
      "Loop 4976 Loss_Train:  [[ 13.19603737]] Loss_Validation:  [[ 11.02531172]]\n",
      "Loop 4977 Loss_Train:  [[ 13.19603622]] Loss_Validation:  [[ 11.0253303]]\n",
      "Loop 4978 Loss_Train:  [[ 13.19603507]] Loss_Validation:  [[ 11.02534886]]\n",
      "Loop 4979 Loss_Train:  [[ 13.19603393]] Loss_Validation:  [[ 11.02536742]]\n",
      "Loop 4980 Loss_Train:  [[ 13.19603279]] Loss_Validation:  [[ 11.02538595]]\n",
      "Loop 4981 Loss_Train:  [[ 13.19603165]] Loss_Validation:  [[ 11.02540448]]\n",
      "Loop 4982 Loss_Train:  [[ 13.19603051]] Loss_Validation:  [[ 11.02542299]]\n",
      "Loop 4983 Loss_Train:  [[ 13.19602937]] Loss_Validation:  [[ 11.02544149]]\n",
      "Loop 4984 Loss_Train:  [[ 13.19602824]] Loss_Validation:  [[ 11.02545998]]\n",
      "Loop 4985 Loss_Train:  [[ 13.1960271]] Loss_Validation:  [[ 11.02547845]]\n",
      "Loop 4986 Loss_Train:  [[ 13.19602597]] Loss_Validation:  [[ 11.02549691]]\n",
      "Loop 4987 Loss_Train:  [[ 13.19602484]] Loss_Validation:  [[ 11.02551536]]\n",
      "Loop 4988 Loss_Train:  [[ 13.19602371]] Loss_Validation:  [[ 11.02553379]]\n",
      "Loop 4989 Loss_Train:  [[ 13.19602259]] Loss_Validation:  [[ 11.02555222]]\n",
      "Loop 4990 Loss_Train:  [[ 13.19602146]] Loss_Validation:  [[ 11.02557063]]\n",
      "Loop 4991 Loss_Train:  [[ 13.19602034]] Loss_Validation:  [[ 11.02558902]]\n",
      "Loop 4992 Loss_Train:  [[ 13.19601921]] Loss_Validation:  [[ 11.02560741]]\n",
      "Loop 4993 Loss_Train:  [[ 13.19601809]] Loss_Validation:  [[ 11.02562578]]\n",
      "Loop 4994 Loss_Train:  [[ 13.19601697]] Loss_Validation:  [[ 11.02564414]]\n",
      "Loop 4995 Loss_Train:  [[ 13.19601586]] Loss_Validation:  [[ 11.02566249]]\n",
      "Loop 4996 Loss_Train:  [[ 13.19601474]] Loss_Validation:  [[ 11.02568082]]\n",
      "Loop 4997 Loss_Train:  [[ 13.19601363]] Loss_Validation:  [[ 11.02569914]]\n",
      "Loop 4998 Loss_Train:  [[ 13.19601252]] Loss_Validation:  [[ 11.02571745]]\n",
      "Loop 4999 Loss_Train:  [[ 13.19601141]] Loss_Validation:  [[ 11.02573574]]\n",
      "Loop 5000 Loss_Train:  [[ 13.1960103]] Loss_Validation:  [[ 11.02575403]]\n",
      "Loop 5001 Loss_Train:  [[ 13.19600919]] Loss_Validation:  [[ 11.0257723]]\n",
      "Loop 5002 Loss_Train:  [[ 13.19600808]] Loss_Validation:  [[ 11.02579055]]\n",
      "Loop 5003 Loss_Train:  [[ 13.19600698]] Loss_Validation:  [[ 11.0258088]]\n",
      "Loop 5004 Loss_Train:  [[ 13.19600588]] Loss_Validation:  [[ 11.02582703]]\n",
      "Loop 5005 Loss_Train:  [[ 13.19600478]] Loss_Validation:  [[ 11.02584525]]\n",
      "Loop 5006 Loss_Train:  [[ 13.19600368]] Loss_Validation:  [[ 11.02586346]]\n",
      "Loop 5007 Loss_Train:  [[ 13.19600258]] Loss_Validation:  [[ 11.02588165]]\n",
      "Loop 5008 Loss_Train:  [[ 13.19600148]] Loss_Validation:  [[ 11.02589983]]\n",
      "Loop 5009 Loss_Train:  [[ 13.19600039]] Loss_Validation:  [[ 11.025918]]\n",
      "Loop 5010 Loss_Train:  [[ 13.1959993]] Loss_Validation:  [[ 11.02593616]]\n",
      "Loop 5011 Loss_Train:  [[ 13.1959982]] Loss_Validation:  [[ 11.02595431]]\n",
      "Loop 5012 Loss_Train:  [[ 13.19599711]] Loss_Validation:  [[ 11.02597244]]\n",
      "Loop 5013 Loss_Train:  [[ 13.19599603]] Loss_Validation:  [[ 11.02599056]]\n",
      "Loop 5014 Loss_Train:  [[ 13.19599494]] Loss_Validation:  [[ 11.02600866]]\n",
      "Loop 5015 Loss_Train:  [[ 13.19599385]] Loss_Validation:  [[ 11.02602676]]\n",
      "Loop 5016 Loss_Train:  [[ 13.19599277]] Loss_Validation:  [[ 11.02604484]]\n",
      "Loop 5017 Loss_Train:  [[ 13.19599169]] Loss_Validation:  [[ 11.02606291]]\n",
      "Loop 5018 Loss_Train:  [[ 13.19599061]] Loss_Validation:  [[ 11.02608096]]\n",
      "Loop 5019 Loss_Train:  [[ 13.19598953]] Loss_Validation:  [[ 11.02609901]]\n",
      "Loop 5020 Loss_Train:  [[ 13.19598845]] Loss_Validation:  [[ 11.02611704]]\n",
      "Loop 5021 Loss_Train:  [[ 13.19598738]] Loss_Validation:  [[ 11.02613506]]\n",
      "Loop 5022 Loss_Train:  [[ 13.1959863]] Loss_Validation:  [[ 11.02615306]]\n",
      "Loop 5023 Loss_Train:  [[ 13.19598523]] Loss_Validation:  [[ 11.02617106]]\n",
      "Loop 5024 Loss_Train:  [[ 13.19598416]] Loss_Validation:  [[ 11.02618904]]\n",
      "Loop 5025 Loss_Train:  [[ 13.19598309]] Loss_Validation:  [[ 11.02620701]]\n",
      "Loop 5026 Loss_Train:  [[ 13.19598202]] Loss_Validation:  [[ 11.02622497]]\n",
      "Loop 5027 Loss_Train:  [[ 13.19598096]] Loss_Validation:  [[ 11.02624291]]\n",
      "Loop 5028 Loss_Train:  [[ 13.19597989]] Loss_Validation:  [[ 11.02626084]]\n",
      "Loop 5029 Loss_Train:  [[ 13.19597883]] Loss_Validation:  [[ 11.02627876]]\n",
      "Loop 5030 Loss_Train:  [[ 13.19597777]] Loss_Validation:  [[ 11.02629667]]\n",
      "Loop 5031 Loss_Train:  [[ 13.19597671]] Loss_Validation:  [[ 11.02631457]]\n",
      "Loop 5032 Loss_Train:  [[ 13.19597565]] Loss_Validation:  [[ 11.02633245]]\n",
      "Loop 5033 Loss_Train:  [[ 13.19597459]] Loss_Validation:  [[ 11.02635032]]\n",
      "Loop 5034 Loss_Train:  [[ 13.19597354]] Loss_Validation:  [[ 11.02636818]]\n",
      "Loop 5035 Loss_Train:  [[ 13.19597249]] Loss_Validation:  [[ 11.02638602]]\n",
      "Loop 5036 Loss_Train:  [[ 13.19597143]] Loss_Validation:  [[ 11.02640385]]\n",
      "Loop 5037 Loss_Train:  [[ 13.19597038]] Loss_Validation:  [[ 11.02642167]]\n",
      "Loop 5038 Loss_Train:  [[ 13.19596933]] Loss_Validation:  [[ 11.02643948]]\n",
      "Loop 5039 Loss_Train:  [[ 13.19596829]] Loss_Validation:  [[ 11.02645728]]\n",
      "Loop 5040 Loss_Train:  [[ 13.19596724]] Loss_Validation:  [[ 11.02647506]]\n",
      "Loop 5041 Loss_Train:  [[ 13.1959662]] Loss_Validation:  [[ 11.02649283]]\n",
      "Loop 5042 Loss_Train:  [[ 13.19596515]] Loss_Validation:  [[ 11.02651059]]\n",
      "Loop 5043 Loss_Train:  [[ 13.19596411]] Loss_Validation:  [[ 11.02652834]]\n",
      "Loop 5044 Loss_Train:  [[ 13.19596307]] Loss_Validation:  [[ 11.02654608]]\n",
      "Loop 5045 Loss_Train:  [[ 13.19596203]] Loss_Validation:  [[ 11.0265638]]\n",
      "Loop 5046 Loss_Train:  [[ 13.195961]] Loss_Validation:  [[ 11.02658151]]\n",
      "Loop 5047 Loss_Train:  [[ 13.19595996]] Loss_Validation:  [[ 11.02659921]]\n",
      "Loop 5048 Loss_Train:  [[ 13.19595893]] Loss_Validation:  [[ 11.02661689]]\n",
      "Loop 5049 Loss_Train:  [[ 13.19595789]] Loss_Validation:  [[ 11.02663456]]\n",
      "Loop 5050 Loss_Train:  [[ 13.19595686]] Loss_Validation:  [[ 11.02665223]]\n",
      "Loop 5051 Loss_Train:  [[ 13.19595583]] Loss_Validation:  [[ 11.02666988]]\n",
      "Loop 5052 Loss_Train:  [[ 13.19595481]] Loss_Validation:  [[ 11.02668751]]\n",
      "Loop 5053 Loss_Train:  [[ 13.19595378]] Loss_Validation:  [[ 11.02670514]]\n",
      "Loop 5054 Loss_Train:  [[ 13.19595276]] Loss_Validation:  [[ 11.02672275]]\n",
      "Loop 5055 Loss_Train:  [[ 13.19595173]] Loss_Validation:  [[ 11.02674035]]\n",
      "Loop 5056 Loss_Train:  [[ 13.19595071]] Loss_Validation:  [[ 11.02675794]]\n",
      "Loop 5057 Loss_Train:  [[ 13.19594969]] Loss_Validation:  [[ 11.02677551]]\n",
      "Loop 5058 Loss_Train:  [[ 13.19594867]] Loss_Validation:  [[ 11.02679308]]\n",
      "Loop 5059 Loss_Train:  [[ 13.19594765]] Loss_Validation:  [[ 11.02681063]]\n",
      "Loop 5060 Loss_Train:  [[ 13.19594664]] Loss_Validation:  [[ 11.02682817]]\n",
      "Loop 5061 Loss_Train:  [[ 13.19594562]] Loss_Validation:  [[ 11.0268457]]\n",
      "Loop 5062 Loss_Train:  [[ 13.19594461]] Loss_Validation:  [[ 11.02686321]]\n",
      "Loop 5063 Loss_Train:  [[ 13.1959436]] Loss_Validation:  [[ 11.02688071]]\n",
      "Loop 5064 Loss_Train:  [[ 13.19594259]] Loss_Validation:  [[ 11.02689821]]\n",
      "Loop 5065 Loss_Train:  [[ 13.19594158]] Loss_Validation:  [[ 11.02691569]]\n",
      "Loop 5066 Loss_Train:  [[ 13.19594057]] Loss_Validation:  [[ 11.02693315]]\n",
      "Loop 5067 Loss_Train:  [[ 13.19593957]] Loss_Validation:  [[ 11.02695061]]\n",
      "Loop 5068 Loss_Train:  [[ 13.19593856]] Loss_Validation:  [[ 11.02696805]]\n",
      "Loop 5069 Loss_Train:  [[ 13.19593756]] Loss_Validation:  [[ 11.02698548]]\n",
      "Loop 5070 Loss_Train:  [[ 13.19593656]] Loss_Validation:  [[ 11.0270029]]\n",
      "Loop 5071 Loss_Train:  [[ 13.19593556]] Loss_Validation:  [[ 11.02702031]]\n",
      "Loop 5072 Loss_Train:  [[ 13.19593456]] Loss_Validation:  [[ 11.0270377]]\n",
      "Loop 5073 Loss_Train:  [[ 13.19593357]] Loss_Validation:  [[ 11.02705508]]\n",
      "Loop 5074 Loss_Train:  [[ 13.19593257]] Loss_Validation:  [[ 11.02707245]]\n",
      "Loop 5075 Loss_Train:  [[ 13.19593158]] Loss_Validation:  [[ 11.02708981]]\n",
      "Loop 5076 Loss_Train:  [[ 13.19593059]] Loss_Validation:  [[ 11.02710716]]\n",
      "Loop 5077 Loss_Train:  [[ 13.19592959]] Loss_Validation:  [[ 11.02712449]]\n",
      "Loop 5078 Loss_Train:  [[ 13.1959286]] Loss_Validation:  [[ 11.02714182]]\n",
      "Loop 5079 Loss_Train:  [[ 13.19592762]] Loss_Validation:  [[ 11.02715913]]\n",
      "Loop 5080 Loss_Train:  [[ 13.19592663]] Loss_Validation:  [[ 11.02717643]]\n",
      "Loop 5081 Loss_Train:  [[ 13.19592564]] Loss_Validation:  [[ 11.02719371]]\n",
      "Loop 5082 Loss_Train:  [[ 13.19592466]] Loss_Validation:  [[ 11.02721099]]\n",
      "Loop 5083 Loss_Train:  [[ 13.19592368]] Loss_Validation:  [[ 11.02722825]]\n",
      "Loop 5084 Loss_Train:  [[ 13.1959227]] Loss_Validation:  [[ 11.0272455]]\n",
      "Loop 5085 Loss_Train:  [[ 13.19592172]] Loss_Validation:  [[ 11.02726274]]\n",
      "Loop 5086 Loss_Train:  [[ 13.19592074]] Loss_Validation:  [[ 11.02727997]]\n",
      "Loop 5087 Loss_Train:  [[ 13.19591976]] Loss_Validation:  [[ 11.02729718]]\n",
      "Loop 5088 Loss_Train:  [[ 13.19591879]] Loss_Validation:  [[ 11.02731439]]\n",
      "Loop 5089 Loss_Train:  [[ 13.19591782]] Loss_Validation:  [[ 11.02733158]]\n",
      "Loop 5090 Loss_Train:  [[ 13.19591684]] Loss_Validation:  [[ 11.02734876]]\n",
      "Loop 5091 Loss_Train:  [[ 13.19591587]] Loss_Validation:  [[ 11.02736593]]\n",
      "Loop 5092 Loss_Train:  [[ 13.1959149]] Loss_Validation:  [[ 11.02738308]]\n",
      "Loop 5093 Loss_Train:  [[ 13.19591393]] Loss_Validation:  [[ 11.02740023]]\n",
      "Loop 5094 Loss_Train:  [[ 13.19591297]] Loss_Validation:  [[ 11.02741736]]\n",
      "Loop 5095 Loss_Train:  [[ 13.195912]] Loss_Validation:  [[ 11.02743448]]\n",
      "Loop 5096 Loss_Train:  [[ 13.19591104]] Loss_Validation:  [[ 11.02745159]]\n",
      "Loop 5097 Loss_Train:  [[ 13.19591008]] Loss_Validation:  [[ 11.02746868]]\n",
      "Loop 5098 Loss_Train:  [[ 13.19590912]] Loss_Validation:  [[ 11.02748577]]\n",
      "Loop 5099 Loss_Train:  [[ 13.19590816]] Loss_Validation:  [[ 11.02750284]]\n",
      "Loop 5100 Loss_Train:  [[ 13.1959072]] Loss_Validation:  [[ 11.0275199]]\n",
      "Loop 5101 Loss_Train:  [[ 13.19590624]] Loss_Validation:  [[ 11.02753695]]\n",
      "Loop 5102 Loss_Train:  [[ 13.19590529]] Loss_Validation:  [[ 11.02755399]]\n",
      "Loop 5103 Loss_Train:  [[ 13.19590433]] Loss_Validation:  [[ 11.02757102]]\n",
      "Loop 5104 Loss_Train:  [[ 13.19590338]] Loss_Validation:  [[ 11.02758803]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 5105 Loss_Train:  [[ 13.19590243]] Loss_Validation:  [[ 11.02760503]]\n",
      "Loop 5106 Loss_Train:  [[ 13.19590148]] Loss_Validation:  [[ 11.02762203]]\n",
      "Loop 5107 Loss_Train:  [[ 13.19590053]] Loss_Validation:  [[ 11.027639]]\n",
      "Loop 5108 Loss_Train:  [[ 13.19589958]] Loss_Validation:  [[ 11.02765597]]\n",
      "Loop 5109 Loss_Train:  [[ 13.19589864]] Loss_Validation:  [[ 11.02767293]]\n",
      "Loop 5110 Loss_Train:  [[ 13.19589769]] Loss_Validation:  [[ 11.02768987]]\n",
      "Loop 5111 Loss_Train:  [[ 13.19589675]] Loss_Validation:  [[ 11.0277068]]\n",
      "Loop 5112 Loss_Train:  [[ 13.19589581]] Loss_Validation:  [[ 11.02772373]]\n",
      "Loop 5113 Loss_Train:  [[ 13.19589487]] Loss_Validation:  [[ 11.02774063]]\n",
      "Loop 5114 Loss_Train:  [[ 13.19589393]] Loss_Validation:  [[ 11.02775753]]\n",
      "Loop 5115 Loss_Train:  [[ 13.19589299]] Loss_Validation:  [[ 11.02777442]]\n",
      "Loop 5116 Loss_Train:  [[ 13.19589206]] Loss_Validation:  [[ 11.02779129]]\n",
      "Loop 5117 Loss_Train:  [[ 13.19589112]] Loss_Validation:  [[ 11.02780815]]\n",
      "Loop 5118 Loss_Train:  [[ 13.19589019]] Loss_Validation:  [[ 11.027825]]\n",
      "Loop 5119 Loss_Train:  [[ 13.19588926]] Loss_Validation:  [[ 11.02784184]]\n",
      "Loop 5120 Loss_Train:  [[ 13.19588833]] Loss_Validation:  [[ 11.02785867]]\n",
      "Loop 5121 Loss_Train:  [[ 13.1958874]] Loss_Validation:  [[ 11.02787549]]\n",
      "Loop 5122 Loss_Train:  [[ 13.19588647]] Loss_Validation:  [[ 11.02789229]]\n",
      "Loop 5123 Loss_Train:  [[ 13.19588554]] Loss_Validation:  [[ 11.02790908]]\n",
      "Loop 5124 Loss_Train:  [[ 13.19588462]] Loss_Validation:  [[ 11.02792586]]\n",
      "Loop 5125 Loss_Train:  [[ 13.19588369]] Loss_Validation:  [[ 11.02794263]]\n",
      "Loop 5126 Loss_Train:  [[ 13.19588277]] Loss_Validation:  [[ 11.02795939]]\n",
      "Loop 5127 Loss_Train:  [[ 13.19588185]] Loss_Validation:  [[ 11.02797614]]\n",
      "Loop 5128 Loss_Train:  [[ 13.19588093]] Loss_Validation:  [[ 11.02799287]]\n",
      "Loop 5129 Loss_Train:  [[ 13.19588001]] Loss_Validation:  [[ 11.0280096]]\n",
      "Loop 5130 Loss_Train:  [[ 13.19587909]] Loss_Validation:  [[ 11.02802631]]\n",
      "Loop 5131 Loss_Train:  [[ 13.19587818]] Loss_Validation:  [[ 11.02804301]]\n",
      "Loop 5132 Loss_Train:  [[ 13.19587726]] Loss_Validation:  [[ 11.0280597]]\n",
      "Loop 5133 Loss_Train:  [[ 13.19587635]] Loss_Validation:  [[ 11.02807637]]\n",
      "Loop 5134 Loss_Train:  [[ 13.19587544]] Loss_Validation:  [[ 11.02809304]]\n",
      "Loop 5135 Loss_Train:  [[ 13.19587453]] Loss_Validation:  [[ 11.02810969]]\n",
      "Loop 5136 Loss_Train:  [[ 13.19587362]] Loss_Validation:  [[ 11.02812634]]\n",
      "Loop 5137 Loss_Train:  [[ 13.19587271]] Loss_Validation:  [[ 11.02814297]]\n",
      "Loop 5138 Loss_Train:  [[ 13.19587181]] Loss_Validation:  [[ 11.02815959]]\n",
      "Loop 5139 Loss_Train:  [[ 13.1958709]] Loss_Validation:  [[ 11.02817619]]\n",
      "Loop 5140 Loss_Train:  [[ 13.19587]] Loss_Validation:  [[ 11.02819279]]\n",
      "Loop 5141 Loss_Train:  [[ 13.19586909]] Loss_Validation:  [[ 11.02820938]]\n",
      "Loop 5142 Loss_Train:  [[ 13.19586819]] Loss_Validation:  [[ 11.02822595]]\n",
      "Loop 5143 Loss_Train:  [[ 13.19586729]] Loss_Validation:  [[ 11.02824251]]\n",
      "Loop 5144 Loss_Train:  [[ 13.1958664]] Loss_Validation:  [[ 11.02825906]]\n",
      "Loop 5145 Loss_Train:  [[ 13.1958655]] Loss_Validation:  [[ 11.0282756]]\n",
      "Loop 5146 Loss_Train:  [[ 13.1958646]] Loss_Validation:  [[ 11.02829213]]\n",
      "Loop 5147 Loss_Train:  [[ 13.19586371]] Loss_Validation:  [[ 11.02830865]]\n",
      "Loop 5148 Loss_Train:  [[ 13.19586281]] Loss_Validation:  [[ 11.02832515]]\n",
      "Loop 5149 Loss_Train:  [[ 13.19586192]] Loss_Validation:  [[ 11.02834165]]\n",
      "Loop 5150 Loss_Train:  [[ 13.19586103]] Loss_Validation:  [[ 11.02835813]]\n",
      "Loop 5151 Loss_Train:  [[ 13.19586014]] Loss_Validation:  [[ 11.0283746]]\n",
      "Loop 5152 Loss_Train:  [[ 13.19585925]] Loss_Validation:  [[ 11.02839106]]\n",
      "Loop 5153 Loss_Train:  [[ 13.19585837]] Loss_Validation:  [[ 11.02840751]]\n",
      "Loop 5154 Loss_Train:  [[ 13.19585748]] Loss_Validation:  [[ 11.02842395]]\n",
      "Loop 5155 Loss_Train:  [[ 13.1958566]] Loss_Validation:  [[ 11.02844037]]\n",
      "Loop 5156 Loss_Train:  [[ 13.19585572]] Loss_Validation:  [[ 11.02845679]]\n",
      "Loop 5157 Loss_Train:  [[ 13.19585483]] Loss_Validation:  [[ 11.02847319]]\n",
      "Loop 5158 Loss_Train:  [[ 13.19585395]] Loss_Validation:  [[ 11.02848958]]\n",
      "Loop 5159 Loss_Train:  [[ 13.19585307]] Loss_Validation:  [[ 11.02850596]]\n",
      "Loop 5160 Loss_Train:  [[ 13.1958522]] Loss_Validation:  [[ 11.02852233]]\n",
      "Loop 5161 Loss_Train:  [[ 13.19585132]] Loss_Validation:  [[ 11.02853869]]\n",
      "Loop 5162 Loss_Train:  [[ 13.19585044]] Loss_Validation:  [[ 11.02855504]]\n",
      "Loop 5163 Loss_Train:  [[ 13.19584957]] Loss_Validation:  [[ 11.02857137]]\n",
      "Loop 5164 Loss_Train:  [[ 13.1958487]] Loss_Validation:  [[ 11.0285877]]\n",
      "Loop 5165 Loss_Train:  [[ 13.19584783]] Loss_Validation:  [[ 11.02860401]]\n",
      "Loop 5166 Loss_Train:  [[ 13.19584696]] Loss_Validation:  [[ 11.02862031]]\n",
      "Loop 5167 Loss_Train:  [[ 13.19584609]] Loss_Validation:  [[ 11.0286366]]\n",
      "Loop 5168 Loss_Train:  [[ 13.19584522]] Loss_Validation:  [[ 11.02865288]]\n",
      "Loop 5169 Loss_Train:  [[ 13.19584435]] Loss_Validation:  [[ 11.02866915]]\n",
      "Loop 5170 Loss_Train:  [[ 13.19584349]] Loss_Validation:  [[ 11.0286854]]\n",
      "Loop 5171 Loss_Train:  [[ 13.19584263]] Loss_Validation:  [[ 11.02870165]]\n",
      "Loop 5172 Loss_Train:  [[ 13.19584176]] Loss_Validation:  [[ 11.02871788]]\n",
      "Loop 5173 Loss_Train:  [[ 13.1958409]] Loss_Validation:  [[ 11.02873411]]\n",
      "Loop 5174 Loss_Train:  [[ 13.19584004]] Loss_Validation:  [[ 11.02875032]]\n",
      "Loop 5175 Loss_Train:  [[ 13.19583918]] Loss_Validation:  [[ 11.02876652]]\n",
      "Loop 5176 Loss_Train:  [[ 13.19583833]] Loss_Validation:  [[ 11.02878271]]\n",
      "Loop 5177 Loss_Train:  [[ 13.19583747]] Loss_Validation:  [[ 11.02879889]]\n",
      "Loop 5178 Loss_Train:  [[ 13.19583661]] Loss_Validation:  [[ 11.02881506]]\n",
      "Loop 5179 Loss_Train:  [[ 13.19583576]] Loss_Validation:  [[ 11.02883121]]\n",
      "Loop 5180 Loss_Train:  [[ 13.19583491]] Loss_Validation:  [[ 11.02884736]]\n",
      "Loop 5181 Loss_Train:  [[ 13.19583406]] Loss_Validation:  [[ 11.02886349]]\n",
      "Loop 5182 Loss_Train:  [[ 13.19583321]] Loss_Validation:  [[ 11.02887961]]\n",
      "Loop 5183 Loss_Train:  [[ 13.19583236]] Loss_Validation:  [[ 11.02889572]]\n",
      "Loop 5184 Loss_Train:  [[ 13.19583151]] Loss_Validation:  [[ 11.02891182]]\n",
      "Loop 5185 Loss_Train:  [[ 13.19583066]] Loss_Validation:  [[ 11.02892791]]\n",
      "Loop 5186 Loss_Train:  [[ 13.19582982]] Loss_Validation:  [[ 11.02894399]]\n",
      "Loop 5187 Loss_Train:  [[ 13.19582898]] Loss_Validation:  [[ 11.02896006]]\n",
      "Loop 5188 Loss_Train:  [[ 13.19582813]] Loss_Validation:  [[ 11.02897612]]\n",
      "Loop 5189 Loss_Train:  [[ 13.19582729]] Loss_Validation:  [[ 11.02899216]]\n",
      "Loop 5190 Loss_Train:  [[ 13.19582645]] Loss_Validation:  [[ 11.0290082]]\n",
      "Loop 5191 Loss_Train:  [[ 13.19582561]] Loss_Validation:  [[ 11.02902422]]\n",
      "Loop 5192 Loss_Train:  [[ 13.19582477]] Loss_Validation:  [[ 11.02904023]]\n",
      "Loop 5193 Loss_Train:  [[ 13.19582394]] Loss_Validation:  [[ 11.02905623]]\n",
      "Loop 5194 Loss_Train:  [[ 13.1958231]] Loss_Validation:  [[ 11.02907222]]\n",
      "Loop 5195 Loss_Train:  [[ 13.19582227]] Loss_Validation:  [[ 11.0290882]]\n",
      "Loop 5196 Loss_Train:  [[ 13.19582144]] Loss_Validation:  [[ 11.02910417]]\n",
      "Loop 5197 Loss_Train:  [[ 13.1958206]] Loss_Validation:  [[ 11.02912012]]\n",
      "Loop 5198 Loss_Train:  [[ 13.19581977]] Loss_Validation:  [[ 11.02913607]]\n",
      "Loop 5199 Loss_Train:  [[ 13.19581894]] Loss_Validation:  [[ 11.02915201]]\n",
      "Loop 5200 Loss_Train:  [[ 13.19581812]] Loss_Validation:  [[ 11.02916793]]\n",
      "Loop 5201 Loss_Train:  [[ 13.19581729]] Loss_Validation:  [[ 11.02918384]]\n",
      "Loop 5202 Loss_Train:  [[ 13.19581646]] Loss_Validation:  [[ 11.02919974]]\n",
      "Loop 5203 Loss_Train:  [[ 13.19581564]] Loss_Validation:  [[ 11.02921564]]\n",
      "Loop 5204 Loss_Train:  [[ 13.19581482]] Loss_Validation:  [[ 11.02923152]]\n",
      "Loop 5205 Loss_Train:  [[ 13.195814]] Loss_Validation:  [[ 11.02924738]]\n",
      "Loop 5206 Loss_Train:  [[ 13.19581317]] Loss_Validation:  [[ 11.02926324]]\n",
      "Loop 5207 Loss_Train:  [[ 13.19581236]] Loss_Validation:  [[ 11.02927909]]\n",
      "Loop 5208 Loss_Train:  [[ 13.19581154]] Loss_Validation:  [[ 11.02929493]]\n",
      "Loop 5209 Loss_Train:  [[ 13.19581072]] Loss_Validation:  [[ 11.02931075]]\n",
      "Loop 5210 Loss_Train:  [[ 13.1958099]] Loss_Validation:  [[ 11.02932657]]\n",
      "Loop 5211 Loss_Train:  [[ 13.19580909]] Loss_Validation:  [[ 11.02934237]]\n",
      "Loop 5212 Loss_Train:  [[ 13.19580828]] Loss_Validation:  [[ 11.02935816]]\n",
      "Loop 5213 Loss_Train:  [[ 13.19580746]] Loss_Validation:  [[ 11.02937394]]\n",
      "Loop 5214 Loss_Train:  [[ 13.19580665]] Loss_Validation:  [[ 11.02938972]]\n",
      "Loop 5215 Loss_Train:  [[ 13.19580584]] Loss_Validation:  [[ 11.02940548]]\n",
      "Loop 5216 Loss_Train:  [[ 13.19580503]] Loss_Validation:  [[ 11.02942122]]\n",
      "Loop 5217 Loss_Train:  [[ 13.19580423]] Loss_Validation:  [[ 11.02943696]]\n",
      "Loop 5218 Loss_Train:  [[ 13.19580342]] Loss_Validation:  [[ 11.02945269]]\n",
      "Loop 5219 Loss_Train:  [[ 13.19580261]] Loss_Validation:  [[ 11.02946841]]\n",
      "Loop 5220 Loss_Train:  [[ 13.19580181]] Loss_Validation:  [[ 11.02948411]]\n",
      "Loop 5221 Loss_Train:  [[ 13.19580101]] Loss_Validation:  [[ 11.02949981]]\n",
      "Loop 5222 Loss_Train:  [[ 13.1958002]] Loss_Validation:  [[ 11.02951549]]\n",
      "Loop 5223 Loss_Train:  [[ 13.1957994]] Loss_Validation:  [[ 11.02953117]]\n",
      "Loop 5224 Loss_Train:  [[ 13.1957986]] Loss_Validation:  [[ 11.02954683]]\n",
      "Loop 5225 Loss_Train:  [[ 13.19579781]] Loss_Validation:  [[ 11.02956248]]\n",
      "Loop 5226 Loss_Train:  [[ 13.19579701]] Loss_Validation:  [[ 11.02957812]]\n",
      "Loop 5227 Loss_Train:  [[ 13.19579621]] Loss_Validation:  [[ 11.02959375]]\n",
      "Loop 5228 Loss_Train:  [[ 13.19579542]] Loss_Validation:  [[ 11.02960937]]\n",
      "Loop 5229 Loss_Train:  [[ 13.19579462]] Loss_Validation:  [[ 11.02962498]]\n",
      "Loop 5230 Loss_Train:  [[ 13.19579383]] Loss_Validation:  [[ 11.02964058]]\n",
      "Loop 5231 Loss_Train:  [[ 13.19579304]] Loss_Validation:  [[ 11.02965617]]\n",
      "Loop 5232 Loss_Train:  [[ 13.19579225]] Loss_Validation:  [[ 11.02967174]]\n",
      "Loop 5233 Loss_Train:  [[ 13.19579146]] Loss_Validation:  [[ 11.02968731]]\n",
      "Loop 5234 Loss_Train:  [[ 13.19579067]] Loss_Validation:  [[ 11.02970286]]\n",
      "Loop 5235 Loss_Train:  [[ 13.19578989]] Loss_Validation:  [[ 11.02971841]]\n",
      "Loop 5236 Loss_Train:  [[ 13.1957891]] Loss_Validation:  [[ 11.02973394]]\n",
      "Loop 5237 Loss_Train:  [[ 13.19578832]] Loss_Validation:  [[ 11.02974946]]\n",
      "Loop 5238 Loss_Train:  [[ 13.19578753]] Loss_Validation:  [[ 11.02976498]]\n",
      "Loop 5239 Loss_Train:  [[ 13.19578675]] Loss_Validation:  [[ 11.02978048]]\n",
      "Loop 5240 Loss_Train:  [[ 13.19578597]] Loss_Validation:  [[ 11.02979597]]\n",
      "Loop 5241 Loss_Train:  [[ 13.19578519]] Loss_Validation:  [[ 11.02981145]]\n",
      "Loop 5242 Loss_Train:  [[ 13.19578441]] Loss_Validation:  [[ 11.02982692]]\n",
      "Loop 5243 Loss_Train:  [[ 13.19578363]] Loss_Validation:  [[ 11.02984238]]\n",
      "Loop 5244 Loss_Train:  [[ 13.19578286]] Loss_Validation:  [[ 11.02985783]]\n",
      "Loop 5245 Loss_Train:  [[ 13.19578208]] Loss_Validation:  [[ 11.02987326]]\n",
      "Loop 5246 Loss_Train:  [[ 13.19578131]] Loss_Validation:  [[ 11.02988869]]\n",
      "Loop 5247 Loss_Train:  [[ 13.19578054]] Loss_Validation:  [[ 11.02990411]]\n",
      "Loop 5248 Loss_Train:  [[ 13.19577976]] Loss_Validation:  [[ 11.02991951]]\n",
      "Loop 5249 Loss_Train:  [[ 13.19577899]] Loss_Validation:  [[ 11.02993491]]\n",
      "Loop 5250 Loss_Train:  [[ 13.19577822]] Loss_Validation:  [[ 11.02995029]]\n",
      "Loop 5251 Loss_Train:  [[ 13.19577745]] Loss_Validation:  [[ 11.02996567]]\n",
      "Loop 5252 Loss_Train:  [[ 13.19577669]] Loss_Validation:  [[ 11.02998103]]\n",
      "Loop 5253 Loss_Train:  [[ 13.19577592]] Loss_Validation:  [[ 11.02999638]]\n",
      "Loop 5254 Loss_Train:  [[ 13.19577516]] Loss_Validation:  [[ 11.03001173]]\n",
      "Loop 5255 Loss_Train:  [[ 13.19577439]] Loss_Validation:  [[ 11.03002706]]\n",
      "Loop 5256 Loss_Train:  [[ 13.19577363]] Loss_Validation:  [[ 11.03004238]]\n",
      "Loop 5257 Loss_Train:  [[ 13.19577287]] Loss_Validation:  [[ 11.03005769]]\n",
      "Loop 5258 Loss_Train:  [[ 13.19577211]] Loss_Validation:  [[ 11.03007299]]\n",
      "Loop 5259 Loss_Train:  [[ 13.19577135]] Loss_Validation:  [[ 11.03008828]]\n",
      "Loop 5260 Loss_Train:  [[ 13.19577059]] Loss_Validation:  [[ 11.03010356]]\n",
      "Loop 5261 Loss_Train:  [[ 13.19576983]] Loss_Validation:  [[ 11.03011883]]\n",
      "Loop 5262 Loss_Train:  [[ 13.19576907]] Loss_Validation:  [[ 11.03013408]]\n",
      "Loop 5263 Loss_Train:  [[ 13.19576832]] Loss_Validation:  [[ 11.03014933]]\n",
      "Loop 5264 Loss_Train:  [[ 13.19576756]] Loss_Validation:  [[ 11.03016457]]\n",
      "Loop 5265 Loss_Train:  [[ 13.19576681]] Loss_Validation:  [[ 11.0301798]]\n",
      "Loop 5266 Loss_Train:  [[ 13.19576606]] Loss_Validation:  [[ 11.03019501]]\n",
      "Loop 5267 Loss_Train:  [[ 13.19576531]] Loss_Validation:  [[ 11.03021022]]\n",
      "Loop 5268 Loss_Train:  [[ 13.19576456]] Loss_Validation:  [[ 11.03022541]]\n",
      "Loop 5269 Loss_Train:  [[ 13.19576381]] Loss_Validation:  [[ 11.0302406]]\n",
      "Loop 5270 Loss_Train:  [[ 13.19576306]] Loss_Validation:  [[ 11.03025577]]\n",
      "Loop 5271 Loss_Train:  [[ 13.19576232]] Loss_Validation:  [[ 11.03027093]]\n",
      "Loop 5272 Loss_Train:  [[ 13.19576157]] Loss_Validation:  [[ 11.03028609]]\n",
      "Loop 5273 Loss_Train:  [[ 13.19576083]] Loss_Validation:  [[ 11.03030123]]\n",
      "Loop 5274 Loss_Train:  [[ 13.19576008]] Loss_Validation:  [[ 11.03031636]]\n",
      "Loop 5275 Loss_Train:  [[ 13.19575934]] Loss_Validation:  [[ 11.03033149]]\n",
      "Loop 5276 Loss_Train:  [[ 13.1957586]] Loss_Validation:  [[ 11.0303466]]\n",
      "Loop 5277 Loss_Train:  [[ 13.19575786]] Loss_Validation:  [[ 11.0303617]]\n",
      "Loop 5278 Loss_Train:  [[ 13.19575712]] Loss_Validation:  [[ 11.03037679]]\n",
      "Loop 5279 Loss_Train:  [[ 13.19575638]] Loss_Validation:  [[ 11.03039187]]\n",
      "Loop 5280 Loss_Train:  [[ 13.19575565]] Loss_Validation:  [[ 11.03040694]]\n",
      "Loop 5281 Loss_Train:  [[ 13.19575491]] Loss_Validation:  [[ 11.030422]]\n",
      "Loop 5282 Loss_Train:  [[ 13.19575418]] Loss_Validation:  [[ 11.03043705]]\n",
      "Loop 5283 Loss_Train:  [[ 13.19575344]] Loss_Validation:  [[ 11.03045209]]\n",
      "Loop 5284 Loss_Train:  [[ 13.19575271]] Loss_Validation:  [[ 11.03046712]]\n",
      "Loop 5285 Loss_Train:  [[ 13.19575198]] Loss_Validation:  [[ 11.03048213]]\n",
      "Loop 5286 Loss_Train:  [[ 13.19575125]] Loss_Validation:  [[ 11.03049714]]\n",
      "Loop 5287 Loss_Train:  [[ 13.19575052]] Loss_Validation:  [[ 11.03051214]]\n",
      "Loop 5288 Loss_Train:  [[ 13.19574979]] Loss_Validation:  [[ 11.03052713]]\n",
      "Loop 5289 Loss_Train:  [[ 13.19574906]] Loss_Validation:  [[ 11.0305421]]\n",
      "Loop 5290 Loss_Train:  [[ 13.19574834]] Loss_Validation:  [[ 11.03055707]]\n",
      "Loop 5291 Loss_Train:  [[ 13.19574761]] Loss_Validation:  [[ 11.03057203]]\n",
      "Loop 5292 Loss_Train:  [[ 13.19574689]] Loss_Validation:  [[ 11.03058697]]\n",
      "Loop 5293 Loss_Train:  [[ 13.19574617]] Loss_Validation:  [[ 11.03060191]]\n",
      "Loop 5294 Loss_Train:  [[ 13.19574544]] Loss_Validation:  [[ 11.03061683]]\n",
      "Loop 5295 Loss_Train:  [[ 13.19574472]] Loss_Validation:  [[ 11.03063175]]\n",
      "Loop 5296 Loss_Train:  [[ 13.195744]] Loss_Validation:  [[ 11.03064666]]\n",
      "Loop 5297 Loss_Train:  [[ 13.19574329]] Loss_Validation:  [[ 11.03066155]]\n",
      "Loop 5298 Loss_Train:  [[ 13.19574257]] Loss_Validation:  [[ 11.03067643]]\n",
      "Loop 5299 Loss_Train:  [[ 13.19574185]] Loss_Validation:  [[ 11.03069131]]\n",
      "Loop 5300 Loss_Train:  [[ 13.19574114]] Loss_Validation:  [[ 11.03070617]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 5301 Loss_Train:  [[ 13.19574042]] Loss_Validation:  [[ 11.03072103]]\n",
      "Loop 5302 Loss_Train:  [[ 13.19573971]] Loss_Validation:  [[ 11.03073587]]\n",
      "Loop 5303 Loss_Train:  [[ 13.195739]] Loss_Validation:  [[ 11.0307507]]\n",
      "Loop 5304 Loss_Train:  [[ 13.19573828]] Loss_Validation:  [[ 11.03076553]]\n",
      "Loop 5305 Loss_Train:  [[ 13.19573757]] Loss_Validation:  [[ 11.03078034]]\n",
      "Loop 5306 Loss_Train:  [[ 13.19573686]] Loss_Validation:  [[ 11.03079514]]\n",
      "Loop 5307 Loss_Train:  [[ 13.19573616]] Loss_Validation:  [[ 11.03080993]]\n",
      "Loop 5308 Loss_Train:  [[ 13.19573545]] Loss_Validation:  [[ 11.03082472]]\n",
      "Loop 5309 Loss_Train:  [[ 13.19573474]] Loss_Validation:  [[ 11.03083949]]\n",
      "Loop 5310 Loss_Train:  [[ 13.19573404]] Loss_Validation:  [[ 11.03085425]]\n",
      "Loop 5311 Loss_Train:  [[ 13.19573333]] Loss_Validation:  [[ 11.030869]]\n",
      "Loop 5312 Loss_Train:  [[ 13.19573263]] Loss_Validation:  [[ 11.03088375]]\n",
      "Loop 5313 Loss_Train:  [[ 13.19573193]] Loss_Validation:  [[ 11.03089848]]\n",
      "Loop 5314 Loss_Train:  [[ 13.19573123]] Loss_Validation:  [[ 11.0309132]]\n",
      "Loop 5315 Loss_Train:  [[ 13.19573053]] Loss_Validation:  [[ 11.03092791]]\n",
      "Loop 5316 Loss_Train:  [[ 13.19572983]] Loss_Validation:  [[ 11.03094261]]\n",
      "Loop 5317 Loss_Train:  [[ 13.19572913]] Loss_Validation:  [[ 11.0309573]]\n",
      "Loop 5318 Loss_Train:  [[ 13.19572843]] Loss_Validation:  [[ 11.03097198]]\n",
      "Loop 5319 Loss_Train:  [[ 13.19572774]] Loss_Validation:  [[ 11.03098665]]\n",
      "Loop 5320 Loss_Train:  [[ 13.19572704]] Loss_Validation:  [[ 11.03100132]]\n",
      "Loop 5321 Loss_Train:  [[ 13.19572635]] Loss_Validation:  [[ 11.03101597]]\n",
      "Loop 5322 Loss_Train:  [[ 13.19572566]] Loss_Validation:  [[ 11.03103061]]\n",
      "Loop 5323 Loss_Train:  [[ 13.19572496]] Loss_Validation:  [[ 11.03104524]]\n",
      "Loop 5324 Loss_Train:  [[ 13.19572427]] Loss_Validation:  [[ 11.03105986]]\n",
      "Loop 5325 Loss_Train:  [[ 13.19572358]] Loss_Validation:  [[ 11.03107447]]\n",
      "Loop 5326 Loss_Train:  [[ 13.19572289]] Loss_Validation:  [[ 11.03108907]]\n",
      "Loop 5327 Loss_Train:  [[ 13.19572221]] Loss_Validation:  [[ 11.03110366]]\n",
      "Loop 5328 Loss_Train:  [[ 13.19572152]] Loss_Validation:  [[ 11.03111824]]\n",
      "Loop 5329 Loss_Train:  [[ 13.19572083]] Loss_Validation:  [[ 11.03113281]]\n",
      "Loop 5330 Loss_Train:  [[ 13.19572015]] Loss_Validation:  [[ 11.03114737]]\n",
      "Loop 5331 Loss_Train:  [[ 13.19571946]] Loss_Validation:  [[ 11.03116192]]\n",
      "Loop 5332 Loss_Train:  [[ 13.19571878]] Loss_Validation:  [[ 11.03117646]]\n",
      "Loop 5333 Loss_Train:  [[ 13.1957181]] Loss_Validation:  [[ 11.03119099]]\n",
      "Loop 5334 Loss_Train:  [[ 13.19571742]] Loss_Validation:  [[ 11.03120551]]\n",
      "Loop 5335 Loss_Train:  [[ 13.19571674]] Loss_Validation:  [[ 11.03122002]]\n",
      "Loop 5336 Loss_Train:  [[ 13.19571606]] Loss_Validation:  [[ 11.03123452]]\n",
      "Loop 5337 Loss_Train:  [[ 13.19571538]] Loss_Validation:  [[ 11.03124901]]\n",
      "Loop 5338 Loss_Train:  [[ 13.1957147]] Loss_Validation:  [[ 11.03126349]]\n",
      "Loop 5339 Loss_Train:  [[ 13.19571403]] Loss_Validation:  [[ 11.03127796]]\n",
      "Loop 5340 Loss_Train:  [[ 13.19571335]] Loss_Validation:  [[ 11.03129242]]\n",
      "Loop 5341 Loss_Train:  [[ 13.19571268]] Loss_Validation:  [[ 11.03130688]]\n",
      "Loop 5342 Loss_Train:  [[ 13.19571201]] Loss_Validation:  [[ 11.03132132]]\n",
      "Loop 5343 Loss_Train:  [[ 13.19571133]] Loss_Validation:  [[ 11.03133575]]\n",
      "Loop 5344 Loss_Train:  [[ 13.19571066]] Loss_Validation:  [[ 11.03135017]]\n",
      "Loop 5345 Loss_Train:  [[ 13.19570999]] Loss_Validation:  [[ 11.03136458]]\n",
      "Loop 5346 Loss_Train:  [[ 13.19570932]] Loss_Validation:  [[ 11.03137898]]\n",
      "Loop 5347 Loss_Train:  [[ 13.19570866]] Loss_Validation:  [[ 11.03139337]]\n",
      "Loop 5348 Loss_Train:  [[ 13.19570799]] Loss_Validation:  [[ 11.03140775]]\n",
      "Loop 5349 Loss_Train:  [[ 13.19570732]] Loss_Validation:  [[ 11.03142212]]\n",
      "Loop 5350 Loss_Train:  [[ 13.19570666]] Loss_Validation:  [[ 11.03143648]]\n",
      "Loop 5351 Loss_Train:  [[ 13.19570599]] Loss_Validation:  [[ 11.03145084]]\n",
      "Loop 5352 Loss_Train:  [[ 13.19570533]] Loss_Validation:  [[ 11.03146518]]\n",
      "Loop 5353 Loss_Train:  [[ 13.19570467]] Loss_Validation:  [[ 11.03147951]]\n",
      "Loop 5354 Loss_Train:  [[ 13.19570401]] Loss_Validation:  [[ 11.03149383]]\n",
      "Loop 5355 Loss_Train:  [[ 13.19570335]] Loss_Validation:  [[ 11.03150814]]\n",
      "Loop 5356 Loss_Train:  [[ 13.19570269]] Loss_Validation:  [[ 11.03152245]]\n",
      "Loop 5357 Loss_Train:  [[ 13.19570203]] Loss_Validation:  [[ 11.03153674]]\n",
      "Loop 5358 Loss_Train:  [[ 13.19570137]] Loss_Validation:  [[ 11.03155102]]\n",
      "Loop 5359 Loss_Train:  [[ 13.19570071]] Loss_Validation:  [[ 11.03156529]]\n",
      "Loop 5360 Loss_Train:  [[ 13.19570006]] Loss_Validation:  [[ 11.03157956]]\n",
      "Loop 5361 Loss_Train:  [[ 13.1956994]] Loss_Validation:  [[ 11.03159381]]\n",
      "Loop 5362 Loss_Train:  [[ 13.19569875]] Loss_Validation:  [[ 11.03160805]]\n",
      "Loop 5363 Loss_Train:  [[ 13.1956981]] Loss_Validation:  [[ 11.03162229]]\n",
      "Loop 5364 Loss_Train:  [[ 13.19569745]] Loss_Validation:  [[ 11.03163651]]\n",
      "Loop 5365 Loss_Train:  [[ 13.19569679]] Loss_Validation:  [[ 11.03165072]]\n",
      "Loop 5366 Loss_Train:  [[ 13.19569614]] Loss_Validation:  [[ 11.03166493]]\n",
      "Loop 5367 Loss_Train:  [[ 13.1956955]] Loss_Validation:  [[ 11.03167912]]\n",
      "Loop 5368 Loss_Train:  [[ 13.19569485]] Loss_Validation:  [[ 11.03169331]]\n",
      "Loop 5369 Loss_Train:  [[ 13.1956942]] Loss_Validation:  [[ 11.03170748]]\n",
      "Loop 5370 Loss_Train:  [[ 13.19569355]] Loss_Validation:  [[ 11.03172165]]\n",
      "Loop 5371 Loss_Train:  [[ 13.19569291]] Loss_Validation:  [[ 11.0317358]]\n",
      "Loop 5372 Loss_Train:  [[ 13.19569227]] Loss_Validation:  [[ 11.03174995]]\n",
      "Loop 5373 Loss_Train:  [[ 13.19569162]] Loss_Validation:  [[ 11.03176409]]\n",
      "Loop 5374 Loss_Train:  [[ 13.19569098]] Loss_Validation:  [[ 11.03177821]]\n",
      "Loop 5375 Loss_Train:  [[ 13.19569034]] Loss_Validation:  [[ 11.03179233]]\n",
      "Loop 5376 Loss_Train:  [[ 13.1956897]] Loss_Validation:  [[ 11.03180644]]\n",
      "Loop 5377 Loss_Train:  [[ 13.19568906]] Loss_Validation:  [[ 11.03182053]]\n",
      "Loop 5378 Loss_Train:  [[ 13.19568842]] Loss_Validation:  [[ 11.03183462]]\n",
      "Loop 5379 Loss_Train:  [[ 13.19568778]] Loss_Validation:  [[ 11.0318487]]\n",
      "Loop 5380 Loss_Train:  [[ 13.19568714]] Loss_Validation:  [[ 11.03186277]]\n",
      "Loop 5381 Loss_Train:  [[ 13.19568651]] Loss_Validation:  [[ 11.03187683]]\n",
      "Loop 5382 Loss_Train:  [[ 13.19568587]] Loss_Validation:  [[ 11.03189087]]\n",
      "Loop 5383 Loss_Train:  [[ 13.19568524]] Loss_Validation:  [[ 11.03190491]]\n",
      "Loop 5384 Loss_Train:  [[ 13.19568461]] Loss_Validation:  [[ 11.03191894]]\n",
      "Loop 5385 Loss_Train:  [[ 13.19568397]] Loss_Validation:  [[ 11.03193296]]\n",
      "Loop 5386 Loss_Train:  [[ 13.19568334]] Loss_Validation:  [[ 11.03194697]]\n",
      "Loop 5387 Loss_Train:  [[ 13.19568271]] Loss_Validation:  [[ 11.03196097]]\n",
      "Loop 5388 Loss_Train:  [[ 13.19568208]] Loss_Validation:  [[ 11.03197497]]\n",
      "Loop 5389 Loss_Train:  [[ 13.19568146]] Loss_Validation:  [[ 11.03198895]]\n",
      "Loop 5390 Loss_Train:  [[ 13.19568083]] Loss_Validation:  [[ 11.03200292]]\n",
      "Loop 5391 Loss_Train:  [[ 13.1956802]] Loss_Validation:  [[ 11.03201688]]\n",
      "Loop 5392 Loss_Train:  [[ 13.19567958]] Loss_Validation:  [[ 11.03203083]]\n",
      "Loop 5393 Loss_Train:  [[ 13.19567895]] Loss_Validation:  [[ 11.03204478]]\n",
      "Loop 5394 Loss_Train:  [[ 13.19567833]] Loss_Validation:  [[ 11.03205871]]\n",
      "Loop 5395 Loss_Train:  [[ 13.1956777]] Loss_Validation:  [[ 11.03207263]]\n",
      "Loop 5396 Loss_Train:  [[ 13.19567708]] Loss_Validation:  [[ 11.03208655]]\n",
      "Loop 5397 Loss_Train:  [[ 13.19567646]] Loss_Validation:  [[ 11.03210045]]\n",
      "Loop 5398 Loss_Train:  [[ 13.19567584]] Loss_Validation:  [[ 11.03211435]]\n",
      "Loop 5399 Loss_Train:  [[ 13.19567522]] Loss_Validation:  [[ 11.03212823]]\n",
      "Loop 5400 Loss_Train:  [[ 13.1956746]] Loss_Validation:  [[ 11.03214211]]\n",
      "Loop 5401 Loss_Train:  [[ 13.19567398]] Loss_Validation:  [[ 11.03215598]]\n",
      "Loop 5402 Loss_Train:  [[ 13.19567337]] Loss_Validation:  [[ 11.03216983]]\n",
      "Loop 5403 Loss_Train:  [[ 13.19567275]] Loss_Validation:  [[ 11.03218368]]\n",
      "Loop 5404 Loss_Train:  [[ 13.19567214]] Loss_Validation:  [[ 11.03219752]]\n",
      "Loop 5405 Loss_Train:  [[ 13.19567152]] Loss_Validation:  [[ 11.03221135]]\n",
      "Loop 5406 Loss_Train:  [[ 13.19567091]] Loss_Validation:  [[ 11.03222517]]\n",
      "Loop 5407 Loss_Train:  [[ 13.1956703]] Loss_Validation:  [[ 11.03223898]]\n",
      "Loop 5408 Loss_Train:  [[ 13.19566969]] Loss_Validation:  [[ 11.03225278]]\n",
      "Loop 5409 Loss_Train:  [[ 13.19566908]] Loss_Validation:  [[ 11.03226657]]\n",
      "Loop 5410 Loss_Train:  [[ 13.19566847]] Loss_Validation:  [[ 11.03228035]]\n",
      "Loop 5411 Loss_Train:  [[ 13.19566786]] Loss_Validation:  [[ 11.03229412]]\n",
      "Loop 5412 Loss_Train:  [[ 13.19566725]] Loss_Validation:  [[ 11.03230788]]\n",
      "Loop 5413 Loss_Train:  [[ 13.19566664]] Loss_Validation:  [[ 11.03232164]]\n",
      "Loop 5414 Loss_Train:  [[ 13.19566604]] Loss_Validation:  [[ 11.03233538]]\n",
      "Loop 5415 Loss_Train:  [[ 13.19566543]] Loss_Validation:  [[ 11.03234911]]\n",
      "Loop 5416 Loss_Train:  [[ 13.19566483]] Loss_Validation:  [[ 11.03236284]]\n",
      "Loop 5417 Loss_Train:  [[ 13.19566423]] Loss_Validation:  [[ 11.03237655]]\n",
      "Loop 5418 Loss_Train:  [[ 13.19566362]] Loss_Validation:  [[ 11.03239026]]\n",
      "Loop 5419 Loss_Train:  [[ 13.19566302]] Loss_Validation:  [[ 11.03240395]]\n",
      "Loop 5420 Loss_Train:  [[ 13.19566242]] Loss_Validation:  [[ 11.03241764]]\n",
      "Loop 5421 Loss_Train:  [[ 13.19566182]] Loss_Validation:  [[ 11.03243132]]\n",
      "Loop 5422 Loss_Train:  [[ 13.19566122]] Loss_Validation:  [[ 11.03244499]]\n",
      "Loop 5423 Loss_Train:  [[ 13.19566062]] Loss_Validation:  [[ 11.03245864]]\n",
      "Loop 5424 Loss_Train:  [[ 13.19566003]] Loss_Validation:  [[ 11.03247229]]\n",
      "Loop 5425 Loss_Train:  [[ 13.19565943]] Loss_Validation:  [[ 11.03248593]]\n",
      "Loop 5426 Loss_Train:  [[ 13.19565883]] Loss_Validation:  [[ 11.03249956]]\n",
      "Loop 5427 Loss_Train:  [[ 13.19565824]] Loss_Validation:  [[ 11.03251318]]\n",
      "Loop 5428 Loss_Train:  [[ 13.19565765]] Loss_Validation:  [[ 11.0325268]]\n",
      "Loop 5429 Loss_Train:  [[ 13.19565705]] Loss_Validation:  [[ 11.0325404]]\n",
      "Loop 5430 Loss_Train:  [[ 13.19565646]] Loss_Validation:  [[ 11.03255399]]\n",
      "Loop 5431 Loss_Train:  [[ 13.19565587]] Loss_Validation:  [[ 11.03256758]]\n",
      "Loop 5432 Loss_Train:  [[ 13.19565528]] Loss_Validation:  [[ 11.03258115]]\n",
      "Loop 5433 Loss_Train:  [[ 13.19565469]] Loss_Validation:  [[ 11.03259471]]\n",
      "Loop 5434 Loss_Train:  [[ 13.1956541]] Loss_Validation:  [[ 11.03260827]]\n",
      "Loop 5435 Loss_Train:  [[ 13.19565351]] Loss_Validation:  [[ 11.03262182]]\n",
      "Loop 5436 Loss_Train:  [[ 13.19565293]] Loss_Validation:  [[ 11.03263535]]\n",
      "Loop 5437 Loss_Train:  [[ 13.19565234]] Loss_Validation:  [[ 11.03264888]]\n",
      "Loop 5438 Loss_Train:  [[ 13.19565176]] Loss_Validation:  [[ 11.0326624]]\n",
      "Loop 5439 Loss_Train:  [[ 13.19565117]] Loss_Validation:  [[ 11.03267591]]\n",
      "Loop 5440 Loss_Train:  [[ 13.19565059]] Loss_Validation:  [[ 11.03268941]]\n",
      "Loop 5441 Loss_Train:  [[ 13.19565001]] Loss_Validation:  [[ 11.0327029]]\n",
      "Loop 5442 Loss_Train:  [[ 13.19564942]] Loss_Validation:  [[ 11.03271638]]\n",
      "Loop 5443 Loss_Train:  [[ 13.19564884]] Loss_Validation:  [[ 11.03272985]]\n",
      "Loop 5444 Loss_Train:  [[ 13.19564826]] Loss_Validation:  [[ 11.03274332]]\n",
      "Loop 5445 Loss_Train:  [[ 13.19564768]] Loss_Validation:  [[ 11.03275677]]\n",
      "Loop 5446 Loss_Train:  [[ 13.19564711]] Loss_Validation:  [[ 11.03277021]]\n",
      "Loop 5447 Loss_Train:  [[ 13.19564653]] Loss_Validation:  [[ 11.03278365]]\n",
      "Loop 5448 Loss_Train:  [[ 13.19564595]] Loss_Validation:  [[ 11.03279708]]\n",
      "Loop 5449 Loss_Train:  [[ 13.19564538]] Loss_Validation:  [[ 11.03281049]]\n",
      "Loop 5450 Loss_Train:  [[ 13.1956448]] Loss_Validation:  [[ 11.0328239]]\n",
      "Loop 5451 Loss_Train:  [[ 13.19564423]] Loss_Validation:  [[ 11.0328373]]\n",
      "Loop 5452 Loss_Train:  [[ 13.19564365]] Loss_Validation:  [[ 11.03285069]]\n",
      "Loop 5453 Loss_Train:  [[ 13.19564308]] Loss_Validation:  [[ 11.03286407]]\n",
      "Loop 5454 Loss_Train:  [[ 13.19564251]] Loss_Validation:  [[ 11.03287744]]\n",
      "Loop 5455 Loss_Train:  [[ 13.19564194]] Loss_Validation:  [[ 11.0328908]]\n",
      "Loop 5456 Loss_Train:  [[ 13.19564137]] Loss_Validation:  [[ 11.03290415]]\n",
      "Loop 5457 Loss_Train:  [[ 13.1956408]] Loss_Validation:  [[ 11.0329175]]\n",
      "Loop 5458 Loss_Train:  [[ 13.19564023]] Loss_Validation:  [[ 11.03293083]]\n",
      "Loop 5459 Loss_Train:  [[ 13.19563966]] Loss_Validation:  [[ 11.03294416]]\n",
      "Loop 5460 Loss_Train:  [[ 13.1956391]] Loss_Validation:  [[ 11.03295747]]\n",
      "Loop 5461 Loss_Train:  [[ 13.19563853]] Loss_Validation:  [[ 11.03297078]]\n",
      "Loop 5462 Loss_Train:  [[ 13.19563796]] Loss_Validation:  [[ 11.03298407]]\n",
      "Loop 5463 Loss_Train:  [[ 13.1956374]] Loss_Validation:  [[ 11.03299736]]\n",
      "Loop 5464 Loss_Train:  [[ 13.19563684]] Loss_Validation:  [[ 11.03301064]]\n",
      "Loop 5465 Loss_Train:  [[ 13.19563627]] Loss_Validation:  [[ 11.03302391]]\n",
      "Loop 5466 Loss_Train:  [[ 13.19563571]] Loss_Validation:  [[ 11.03303717]]\n",
      "Loop 5467 Loss_Train:  [[ 13.19563515]] Loss_Validation:  [[ 11.03305043]]\n",
      "Loop 5468 Loss_Train:  [[ 13.19563459]] Loss_Validation:  [[ 11.03306367]]\n",
      "Loop 5469 Loss_Train:  [[ 13.19563403]] Loss_Validation:  [[ 11.0330769]]\n",
      "Loop 5470 Loss_Train:  [[ 13.19563347]] Loss_Validation:  [[ 11.03309013]]\n",
      "Loop 5471 Loss_Train:  [[ 13.19563292]] Loss_Validation:  [[ 11.03310334]]\n",
      "Loop 5472 Loss_Train:  [[ 13.19563236]] Loss_Validation:  [[ 11.03311655]]\n",
      "Loop 5473 Loss_Train:  [[ 13.1956318]] Loss_Validation:  [[ 11.03312975]]\n",
      "Loop 5474 Loss_Train:  [[ 13.19563125]] Loss_Validation:  [[ 11.03314293]]\n",
      "Loop 5475 Loss_Train:  [[ 13.19563069]] Loss_Validation:  [[ 11.03315611]]\n",
      "Loop 5476 Loss_Train:  [[ 13.19563014]] Loss_Validation:  [[ 11.03316928]]\n",
      "Loop 5477 Loss_Train:  [[ 13.19562959]] Loss_Validation:  [[ 11.03318245]]\n",
      "Loop 5478 Loss_Train:  [[ 13.19562904]] Loss_Validation:  [[ 11.0331956]]\n",
      "Loop 5479 Loss_Train:  [[ 13.19562848]] Loss_Validation:  [[ 11.03320874]]\n",
      "Loop 5480 Loss_Train:  [[ 13.19562793]] Loss_Validation:  [[ 11.03322188]]\n",
      "Loop 5481 Loss_Train:  [[ 13.19562738]] Loss_Validation:  [[ 11.033235]]\n",
      "Loop 5482 Loss_Train:  [[ 13.19562683]] Loss_Validation:  [[ 11.03324812]]\n",
      "Loop 5483 Loss_Train:  [[ 13.19562629]] Loss_Validation:  [[ 11.03326122]]\n",
      "Loop 5484 Loss_Train:  [[ 13.19562574]] Loss_Validation:  [[ 11.03327432]]\n",
      "Loop 5485 Loss_Train:  [[ 13.19562519]] Loss_Validation:  [[ 11.03328741]]\n",
      "Loop 5486 Loss_Train:  [[ 13.19562465]] Loss_Validation:  [[ 11.03330049]]\n",
      "Loop 5487 Loss_Train:  [[ 13.1956241]] Loss_Validation:  [[ 11.03331356]]\n",
      "Loop 5488 Loss_Train:  [[ 13.19562356]] Loss_Validation:  [[ 11.03332662]]\n",
      "Loop 5489 Loss_Train:  [[ 13.19562302]] Loss_Validation:  [[ 11.03333968]]\n",
      "Loop 5490 Loss_Train:  [[ 13.19562247]] Loss_Validation:  [[ 11.03335272]]\n",
      "Loop 5491 Loss_Train:  [[ 13.19562193]] Loss_Validation:  [[ 11.03336576]]\n",
      "Loop 5492 Loss_Train:  [[ 13.19562139]] Loss_Validation:  [[ 11.03337878]]\n",
      "Loop 5493 Loss_Train:  [[ 13.19562085]] Loss_Validation:  [[ 11.0333918]]\n",
      "Loop 5494 Loss_Train:  [[ 13.19562031]] Loss_Validation:  [[ 11.03340481]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 5495 Loss_Train:  [[ 13.19561977]] Loss_Validation:  [[ 11.03341781]]\n",
      "Loop 5496 Loss_Train:  [[ 13.19561923]] Loss_Validation:  [[ 11.0334308]]\n",
      "Loop 5497 Loss_Train:  [[ 13.1956187]] Loss_Validation:  [[ 11.03344378]]\n",
      "Loop 5498 Loss_Train:  [[ 13.19561816]] Loss_Validation:  [[ 11.03345675]]\n",
      "Loop 5499 Loss_Train:  [[ 13.19561763]] Loss_Validation:  [[ 11.03346972]]\n",
      "Loop 5500 Loss_Train:  [[ 13.19561709]] Loss_Validation:  [[ 11.03348267]]\n",
      "Loop 5501 Loss_Train:  [[ 13.19561656]] Loss_Validation:  [[ 11.03349562]]\n",
      "Loop 5502 Loss_Train:  [[ 13.19561602]] Loss_Validation:  [[ 11.03350856]]\n",
      "Loop 5503 Loss_Train:  [[ 13.19561549]] Loss_Validation:  [[ 11.03352149]]\n",
      "Loop 5504 Loss_Train:  [[ 13.19561496]] Loss_Validation:  [[ 11.0335344]]\n",
      "Loop 5505 Loss_Train:  [[ 13.19561443]] Loss_Validation:  [[ 11.03354732]]\n",
      "Loop 5506 Loss_Train:  [[ 13.1956139]] Loss_Validation:  [[ 11.03356022]]\n",
      "Loop 5507 Loss_Train:  [[ 13.19561337]] Loss_Validation:  [[ 11.03357311]]\n",
      "Loop 5508 Loss_Train:  [[ 13.19561284]] Loss_Validation:  [[ 11.03358599]]\n",
      "Loop 5509 Loss_Train:  [[ 13.19561231]] Loss_Validation:  [[ 11.03359887]]\n",
      "Loop 5510 Loss_Train:  [[ 13.19561179]] Loss_Validation:  [[ 11.03361174]]\n",
      "Loop 5511 Loss_Train:  [[ 13.19561126]] Loss_Validation:  [[ 11.03362459]]\n",
      "Loop 5512 Loss_Train:  [[ 13.19561074]] Loss_Validation:  [[ 11.03363744]]\n",
      "Loop 5513 Loss_Train:  [[ 13.19561021]] Loss_Validation:  [[ 11.03365028]]\n",
      "Loop 5514 Loss_Train:  [[ 13.19560969]] Loss_Validation:  [[ 11.03366311]]\n",
      "Loop 5515 Loss_Train:  [[ 13.19560916]] Loss_Validation:  [[ 11.03367594]]\n",
      "Loop 5516 Loss_Train:  [[ 13.19560864]] Loss_Validation:  [[ 11.03368875]]\n",
      "Loop 5517 Loss_Train:  [[ 13.19560812]] Loss_Validation:  [[ 11.03370155]]\n",
      "Loop 5518 Loss_Train:  [[ 13.1956076]] Loss_Validation:  [[ 11.03371435]]\n",
      "Loop 5519 Loss_Train:  [[ 13.19560708]] Loss_Validation:  [[ 11.03372714]]\n",
      "Loop 5520 Loss_Train:  [[ 13.19560656]] Loss_Validation:  [[ 11.03373992]]\n",
      "Loop 5521 Loss_Train:  [[ 13.19560604]] Loss_Validation:  [[ 11.03375269]]\n",
      "Loop 5522 Loss_Train:  [[ 13.19560552]] Loss_Validation:  [[ 11.03376545]]\n",
      "Loop 5523 Loss_Train:  [[ 13.19560501]] Loss_Validation:  [[ 11.0337782]]\n",
      "Loop 5524 Loss_Train:  [[ 13.19560449]] Loss_Validation:  [[ 11.03379094]]\n",
      "Loop 5525 Loss_Train:  [[ 13.19560398]] Loss_Validation:  [[ 11.03380368]]\n",
      "Loop 5526 Loss_Train:  [[ 13.19560346]] Loss_Validation:  [[ 11.0338164]]\n",
      "Loop 5527 Loss_Train:  [[ 13.19560295]] Loss_Validation:  [[ 11.03382912]]\n",
      "Loop 5528 Loss_Train:  [[ 13.19560243]] Loss_Validation:  [[ 11.03384183]]\n",
      "Loop 5529 Loss_Train:  [[ 13.19560192]] Loss_Validation:  [[ 11.03385453]]\n",
      "Loop 5530 Loss_Train:  [[ 13.19560141]] Loss_Validation:  [[ 11.03386722]]\n",
      "Loop 5531 Loss_Train:  [[ 13.1956009]] Loss_Validation:  [[ 11.0338799]]\n",
      "Loop 5532 Loss_Train:  [[ 13.19560039]] Loss_Validation:  [[ 11.03389257]]\n",
      "Loop 5533 Loss_Train:  [[ 13.19559988]] Loss_Validation:  [[ 11.03390524]]\n",
      "Loop 5534 Loss_Train:  [[ 13.19559937]] Loss_Validation:  [[ 11.0339179]]\n",
      "Loop 5535 Loss_Train:  [[ 13.19559886]] Loss_Validation:  [[ 11.03393054]]\n",
      "Loop 5536 Loss_Train:  [[ 13.19559835]] Loss_Validation:  [[ 11.03394318]]\n",
      "Loop 5537 Loss_Train:  [[ 13.19559785]] Loss_Validation:  [[ 11.03395581]]\n",
      "Loop 5538 Loss_Train:  [[ 13.19559734]] Loss_Validation:  [[ 11.03396843]]\n",
      "Loop 5539 Loss_Train:  [[ 13.19559684]] Loss_Validation:  [[ 11.03398105]]\n",
      "Loop 5540 Loss_Train:  [[ 13.19559633]] Loss_Validation:  [[ 11.03399365]]\n",
      "Loop 5541 Loss_Train:  [[ 13.19559583]] Loss_Validation:  [[ 11.03400625]]\n",
      "Loop 5542 Loss_Train:  [[ 13.19559533]] Loss_Validation:  [[ 11.03401883]]\n",
      "Loop 5543 Loss_Train:  [[ 13.19559482]] Loss_Validation:  [[ 11.03403141]]\n",
      "Loop 5544 Loss_Train:  [[ 13.19559432]] Loss_Validation:  [[ 11.03404398]]\n",
      "Loop 5545 Loss_Train:  [[ 13.19559382]] Loss_Validation:  [[ 11.03405654]]\n",
      "Loop 5546 Loss_Train:  [[ 13.19559332]] Loss_Validation:  [[ 11.03406909]]\n",
      "Loop 5547 Loss_Train:  [[ 13.19559282]] Loss_Validation:  [[ 11.03408164]]\n",
      "Loop 5548 Loss_Train:  [[ 13.19559232]] Loss_Validation:  [[ 11.03409417]]\n",
      "Loop 5549 Loss_Train:  [[ 13.19559183]] Loss_Validation:  [[ 11.0341067]]\n",
      "Loop 5550 Loss_Train:  [[ 13.19559133]] Loss_Validation:  [[ 11.03411922]]\n",
      "Loop 5551 Loss_Train:  [[ 13.19559083]] Loss_Validation:  [[ 11.03413173]]\n",
      "Loop 5552 Loss_Train:  [[ 13.19559034]] Loss_Validation:  [[ 11.03414423]]\n",
      "Loop 5553 Loss_Train:  [[ 13.19558984]] Loss_Validation:  [[ 11.03415672]]\n",
      "Loop 5554 Loss_Train:  [[ 13.19558935]] Loss_Validation:  [[ 11.0341692]]\n",
      "Loop 5555 Loss_Train:  [[ 13.19558885]] Loss_Validation:  [[ 11.03418168]]\n",
      "Loop 5556 Loss_Train:  [[ 13.19558836]] Loss_Validation:  [[ 11.03419415]]\n",
      "Loop 5557 Loss_Train:  [[ 13.19558787]] Loss_Validation:  [[ 11.0342066]]\n",
      "Loop 5558 Loss_Train:  [[ 13.19558738]] Loss_Validation:  [[ 11.03421905]]\n",
      "Loop 5559 Loss_Train:  [[ 13.19558689]] Loss_Validation:  [[ 11.0342315]]\n",
      "Loop 5560 Loss_Train:  [[ 13.1955864]] Loss_Validation:  [[ 11.03424393]]\n",
      "Loop 5561 Loss_Train:  [[ 13.19558591]] Loss_Validation:  [[ 11.03425635]]\n",
      "Loop 5562 Loss_Train:  [[ 13.19558542]] Loss_Validation:  [[ 11.03426877]]\n",
      "Loop 5563 Loss_Train:  [[ 13.19558493]] Loss_Validation:  [[ 11.03428117]]\n",
      "Loop 5564 Loss_Train:  [[ 13.19558444]] Loss_Validation:  [[ 11.03429357]]\n",
      "Loop 5565 Loss_Train:  [[ 13.19558396]] Loss_Validation:  [[ 11.03430596]]\n",
      "Loop 5566 Loss_Train:  [[ 13.19558347]] Loss_Validation:  [[ 11.03431834]]\n",
      "Loop 5567 Loss_Train:  [[ 13.19558299]] Loss_Validation:  [[ 11.03433072]]\n",
      "Loop 5568 Loss_Train:  [[ 13.1955825]] Loss_Validation:  [[ 11.03434308]]\n",
      "Loop 5569 Loss_Train:  [[ 13.19558202]] Loss_Validation:  [[ 11.03435544]]\n",
      "Loop 5570 Loss_Train:  [[ 13.19558154]] Loss_Validation:  [[ 11.03436778]]\n",
      "Loop 5571 Loss_Train:  [[ 13.19558105]] Loss_Validation:  [[ 11.03438012]]\n",
      "Loop 5572 Loss_Train:  [[ 13.19558057]] Loss_Validation:  [[ 11.03439245]]\n",
      "Loop 5573 Loss_Train:  [[ 13.19558009]] Loss_Validation:  [[ 11.03440478]]\n",
      "Loop 5574 Loss_Train:  [[ 13.19557961]] Loss_Validation:  [[ 11.03441709]]\n",
      "Loop 5575 Loss_Train:  [[ 13.19557913]] Loss_Validation:  [[ 11.03442939]]\n",
      "Loop 5576 Loss_Train:  [[ 13.19557865]] Loss_Validation:  [[ 11.03444169]]\n",
      "Loop 5577 Loss_Train:  [[ 13.19557818]] Loss_Validation:  [[ 11.03445398]]\n",
      "Loop 5578 Loss_Train:  [[ 13.1955777]] Loss_Validation:  [[ 11.03446626]]\n",
      "Loop 5579 Loss_Train:  [[ 13.19557722]] Loss_Validation:  [[ 11.03447853]]\n",
      "Loop 5580 Loss_Train:  [[ 13.19557675]] Loss_Validation:  [[ 11.03449079]]\n",
      "Loop 5581 Loss_Train:  [[ 13.19557627]] Loss_Validation:  [[ 11.03450305]]\n",
      "Loop 5582 Loss_Train:  [[ 13.1955758]] Loss_Validation:  [[ 11.03451529]]\n",
      "Loop 5583 Loss_Train:  [[ 13.19557532]] Loss_Validation:  [[ 11.03452753]]\n",
      "Loop 5584 Loss_Train:  [[ 13.19557485]] Loss_Validation:  [[ 11.03453976]]\n",
      "Loop 5585 Loss_Train:  [[ 13.19557438]] Loss_Validation:  [[ 11.03455198]]\n",
      "Loop 5586 Loss_Train:  [[ 13.19557391]] Loss_Validation:  [[ 11.0345642]]\n",
      "Loop 5587 Loss_Train:  [[ 13.19557343]] Loss_Validation:  [[ 11.0345764]]\n",
      "Loop 5588 Loss_Train:  [[ 13.19557296]] Loss_Validation:  [[ 11.0345886]]\n",
      "Loop 5589 Loss_Train:  [[ 13.19557249]] Loss_Validation:  [[ 11.03460078]]\n",
      "Loop 5590 Loss_Train:  [[ 13.19557203]] Loss_Validation:  [[ 11.03461296]]\n",
      "Loop 5591 Loss_Train:  [[ 13.19557156]] Loss_Validation:  [[ 11.03462513]]\n",
      "Loop 5592 Loss_Train:  [[ 13.19557109]] Loss_Validation:  [[ 11.0346373]]\n",
      "Loop 5593 Loss_Train:  [[ 13.19557062]] Loss_Validation:  [[ 11.03464945]]\n",
      "Loop 5594 Loss_Train:  [[ 13.19557016]] Loss_Validation:  [[ 11.0346616]]\n",
      "Loop 5595 Loss_Train:  [[ 13.19556969]] Loss_Validation:  [[ 11.03467373]]\n",
      "Loop 5596 Loss_Train:  [[ 13.19556923]] Loss_Validation:  [[ 11.03468586]]\n",
      "Loop 5597 Loss_Train:  [[ 13.19556876]] Loss_Validation:  [[ 11.03469798]]\n",
      "Loop 5598 Loss_Train:  [[ 13.1955683]] Loss_Validation:  [[ 11.0347101]]\n",
      "Loop 5599 Loss_Train:  [[ 13.19556784]] Loss_Validation:  [[ 11.0347222]]\n",
      "Loop 5600 Loss_Train:  [[ 13.19556737]] Loss_Validation:  [[ 11.0347343]]\n",
      "Loop 5601 Loss_Train:  [[ 13.19556691]] Loss_Validation:  [[ 11.03474638]]\n",
      "Loop 5602 Loss_Train:  [[ 13.19556645]] Loss_Validation:  [[ 11.03475846]]\n",
      "Loop 5603 Loss_Train:  [[ 13.19556599]] Loss_Validation:  [[ 11.03477053]]\n",
      "Loop 5604 Loss_Train:  [[ 13.19556553]] Loss_Validation:  [[ 11.0347826]]\n",
      "Loop 5605 Loss_Train:  [[ 13.19556507]] Loss_Validation:  [[ 11.03479465]]\n",
      "Loop 5606 Loss_Train:  [[ 13.19556461]] Loss_Validation:  [[ 11.0348067]]\n",
      "Loop 5607 Loss_Train:  [[ 13.19556416]] Loss_Validation:  [[ 11.03481874]]\n",
      "Loop 5608 Loss_Train:  [[ 13.1955637]] Loss_Validation:  [[ 11.03483077]]\n",
      "Loop 5609 Loss_Train:  [[ 13.19556324]] Loss_Validation:  [[ 11.03484279]]\n",
      "Loop 5610 Loss_Train:  [[ 13.19556279]] Loss_Validation:  [[ 11.0348548]]\n",
      "Loop 5611 Loss_Train:  [[ 13.19556233]] Loss_Validation:  [[ 11.03486681]]\n",
      "Loop 5612 Loss_Train:  [[ 13.19556188]] Loss_Validation:  [[ 11.0348788]]\n",
      "Loop 5613 Loss_Train:  [[ 13.19556142]] Loss_Validation:  [[ 11.03489079]]\n",
      "Loop 5614 Loss_Train:  [[ 13.19556097]] Loss_Validation:  [[ 11.03490277]]\n",
      "Loop 5615 Loss_Train:  [[ 13.19556052]] Loss_Validation:  [[ 11.03491474]]\n",
      "Loop 5616 Loss_Train:  [[ 13.19556007]] Loss_Validation:  [[ 11.03492671]]\n",
      "Loop 5617 Loss_Train:  [[ 13.19555962]] Loss_Validation:  [[ 11.03493866]]\n",
      "Loop 5618 Loss_Train:  [[ 13.19555917]] Loss_Validation:  [[ 11.03495061]]\n",
      "Loop 5619 Loss_Train:  [[ 13.19555872]] Loss_Validation:  [[ 11.03496255]]\n",
      "Loop 5620 Loss_Train:  [[ 13.19555827]] Loss_Validation:  [[ 11.03497448]]\n",
      "Loop 5621 Loss_Train:  [[ 13.19555782]] Loss_Validation:  [[ 11.0349864]]\n",
      "Loop 5622 Loss_Train:  [[ 13.19555737]] Loss_Validation:  [[ 11.03499832]]\n",
      "Loop 5623 Loss_Train:  [[ 13.19555693]] Loss_Validation:  [[ 11.03501023]]\n",
      "Loop 5624 Loss_Train:  [[ 13.19555648]] Loss_Validation:  [[ 11.03502212]]\n",
      "Loop 5625 Loss_Train:  [[ 13.19555603]] Loss_Validation:  [[ 11.03503401]]\n",
      "Loop 5626 Loss_Train:  [[ 13.19555559]] Loss_Validation:  [[ 11.0350459]]\n",
      "Loop 5627 Loss_Train:  [[ 13.19555514]] Loss_Validation:  [[ 11.03505777]]\n",
      "Loop 5628 Loss_Train:  [[ 13.1955547]] Loss_Validation:  [[ 11.03506964]]\n",
      "Loop 5629 Loss_Train:  [[ 13.19555426]] Loss_Validation:  [[ 11.03508149]]\n",
      "Loop 5630 Loss_Train:  [[ 13.19555381]] Loss_Validation:  [[ 11.03509334]]\n",
      "Loop 5631 Loss_Train:  [[ 13.19555337]] Loss_Validation:  [[ 11.03510519]]\n",
      "Loop 5632 Loss_Train:  [[ 13.19555293]] Loss_Validation:  [[ 11.03511702]]\n",
      "Loop 5633 Loss_Train:  [[ 13.19555249]] Loss_Validation:  [[ 11.03512884]]\n",
      "Loop 5634 Loss_Train:  [[ 13.19555205]] Loss_Validation:  [[ 11.03514066]]\n",
      "Loop 5635 Loss_Train:  [[ 13.19555161]] Loss_Validation:  [[ 11.03515247]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 5636 Loss_Train:  [[ 13.19555117]] Loss_Validation:  [[ 11.03516427]]\n",
      "Loop 5637 Loss_Train:  [[ 13.19555073]] Loss_Validation:  [[ 11.03517606]]\n",
      "Loop 5638 Loss_Train:  [[ 13.1955503]] Loss_Validation:  [[ 11.03518785]]\n",
      "Loop 5639 Loss_Train:  [[ 13.19554986]] Loss_Validation:  [[ 11.03519963]]\n",
      "Loop 5640 Loss_Train:  [[ 13.19554942]] Loss_Validation:  [[ 11.03521139]]\n",
      "Loop 5641 Loss_Train:  [[ 13.19554899]] Loss_Validation:  [[ 11.03522315]]\n",
      "Loop 5642 Loss_Train:  [[ 13.19554855]] Loss_Validation:  [[ 11.03523491]]\n",
      "Loop 5643 Loss_Train:  [[ 13.19554812]] Loss_Validation:  [[ 11.03524665]]\n",
      "Loop 5644 Loss_Train:  [[ 13.19554769]] Loss_Validation:  [[ 11.03525839]]\n",
      "Loop 5645 Loss_Train:  [[ 13.19554725]] Loss_Validation:  [[ 11.03527012]]\n",
      "Loop 5646 Loss_Train:  [[ 13.19554682]] Loss_Validation:  [[ 11.03528184]]\n",
      "Loop 5647 Loss_Train:  [[ 13.19554639]] Loss_Validation:  [[ 11.03529355]]\n",
      "Loop 5648 Loss_Train:  [[ 13.19554596]] Loss_Validation:  [[ 11.03530525]]\n",
      "Loop 5649 Loss_Train:  [[ 13.19554553]] Loss_Validation:  [[ 11.03531695]]\n",
      "Loop 5650 Loss_Train:  [[ 13.1955451]] Loss_Validation:  [[ 11.03532864]]\n",
      "Loop 5651 Loss_Train:  [[ 13.19554467]] Loss_Validation:  [[ 11.03534032]]\n",
      "Loop 5652 Loss_Train:  [[ 13.19554424]] Loss_Validation:  [[ 11.03535199]]\n",
      "Loop 5653 Loss_Train:  [[ 13.19554381]] Loss_Validation:  [[ 11.03536365]]\n",
      "Loop 5654 Loss_Train:  [[ 13.19554339]] Loss_Validation:  [[ 11.03537531]]\n",
      "Loop 5655 Loss_Train:  [[ 13.19554296]] Loss_Validation:  [[ 11.03538696]]\n",
      "Loop 5656 Loss_Train:  [[ 13.19554253]] Loss_Validation:  [[ 11.0353986]]\n",
      "Loop 5657 Loss_Train:  [[ 13.19554211]] Loss_Validation:  [[ 11.03541023]]\n",
      "Loop 5658 Loss_Train:  [[ 13.19554168]] Loss_Validation:  [[ 11.03542186]]\n",
      "Loop 5659 Loss_Train:  [[ 13.19554126]] Loss_Validation:  [[ 11.03543347]]\n",
      "Loop 5660 Loss_Train:  [[ 13.19554083]] Loss_Validation:  [[ 11.03544508]]\n",
      "Loop 5661 Loss_Train:  [[ 13.19554041]] Loss_Validation:  [[ 11.03545668]]\n",
      "Loop 5662 Loss_Train:  [[ 13.19553999]] Loss_Validation:  [[ 11.03546827]]\n",
      "Loop 5663 Loss_Train:  [[ 13.19553957]] Loss_Validation:  [[ 11.03547986]]\n",
      "Loop 5664 Loss_Train:  [[ 13.19553915]] Loss_Validation:  [[ 11.03549144]]\n",
      "Loop 5665 Loss_Train:  [[ 13.19553873]] Loss_Validation:  [[ 11.035503]]\n",
      "Loop 5666 Loss_Train:  [[ 13.19553831]] Loss_Validation:  [[ 11.03551456]]\n",
      "Loop 5667 Loss_Train:  [[ 13.19553789]] Loss_Validation:  [[ 11.03552612]]\n",
      "Loop 5668 Loss_Train:  [[ 13.19553747]] Loss_Validation:  [[ 11.03553766]]\n",
      "Loop 5669 Loss_Train:  [[ 13.19553705]] Loss_Validation:  [[ 11.0355492]]\n",
      "Loop 5670 Loss_Train:  [[ 13.19553663]] Loss_Validation:  [[ 11.03556073]]\n",
      "Loop 5671 Loss_Train:  [[ 13.19553622]] Loss_Validation:  [[ 11.03557225]]\n",
      "Loop 5672 Loss_Train:  [[ 13.1955358]] Loss_Validation:  [[ 11.03558376]]\n",
      "Loop 5673 Loss_Train:  [[ 13.19553538]] Loss_Validation:  [[ 11.03559527]]\n",
      "Loop 5674 Loss_Train:  [[ 13.19553497]] Loss_Validation:  [[ 11.03560677]]\n",
      "Loop 5675 Loss_Train:  [[ 13.19553455]] Loss_Validation:  [[ 11.03561826]]\n",
      "Loop 5676 Loss_Train:  [[ 13.19553414]] Loss_Validation:  [[ 11.03562974]]\n",
      "Loop 5677 Loss_Train:  [[ 13.19553373]] Loss_Validation:  [[ 11.03564121]]\n",
      "Loop 5678 Loss_Train:  [[ 13.19553331]] Loss_Validation:  [[ 11.03565268]]\n",
      "Loop 5679 Loss_Train:  [[ 13.1955329]] Loss_Validation:  [[ 11.03566414]]\n",
      "Loop 5680 Loss_Train:  [[ 13.19553249]] Loss_Validation:  [[ 11.03567559]]\n",
      "Loop 5681 Loss_Train:  [[ 13.19553208]] Loss_Validation:  [[ 11.03568703]]\n",
      "Loop 5682 Loss_Train:  [[ 13.19553167]] Loss_Validation:  [[ 11.03569846]]\n",
      "Loop 5683 Loss_Train:  [[ 13.19553126]] Loss_Validation:  [[ 11.03570989]]\n",
      "Loop 5684 Loss_Train:  [[ 13.19553085]] Loss_Validation:  [[ 11.03572131]]\n",
      "Loop 5685 Loss_Train:  [[ 13.19553044]] Loss_Validation:  [[ 11.03573272]]\n",
      "Loop 5686 Loss_Train:  [[ 13.19553003]] Loss_Validation:  [[ 11.03574412]]\n",
      "Loop 5687 Loss_Train:  [[ 13.19552963]] Loss_Validation:  [[ 11.03575552]]\n",
      "Loop 5688 Loss_Train:  [[ 13.19552922]] Loss_Validation:  [[ 11.03576691]]\n",
      "Loop 5689 Loss_Train:  [[ 13.19552881]] Loss_Validation:  [[ 11.03577829]]\n",
      "Loop 5690 Loss_Train:  [[ 13.19552841]] Loss_Validation:  [[ 11.03578966]]\n",
      "Loop 5691 Loss_Train:  [[ 13.195528]] Loss_Validation:  [[ 11.03580102]]\n",
      "Loop 5692 Loss_Train:  [[ 13.1955276]] Loss_Validation:  [[ 11.03581238]]\n",
      "Loop 5693 Loss_Train:  [[ 13.1955272]] Loss_Validation:  [[ 11.03582373]]\n",
      "Loop 5694 Loss_Train:  [[ 13.19552679]] Loss_Validation:  [[ 11.03583507]]\n",
      "Loop 5695 Loss_Train:  [[ 13.19552639]] Loss_Validation:  [[ 11.0358464]]\n",
      "Loop 5696 Loss_Train:  [[ 13.19552599]] Loss_Validation:  [[ 11.03585773]]\n",
      "Loop 5697 Loss_Train:  [[ 13.19552559]] Loss_Validation:  [[ 11.03586905]]\n",
      "Loop 5698 Loss_Train:  [[ 13.19552519]] Loss_Validation:  [[ 11.03588036]]\n",
      "Loop 5699 Loss_Train:  [[ 13.19552479]] Loss_Validation:  [[ 11.03589166]]\n",
      "Loop 5700 Loss_Train:  [[ 13.19552439]] Loss_Validation:  [[ 11.03590295]]\n",
      "Loop 5701 Loss_Train:  [[ 13.19552399]] Loss_Validation:  [[ 11.03591424]]\n",
      "Loop 5702 Loss_Train:  [[ 13.19552359]] Loss_Validation:  [[ 11.03592552]]\n",
      "Loop 5703 Loss_Train:  [[ 13.19552319]] Loss_Validation:  [[ 11.03593679]]\n",
      "Loop 5704 Loss_Train:  [[ 13.19552279]] Loss_Validation:  [[ 11.03594805]]\n",
      "Loop 5705 Loss_Train:  [[ 13.1955224]] Loss_Validation:  [[ 11.03595931]]\n",
      "Loop 5706 Loss_Train:  [[ 13.195522]] Loss_Validation:  [[ 11.03597056]]\n",
      "Loop 5707 Loss_Train:  [[ 13.1955216]] Loss_Validation:  [[ 11.0359818]]\n",
      "Loop 5708 Loss_Train:  [[ 13.19552121]] Loss_Validation:  [[ 11.03599303]]\n",
      "Loop 5709 Loss_Train:  [[ 13.19552082]] Loss_Validation:  [[ 11.03600425]]\n",
      "Loop 5710 Loss_Train:  [[ 13.19552042]] Loss_Validation:  [[ 11.03601547]]\n",
      "Loop 5711 Loss_Train:  [[ 13.19552003]] Loss_Validation:  [[ 11.03602668]]\n",
      "Loop 5712 Loss_Train:  [[ 13.19551964]] Loss_Validation:  [[ 11.03603788]]\n",
      "Loop 5713 Loss_Train:  [[ 13.19551924]] Loss_Validation:  [[ 11.03604908]]\n",
      "Loop 5714 Loss_Train:  [[ 13.19551885]] Loss_Validation:  [[ 11.03606026]]\n",
      "Loop 5715 Loss_Train:  [[ 13.19551846]] Loss_Validation:  [[ 11.03607144]]\n",
      "Loop 5716 Loss_Train:  [[ 13.19551807]] Loss_Validation:  [[ 11.03608261]]\n",
      "Loop 5717 Loss_Train:  [[ 13.19551768]] Loss_Validation:  [[ 11.03609378]]\n",
      "Loop 5718 Loss_Train:  [[ 13.19551729]] Loss_Validation:  [[ 11.03610493]]\n",
      "Loop 5719 Loss_Train:  [[ 13.1955169]] Loss_Validation:  [[ 11.03611608]]\n",
      "Loop 5720 Loss_Train:  [[ 13.19551651]] Loss_Validation:  [[ 11.03612722]]\n",
      "Loop 5721 Loss_Train:  [[ 13.19551613]] Loss_Validation:  [[ 11.03613836]]\n",
      "Loop 5722 Loss_Train:  [[ 13.19551574]] Loss_Validation:  [[ 11.03614948]]\n",
      "Loop 5723 Loss_Train:  [[ 13.19551535]] Loss_Validation:  [[ 11.0361606]]\n",
      "Loop 5724 Loss_Train:  [[ 13.19551497]] Loss_Validation:  [[ 11.03617171]]\n",
      "Loop 5725 Loss_Train:  [[ 13.19551458]] Loss_Validation:  [[ 11.03618281]]\n",
      "Loop 5726 Loss_Train:  [[ 13.1955142]] Loss_Validation:  [[ 11.03619391]]\n",
      "Loop 5727 Loss_Train:  [[ 13.19551381]] Loss_Validation:  [[ 11.036205]]\n",
      "Loop 5728 Loss_Train:  [[ 13.19551343]] Loss_Validation:  [[ 11.03621607]]\n",
      "Loop 5729 Loss_Train:  [[ 13.19551304]] Loss_Validation:  [[ 11.03622715]]\n",
      "Loop 5730 Loss_Train:  [[ 13.19551266]] Loss_Validation:  [[ 11.03623821]]\n",
      "Loop 5731 Loss_Train:  [[ 13.19551228]] Loss_Validation:  [[ 11.03624927]]\n",
      "Loop 5732 Loss_Train:  [[ 13.1955119]] Loss_Validation:  [[ 11.03626032]]\n",
      "Loop 5733 Loss_Train:  [[ 13.19551152]] Loss_Validation:  [[ 11.03627136]]\n",
      "Loop 5734 Loss_Train:  [[ 13.19551114]] Loss_Validation:  [[ 11.03628239]]\n",
      "Loop 5735 Loss_Train:  [[ 13.19551076]] Loss_Validation:  [[ 11.03629342]]\n",
      "Loop 5736 Loss_Train:  [[ 13.19551038]] Loss_Validation:  [[ 11.03630444]]\n",
      "Loop 5737 Loss_Train:  [[ 13.19551]] Loss_Validation:  [[ 11.03631545]]\n",
      "Loop 5738 Loss_Train:  [[ 13.19550962]] Loss_Validation:  [[ 11.03632646]]\n",
      "Loop 5739 Loss_Train:  [[ 13.19550924]] Loss_Validation:  [[ 11.03633745]]\n",
      "Loop 5740 Loss_Train:  [[ 13.19550887]] Loss_Validation:  [[ 11.03634844]]\n",
      "Loop 5741 Loss_Train:  [[ 13.19550849]] Loss_Validation:  [[ 11.03635942]]\n",
      "Loop 5742 Loss_Train:  [[ 13.19550811]] Loss_Validation:  [[ 11.0363704]]\n",
      "Loop 5743 Loss_Train:  [[ 13.19550774]] Loss_Validation:  [[ 11.03638136]]\n",
      "Loop 5744 Loss_Train:  [[ 13.19550736]] Loss_Validation:  [[ 11.03639232]]\n",
      "Loop 5745 Loss_Train:  [[ 13.19550699]] Loss_Validation:  [[ 11.03640327]]\n",
      "Loop 5746 Loss_Train:  [[ 13.19550662]] Loss_Validation:  [[ 11.03641422]]\n",
      "Loop 5747 Loss_Train:  [[ 13.19550624]] Loss_Validation:  [[ 11.03642516]]\n",
      "Loop 5748 Loss_Train:  [[ 13.19550587]] Loss_Validation:  [[ 11.03643608]]\n",
      "Loop 5749 Loss_Train:  [[ 13.1955055]] Loss_Validation:  [[ 11.03644701]]\n",
      "Loop 5750 Loss_Train:  [[ 13.19550513]] Loss_Validation:  [[ 11.03645792]]\n",
      "Loop 5751 Loss_Train:  [[ 13.19550475]] Loss_Validation:  [[ 11.03646883]]\n",
      "Loop 5752 Loss_Train:  [[ 13.19550438]] Loss_Validation:  [[ 11.03647973]]\n",
      "Loop 5753 Loss_Train:  [[ 13.19550401]] Loss_Validation:  [[ 11.03649062]]\n",
      "Loop 5754 Loss_Train:  [[ 13.19550364]] Loss_Validation:  [[ 11.0365015]]\n",
      "Loop 5755 Loss_Train:  [[ 13.19550328]] Loss_Validation:  [[ 11.03651238]]\n",
      "Loop 5756 Loss_Train:  [[ 13.19550291]] Loss_Validation:  [[ 11.03652325]]\n",
      "Loop 5757 Loss_Train:  [[ 13.19550254]] Loss_Validation:  [[ 11.03653411]]\n",
      "Loop 5758 Loss_Train:  [[ 13.19550217]] Loss_Validation:  [[ 11.03654496]]\n",
      "Loop 5759 Loss_Train:  [[ 13.19550181]] Loss_Validation:  [[ 11.03655581]]\n",
      "Loop 5760 Loss_Train:  [[ 13.19550144]] Loss_Validation:  [[ 11.03656665]]\n",
      "Loop 5761 Loss_Train:  [[ 13.19550107]] Loss_Validation:  [[ 11.03657748]]\n",
      "Loop 5762 Loss_Train:  [[ 13.19550071]] Loss_Validation:  [[ 11.03658831]]\n",
      "Loop 5763 Loss_Train:  [[ 13.19550034]] Loss_Validation:  [[ 11.03659912]]\n",
      "Loop 5764 Loss_Train:  [[ 13.19549998]] Loss_Validation:  [[ 11.03660993]]\n",
      "Loop 5765 Loss_Train:  [[ 13.19549962]] Loss_Validation:  [[ 11.03662074]]\n",
      "Loop 5766 Loss_Train:  [[ 13.19549925]] Loss_Validation:  [[ 11.03663153]]\n",
      "Loop 5767 Loss_Train:  [[ 13.19549889]] Loss_Validation:  [[ 11.03664232]]\n",
      "Loop 5768 Loss_Train:  [[ 13.19549853]] Loss_Validation:  [[ 11.0366531]]\n",
      "Loop 5769 Loss_Train:  [[ 13.19549817]] Loss_Validation:  [[ 11.03666387]]\n",
      "Loop 5770 Loss_Train:  [[ 13.19549781]] Loss_Validation:  [[ 11.03667464]]\n",
      "Loop 5771 Loss_Train:  [[ 13.19549744]] Loss_Validation:  [[ 11.0366854]]\n",
      "Loop 5772 Loss_Train:  [[ 13.19549708]] Loss_Validation:  [[ 11.03669615]]\n",
      "Loop 5773 Loss_Train:  [[ 13.19549673]] Loss_Validation:  [[ 11.03670689]]\n",
      "Loop 5774 Loss_Train:  [[ 13.19549637]] Loss_Validation:  [[ 11.03671763]]\n",
      "Loop 5775 Loss_Train:  [[ 13.19549601]] Loss_Validation:  [[ 11.03672835]]\n",
      "Loop 5776 Loss_Train:  [[ 13.19549565]] Loss_Validation:  [[ 11.03673908]]\n",
      "Loop 5777 Loss_Train:  [[ 13.19549529]] Loss_Validation:  [[ 11.03674979]]\n",
      "Loop 5778 Loss_Train:  [[ 13.19549494]] Loss_Validation:  [[ 11.0367605]]\n",
      "Loop 5779 Loss_Train:  [[ 13.19549458]] Loss_Validation:  [[ 11.0367712]]\n",
      "Loop 5780 Loss_Train:  [[ 13.19549422]] Loss_Validation:  [[ 11.03678189]]\n",
      "Loop 5781 Loss_Train:  [[ 13.19549387]] Loss_Validation:  [[ 11.03679257]]\n",
      "Loop 5782 Loss_Train:  [[ 13.19549351]] Loss_Validation:  [[ 11.03680325]]\n",
      "Loop 5783 Loss_Train:  [[ 13.19549316]] Loss_Validation:  [[ 11.03681392]]\n",
      "Loop 5784 Loss_Train:  [[ 13.19549281]] Loss_Validation:  [[ 11.03682458]]\n",
      "Loop 5785 Loss_Train:  [[ 13.19549245]] Loss_Validation:  [[ 11.03683524]]\n",
      "Loop 5786 Loss_Train:  [[ 13.1954921]] Loss_Validation:  [[ 11.03684589]]\n",
      "Loop 5787 Loss_Train:  [[ 13.19549175]] Loss_Validation:  [[ 11.03685653]]\n",
      "Loop 5788 Loss_Train:  [[ 13.1954914]] Loss_Validation:  [[ 11.03686716]]\n",
      "Loop 5789 Loss_Train:  [[ 13.19549104]] Loss_Validation:  [[ 11.03687779]]\n",
      "Loop 5790 Loss_Train:  [[ 13.19549069]] Loss_Validation:  [[ 11.03688841]]\n",
      "Loop 5791 Loss_Train:  [[ 13.19549034]] Loss_Validation:  [[ 11.03689902]]\n",
      "Loop 5792 Loss_Train:  [[ 13.19548999]] Loss_Validation:  [[ 11.03690962]]\n",
      "Loop 5793 Loss_Train:  [[ 13.19548965]] Loss_Validation:  [[ 11.03692022]]\n",
      "Loop 5794 Loss_Train:  [[ 13.1954893]] Loss_Validation:  [[ 11.03693081]]\n",
      "Loop 5795 Loss_Train:  [[ 13.19548895]] Loss_Validation:  [[ 11.03694139]]\n",
      "Loop 5796 Loss_Train:  [[ 13.1954886]] Loss_Validation:  [[ 11.03695197]]\n",
      "Loop 5797 Loss_Train:  [[ 13.19548825]] Loss_Validation:  [[ 11.03696254]]\n",
      "Loop 5798 Loss_Train:  [[ 13.19548791]] Loss_Validation:  [[ 11.0369731]]\n",
      "Loop 5799 Loss_Train:  [[ 13.19548756]] Loss_Validation:  [[ 11.03698365]]\n",
      "Loop 5800 Loss_Train:  [[ 13.19548722]] Loss_Validation:  [[ 11.0369942]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 5801 Loss_Train:  [[ 13.19548687]] Loss_Validation:  [[ 11.03700474]]\n",
      "Loop 5802 Loss_Train:  [[ 13.19548653]] Loss_Validation:  [[ 11.03701527]]\n",
      "Loop 5803 Loss_Train:  [[ 13.19548618]] Loss_Validation:  [[ 11.03702579]]\n",
      "Loop 5804 Loss_Train:  [[ 13.19548584]] Loss_Validation:  [[ 11.03703631]]\n",
      "Loop 5805 Loss_Train:  [[ 13.19548549]] Loss_Validation:  [[ 11.03704682]]\n",
      "Loop 5806 Loss_Train:  [[ 13.19548515]] Loss_Validation:  [[ 11.03705733]]\n",
      "Loop 5807 Loss_Train:  [[ 13.19548481]] Loss_Validation:  [[ 11.03706782]]\n",
      "Loop 5808 Loss_Train:  [[ 13.19548447]] Loss_Validation:  [[ 11.03707831]]\n",
      "Loop 5809 Loss_Train:  [[ 13.19548413]] Loss_Validation:  [[ 11.03708879]]\n",
      "Loop 5810 Loss_Train:  [[ 13.19548379]] Loss_Validation:  [[ 11.03709927]]\n",
      "Loop 5811 Loss_Train:  [[ 13.19548345]] Loss_Validation:  [[ 11.03710973]]\n",
      "Loop 5812 Loss_Train:  [[ 13.19548311]] Loss_Validation:  [[ 11.03712019]]\n",
      "Loop 5813 Loss_Train:  [[ 13.19548277]] Loss_Validation:  [[ 11.03713065]]\n",
      "Loop 5814 Loss_Train:  [[ 13.19548243]] Loss_Validation:  [[ 11.03714109]]\n",
      "Loop 5815 Loss_Train:  [[ 13.19548209]] Loss_Validation:  [[ 11.03715153]]\n",
      "Loop 5816 Loss_Train:  [[ 13.19548175]] Loss_Validation:  [[ 11.03716196]]\n",
      "Loop 5817 Loss_Train:  [[ 13.19548142]] Loss_Validation:  [[ 11.03717239]]\n",
      "Loop 5818 Loss_Train:  [[ 13.19548108]] Loss_Validation:  [[ 11.03718281]]\n",
      "Loop 5819 Loss_Train:  [[ 13.19548074]] Loss_Validation:  [[ 11.03719322]]\n",
      "Loop 5820 Loss_Train:  [[ 13.19548041]] Loss_Validation:  [[ 11.03720362]]\n",
      "Loop 5821 Loss_Train:  [[ 13.19548007]] Loss_Validation:  [[ 11.03721401]]\n",
      "Loop 5822 Loss_Train:  [[ 13.19547974]] Loss_Validation:  [[ 11.0372244]]\n",
      "Loop 5823 Loss_Train:  [[ 13.1954794]] Loss_Validation:  [[ 11.03723479]]\n",
      "Loop 5824 Loss_Train:  [[ 13.19547907]] Loss_Validation:  [[ 11.03724516]]\n",
      "Loop 5825 Loss_Train:  [[ 13.19547874]] Loss_Validation:  [[ 11.03725553]]\n",
      "Loop 5826 Loss_Train:  [[ 13.1954784]] Loss_Validation:  [[ 11.03726589]]\n",
      "Loop 5827 Loss_Train:  [[ 13.19547807]] Loss_Validation:  [[ 11.03727624]]\n",
      "Loop 5828 Loss_Train:  [[ 13.19547774]] Loss_Validation:  [[ 11.03728659]]\n",
      "Loop 5829 Loss_Train:  [[ 13.19547741]] Loss_Validation:  [[ 11.03729693]]\n",
      "Loop 5830 Loss_Train:  [[ 13.19547708]] Loss_Validation:  [[ 11.03730726]]\n",
      "Loop 5831 Loss_Train:  [[ 13.19547675]] Loss_Validation:  [[ 11.03731758]]\n",
      "Loop 5832 Loss_Train:  [[ 13.19547642]] Loss_Validation:  [[ 11.0373279]]\n",
      "Loop 5833 Loss_Train:  [[ 13.19547609]] Loss_Validation:  [[ 11.03733821]]\n",
      "Loop 5834 Loss_Train:  [[ 13.19547576]] Loss_Validation:  [[ 11.03734852]]\n",
      "Loop 5835 Loss_Train:  [[ 13.19547543]] Loss_Validation:  [[ 11.03735881]]\n",
      "Loop 5836 Loss_Train:  [[ 13.1954751]] Loss_Validation:  [[ 11.0373691]]\n",
      "Loop 5837 Loss_Train:  [[ 13.19547477]] Loss_Validation:  [[ 11.03737939]]\n",
      "Loop 5838 Loss_Train:  [[ 13.19547445]] Loss_Validation:  [[ 11.03738966]]\n",
      "Loop 5839 Loss_Train:  [[ 13.19547412]] Loss_Validation:  [[ 11.03739993]]\n",
      "Loop 5840 Loss_Train:  [[ 13.19547379]] Loss_Validation:  [[ 11.03741019]]\n",
      "Loop 5841 Loss_Train:  [[ 13.19547347]] Loss_Validation:  [[ 11.03742045]]\n",
      "Loop 5842 Loss_Train:  [[ 13.19547314]] Loss_Validation:  [[ 11.03743069]]\n",
      "Loop 5843 Loss_Train:  [[ 13.19547282]] Loss_Validation:  [[ 11.03744093]]\n",
      "Loop 5844 Loss_Train:  [[ 13.19547249]] Loss_Validation:  [[ 11.03745117]]\n",
      "Loop 5845 Loss_Train:  [[ 13.19547217]] Loss_Validation:  [[ 11.03746139]]\n",
      "Loop 5846 Loss_Train:  [[ 13.19547185]] Loss_Validation:  [[ 11.03747161]]\n",
      "Loop 5847 Loss_Train:  [[ 13.19547152]] Loss_Validation:  [[ 11.03748183]]\n",
      "Loop 5848 Loss_Train:  [[ 13.1954712]] Loss_Validation:  [[ 11.03749203]]\n",
      "Loop 5849 Loss_Train:  [[ 13.19547088]] Loss_Validation:  [[ 11.03750223]]\n",
      "Loop 5850 Loss_Train:  [[ 13.19547056]] Loss_Validation:  [[ 11.03751242]]\n",
      "Loop 5851 Loss_Train:  [[ 13.19547024]] Loss_Validation:  [[ 11.03752261]]\n",
      "Loop 5852 Loss_Train:  [[ 13.19546992]] Loss_Validation:  [[ 11.03753278]]\n",
      "Loop 5853 Loss_Train:  [[ 13.1954696]] Loss_Validation:  [[ 11.03754295]]\n",
      "Loop 5854 Loss_Train:  [[ 13.19546928]] Loss_Validation:  [[ 11.03755312]]\n",
      "Loop 5855 Loss_Train:  [[ 13.19546896]] Loss_Validation:  [[ 11.03756327]]\n",
      "Loop 5856 Loss_Train:  [[ 13.19546864]] Loss_Validation:  [[ 11.03757342]]\n",
      "Loop 5857 Loss_Train:  [[ 13.19546832]] Loss_Validation:  [[ 11.03758357]]\n",
      "Loop 5858 Loss_Train:  [[ 13.195468]] Loss_Validation:  [[ 11.0375937]]\n",
      "Loop 5859 Loss_Train:  [[ 13.19546769]] Loss_Validation:  [[ 11.03760383]]\n",
      "Loop 5860 Loss_Train:  [[ 13.19546737]] Loss_Validation:  [[ 11.03761395]]\n",
      "Loop 5861 Loss_Train:  [[ 13.19546705]] Loss_Validation:  [[ 11.03762407]]\n",
      "Loop 5862 Loss_Train:  [[ 13.19546674]] Loss_Validation:  [[ 11.03763418]]\n",
      "Loop 5863 Loss_Train:  [[ 13.19546642]] Loss_Validation:  [[ 11.03764428]]\n",
      "Loop 5864 Loss_Train:  [[ 13.19546611]] Loss_Validation:  [[ 11.03765437]]\n",
      "Loop 5865 Loss_Train:  [[ 13.19546579]] Loss_Validation:  [[ 11.03766446]]\n",
      "Loop 5866 Loss_Train:  [[ 13.19546548]] Loss_Validation:  [[ 11.03767454]]\n",
      "Loop 5867 Loss_Train:  [[ 13.19546517]] Loss_Validation:  [[ 11.03768461]]\n",
      "Loop 5868 Loss_Train:  [[ 13.19546485]] Loss_Validation:  [[ 11.03769468]]\n",
      "Loop 5869 Loss_Train:  [[ 13.19546454]] Loss_Validation:  [[ 11.03770474]]\n",
      "Loop 5870 Loss_Train:  [[ 13.19546423]] Loss_Validation:  [[ 11.03771479]]\n",
      "Loop 5871 Loss_Train:  [[ 13.19546392]] Loss_Validation:  [[ 11.03772484]]\n",
      "Loop 5872 Loss_Train:  [[ 13.19546361]] Loss_Validation:  [[ 11.03773488]]\n",
      "Loop 5873 Loss_Train:  [[ 13.19546329]] Loss_Validation:  [[ 11.03774491]]\n",
      "Loop 5874 Loss_Train:  [[ 13.19546298]] Loss_Validation:  [[ 11.03775493]]\n",
      "Loop 5875 Loss_Train:  [[ 13.19546267]] Loss_Validation:  [[ 11.03776495]]\n",
      "Loop 5876 Loss_Train:  [[ 13.19546236]] Loss_Validation:  [[ 11.03777496]]\n",
      "Loop 5877 Loss_Train:  [[ 13.19546206]] Loss_Validation:  [[ 11.03778497]]\n",
      "Loop 5878 Loss_Train:  [[ 13.19546175]] Loss_Validation:  [[ 11.03779497]]\n",
      "Loop 5879 Loss_Train:  [[ 13.19546144]] Loss_Validation:  [[ 11.03780496]]\n",
      "Loop 5880 Loss_Train:  [[ 13.19546113]] Loss_Validation:  [[ 11.03781494]]\n",
      "Loop 5881 Loss_Train:  [[ 13.19546082]] Loss_Validation:  [[ 11.03782492]]\n",
      "Loop 5882 Loss_Train:  [[ 13.19546052]] Loss_Validation:  [[ 11.03783489]]\n",
      "Loop 5883 Loss_Train:  [[ 13.19546021]] Loss_Validation:  [[ 11.03784485]]\n",
      "Loop 5884 Loss_Train:  [[ 13.1954599]] Loss_Validation:  [[ 11.03785481]]\n",
      "Loop 5885 Loss_Train:  [[ 13.1954596]] Loss_Validation:  [[ 11.03786476]]\n",
      "Loop 5886 Loss_Train:  [[ 13.19545929]] Loss_Validation:  [[ 11.03787471]]\n",
      "Loop 5887 Loss_Train:  [[ 13.19545899]] Loss_Validation:  [[ 11.03788464]]\n",
      "Loop 5888 Loss_Train:  [[ 13.19545869]] Loss_Validation:  [[ 11.03789457]]\n",
      "Loop 5889 Loss_Train:  [[ 13.19545838]] Loss_Validation:  [[ 11.03790449]]\n",
      "Loop 5890 Loss_Train:  [[ 13.19545808]] Loss_Validation:  [[ 11.03791441]]\n",
      "Loop 5891 Loss_Train:  [[ 13.19545778]] Loss_Validation:  [[ 11.03792432]]\n",
      "Loop 5892 Loss_Train:  [[ 13.19545747]] Loss_Validation:  [[ 11.03793422]]\n",
      "Loop 5893 Loss_Train:  [[ 13.19545717]] Loss_Validation:  [[ 11.03794412]]\n",
      "Loop 5894 Loss_Train:  [[ 13.19545687]] Loss_Validation:  [[ 11.03795401]]\n",
      "Loop 5895 Loss_Train:  [[ 13.19545657]] Loss_Validation:  [[ 11.03796389]]\n",
      "Loop 5896 Loss_Train:  [[ 13.19545627]] Loss_Validation:  [[ 11.03797377]]\n",
      "Loop 5897 Loss_Train:  [[ 13.19545597]] Loss_Validation:  [[ 11.03798363]]\n",
      "Loop 5898 Loss_Train:  [[ 13.19545567]] Loss_Validation:  [[ 11.0379935]]\n",
      "Loop 5899 Loss_Train:  [[ 13.19545537]] Loss_Validation:  [[ 11.03800335]]\n",
      "Loop 5900 Loss_Train:  [[ 13.19545507]] Loss_Validation:  [[ 11.0380132]]\n",
      "Loop 5901 Loss_Train:  [[ 13.19545477]] Loss_Validation:  [[ 11.03802304]]\n",
      "Loop 5902 Loss_Train:  [[ 13.19545447]] Loss_Validation:  [[ 11.03803288]]\n",
      "Loop 5903 Loss_Train:  [[ 13.19545418]] Loss_Validation:  [[ 11.0380427]]\n",
      "Loop 5904 Loss_Train:  [[ 13.19545388]] Loss_Validation:  [[ 11.03805253]]\n",
      "Loop 5905 Loss_Train:  [[ 13.19545358]] Loss_Validation:  [[ 11.03806234]]\n",
      "Loop 5906 Loss_Train:  [[ 13.19545329]] Loss_Validation:  [[ 11.03807215]]\n",
      "Loop 5907 Loss_Train:  [[ 13.19545299]] Loss_Validation:  [[ 11.03808195]]\n",
      "Loop 5908 Loss_Train:  [[ 13.19545269]] Loss_Validation:  [[ 11.03809175]]\n",
      "Loop 5909 Loss_Train:  [[ 13.1954524]] Loss_Validation:  [[ 11.03810153]]\n",
      "Loop 5910 Loss_Train:  [[ 13.1954521]] Loss_Validation:  [[ 11.03811131]]\n",
      "Loop 5911 Loss_Train:  [[ 13.19545181]] Loss_Validation:  [[ 11.03812109]]\n",
      "Loop 5912 Loss_Train:  [[ 13.19545152]] Loss_Validation:  [[ 11.03813086]]\n",
      "Loop 5913 Loss_Train:  [[ 13.19545122]] Loss_Validation:  [[ 11.03814062]]\n",
      "Loop 5914 Loss_Train:  [[ 13.19545093]] Loss_Validation:  [[ 11.03815037]]\n",
      "Loop 5915 Loss_Train:  [[ 13.19545064]] Loss_Validation:  [[ 11.03816012]]\n",
      "Loop 5916 Loss_Train:  [[ 13.19545035]] Loss_Validation:  [[ 11.03816986]]\n",
      "Loop 5917 Loss_Train:  [[ 13.19545005]] Loss_Validation:  [[ 11.0381796]]\n",
      "Loop 5918 Loss_Train:  [[ 13.19544976]] Loss_Validation:  [[ 11.03818932]]\n",
      "Loop 5919 Loss_Train:  [[ 13.19544947]] Loss_Validation:  [[ 11.03819905]]\n",
      "Loop 5920 Loss_Train:  [[ 13.19544918]] Loss_Validation:  [[ 11.03820876]]\n",
      "Loop 5921 Loss_Train:  [[ 13.19544889]] Loss_Validation:  [[ 11.03821847]]\n",
      "Loop 5922 Loss_Train:  [[ 13.1954486]] Loss_Validation:  [[ 11.03822817]]\n",
      "Loop 5923 Loss_Train:  [[ 13.19544831]] Loss_Validation:  [[ 11.03823786]]\n",
      "Loop 5924 Loss_Train:  [[ 13.19544803]] Loss_Validation:  [[ 11.03824755]]\n",
      "Loop 5925 Loss_Train:  [[ 13.19544774]] Loss_Validation:  [[ 11.03825723]]\n",
      "Loop 5926 Loss_Train:  [[ 13.19544745]] Loss_Validation:  [[ 11.03826691]]\n",
      "Loop 5927 Loss_Train:  [[ 13.19544716]] Loss_Validation:  [[ 11.03827658]]\n",
      "Loop 5928 Loss_Train:  [[ 13.19544687]] Loss_Validation:  [[ 11.03828624]]\n",
      "Loop 5929 Loss_Train:  [[ 13.19544659]] Loss_Validation:  [[ 11.03829589]]\n",
      "Loop 5930 Loss_Train:  [[ 13.1954463]] Loss_Validation:  [[ 11.03830554]]\n",
      "Loop 5931 Loss_Train:  [[ 13.19544602]] Loss_Validation:  [[ 11.03831518]]\n",
      "Loop 5932 Loss_Train:  [[ 13.19544573]] Loss_Validation:  [[ 11.03832482]]\n",
      "Loop 5933 Loss_Train:  [[ 13.19544545]] Loss_Validation:  [[ 11.03833445]]\n",
      "Loop 5934 Loss_Train:  [[ 13.19544516]] Loss_Validation:  [[ 11.03834407]]\n",
      "Loop 5935 Loss_Train:  [[ 13.19544488]] Loss_Validation:  [[ 11.03835368]]\n",
      "Loop 5936 Loss_Train:  [[ 13.19544459]] Loss_Validation:  [[ 11.03836329]]\n",
      "Loop 5937 Loss_Train:  [[ 13.19544431]] Loss_Validation:  [[ 11.03837289]]\n",
      "Loop 5938 Loss_Train:  [[ 13.19544403]] Loss_Validation:  [[ 11.03838249]]\n",
      "Loop 5939 Loss_Train:  [[ 13.19544374]] Loss_Validation:  [[ 11.03839208]]\n",
      "Loop 5940 Loss_Train:  [[ 13.19544346]] Loss_Validation:  [[ 11.03840166]]\n",
      "Loop 5941 Loss_Train:  [[ 13.19544318]] Loss_Validation:  [[ 11.03841124]]\n",
      "Loop 5942 Loss_Train:  [[ 13.1954429]] Loss_Validation:  [[ 11.03842081]]\n",
      "Loop 5943 Loss_Train:  [[ 13.19544262]] Loss_Validation:  [[ 11.03843037]]\n",
      "Loop 5944 Loss_Train:  [[ 13.19544234]] Loss_Validation:  [[ 11.03843993]]\n",
      "Loop 5945 Loss_Train:  [[ 13.19544206]] Loss_Validation:  [[ 11.03844947]]\n",
      "Loop 5946 Loss_Train:  [[ 13.19544178]] Loss_Validation:  [[ 11.03845902]]\n",
      "Loop 5947 Loss_Train:  [[ 13.1954415]] Loss_Validation:  [[ 11.03846855]]\n",
      "Loop 5948 Loss_Train:  [[ 13.19544122]] Loss_Validation:  [[ 11.03847808]]\n",
      "Loop 5949 Loss_Train:  [[ 13.19544094]] Loss_Validation:  [[ 11.03848761]]\n",
      "Loop 5950 Loss_Train:  [[ 13.19544066]] Loss_Validation:  [[ 11.03849713]]\n",
      "Loop 5951 Loss_Train:  [[ 13.19544039]] Loss_Validation:  [[ 11.03850664]]\n",
      "Loop 5952 Loss_Train:  [[ 13.19544011]] Loss_Validation:  [[ 11.03851614]]\n",
      "Loop 5953 Loss_Train:  [[ 13.19543983]] Loss_Validation:  [[ 11.03852564]]\n",
      "Loop 5954 Loss_Train:  [[ 13.19543956]] Loss_Validation:  [[ 11.03853513]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 5955 Loss_Train:  [[ 13.19543928]] Loss_Validation:  [[ 11.03854461]]\n",
      "Loop 5956 Loss_Train:  [[ 13.19543901]] Loss_Validation:  [[ 11.03855409]]\n",
      "Loop 5957 Loss_Train:  [[ 13.19543873]] Loss_Validation:  [[ 11.03856356]]\n",
      "Loop 5958 Loss_Train:  [[ 13.19543846]] Loss_Validation:  [[ 11.03857303]]\n",
      "Loop 5959 Loss_Train:  [[ 13.19543818]] Loss_Validation:  [[ 11.03858249]]\n",
      "Loop 5960 Loss_Train:  [[ 13.19543791]] Loss_Validation:  [[ 11.03859194]]\n",
      "Loop 5961 Loss_Train:  [[ 13.19543763]] Loss_Validation:  [[ 11.03860138]]\n",
      "Loop 5962 Loss_Train:  [[ 13.19543736]] Loss_Validation:  [[ 11.03861082]]\n",
      "Loop 5963 Loss_Train:  [[ 13.19543709]] Loss_Validation:  [[ 11.03862026]]\n",
      "Loop 5964 Loss_Train:  [[ 13.19543682]] Loss_Validation:  [[ 11.03862968]]\n",
      "Loop 5965 Loss_Train:  [[ 13.19543654]] Loss_Validation:  [[ 11.0386391]]\n",
      "Loop 5966 Loss_Train:  [[ 13.19543627]] Loss_Validation:  [[ 11.03864852]]\n",
      "Loop 5967 Loss_Train:  [[ 13.195436]] Loss_Validation:  [[ 11.03865792]]\n",
      "Loop 5968 Loss_Train:  [[ 13.19543573]] Loss_Validation:  [[ 11.03866732]]\n",
      "Loop 5969 Loss_Train:  [[ 13.19543546]] Loss_Validation:  [[ 11.03867672]]\n",
      "Loop 5970 Loss_Train:  [[ 13.19543519]] Loss_Validation:  [[ 11.03868611]]\n",
      "Loop 5971 Loss_Train:  [[ 13.19543492]] Loss_Validation:  [[ 11.03869549]]\n",
      "Loop 5972 Loss_Train:  [[ 13.19543465]] Loss_Validation:  [[ 11.03870486]]\n",
      "Loop 5973 Loss_Train:  [[ 13.19543438]] Loss_Validation:  [[ 11.03871423]]\n",
      "Loop 5974 Loss_Train:  [[ 13.19543411]] Loss_Validation:  [[ 11.03872359]]\n",
      "Loop 5975 Loss_Train:  [[ 13.19543384]] Loss_Validation:  [[ 11.03873295]]\n",
      "Loop 5976 Loss_Train:  [[ 13.19543358]] Loss_Validation:  [[ 11.0387423]]\n",
      "Loop 5977 Loss_Train:  [[ 13.19543331]] Loss_Validation:  [[ 11.03875164]]\n",
      "Loop 5978 Loss_Train:  [[ 13.19543304]] Loss_Validation:  [[ 11.03876098]]\n",
      "Loop 5979 Loss_Train:  [[ 13.19543278]] Loss_Validation:  [[ 11.03877031]]\n",
      "Loop 5980 Loss_Train:  [[ 13.19543251]] Loss_Validation:  [[ 11.03877963]]\n",
      "Loop 5981 Loss_Train:  [[ 13.19543224]] Loss_Validation:  [[ 11.03878895]]\n",
      "Loop 5982 Loss_Train:  [[ 13.19543198]] Loss_Validation:  [[ 11.03879826]]\n",
      "Loop 5983 Loss_Train:  [[ 13.19543171]] Loss_Validation:  [[ 11.03880756]]\n",
      "Loop 5984 Loss_Train:  [[ 13.19543145]] Loss_Validation:  [[ 11.03881686]]\n",
      "Loop 5985 Loss_Train:  [[ 13.19543119]] Loss_Validation:  [[ 11.03882615]]\n",
      "Loop 5986 Loss_Train:  [[ 13.19543092]] Loss_Validation:  [[ 11.03883544]]\n",
      "Loop 5987 Loss_Train:  [[ 13.19543066]] Loss_Validation:  [[ 11.03884472]]\n",
      "Loop 5988 Loss_Train:  [[ 13.1954304]] Loss_Validation:  [[ 11.03885399]]\n",
      "Loop 5989 Loss_Train:  [[ 13.19543013]] Loss_Validation:  [[ 11.03886326]]\n",
      "Loop 5990 Loss_Train:  [[ 13.19542987]] Loss_Validation:  [[ 11.03887252]]\n",
      "Loop 5991 Loss_Train:  [[ 13.19542961]] Loss_Validation:  [[ 11.03888177]]\n",
      "Loop 5992 Loss_Train:  [[ 13.19542935]] Loss_Validation:  [[ 11.03889102]]\n",
      "Loop 5993 Loss_Train:  [[ 13.19542909]] Loss_Validation:  [[ 11.03890026]]\n",
      "Loop 5994 Loss_Train:  [[ 13.19542882]] Loss_Validation:  [[ 11.03890949]]\n",
      "Loop 5995 Loss_Train:  [[ 13.19542856]] Loss_Validation:  [[ 11.03891872]]\n",
      "Loop 5996 Loss_Train:  [[ 13.1954283]] Loss_Validation:  [[ 11.03892794]]\n",
      "Loop 5997 Loss_Train:  [[ 13.19542804]] Loss_Validation:  [[ 11.03893716]]\n",
      "Loop 5998 Loss_Train:  [[ 13.19542779]] Loss_Validation:  [[ 11.03894637]]\n",
      "Loop 5999 Loss_Train:  [[ 13.19542753]] Loss_Validation:  [[ 11.03895557]]\n",
      "Loop 6000 Loss_Train:  [[ 13.19542727]] Loss_Validation:  [[ 11.03896477]]\n",
      "Loop 6001 Loss_Train:  [[ 13.19542701]] Loss_Validation:  [[ 11.03897396]]\n",
      "Loop 6002 Loss_Train:  [[ 13.19542675]] Loss_Validation:  [[ 11.03898314]]\n",
      "Loop 6003 Loss_Train:  [[ 13.19542649]] Loss_Validation:  [[ 11.03899232]]\n",
      "Loop 6004 Loss_Train:  [[ 13.19542624]] Loss_Validation:  [[ 11.03900149]]\n",
      "Loop 6005 Loss_Train:  [[ 13.19542598]] Loss_Validation:  [[ 11.03901066]]\n",
      "Loop 6006 Loss_Train:  [[ 13.19542572]] Loss_Validation:  [[ 11.03901982]]\n",
      "Loop 6007 Loss_Train:  [[ 13.19542547]] Loss_Validation:  [[ 11.03902897]]\n",
      "Loop 6008 Loss_Train:  [[ 13.19542521]] Loss_Validation:  [[ 11.03903812]]\n",
      "Loop 6009 Loss_Train:  [[ 13.19542496]] Loss_Validation:  [[ 11.03904726]]\n",
      "Loop 6010 Loss_Train:  [[ 13.1954247]] Loss_Validation:  [[ 11.03905639]]\n",
      "Loop 6011 Loss_Train:  [[ 13.19542445]] Loss_Validation:  [[ 11.03906552]]\n",
      "Loop 6012 Loss_Train:  [[ 13.19542419]] Loss_Validation:  [[ 11.03907464]]\n",
      "Loop 6013 Loss_Train:  [[ 13.19542394]] Loss_Validation:  [[ 11.03908376]]\n",
      "Loop 6014 Loss_Train:  [[ 13.19542369]] Loss_Validation:  [[ 11.03909286]]\n",
      "Loop 6015 Loss_Train:  [[ 13.19542343]] Loss_Validation:  [[ 11.03910197]]\n",
      "Loop 6016 Loss_Train:  [[ 13.19542318]] Loss_Validation:  [[ 11.03911106]]\n",
      "Loop 6017 Loss_Train:  [[ 13.19542293]] Loss_Validation:  [[ 11.03912015]]\n",
      "Loop 6018 Loss_Train:  [[ 13.19542268]] Loss_Validation:  [[ 11.03912924]]\n",
      "Loop 6019 Loss_Train:  [[ 13.19542243]] Loss_Validation:  [[ 11.03913832]]\n",
      "Loop 6020 Loss_Train:  [[ 13.19542218]] Loss_Validation:  [[ 11.03914739]]\n",
      "Loop 6021 Loss_Train:  [[ 13.19542192]] Loss_Validation:  [[ 11.03915645]]\n",
      "Loop 6022 Loss_Train:  [[ 13.19542167]] Loss_Validation:  [[ 11.03916551]]\n",
      "Loop 6023 Loss_Train:  [[ 13.19542142]] Loss_Validation:  [[ 11.03917457]]\n",
      "Loop 6024 Loss_Train:  [[ 13.19542117]] Loss_Validation:  [[ 11.03918361]]\n",
      "Loop 6025 Loss_Train:  [[ 13.19542093]] Loss_Validation:  [[ 11.03919265]]\n",
      "Loop 6026 Loss_Train:  [[ 13.19542068]] Loss_Validation:  [[ 11.03920169]]\n",
      "Loop 6027 Loss_Train:  [[ 13.19542043]] Loss_Validation:  [[ 11.03921072]]\n",
      "Loop 6028 Loss_Train:  [[ 13.19542018]] Loss_Validation:  [[ 11.03921974]]\n",
      "Loop 6029 Loss_Train:  [[ 13.19541993]] Loss_Validation:  [[ 11.03922876]]\n",
      "Loop 6030 Loss_Train:  [[ 13.19541968]] Loss_Validation:  [[ 11.03923777]]\n",
      "Loop 6031 Loss_Train:  [[ 13.19541944]] Loss_Validation:  [[ 11.03924677]]\n",
      "Loop 6032 Loss_Train:  [[ 13.19541919]] Loss_Validation:  [[ 11.03925577]]\n",
      "Loop 6033 Loss_Train:  [[ 13.19541894]] Loss_Validation:  [[ 11.03926476]]\n",
      "Loop 6034 Loss_Train:  [[ 13.1954187]] Loss_Validation:  [[ 11.03927374]]\n",
      "Loop 6035 Loss_Train:  [[ 13.19541845]] Loss_Validation:  [[ 11.03928272]]\n",
      "Loop 6036 Loss_Train:  [[ 13.19541821]] Loss_Validation:  [[ 11.0392917]]\n",
      "Loop 6037 Loss_Train:  [[ 13.19541796]] Loss_Validation:  [[ 11.03930066]]\n",
      "Loop 6038 Loss_Train:  [[ 13.19541772]] Loss_Validation:  [[ 11.03930962]]\n",
      "Loop 6039 Loss_Train:  [[ 13.19541747]] Loss_Validation:  [[ 11.03931858]]\n",
      "Loop 6040 Loss_Train:  [[ 13.19541723]] Loss_Validation:  [[ 11.03932753]]\n",
      "Loop 6041 Loss_Train:  [[ 13.19541698]] Loss_Validation:  [[ 11.03933647]]\n",
      "Loop 6042 Loss_Train:  [[ 13.19541674]] Loss_Validation:  [[ 11.03934541]]\n",
      "Loop 6043 Loss_Train:  [[ 13.1954165]] Loss_Validation:  [[ 11.03935434]]\n",
      "Loop 6044 Loss_Train:  [[ 13.19541626]] Loss_Validation:  [[ 11.03936326]]\n",
      "Loop 6045 Loss_Train:  [[ 13.19541601]] Loss_Validation:  [[ 11.03937218]]\n",
      "Loop 6046 Loss_Train:  [[ 13.19541577]] Loss_Validation:  [[ 11.03938109]]\n",
      "Loop 6047 Loss_Train:  [[ 13.19541553]] Loss_Validation:  [[ 11.03939]]\n",
      "Loop 6048 Loss_Train:  [[ 13.19541529]] Loss_Validation:  [[ 11.03939889]]\n",
      "Loop 6049 Loss_Train:  [[ 13.19541505]] Loss_Validation:  [[ 11.03940779]]\n",
      "Loop 6050 Loss_Train:  [[ 13.19541481]] Loss_Validation:  [[ 11.03941668]]\n",
      "Loop 6051 Loss_Train:  [[ 13.19541457]] Loss_Validation:  [[ 11.03942556]]\n",
      "Loop 6052 Loss_Train:  [[ 13.19541433]] Loss_Validation:  [[ 11.03943443]]\n",
      "Loop 6053 Loss_Train:  [[ 13.19541409]] Loss_Validation:  [[ 11.0394433]]\n",
      "Loop 6054 Loss_Train:  [[ 13.19541385]] Loss_Validation:  [[ 11.03945216]]\n",
      "Loop 6055 Loss_Train:  [[ 13.19541361]] Loss_Validation:  [[ 11.03946102]]\n",
      "Loop 6056 Loss_Train:  [[ 13.19541337]] Loss_Validation:  [[ 11.03946987]]\n",
      "Loop 6057 Loss_Train:  [[ 13.19541313]] Loss_Validation:  [[ 11.03947872]]\n",
      "Loop 6058 Loss_Train:  [[ 13.1954129]] Loss_Validation:  [[ 11.03948756]]\n",
      "Loop 6059 Loss_Train:  [[ 13.19541266]] Loss_Validation:  [[ 11.03949639]]\n",
      "Loop 6060 Loss_Train:  [[ 13.19541242]] Loss_Validation:  [[ 11.03950522]]\n",
      "Loop 6061 Loss_Train:  [[ 13.19541219]] Loss_Validation:  [[ 11.03951404]]\n",
      "Loop 6062 Loss_Train:  [[ 13.19541195]] Loss_Validation:  [[ 11.03952285]]\n",
      "Loop 6063 Loss_Train:  [[ 13.19541171]] Loss_Validation:  [[ 11.03953166]]\n",
      "Loop 6064 Loss_Train:  [[ 13.19541148]] Loss_Validation:  [[ 11.03954046]]\n",
      "Loop 6065 Loss_Train:  [[ 13.19541124]] Loss_Validation:  [[ 11.03954926]]\n",
      "Loop 6066 Loss_Train:  [[ 13.19541101]] Loss_Validation:  [[ 11.03955805]]\n",
      "Loop 6067 Loss_Train:  [[ 13.19541077]] Loss_Validation:  [[ 11.03956684]]\n",
      "Loop 6068 Loss_Train:  [[ 13.19541054]] Loss_Validation:  [[ 11.03957561]]\n",
      "Loop 6069 Loss_Train:  [[ 13.19541031]] Loss_Validation:  [[ 11.03958439]]\n",
      "Loop 6070 Loss_Train:  [[ 13.19541007]] Loss_Validation:  [[ 11.03959315]]\n",
      "Loop 6071 Loss_Train:  [[ 13.19540984]] Loss_Validation:  [[ 11.03960191]]\n",
      "Loop 6072 Loss_Train:  [[ 13.19540961]] Loss_Validation:  [[ 11.03961067]]\n",
      "Loop 6073 Loss_Train:  [[ 13.19540937]] Loss_Validation:  [[ 11.03961942]]\n",
      "Loop 6074 Loss_Train:  [[ 13.19540914]] Loss_Validation:  [[ 11.03962816]]\n",
      "Loop 6075 Loss_Train:  [[ 13.19540891]] Loss_Validation:  [[ 11.0396369]]\n",
      "Loop 6076 Loss_Train:  [[ 13.19540868]] Loss_Validation:  [[ 11.03964563]]\n",
      "Loop 6077 Loss_Train:  [[ 13.19540845]] Loss_Validation:  [[ 11.03965435]]\n",
      "Loop 6078 Loss_Train:  [[ 13.19540822]] Loss_Validation:  [[ 11.03966307]]\n",
      "Loop 6079 Loss_Train:  [[ 13.19540798]] Loss_Validation:  [[ 11.03967178]]\n",
      "Loop 6080 Loss_Train:  [[ 13.19540775]] Loss_Validation:  [[ 11.03968049]]\n",
      "Loop 6081 Loss_Train:  [[ 13.19540752]] Loss_Validation:  [[ 11.03968919]]\n",
      "Loop 6082 Loss_Train:  [[ 13.1954073]] Loss_Validation:  [[ 11.03969789]]\n",
      "Loop 6083 Loss_Train:  [[ 13.19540707]] Loss_Validation:  [[ 11.03970657]]\n",
      "Loop 6084 Loss_Train:  [[ 13.19540684]] Loss_Validation:  [[ 11.03971526]]\n",
      "Loop 6085 Loss_Train:  [[ 13.19540661]] Loss_Validation:  [[ 11.03972393]]\n",
      "Loop 6086 Loss_Train:  [[ 13.19540638]] Loss_Validation:  [[ 11.03973261]]\n",
      "Loop 6087 Loss_Train:  [[ 13.19540615]] Loss_Validation:  [[ 11.03974127]]\n",
      "Loop 6088 Loss_Train:  [[ 13.19540593]] Loss_Validation:  [[ 11.03974993]]\n",
      "Loop 6089 Loss_Train:  [[ 13.1954057]] Loss_Validation:  [[ 11.03975858]]\n",
      "Loop 6090 Loss_Train:  [[ 13.19540547]] Loss_Validation:  [[ 11.03976723]]\n",
      "Loop 6091 Loss_Train:  [[ 13.19540524]] Loss_Validation:  [[ 11.03977587]]\n",
      "Loop 6092 Loss_Train:  [[ 13.19540502]] Loss_Validation:  [[ 11.03978451]]\n",
      "Loop 6093 Loss_Train:  [[ 13.19540479]] Loss_Validation:  [[ 11.03979314]]\n",
      "Loop 6094 Loss_Train:  [[ 13.19540457]] Loss_Validation:  [[ 11.03980176]]\n",
      "Loop 6095 Loss_Train:  [[ 13.19540434]] Loss_Validation:  [[ 11.03981038]]\n",
      "Loop 6096 Loss_Train:  [[ 13.19540412]] Loss_Validation:  [[ 11.03981899]]\n",
      "Loop 6097 Loss_Train:  [[ 13.19540389]] Loss_Validation:  [[ 11.0398276]]\n",
      "Loop 6098 Loss_Train:  [[ 13.19540367]] Loss_Validation:  [[ 11.0398362]]\n",
      "Loop 6099 Loss_Train:  [[ 13.19540344]] Loss_Validation:  [[ 11.03984479]]\n",
      "Loop 6100 Loss_Train:  [[ 13.19540322]] Loss_Validation:  [[ 11.03985338]]\n",
      "Loop 6101 Loss_Train:  [[ 13.195403]] Loss_Validation:  [[ 11.03986196]]\n",
      "Loop 6102 Loss_Train:  [[ 13.19540277]] Loss_Validation:  [[ 11.03987054]]\n",
      "Loop 6103 Loss_Train:  [[ 13.19540255]] Loss_Validation:  [[ 11.03987911]]\n",
      "Loop 6104 Loss_Train:  [[ 13.19540233]] Loss_Validation:  [[ 11.03988768]]\n",
      "Loop 6105 Loss_Train:  [[ 13.19540211]] Loss_Validation:  [[ 11.03989624]]\n",
      "Loop 6106 Loss_Train:  [[ 13.19540189]] Loss_Validation:  [[ 11.03990479]]\n",
      "Loop 6107 Loss_Train:  [[ 13.19540166]] Loss_Validation:  [[ 11.03991334]]\n",
      "Loop 6108 Loss_Train:  [[ 13.19540144]] Loss_Validation:  [[ 11.03992188]]\n",
      "Loop 6109 Loss_Train:  [[ 13.19540122]] Loss_Validation:  [[ 11.03993041]]\n",
      "Loop 6110 Loss_Train:  [[ 13.195401]] Loss_Validation:  [[ 11.03993894]]\n",
      "Loop 6111 Loss_Train:  [[ 13.19540078]] Loss_Validation:  [[ 11.03994747]]\n",
      "Loop 6112 Loss_Train:  [[ 13.19540056]] Loss_Validation:  [[ 11.03995599]]\n",
      "Loop 6113 Loss_Train:  [[ 13.19540034]] Loss_Validation:  [[ 11.0399645]]\n",
      "Loop 6114 Loss_Train:  [[ 13.19540012]] Loss_Validation:  [[ 11.039973]]\n",
      "Loop 6115 Loss_Train:  [[ 13.1953999]] Loss_Validation:  [[ 11.03998151]]\n",
      "Loop 6116 Loss_Train:  [[ 13.19539969]] Loss_Validation:  [[ 11.03999]]\n",
      "Loop 6117 Loss_Train:  [[ 13.19539947]] Loss_Validation:  [[ 11.03999849]]\n",
      "Loop 6118 Loss_Train:  [[ 13.19539925]] Loss_Validation:  [[ 11.04000697]]\n",
      "Loop 6119 Loss_Train:  [[ 13.19539903]] Loss_Validation:  [[ 11.04001545]]\n",
      "Loop 6120 Loss_Train:  [[ 13.19539881]] Loss_Validation:  [[ 11.04002392]]\n",
      "Loop 6121 Loss_Train:  [[ 13.1953986]] Loss_Validation:  [[ 11.04003239]]\n",
      "Loop 6122 Loss_Train:  [[ 13.19539838]] Loss_Validation:  [[ 11.04004085]]\n",
      "Loop 6123 Loss_Train:  [[ 13.19539817]] Loss_Validation:  [[ 11.0400493]]\n",
      "Loop 6124 Loss_Train:  [[ 13.19539795]] Loss_Validation:  [[ 11.04005775]]\n",
      "Loop 6125 Loss_Train:  [[ 13.19539773]] Loss_Validation:  [[ 11.04006619]]\n",
      "Loop 6126 Loss_Train:  [[ 13.19539752]] Loss_Validation:  [[ 11.04007463]]\n",
      "Loop 6127 Loss_Train:  [[ 13.1953973]] Loss_Validation:  [[ 11.04008306]]\n",
      "Loop 6128 Loss_Train:  [[ 13.19539709]] Loss_Validation:  [[ 11.04009149]]\n",
      "Loop 6129 Loss_Train:  [[ 13.19539687]] Loss_Validation:  [[ 11.04009991]]\n",
      "Loop 6130 Loss_Train:  [[ 13.19539666]] Loss_Validation:  [[ 11.04010832]]\n",
      "Loop 6131 Loss_Train:  [[ 13.19539645]] Loss_Validation:  [[ 11.04011673]]\n",
      "Loop 6132 Loss_Train:  [[ 13.19539623]] Loss_Validation:  [[ 11.04012513]]\n",
      "Loop 6133 Loss_Train:  [[ 13.19539602]] Loss_Validation:  [[ 11.04013353]]\n",
      "Loop 6134 Loss_Train:  [[ 13.19539581]] Loss_Validation:  [[ 11.04014192]]\n",
      "Loop 6135 Loss_Train:  [[ 13.19539559]] Loss_Validation:  [[ 11.0401503]]\n",
      "Loop 6136 Loss_Train:  [[ 13.19539538]] Loss_Validation:  [[ 11.04015868]]\n",
      "Loop 6137 Loss_Train:  [[ 13.19539517]] Loss_Validation:  [[ 11.04016706]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 6138 Loss_Train:  [[ 13.19539496]] Loss_Validation:  [[ 11.04017543]]\n",
      "Loop 6139 Loss_Train:  [[ 13.19539475]] Loss_Validation:  [[ 11.04018379]]\n",
      "Loop 6140 Loss_Train:  [[ 13.19539454]] Loss_Validation:  [[ 11.04019214]]\n",
      "Loop 6141 Loss_Train:  [[ 13.19539432]] Loss_Validation:  [[ 11.04020049]]\n",
      "Loop 6142 Loss_Train:  [[ 13.19539411]] Loss_Validation:  [[ 11.04020884]]\n",
      "Loop 6143 Loss_Train:  [[ 13.1953939]] Loss_Validation:  [[ 11.04021718]]\n",
      "Loop 6144 Loss_Train:  [[ 13.19539369]] Loss_Validation:  [[ 11.04022551]]\n",
      "Loop 6145 Loss_Train:  [[ 13.19539348]] Loss_Validation:  [[ 11.04023384]]\n",
      "Loop 6146 Loss_Train:  [[ 13.19539328]] Loss_Validation:  [[ 11.04024216]]\n",
      "Loop 6147 Loss_Train:  [[ 13.19539307]] Loss_Validation:  [[ 11.04025048]]\n",
      "Loop 6148 Loss_Train:  [[ 13.19539286]] Loss_Validation:  [[ 11.04025879]]\n",
      "Loop 6149 Loss_Train:  [[ 13.19539265]] Loss_Validation:  [[ 11.0402671]]\n",
      "Loop 6150 Loss_Train:  [[ 13.19539244]] Loss_Validation:  [[ 11.0402754]]\n",
      "Loop 6151 Loss_Train:  [[ 13.19539223]] Loss_Validation:  [[ 11.04028369]]\n",
      "Loop 6152 Loss_Train:  [[ 13.19539203]] Loss_Validation:  [[ 11.04029198]]\n",
      "Loop 6153 Loss_Train:  [[ 13.19539182]] Loss_Validation:  [[ 11.04030026]]\n",
      "Loop 6154 Loss_Train:  [[ 13.19539161]] Loss_Validation:  [[ 11.04030854]]\n",
      "Loop 6155 Loss_Train:  [[ 13.19539141]] Loss_Validation:  [[ 11.04031681]]\n",
      "Loop 6156 Loss_Train:  [[ 13.1953912]] Loss_Validation:  [[ 11.04032507]]\n",
      "Loop 6157 Loss_Train:  [[ 13.19539099]] Loss_Validation:  [[ 11.04033333]]\n",
      "Loop 6158 Loss_Train:  [[ 13.19539079]] Loss_Validation:  [[ 11.04034159]]\n",
      "Loop 6159 Loss_Train:  [[ 13.19539058]] Loss_Validation:  [[ 11.04034984]]\n",
      "Loop 6160 Loss_Train:  [[ 13.19539038]] Loss_Validation:  [[ 11.04035808]]\n",
      "Loop 6161 Loss_Train:  [[ 13.19539017]] Loss_Validation:  [[ 11.04036632]]\n",
      "Loop 6162 Loss_Train:  [[ 13.19538997]] Loss_Validation:  [[ 11.04037455]]\n",
      "Loop 6163 Loss_Train:  [[ 13.19538977]] Loss_Validation:  [[ 11.04038277]]\n",
      "Loop 6164 Loss_Train:  [[ 13.19538956]] Loss_Validation:  [[ 11.04039099]]\n",
      "Loop 6165 Loss_Train:  [[ 13.19538936]] Loss_Validation:  [[ 11.04039921]]\n",
      "Loop 6166 Loss_Train:  [[ 13.19538915]] Loss_Validation:  [[ 11.04040742]]\n",
      "Loop 6167 Loss_Train:  [[ 13.19538895]] Loss_Validation:  [[ 11.04041562]]\n",
      "Loop 6168 Loss_Train:  [[ 13.19538875]] Loss_Validation:  [[ 11.04042382]]\n",
      "Loop 6169 Loss_Train:  [[ 13.19538855]] Loss_Validation:  [[ 11.04043201]]\n",
      "Loop 6170 Loss_Train:  [[ 13.19538834]] Loss_Validation:  [[ 11.0404402]]\n",
      "Loop 6171 Loss_Train:  [[ 13.19538814]] Loss_Validation:  [[ 11.04044838]]\n",
      "Loop 6172 Loss_Train:  [[ 13.19538794]] Loss_Validation:  [[ 11.04045656]]\n",
      "Loop 6173 Loss_Train:  [[ 13.19538774]] Loss_Validation:  [[ 11.04046473]]\n",
      "Loop 6174 Loss_Train:  [[ 13.19538754]] Loss_Validation:  [[ 11.04047289]]\n",
      "Loop 6175 Loss_Train:  [[ 13.19538734]] Loss_Validation:  [[ 11.04048105]]\n",
      "Loop 6176 Loss_Train:  [[ 13.19538714]] Loss_Validation:  [[ 11.0404892]]\n",
      "Loop 6177 Loss_Train:  [[ 13.19538694]] Loss_Validation:  [[ 11.04049735]]\n",
      "Loop 6178 Loss_Train:  [[ 13.19538674]] Loss_Validation:  [[ 11.04050549]]\n",
      "Loop 6179 Loss_Train:  [[ 13.19538654]] Loss_Validation:  [[ 11.04051363]]\n",
      "Loop 6180 Loss_Train:  [[ 13.19538634]] Loss_Validation:  [[ 11.04052176]]\n",
      "Loop 6181 Loss_Train:  [[ 13.19538614]] Loss_Validation:  [[ 11.04052988]]\n",
      "Loop 6182 Loss_Train:  [[ 13.19538594]] Loss_Validation:  [[ 11.040538]]\n",
      "Loop 6183 Loss_Train:  [[ 13.19538574]] Loss_Validation:  [[ 11.04054612]]\n",
      "Loop 6184 Loss_Train:  [[ 13.19538555]] Loss_Validation:  [[ 11.04055423]]\n",
      "Loop 6185 Loss_Train:  [[ 13.19538535]] Loss_Validation:  [[ 11.04056233]]\n",
      "Loop 6186 Loss_Train:  [[ 13.19538515]] Loss_Validation:  [[ 11.04057043]]\n",
      "Loop 6187 Loss_Train:  [[ 13.19538495]] Loss_Validation:  [[ 11.04057852]]\n",
      "Loop 6188 Loss_Train:  [[ 13.19538476]] Loss_Validation:  [[ 11.04058661]]\n",
      "Loop 6189 Loss_Train:  [[ 13.19538456]] Loss_Validation:  [[ 11.04059469]]\n",
      "Loop 6190 Loss_Train:  [[ 13.19538436]] Loss_Validation:  [[ 11.04060276]]\n",
      "Loop 6191 Loss_Train:  [[ 13.19538417]] Loss_Validation:  [[ 11.04061083]]\n",
      "Loop 6192 Loss_Train:  [[ 13.19538397]] Loss_Validation:  [[ 11.0406189]]\n",
      "Loop 6193 Loss_Train:  [[ 13.19538378]] Loss_Validation:  [[ 11.04062696]]\n",
      "Loop 6194 Loss_Train:  [[ 13.19538358]] Loss_Validation:  [[ 11.04063501]]\n",
      "Loop 6195 Loss_Train:  [[ 13.19538339]] Loss_Validation:  [[ 11.04064306]]\n",
      "Loop 6196 Loss_Train:  [[ 13.19538319]] Loss_Validation:  [[ 11.0406511]]\n",
      "Loop 6197 Loss_Train:  [[ 13.195383]] Loss_Validation:  [[ 11.04065914]]\n",
      "Loop 6198 Loss_Train:  [[ 13.1953828]] Loss_Validation:  [[ 11.04066717]]\n",
      "Loop 6199 Loss_Train:  [[ 13.19538261]] Loss_Validation:  [[ 11.04067519]]\n",
      "Loop 6200 Loss_Train:  [[ 13.19538242]] Loss_Validation:  [[ 11.04068321]]\n",
      "Loop 6201 Loss_Train:  [[ 13.19538222]] Loss_Validation:  [[ 11.04069123]]\n",
      "Loop 6202 Loss_Train:  [[ 13.19538203]] Loss_Validation:  [[ 11.04069924]]\n",
      "Loop 6203 Loss_Train:  [[ 13.19538184]] Loss_Validation:  [[ 11.04070724]]\n",
      "Loop 6204 Loss_Train:  [[ 13.19538165]] Loss_Validation:  [[ 11.04071524]]\n",
      "Loop 6205 Loss_Train:  [[ 13.19538145]] Loss_Validation:  [[ 11.04072323]]\n",
      "Loop 6206 Loss_Train:  [[ 13.19538126]] Loss_Validation:  [[ 11.04073122]]\n",
      "Loop 6207 Loss_Train:  [[ 13.19538107]] Loss_Validation:  [[ 11.0407392]]\n",
      "Loop 6208 Loss_Train:  [[ 13.19538088]] Loss_Validation:  [[ 11.04074718]]\n",
      "Loop 6209 Loss_Train:  [[ 13.19538069]] Loss_Validation:  [[ 11.04075515]]\n",
      "Loop 6210 Loss_Train:  [[ 13.1953805]] Loss_Validation:  [[ 11.04076312]]\n",
      "Loop 6211 Loss_Train:  [[ 13.19538031]] Loss_Validation:  [[ 11.04077108]]\n",
      "Loop 6212 Loss_Train:  [[ 13.19538012]] Loss_Validation:  [[ 11.04077903]]\n",
      "Loop 6213 Loss_Train:  [[ 13.19537993]] Loss_Validation:  [[ 11.04078698]]\n",
      "Loop 6214 Loss_Train:  [[ 13.19537974]] Loss_Validation:  [[ 11.04079493]]\n",
      "Loop 6215 Loss_Train:  [[ 13.19537955]] Loss_Validation:  [[ 11.04080286]]\n",
      "Loop 6216 Loss_Train:  [[ 13.19537936]] Loss_Validation:  [[ 11.0408108]]\n",
      "Loop 6217 Loss_Train:  [[ 13.19537917]] Loss_Validation:  [[ 11.04081872]]\n",
      "Loop 6218 Loss_Train:  [[ 13.19537898]] Loss_Validation:  [[ 11.04082665]]\n",
      "Loop 6219 Loss_Train:  [[ 13.19537879]] Loss_Validation:  [[ 11.04083456]]\n",
      "Loop 6220 Loss_Train:  [[ 13.19537861]] Loss_Validation:  [[ 11.04084247]]\n",
      "Loop 6221 Loss_Train:  [[ 13.19537842]] Loss_Validation:  [[ 11.04085038]]\n",
      "Loop 6222 Loss_Train:  [[ 13.19537823]] Loss_Validation:  [[ 11.04085828]]\n",
      "Loop 6223 Loss_Train:  [[ 13.19537804]] Loss_Validation:  [[ 11.04086618]]\n",
      "Loop 6224 Loss_Train:  [[ 13.19537786]] Loss_Validation:  [[ 11.04087407]]\n",
      "Loop 6225 Loss_Train:  [[ 13.19537767]] Loss_Validation:  [[ 11.04088195]]\n",
      "Loop 6226 Loss_Train:  [[ 13.19537748]] Loss_Validation:  [[ 11.04088983]]\n",
      "Loop 6227 Loss_Train:  [[ 13.1953773]] Loss_Validation:  [[ 11.0408977]]\n",
      "Loop 6228 Loss_Train:  [[ 13.19537711]] Loss_Validation:  [[ 11.04090557]]\n",
      "Loop 6229 Loss_Train:  [[ 13.19537693]] Loss_Validation:  [[ 11.04091343]]\n",
      "Loop 6230 Loss_Train:  [[ 13.19537674]] Loss_Validation:  [[ 11.04092129]]\n",
      "Loop 6231 Loss_Train:  [[ 13.19537656]] Loss_Validation:  [[ 11.04092914]]\n",
      "Loop 6232 Loss_Train:  [[ 13.19537637]] Loss_Validation:  [[ 11.04093699]]\n",
      "Loop 6233 Loss_Train:  [[ 13.19537619]] Loss_Validation:  [[ 11.04094483]]\n",
      "Loop 6234 Loss_Train:  [[ 13.195376]] Loss_Validation:  [[ 11.04095267]]\n",
      "Loop 6235 Loss_Train:  [[ 13.19537582]] Loss_Validation:  [[ 11.0409605]]\n",
      "Loop 6236 Loss_Train:  [[ 13.19537564]] Loss_Validation:  [[ 11.04096832]]\n",
      "Loop 6237 Loss_Train:  [[ 13.19537545]] Loss_Validation:  [[ 11.04097614]]\n",
      "Loop 6238 Loss_Train:  [[ 13.19537527]] Loss_Validation:  [[ 11.04098396]]\n",
      "Loop 6239 Loss_Train:  [[ 13.19537509]] Loss_Validation:  [[ 11.04099177]]\n",
      "Loop 6240 Loss_Train:  [[ 13.1953749]] Loss_Validation:  [[ 11.04099957]]\n",
      "Loop 6241 Loss_Train:  [[ 13.19537472]] Loss_Validation:  [[ 11.04100737]]\n",
      "Loop 6242 Loss_Train:  [[ 13.19537454]] Loss_Validation:  [[ 11.04101516]]\n",
      "Loop 6243 Loss_Train:  [[ 13.19537436]] Loss_Validation:  [[ 11.04102295]]\n",
      "Loop 6244 Loss_Train:  [[ 13.19537418]] Loss_Validation:  [[ 11.04103073]]\n",
      "Loop 6245 Loss_Train:  [[ 13.195374]] Loss_Validation:  [[ 11.04103851]]\n",
      "Loop 6246 Loss_Train:  [[ 13.19537381]] Loss_Validation:  [[ 11.04104628]]\n",
      "Loop 6247 Loss_Train:  [[ 13.19537363]] Loss_Validation:  [[ 11.04105405]]\n",
      "Loop 6248 Loss_Train:  [[ 13.19537345]] Loss_Validation:  [[ 11.04106181]]\n",
      "Loop 6249 Loss_Train:  [[ 13.19537327]] Loss_Validation:  [[ 11.04106956]]\n",
      "Loop 6250 Loss_Train:  [[ 13.19537309]] Loss_Validation:  [[ 11.04107731]]\n",
      "Loop 6251 Loss_Train:  [[ 13.19537291]] Loss_Validation:  [[ 11.04108506]]\n",
      "Loop 6252 Loss_Train:  [[ 13.19537273]] Loss_Validation:  [[ 11.0410928]]\n",
      "Loop 6253 Loss_Train:  [[ 13.19537255]] Loss_Validation:  [[ 11.04110053]]\n",
      "Loop 6254 Loss_Train:  [[ 13.19537238]] Loss_Validation:  [[ 11.04110826]]\n",
      "Loop 6255 Loss_Train:  [[ 13.1953722]] Loss_Validation:  [[ 11.04111599]]\n",
      "Loop 6256 Loss_Train:  [[ 13.19537202]] Loss_Validation:  [[ 11.04112371]]\n",
      "Loop 6257 Loss_Train:  [[ 13.19537184]] Loss_Validation:  [[ 11.04113142]]\n",
      "Loop 6258 Loss_Train:  [[ 13.19537166]] Loss_Validation:  [[ 11.04113913]]\n",
      "Loop 6259 Loss_Train:  [[ 13.19537149]] Loss_Validation:  [[ 11.04114683]]\n",
      "Loop 6260 Loss_Train:  [[ 13.19537131]] Loss_Validation:  [[ 11.04115453]]\n",
      "Loop 6261 Loss_Train:  [[ 13.19537113]] Loss_Validation:  [[ 11.04116222]]\n",
      "Loop 6262 Loss_Train:  [[ 13.19537095]] Loss_Validation:  [[ 11.04116991]]\n",
      "Loop 6263 Loss_Train:  [[ 13.19537078]] Loss_Validation:  [[ 11.04117759]]\n",
      "Loop 6264 Loss_Train:  [[ 13.1953706]] Loss_Validation:  [[ 11.04118527]]\n",
      "Loop 6265 Loss_Train:  [[ 13.19537042]] Loss_Validation:  [[ 11.04119294]]\n",
      "Loop 6266 Loss_Train:  [[ 13.19537025]] Loss_Validation:  [[ 11.04120061]]\n",
      "Loop 6267 Loss_Train:  [[ 13.19537007]] Loss_Validation:  [[ 11.04120827]]\n",
      "Loop 6268 Loss_Train:  [[ 13.1953699]] Loss_Validation:  [[ 11.04121592]]\n",
      "Loop 6269 Loss_Train:  [[ 13.19536972]] Loss_Validation:  [[ 11.04122357]]\n",
      "Loop 6270 Loss_Train:  [[ 13.19536955]] Loss_Validation:  [[ 11.04123122]]\n",
      "Loop 6271 Loss_Train:  [[ 13.19536937]] Loss_Validation:  [[ 11.04123886]]\n",
      "Loop 6272 Loss_Train:  [[ 13.1953692]] Loss_Validation:  [[ 11.04124649]]\n",
      "Loop 6273 Loss_Train:  [[ 13.19536903]] Loss_Validation:  [[ 11.04125412]]\n",
      "Loop 6274 Loss_Train:  [[ 13.19536885]] Loss_Validation:  [[ 11.04126175]]\n",
      "Loop 6275 Loss_Train:  [[ 13.19536868]] Loss_Validation:  [[ 11.04126937]]\n",
      "Loop 6276 Loss_Train:  [[ 13.1953685]] Loss_Validation:  [[ 11.04127698]]\n",
      "Loop 6277 Loss_Train:  [[ 13.19536833]] Loss_Validation:  [[ 11.04128459]]\n",
      "Loop 6278 Loss_Train:  [[ 13.19536816]] Loss_Validation:  [[ 11.04129219]]\n",
      "Loop 6279 Loss_Train:  [[ 13.19536799]] Loss_Validation:  [[ 11.04129979]]\n",
      "Loop 6280 Loss_Train:  [[ 13.19536781]] Loss_Validation:  [[ 11.04130738]]\n",
      "Loop 6281 Loss_Train:  [[ 13.19536764]] Loss_Validation:  [[ 11.04131497]]\n",
      "Loop 6282 Loss_Train:  [[ 13.19536747]] Loss_Validation:  [[ 11.04132255]]\n",
      "Loop 6283 Loss_Train:  [[ 13.1953673]] Loss_Validation:  [[ 11.04133013]]\n",
      "Loop 6284 Loss_Train:  [[ 13.19536713]] Loss_Validation:  [[ 11.0413377]]\n",
      "Loop 6285 Loss_Train:  [[ 13.19536696]] Loss_Validation:  [[ 11.04134527]]\n",
      "Loop 6286 Loss_Train:  [[ 13.19536679]] Loss_Validation:  [[ 11.04135283]]\n",
      "Loop 6287 Loss_Train:  [[ 13.19536661]] Loss_Validation:  [[ 11.04136039]]\n",
      "Loop 6288 Loss_Train:  [[ 13.19536644]] Loss_Validation:  [[ 11.04136794]]\n",
      "Loop 6289 Loss_Train:  [[ 13.19536627]] Loss_Validation:  [[ 11.04137549]]\n",
      "Loop 6290 Loss_Train:  [[ 13.1953661]] Loss_Validation:  [[ 11.04138303]]\n",
      "Loop 6291 Loss_Train:  [[ 13.19536594]] Loss_Validation:  [[ 11.04139056]]\n",
      "Loop 6292 Loss_Train:  [[ 13.19536577]] Loss_Validation:  [[ 11.0413981]]\n",
      "Loop 6293 Loss_Train:  [[ 13.1953656]] Loss_Validation:  [[ 11.04140562]]\n",
      "Loop 6294 Loss_Train:  [[ 13.19536543]] Loss_Validation:  [[ 11.04141314]]\n",
      "Loop 6295 Loss_Train:  [[ 13.19536526]] Loss_Validation:  [[ 11.04142066]]\n",
      "Loop 6296 Loss_Train:  [[ 13.19536509]] Loss_Validation:  [[ 11.04142817]]\n",
      "Loop 6297 Loss_Train:  [[ 13.19536492]] Loss_Validation:  [[ 11.04143567]]\n",
      "Loop 6298 Loss_Train:  [[ 13.19536475]] Loss_Validation:  [[ 11.04144317]]\n",
      "Loop 6299 Loss_Train:  [[ 13.19536459]] Loss_Validation:  [[ 11.04145067]]\n",
      "Loop 6300 Loss_Train:  [[ 13.19536442]] Loss_Validation:  [[ 11.04145816]]\n",
      "Loop 6301 Loss_Train:  [[ 13.19536425]] Loss_Validation:  [[ 11.04146564]]\n",
      "Loop 6302 Loss_Train:  [[ 13.19536409]] Loss_Validation:  [[ 11.04147312]]\n",
      "Loop 6303 Loss_Train:  [[ 13.19536392]] Loss_Validation:  [[ 11.0414806]]\n",
      "Loop 6304 Loss_Train:  [[ 13.19536375]] Loss_Validation:  [[ 11.04148807]]\n",
      "Loop 6305 Loss_Train:  [[ 13.19536359]] Loss_Validation:  [[ 11.04149553]]\n",
      "Loop 6306 Loss_Train:  [[ 13.19536342]] Loss_Validation:  [[ 11.04150299]]\n",
      "Loop 6307 Loss_Train:  [[ 13.19536326]] Loss_Validation:  [[ 11.04151044]]\n",
      "Loop 6308 Loss_Train:  [[ 13.19536309]] Loss_Validation:  [[ 11.04151789]]\n",
      "Loop 6309 Loss_Train:  [[ 13.19536292]] Loss_Validation:  [[ 11.04152534]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 6310 Loss_Train:  [[ 13.19536276]] Loss_Validation:  [[ 11.04153278]]\n",
      "Loop 6311 Loss_Train:  [[ 13.19536259]] Loss_Validation:  [[ 11.04154021]]\n",
      "Loop 6312 Loss_Train:  [[ 13.19536243]] Loss_Validation:  [[ 11.04154764]]\n",
      "Loop 6313 Loss_Train:  [[ 13.19536227]] Loss_Validation:  [[ 11.04155506]]\n",
      "Loop 6314 Loss_Train:  [[ 13.1953621]] Loss_Validation:  [[ 11.04156248]]\n",
      "Loop 6315 Loss_Train:  [[ 13.19536194]] Loss_Validation:  [[ 11.04156989]]\n",
      "Loop 6316 Loss_Train:  [[ 13.19536177]] Loss_Validation:  [[ 11.0415773]]\n",
      "Loop 6317 Loss_Train:  [[ 13.19536161]] Loss_Validation:  [[ 11.0415847]]\n",
      "Loop 6318 Loss_Train:  [[ 13.19536145]] Loss_Validation:  [[ 11.0415921]]\n",
      "Loop 6319 Loss_Train:  [[ 13.19536129]] Loss_Validation:  [[ 11.0415995]]\n",
      "Loop 6320 Loss_Train:  [[ 13.19536112]] Loss_Validation:  [[ 11.04160688]]\n",
      "Loop 6321 Loss_Train:  [[ 13.19536096]] Loss_Validation:  [[ 11.04161427]]\n",
      "Loop 6322 Loss_Train:  [[ 13.1953608]] Loss_Validation:  [[ 11.04162165]]\n",
      "Loop 6323 Loss_Train:  [[ 13.19536064]] Loss_Validation:  [[ 11.04162902]]\n",
      "Loop 6324 Loss_Train:  [[ 13.19536047]] Loss_Validation:  [[ 11.04163639]]\n",
      "Loop 6325 Loss_Train:  [[ 13.19536031]] Loss_Validation:  [[ 11.04164375]]\n",
      "Loop 6326 Loss_Train:  [[ 13.19536015]] Loss_Validation:  [[ 11.04165111]]\n",
      "Loop 6327 Loss_Train:  [[ 13.19535999]] Loss_Validation:  [[ 11.04165846]]\n",
      "Loop 6328 Loss_Train:  [[ 13.19535983]] Loss_Validation:  [[ 11.04166581]]\n",
      "Loop 6329 Loss_Train:  [[ 13.19535967]] Loss_Validation:  [[ 11.04167315]]\n",
      "Loop 6330 Loss_Train:  [[ 13.19535951]] Loss_Validation:  [[ 11.04168049]]\n",
      "Loop 6331 Loss_Train:  [[ 13.19535935]] Loss_Validation:  [[ 11.04168782]]\n",
      "Loop 6332 Loss_Train:  [[ 13.19535919]] Loss_Validation:  [[ 11.04169515]]\n",
      "Loop 6333 Loss_Train:  [[ 13.19535903]] Loss_Validation:  [[ 11.04170247]]\n",
      "Loop 6334 Loss_Train:  [[ 13.19535887]] Loss_Validation:  [[ 11.04170979]]\n",
      "Loop 6335 Loss_Train:  [[ 13.19535871]] Loss_Validation:  [[ 11.0417171]]\n",
      "Loop 6336 Loss_Train:  [[ 13.19535855]] Loss_Validation:  [[ 11.04172441]]\n",
      "Loop 6337 Loss_Train:  [[ 13.19535839]] Loss_Validation:  [[ 11.04173171]]\n",
      "Loop 6338 Loss_Train:  [[ 13.19535824]] Loss_Validation:  [[ 11.04173901]]\n",
      "Loop 6339 Loss_Train:  [[ 13.19535808]] Loss_Validation:  [[ 11.0417463]]\n",
      "Loop 6340 Loss_Train:  [[ 13.19535792]] Loss_Validation:  [[ 11.04175359]]\n",
      "Loop 6341 Loss_Train:  [[ 13.19535776]] Loss_Validation:  [[ 11.04176087]]\n",
      "Loop 6342 Loss_Train:  [[ 13.1953576]] Loss_Validation:  [[ 11.04176815]]\n",
      "Loop 6343 Loss_Train:  [[ 13.19535745]] Loss_Validation:  [[ 11.04177542]]\n",
      "Loop 6344 Loss_Train:  [[ 13.19535729]] Loss_Validation:  [[ 11.04178269]]\n",
      "Loop 6345 Loss_Train:  [[ 13.19535713]] Loss_Validation:  [[ 11.04178995]]\n",
      "Loop 6346 Loss_Train:  [[ 13.19535698]] Loss_Validation:  [[ 11.04179721]]\n",
      "Loop 6347 Loss_Train:  [[ 13.19535682]] Loss_Validation:  [[ 11.04180446]]\n",
      "Loop 6348 Loss_Train:  [[ 13.19535666]] Loss_Validation:  [[ 11.04181171]]\n",
      "Loop 6349 Loss_Train:  [[ 13.19535651]] Loss_Validation:  [[ 11.04181895]]\n",
      "Loop 6350 Loss_Train:  [[ 13.19535635]] Loss_Validation:  [[ 11.04182619]]\n",
      "Loop 6351 Loss_Train:  [[ 13.1953562]] Loss_Validation:  [[ 11.04183342]]\n",
      "Loop 6352 Loss_Train:  [[ 13.19535604]] Loss_Validation:  [[ 11.04184065]]\n",
      "Loop 6353 Loss_Train:  [[ 13.19535589]] Loss_Validation:  [[ 11.04184787]]\n",
      "Loop 6354 Loss_Train:  [[ 13.19535573]] Loss_Validation:  [[ 11.04185509]]\n",
      "Loop 6355 Loss_Train:  [[ 13.19535558]] Loss_Validation:  [[ 11.04186231]]\n",
      "Loop 6356 Loss_Train:  [[ 13.19535542]] Loss_Validation:  [[ 11.04186951]]\n",
      "Loop 6357 Loss_Train:  [[ 13.19535527]] Loss_Validation:  [[ 11.04187672]]\n",
      "Loop 6358 Loss_Train:  [[ 13.19535512]] Loss_Validation:  [[ 11.04188392]]\n",
      "Loop 6359 Loss_Train:  [[ 13.19535496]] Loss_Validation:  [[ 11.04189111]]\n",
      "Loop 6360 Loss_Train:  [[ 13.19535481]] Loss_Validation:  [[ 11.0418983]]\n",
      "Loop 6361 Loss_Train:  [[ 13.19535465]] Loss_Validation:  [[ 11.04190548]]\n",
      "Loop 6362 Loss_Train:  [[ 13.1953545]] Loss_Validation:  [[ 11.04191266]]\n",
      "Loop 6363 Loss_Train:  [[ 13.19535435]] Loss_Validation:  [[ 11.04191983]]\n",
      "Loop 6364 Loss_Train:  [[ 13.1953542]] Loss_Validation:  [[ 11.041927]]\n",
      "Loop 6365 Loss_Train:  [[ 13.19535404]] Loss_Validation:  [[ 11.04193417]]\n",
      "Loop 6366 Loss_Train:  [[ 13.19535389]] Loss_Validation:  [[ 11.04194133]]\n",
      "Loop 6367 Loss_Train:  [[ 13.19535374]] Loss_Validation:  [[ 11.04194848]]\n",
      "Loop 6368 Loss_Train:  [[ 13.19535359]] Loss_Validation:  [[ 11.04195563]]\n",
      "Loop 6369 Loss_Train:  [[ 13.19535344]] Loss_Validation:  [[ 11.04196277]]\n",
      "Loop 6370 Loss_Train:  [[ 13.19535329]] Loss_Validation:  [[ 11.04196991]]\n",
      "Loop 6371 Loss_Train:  [[ 13.19535313]] Loss_Validation:  [[ 11.04197705]]\n",
      "Loop 6372 Loss_Train:  [[ 13.19535298]] Loss_Validation:  [[ 11.04198418]]\n",
      "Loop 6373 Loss_Train:  [[ 13.19535283]] Loss_Validation:  [[ 11.0419913]]\n",
      "Loop 6374 Loss_Train:  [[ 13.19535268]] Loss_Validation:  [[ 11.04199842]]\n",
      "Loop 6375 Loss_Train:  [[ 13.19535253]] Loss_Validation:  [[ 11.04200554]]\n",
      "Loop 6376 Loss_Train:  [[ 13.19535238]] Loss_Validation:  [[ 11.04201265]]\n",
      "Loop 6377 Loss_Train:  [[ 13.19535223]] Loss_Validation:  [[ 11.04201975]]\n",
      "Loop 6378 Loss_Train:  [[ 13.19535208]] Loss_Validation:  [[ 11.04202685]]\n",
      "Loop 6379 Loss_Train:  [[ 13.19535193]] Loss_Validation:  [[ 11.04203395]]\n",
      "Loop 6380 Loss_Train:  [[ 13.19535179]] Loss_Validation:  [[ 11.04204104]]\n",
      "Loop 6381 Loss_Train:  [[ 13.19535164]] Loss_Validation:  [[ 11.04204813]]\n",
      "Loop 6382 Loss_Train:  [[ 13.19535149]] Loss_Validation:  [[ 11.04205521]]\n",
      "Loop 6383 Loss_Train:  [[ 13.19535134]] Loss_Validation:  [[ 11.04206228]]\n",
      "Loop 6384 Loss_Train:  [[ 13.19535119]] Loss_Validation:  [[ 11.04206935]]\n",
      "Loop 6385 Loss_Train:  [[ 13.19535104]] Loss_Validation:  [[ 11.04207642]]\n",
      "Loop 6386 Loss_Train:  [[ 13.1953509]] Loss_Validation:  [[ 11.04208348]]\n",
      "Loop 6387 Loss_Train:  [[ 13.19535075]] Loss_Validation:  [[ 11.04209054]]\n",
      "Loop 6388 Loss_Train:  [[ 13.1953506]] Loss_Validation:  [[ 11.04209759]]\n",
      "Loop 6389 Loss_Train:  [[ 13.19535045]] Loss_Validation:  [[ 11.04210464]]\n",
      "Loop 6390 Loss_Train:  [[ 13.19535031]] Loss_Validation:  [[ 11.04211168]]\n",
      "Loop 6391 Loss_Train:  [[ 13.19535016]] Loss_Validation:  [[ 11.04211872]]\n",
      "Loop 6392 Loss_Train:  [[ 13.19535001]] Loss_Validation:  [[ 11.04212575]]\n",
      "Loop 6393 Loss_Train:  [[ 13.19534987]] Loss_Validation:  [[ 11.04213278]]\n",
      "Loop 6394 Loss_Train:  [[ 13.19534972]] Loss_Validation:  [[ 11.0421398]]\n",
      "Loop 6395 Loss_Train:  [[ 13.19534957]] Loss_Validation:  [[ 11.04214682]]\n",
      "Loop 6396 Loss_Train:  [[ 13.19534943]] Loss_Validation:  [[ 11.04215384]]\n",
      "Loop 6397 Loss_Train:  [[ 13.19534928]] Loss_Validation:  [[ 11.04216084]]\n",
      "Loop 6398 Loss_Train:  [[ 13.19534914]] Loss_Validation:  [[ 11.04216785]]\n",
      "Loop 6399 Loss_Train:  [[ 13.19534899]] Loss_Validation:  [[ 11.04217485]]\n",
      "Loop 6400 Loss_Train:  [[ 13.19534885]] Loss_Validation:  [[ 11.04218184]]\n",
      "Loop 6401 Loss_Train:  [[ 13.1953487]] Loss_Validation:  [[ 11.04218883]]\n",
      "Loop 6402 Loss_Train:  [[ 13.19534856]] Loss_Validation:  [[ 11.04219582]]\n",
      "Loop 6403 Loss_Train:  [[ 13.19534842]] Loss_Validation:  [[ 11.0422028]]\n",
      "Loop 6404 Loss_Train:  [[ 13.19534827]] Loss_Validation:  [[ 11.04220977]]\n",
      "Loop 6405 Loss_Train:  [[ 13.19534813]] Loss_Validation:  [[ 11.04221674]]\n",
      "Loop 6406 Loss_Train:  [[ 13.19534798]] Loss_Validation:  [[ 11.04222371]]\n",
      "Loop 6407 Loss_Train:  [[ 13.19534784]] Loss_Validation:  [[ 11.04223067]]\n",
      "Loop 6408 Loss_Train:  [[ 13.1953477]] Loss_Validation:  [[ 11.04223763]]\n",
      "Loop 6409 Loss_Train:  [[ 13.19534755]] Loss_Validation:  [[ 11.04224458]]\n",
      "Loop 6410 Loss_Train:  [[ 13.19534741]] Loss_Validation:  [[ 11.04225152]]\n",
      "Loop 6411 Loss_Train:  [[ 13.19534727]] Loss_Validation:  [[ 11.04225847]]\n",
      "Loop 6412 Loss_Train:  [[ 13.19534713]] Loss_Validation:  [[ 11.0422654]]\n",
      "Loop 6413 Loss_Train:  [[ 13.19534698]] Loss_Validation:  [[ 11.04227233]]\n",
      "Loop 6414 Loss_Train:  [[ 13.19534684]] Loss_Validation:  [[ 11.04227926]]\n",
      "Loop 6415 Loss_Train:  [[ 13.1953467]] Loss_Validation:  [[ 11.04228619]]\n",
      "Loop 6416 Loss_Train:  [[ 13.19534656]] Loss_Validation:  [[ 11.0422931]]\n",
      "Loop 6417 Loss_Train:  [[ 13.19534642]] Loss_Validation:  [[ 11.04230002]]\n",
      "Loop 6418 Loss_Train:  [[ 13.19534628]] Loss_Validation:  [[ 11.04230693]]\n",
      "Loop 6419 Loss_Train:  [[ 13.19534614]] Loss_Validation:  [[ 11.04231383]]\n",
      "Loop 6420 Loss_Train:  [[ 13.195346]] Loss_Validation:  [[ 11.04232073]]\n",
      "Loop 6421 Loss_Train:  [[ 13.19534586]] Loss_Validation:  [[ 11.04232762]]\n",
      "Loop 6422 Loss_Train:  [[ 13.19534571]] Loss_Validation:  [[ 11.04233451]]\n",
      "Loop 6423 Loss_Train:  [[ 13.19534557]] Loss_Validation:  [[ 11.0423414]]\n",
      "Loop 6424 Loss_Train:  [[ 13.19534543]] Loss_Validation:  [[ 11.04234828]]\n",
      "Loop 6425 Loss_Train:  [[ 13.1953453]] Loss_Validation:  [[ 11.04235516]]\n",
      "Loop 6426 Loss_Train:  [[ 13.19534516]] Loss_Validation:  [[ 11.04236203]]\n",
      "Loop 6427 Loss_Train:  [[ 13.19534502]] Loss_Validation:  [[ 11.04236889]]\n",
      "Loop 6428 Loss_Train:  [[ 13.19534488]] Loss_Validation:  [[ 11.04237575]]\n",
      "Loop 6429 Loss_Train:  [[ 13.19534474]] Loss_Validation:  [[ 11.04238261]]\n",
      "Loop 6430 Loss_Train:  [[ 13.1953446]] Loss_Validation:  [[ 11.04238946]]\n",
      "Loop 6431 Loss_Train:  [[ 13.19534446]] Loss_Validation:  [[ 11.04239631]]\n",
      "Loop 6432 Loss_Train:  [[ 13.19534432]] Loss_Validation:  [[ 11.04240315]]\n",
      "Loop 6433 Loss_Train:  [[ 13.19534418]] Loss_Validation:  [[ 11.04240999]]\n",
      "Loop 6434 Loss_Train:  [[ 13.19534405]] Loss_Validation:  [[ 11.04241683]]\n",
      "Loop 6435 Loss_Train:  [[ 13.19534391]] Loss_Validation:  [[ 11.04242365]]\n",
      "Loop 6436 Loss_Train:  [[ 13.19534377]] Loss_Validation:  [[ 11.04243048]]\n",
      "Loop 6437 Loss_Train:  [[ 13.19534363]] Loss_Validation:  [[ 11.0424373]]\n",
      "Loop 6438 Loss_Train:  [[ 13.1953435]] Loss_Validation:  [[ 11.04244411]]\n",
      "Loop 6439 Loss_Train:  [[ 13.19534336]] Loss_Validation:  [[ 11.04245092]]\n",
      "Loop 6440 Loss_Train:  [[ 13.19534322]] Loss_Validation:  [[ 11.04245773]]\n",
      "Loop 6441 Loss_Train:  [[ 13.19534309]] Loss_Validation:  [[ 11.04246453]]\n",
      "Loop 6442 Loss_Train:  [[ 13.19534295]] Loss_Validation:  [[ 11.04247133]]\n",
      "Loop 6443 Loss_Train:  [[ 13.19534282]] Loss_Validation:  [[ 11.04247812]]\n",
      "Loop 6444 Loss_Train:  [[ 13.19534268]] Loss_Validation:  [[ 11.0424849]]\n",
      "Loop 6445 Loss_Train:  [[ 13.19534254]] Loss_Validation:  [[ 11.04249169]]\n",
      "Loop 6446 Loss_Train:  [[ 13.19534241]] Loss_Validation:  [[ 11.04249846]]\n",
      "Loop 6447 Loss_Train:  [[ 13.19534227]] Loss_Validation:  [[ 11.04250524]]\n",
      "Loop 6448 Loss_Train:  [[ 13.19534214]] Loss_Validation:  [[ 11.04251201]]\n",
      "Loop 6449 Loss_Train:  [[ 13.195342]] Loss_Validation:  [[ 11.04251877]]\n",
      "Loop 6450 Loss_Train:  [[ 13.19534187]] Loss_Validation:  [[ 11.04252553]]\n",
      "Loop 6451 Loss_Train:  [[ 13.19534173]] Loss_Validation:  [[ 11.04253228]]\n",
      "Loop 6452 Loss_Train:  [[ 13.1953416]] Loss_Validation:  [[ 11.04253903]]\n",
      "Loop 6453 Loss_Train:  [[ 13.19534147]] Loss_Validation:  [[ 11.04254578]]\n",
      "Loop 6454 Loss_Train:  [[ 13.19534133]] Loss_Validation:  [[ 11.04255252]]\n",
      "Loop 6455 Loss_Train:  [[ 13.1953412]] Loss_Validation:  [[ 11.04255925]]\n",
      "Loop 6456 Loss_Train:  [[ 13.19534106]] Loss_Validation:  [[ 11.04256599]]\n",
      "Loop 6457 Loss_Train:  [[ 13.19534093]] Loss_Validation:  [[ 11.04257271]]\n",
      "Loop 6458 Loss_Train:  [[ 13.1953408]] Loss_Validation:  [[ 11.04257943]]\n",
      "Loop 6459 Loss_Train:  [[ 13.19534066]] Loss_Validation:  [[ 11.04258615]]\n",
      "Loop 6460 Loss_Train:  [[ 13.19534053]] Loss_Validation:  [[ 11.04259286]]\n",
      "Loop 6461 Loss_Train:  [[ 13.1953404]] Loss_Validation:  [[ 11.04259957]]\n",
      "Loop 6462 Loss_Train:  [[ 13.19534027]] Loss_Validation:  [[ 11.04260628]]\n",
      "Loop 6463 Loss_Train:  [[ 13.19534013]] Loss_Validation:  [[ 11.04261298]]\n",
      "Loop 6464 Loss_Train:  [[ 13.19534]] Loss_Validation:  [[ 11.04261967]]\n",
      "Loop 6465 Loss_Train:  [[ 13.19533987]] Loss_Validation:  [[ 11.04262636]]\n",
      "Loop 6466 Loss_Train:  [[ 13.19533974]] Loss_Validation:  [[ 11.04263305]]\n",
      "Loop 6467 Loss_Train:  [[ 13.19533961]] Loss_Validation:  [[ 11.04263973]]\n",
      "Loop 6468 Loss_Train:  [[ 13.19533948]] Loss_Validation:  [[ 11.0426464]]\n",
      "Loop 6469 Loss_Train:  [[ 13.19533935]] Loss_Validation:  [[ 11.04265308]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 6470 Loss_Train:  [[ 13.19533921]] Loss_Validation:  [[ 11.04265974]]\n",
      "Loop 6471 Loss_Train:  [[ 13.19533908]] Loss_Validation:  [[ 11.0426664]]\n",
      "Loop 6472 Loss_Train:  [[ 13.19533895]] Loss_Validation:  [[ 11.04267306]]\n",
      "Loop 6473 Loss_Train:  [[ 13.19533882]] Loss_Validation:  [[ 11.04267972]]\n",
      "Loop 6474 Loss_Train:  [[ 13.19533869]] Loss_Validation:  [[ 11.04268637]]\n",
      "Loop 6475 Loss_Train:  [[ 13.19533856]] Loss_Validation:  [[ 11.04269301]]\n",
      "Loop 6476 Loss_Train:  [[ 13.19533843]] Loss_Validation:  [[ 11.04269965]]\n",
      "Loop 6477 Loss_Train:  [[ 13.1953383]] Loss_Validation:  [[ 11.04270629]]\n",
      "Loop 6478 Loss_Train:  [[ 13.19533817]] Loss_Validation:  [[ 11.04271292]]\n",
      "Loop 6479 Loss_Train:  [[ 13.19533804]] Loss_Validation:  [[ 11.04271954]]\n",
      "Loop 6480 Loss_Train:  [[ 13.19533792]] Loss_Validation:  [[ 11.04272616]]\n",
      "Loop 6481 Loss_Train:  [[ 13.19533779]] Loss_Validation:  [[ 11.04273278]]\n",
      "Loop 6482 Loss_Train:  [[ 13.19533766]] Loss_Validation:  [[ 11.04273939]]\n",
      "Loop 6483 Loss_Train:  [[ 13.19533753]] Loss_Validation:  [[ 11.042746]]\n",
      "Loop 6484 Loss_Train:  [[ 13.1953374]] Loss_Validation:  [[ 11.04275261]]\n",
      "Loop 6485 Loss_Train:  [[ 13.19533727]] Loss_Validation:  [[ 11.0427592]]\n",
      "Loop 6486 Loss_Train:  [[ 13.19533715]] Loss_Validation:  [[ 11.0427658]]\n",
      "Loop 6487 Loss_Train:  [[ 13.19533702]] Loss_Validation:  [[ 11.04277239]]\n",
      "Loop 6488 Loss_Train:  [[ 13.19533689]] Loss_Validation:  [[ 11.04277897]]\n",
      "Loop 6489 Loss_Train:  [[ 13.19533676]] Loss_Validation:  [[ 11.04278556]]\n",
      "Loop 6490 Loss_Train:  [[ 13.19533664]] Loss_Validation:  [[ 11.04279213]]\n",
      "Loop 6491 Loss_Train:  [[ 13.19533651]] Loss_Validation:  [[ 11.0427987]]\n",
      "Loop 6492 Loss_Train:  [[ 13.19533638]] Loss_Validation:  [[ 11.04280527]]\n",
      "Loop 6493 Loss_Train:  [[ 13.19533626]] Loss_Validation:  [[ 11.04281183]]\n",
      "Loop 6494 Loss_Train:  [[ 13.19533613]] Loss_Validation:  [[ 11.04281839]]\n",
      "Loop 6495 Loss_Train:  [[ 13.195336]] Loss_Validation:  [[ 11.04282495]]\n",
      "Loop 6496 Loss_Train:  [[ 13.19533588]] Loss_Validation:  [[ 11.0428315]]\n",
      "Loop 6497 Loss_Train:  [[ 13.19533575]] Loss_Validation:  [[ 11.04283804]]\n",
      "Loop 6498 Loss_Train:  [[ 13.19533563]] Loss_Validation:  [[ 11.04284458]]\n",
      "Loop 6499 Loss_Train:  [[ 13.1953355]] Loss_Validation:  [[ 11.04285112]]\n",
      "Loop 6500 Loss_Train:  [[ 13.19533537]] Loss_Validation:  [[ 11.04285765]]\n",
      "Loop 6501 Loss_Train:  [[ 13.19533525]] Loss_Validation:  [[ 11.04286418]]\n",
      "Loop 6502 Loss_Train:  [[ 13.19533512]] Loss_Validation:  [[ 11.0428707]]\n",
      "Loop 6503 Loss_Train:  [[ 13.195335]] Loss_Validation:  [[ 11.04287722]]\n",
      "Loop 6504 Loss_Train:  [[ 13.19533488]] Loss_Validation:  [[ 11.04288373]]\n",
      "Loop 6505 Loss_Train:  [[ 13.19533475]] Loss_Validation:  [[ 11.04289024]]\n",
      "Loop 6506 Loss_Train:  [[ 13.19533463]] Loss_Validation:  [[ 11.04289675]]\n",
      "Loop 6507 Loss_Train:  [[ 13.1953345]] Loss_Validation:  [[ 11.04290325]]\n",
      "Loop 6508 Loss_Train:  [[ 13.19533438]] Loss_Validation:  [[ 11.04290974]]\n",
      "Loop 6509 Loss_Train:  [[ 13.19533425]] Loss_Validation:  [[ 11.04291623]]\n",
      "Loop 6510 Loss_Train:  [[ 13.19533413]] Loss_Validation:  [[ 11.04292272]]\n",
      "Loop 6511 Loss_Train:  [[ 13.19533401]] Loss_Validation:  [[ 11.0429292]]\n",
      "Loop 6512 Loss_Train:  [[ 13.19533388]] Loss_Validation:  [[ 11.04293568]]\n",
      "Loop 6513 Loss_Train:  [[ 13.19533376]] Loss_Validation:  [[ 11.04294216]]\n",
      "Loop 6514 Loss_Train:  [[ 13.19533364]] Loss_Validation:  [[ 11.04294863]]\n",
      "Loop 6515 Loss_Train:  [[ 13.19533352]] Loss_Validation:  [[ 11.04295509]]\n",
      "Loop 6516 Loss_Train:  [[ 13.19533339]] Loss_Validation:  [[ 11.04296155]]\n",
      "Loop 6517 Loss_Train:  [[ 13.19533327]] Loss_Validation:  [[ 11.04296801]]\n",
      "Loop 6518 Loss_Train:  [[ 13.19533315]] Loss_Validation:  [[ 11.04297446]]\n",
      "Loop 6519 Loss_Train:  [[ 13.19533303]] Loss_Validation:  [[ 11.04298091]]\n",
      "Loop 6520 Loss_Train:  [[ 13.19533291]] Loss_Validation:  [[ 11.04298735]]\n",
      "Loop 6521 Loss_Train:  [[ 13.19533278]] Loss_Validation:  [[ 11.04299379]]\n",
      "Loop 6522 Loss_Train:  [[ 13.19533266]] Loss_Validation:  [[ 11.04300022]]\n",
      "Loop 6523 Loss_Train:  [[ 13.19533254]] Loss_Validation:  [[ 11.04300665]]\n",
      "Loop 6524 Loss_Train:  [[ 13.19533242]] Loss_Validation:  [[ 11.04301308]]\n",
      "Loop 6525 Loss_Train:  [[ 13.1953323]] Loss_Validation:  [[ 11.0430195]]\n",
      "Loop 6526 Loss_Train:  [[ 13.19533218]] Loss_Validation:  [[ 11.04302591]]\n",
      "Loop 6527 Loss_Train:  [[ 13.19533206]] Loss_Validation:  [[ 11.04303232]]\n",
      "Loop 6528 Loss_Train:  [[ 13.19533194]] Loss_Validation:  [[ 11.04303873]]\n",
      "Loop 6529 Loss_Train:  [[ 13.19533182]] Loss_Validation:  [[ 11.04304514]]\n",
      "Loop 6530 Loss_Train:  [[ 13.1953317]] Loss_Validation:  [[ 11.04305153]]\n",
      "Loop 6531 Loss_Train:  [[ 13.19533158]] Loss_Validation:  [[ 11.04305793]]\n",
      "Loop 6532 Loss_Train:  [[ 13.19533146]] Loss_Validation:  [[ 11.04306432]]\n",
      "Loop 6533 Loss_Train:  [[ 13.19533134]] Loss_Validation:  [[ 11.04307071]]\n",
      "Loop 6534 Loss_Train:  [[ 13.19533122]] Loss_Validation:  [[ 11.04307709]]\n",
      "Loop 6535 Loss_Train:  [[ 13.1953311]] Loss_Validation:  [[ 11.04308346]]\n",
      "Loop 6536 Loss_Train:  [[ 13.19533098]] Loss_Validation:  [[ 11.04308984]]\n",
      "Loop 6537 Loss_Train:  [[ 13.19533086]] Loss_Validation:  [[ 11.0430962]]\n",
      "Loop 6538 Loss_Train:  [[ 13.19533074]] Loss_Validation:  [[ 11.04310257]]\n",
      "Loop 6539 Loss_Train:  [[ 13.19533063]] Loss_Validation:  [[ 11.04310893]]\n",
      "Loop 6540 Loss_Train:  [[ 13.19533051]] Loss_Validation:  [[ 11.04311528]]\n",
      "Loop 6541 Loss_Train:  [[ 13.19533039]] Loss_Validation:  [[ 11.04312163]]\n",
      "Loop 6542 Loss_Train:  [[ 13.19533027]] Loss_Validation:  [[ 11.04312798]]\n",
      "Loop 6543 Loss_Train:  [[ 13.19533015]] Loss_Validation:  [[ 11.04313432]]\n",
      "Loop 6544 Loss_Train:  [[ 13.19533004]] Loss_Validation:  [[ 11.04314066]]\n",
      "Loop 6545 Loss_Train:  [[ 13.19532992]] Loss_Validation:  [[ 11.04314699]]\n",
      "Loop 6546 Loss_Train:  [[ 13.1953298]] Loss_Validation:  [[ 11.04315332]]\n",
      "Loop 6547 Loss_Train:  [[ 13.19532968]] Loss_Validation:  [[ 11.04315965]]\n",
      "Loop 6548 Loss_Train:  [[ 13.19532957]] Loss_Validation:  [[ 11.04316597]]\n",
      "Loop 6549 Loss_Train:  [[ 13.19532945]] Loss_Validation:  [[ 11.04317228]]\n",
      "Loop 6550 Loss_Train:  [[ 13.19532933]] Loss_Validation:  [[ 11.0431786]]\n",
      "Loop 6551 Loss_Train:  [[ 13.19532922]] Loss_Validation:  [[ 11.0431849]]\n",
      "Loop 6552 Loss_Train:  [[ 13.1953291]] Loss_Validation:  [[ 11.04319121]]\n",
      "Loop 6553 Loss_Train:  [[ 13.19532899]] Loss_Validation:  [[ 11.04319751]]\n",
      "Loop 6554 Loss_Train:  [[ 13.19532887]] Loss_Validation:  [[ 11.0432038]]\n",
      "Loop 6555 Loss_Train:  [[ 13.19532875]] Loss_Validation:  [[ 11.04321009]]\n",
      "Loop 6556 Loss_Train:  [[ 13.19532864]] Loss_Validation:  [[ 11.04321638]]\n",
      "Loop 6557 Loss_Train:  [[ 13.19532852]] Loss_Validation:  [[ 11.04322266]]\n",
      "Loop 6558 Loss_Train:  [[ 13.19532841]] Loss_Validation:  [[ 11.04322894]]\n",
      "Loop 6559 Loss_Train:  [[ 13.19532829]] Loss_Validation:  [[ 11.04323521]]\n",
      "Loop 6560 Loss_Train:  [[ 13.19532818]] Loss_Validation:  [[ 11.04324148]]\n",
      "Loop 6561 Loss_Train:  [[ 13.19532806]] Loss_Validation:  [[ 11.04324774]]\n",
      "Loop 6562 Loss_Train:  [[ 13.19532795]] Loss_Validation:  [[ 11.043254]]\n",
      "Loop 6563 Loss_Train:  [[ 13.19532783]] Loss_Validation:  [[ 11.04326026]]\n",
      "Loop 6564 Loss_Train:  [[ 13.19532772]] Loss_Validation:  [[ 11.04326651]]\n",
      "Loop 6565 Loss_Train:  [[ 13.19532761]] Loss_Validation:  [[ 11.04327276]]\n",
      "Loop 6566 Loss_Train:  [[ 13.19532749]] Loss_Validation:  [[ 11.043279]]\n",
      "Loop 6567 Loss_Train:  [[ 13.19532738]] Loss_Validation:  [[ 11.04328524]]\n",
      "Loop 6568 Loss_Train:  [[ 13.19532726]] Loss_Validation:  [[ 11.04329147]]\n",
      "Loop 6569 Loss_Train:  [[ 13.19532715]] Loss_Validation:  [[ 11.0432977]]\n",
      "Loop 6570 Loss_Train:  [[ 13.19532704]] Loss_Validation:  [[ 11.04330393]]\n",
      "Loop 6571 Loss_Train:  [[ 13.19532692]] Loss_Validation:  [[ 11.04331015]]\n",
      "Loop 6572 Loss_Train:  [[ 13.19532681]] Loss_Validation:  [[ 11.04331637]]\n",
      "Loop 6573 Loss_Train:  [[ 13.1953267]] Loss_Validation:  [[ 11.04332258]]\n",
      "Loop 6574 Loss_Train:  [[ 13.19532659]] Loss_Validation:  [[ 11.04332879]]\n",
      "Loop 6575 Loss_Train:  [[ 13.19532647]] Loss_Validation:  [[ 11.043335]]\n",
      "Loop 6576 Loss_Train:  [[ 13.19532636]] Loss_Validation:  [[ 11.0433412]]\n",
      "Loop 6577 Loss_Train:  [[ 13.19532625]] Loss_Validation:  [[ 11.04334739]]\n",
      "Loop 6578 Loss_Train:  [[ 13.19532614]] Loss_Validation:  [[ 11.04335359]]\n",
      "Loop 6579 Loss_Train:  [[ 13.19532603]] Loss_Validation:  [[ 11.04335977]]\n",
      "Loop 6580 Loss_Train:  [[ 13.19532591]] Loss_Validation:  [[ 11.04336596]]\n",
      "Loop 6581 Loss_Train:  [[ 13.1953258]] Loss_Validation:  [[ 11.04337214]]\n",
      "Loop 6582 Loss_Train:  [[ 13.19532569]] Loss_Validation:  [[ 11.04337831]]\n",
      "Loop 6583 Loss_Train:  [[ 13.19532558]] Loss_Validation:  [[ 11.04338448]]\n",
      "Loop 6584 Loss_Train:  [[ 13.19532547]] Loss_Validation:  [[ 11.04339065]]\n",
      "Loop 6585 Loss_Train:  [[ 13.19532536]] Loss_Validation:  [[ 11.04339681]]\n",
      "Loop 6586 Loss_Train:  [[ 13.19532525]] Loss_Validation:  [[ 11.04340297]]\n",
      "Loop 6587 Loss_Train:  [[ 13.19532514]] Loss_Validation:  [[ 11.04340912]]\n",
      "Loop 6588 Loss_Train:  [[ 13.19532503]] Loss_Validation:  [[ 11.04341527]]\n",
      "Loop 6589 Loss_Train:  [[ 13.19532492]] Loss_Validation:  [[ 11.04342142]]\n",
      "Loop 6590 Loss_Train:  [[ 13.19532481]] Loss_Validation:  [[ 11.04342756]]\n",
      "Loop 6591 Loss_Train:  [[ 13.1953247]] Loss_Validation:  [[ 11.0434337]]\n",
      "Loop 6592 Loss_Train:  [[ 13.19532459]] Loss_Validation:  [[ 11.04343983]]\n",
      "Loop 6593 Loss_Train:  [[ 13.19532448]] Loss_Validation:  [[ 11.04344596]]\n",
      "Loop 6594 Loss_Train:  [[ 13.19532437]] Loss_Validation:  [[ 11.04345208]]\n",
      "Loop 6595 Loss_Train:  [[ 13.19532426]] Loss_Validation:  [[ 11.0434582]]\n",
      "Loop 6596 Loss_Train:  [[ 13.19532415]] Loss_Validation:  [[ 11.04346432]]\n",
      "Loop 6597 Loss_Train:  [[ 13.19532404]] Loss_Validation:  [[ 11.04347043]]\n",
      "Loop 6598 Loss_Train:  [[ 13.19532393]] Loss_Validation:  [[ 11.04347654]]\n",
      "Loop 6599 Loss_Train:  [[ 13.19532382]] Loss_Validation:  [[ 11.04348264]]\n",
      "Loop 6600 Loss_Train:  [[ 13.19532371]] Loss_Validation:  [[ 11.04348874]]\n",
      "Loop 6601 Loss_Train:  [[ 13.19532361]] Loss_Validation:  [[ 11.04349484]]\n",
      "Loop 6602 Loss_Train:  [[ 13.1953235]] Loss_Validation:  [[ 11.04350093]]\n",
      "Loop 6603 Loss_Train:  [[ 13.19532339]] Loss_Validation:  [[ 11.04350702]]\n",
      "Loop 6604 Loss_Train:  [[ 13.19532328]] Loss_Validation:  [[ 11.0435131]]\n",
      "Loop 6605 Loss_Train:  [[ 13.19532318]] Loss_Validation:  [[ 11.04351918]]\n",
      "Loop 6606 Loss_Train:  [[ 13.19532307]] Loss_Validation:  [[ 11.04352525]]\n",
      "Loop 6607 Loss_Train:  [[ 13.19532296]] Loss_Validation:  [[ 11.04353132]]\n",
      "Loop 6608 Loss_Train:  [[ 13.19532285]] Loss_Validation:  [[ 11.04353739]]\n",
      "Loop 6609 Loss_Train:  [[ 13.19532275]] Loss_Validation:  [[ 11.04354345]]\n",
      "Loop 6610 Loss_Train:  [[ 13.19532264]] Loss_Validation:  [[ 11.04354951]]\n",
      "Loop 6611 Loss_Train:  [[ 13.19532253]] Loss_Validation:  [[ 11.04355556]]\n",
      "Loop 6612 Loss_Train:  [[ 13.19532243]] Loss_Validation:  [[ 11.04356161]]\n",
      "Loop 6613 Loss_Train:  [[ 13.19532232]] Loss_Validation:  [[ 11.04356766]]\n",
      "Loop 6614 Loss_Train:  [[ 13.19532221]] Loss_Validation:  [[ 11.0435737]]\n",
      "Loop 6615 Loss_Train:  [[ 13.19532211]] Loss_Validation:  [[ 11.04357973]]\n",
      "Loop 6616 Loss_Train:  [[ 13.195322]] Loss_Validation:  [[ 11.04358577]]\n",
      "Loop 6617 Loss_Train:  [[ 13.1953219]] Loss_Validation:  [[ 11.0435918]]\n",
      "Loop 6618 Loss_Train:  [[ 13.19532179]] Loss_Validation:  [[ 11.04359782]]\n",
      "Loop 6619 Loss_Train:  [[ 13.19532168]] Loss_Validation:  [[ 11.04360384]]\n",
      "Loop 6620 Loss_Train:  [[ 13.19532158]] Loss_Validation:  [[ 11.04360986]]\n",
      "Loop 6621 Loss_Train:  [[ 13.19532147]] Loss_Validation:  [[ 11.04361587]]\n",
      "Loop 6622 Loss_Train:  [[ 13.19532137]] Loss_Validation:  [[ 11.04362188]]\n",
      "Loop 6623 Loss_Train:  [[ 13.19532126]] Loss_Validation:  [[ 11.04362788]]\n",
      "Loop 6624 Loss_Train:  [[ 13.19532116]] Loss_Validation:  [[ 11.04363388]]\n",
      "Loop 6625 Loss_Train:  [[ 13.19532105]] Loss_Validation:  [[ 11.04363988]]\n",
      "Loop 6626 Loss_Train:  [[ 13.19532095]] Loss_Validation:  [[ 11.04364587]]\n",
      "Loop 6627 Loss_Train:  [[ 13.19532085]] Loss_Validation:  [[ 11.04365186]]\n",
      "Loop 6628 Loss_Train:  [[ 13.19532074]] Loss_Validation:  [[ 11.04365784]]\n",
      "Loop 6629 Loss_Train:  [[ 13.19532064]] Loss_Validation:  [[ 11.04366382]]\n",
      "Loop 6630 Loss_Train:  [[ 13.19532053]] Loss_Validation:  [[ 11.0436698]]\n",
      "Loop 6631 Loss_Train:  [[ 13.19532043]] Loss_Validation:  [[ 11.04367577]]\n",
      "Loop 6632 Loss_Train:  [[ 13.19532033]] Loss_Validation:  [[ 11.04368173]]\n",
      "Loop 6633 Loss_Train:  [[ 13.19532022]] Loss_Validation:  [[ 11.0436877]]\n",
      "Loop 6634 Loss_Train:  [[ 13.19532012]] Loss_Validation:  [[ 11.04369366]]\n",
      "Loop 6635 Loss_Train:  [[ 13.19532002]] Loss_Validation:  [[ 11.04369961]]\n",
      "Loop 6636 Loss_Train:  [[ 13.19531991]] Loss_Validation:  [[ 11.04370556]]\n",
      "Loop 6637 Loss_Train:  [[ 13.19531981]] Loss_Validation:  [[ 11.04371151]]\n",
      "Loop 6638 Loss_Train:  [[ 13.19531971]] Loss_Validation:  [[ 11.04371745]]\n",
      "Loop 6639 Loss_Train:  [[ 13.19531961]] Loss_Validation:  [[ 11.04372339]]\n",
      "Loop 6640 Loss_Train:  [[ 13.1953195]] Loss_Validation:  [[ 11.04372933]]\n",
      "Loop 6641 Loss_Train:  [[ 13.1953194]] Loss_Validation:  [[ 11.04373526]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 6642 Loss_Train:  [[ 13.1953193]] Loss_Validation:  [[ 11.04374118]]\n",
      "Loop 6643 Loss_Train:  [[ 13.1953192]] Loss_Validation:  [[ 11.0437471]]\n",
      "Loop 6644 Loss_Train:  [[ 13.1953191]] Loss_Validation:  [[ 11.04375302]]\n",
      "Loop 6645 Loss_Train:  [[ 13.19531899]] Loss_Validation:  [[ 11.04375894]]\n",
      "Loop 6646 Loss_Train:  [[ 13.19531889]] Loss_Validation:  [[ 11.04376485]]\n",
      "Loop 6647 Loss_Train:  [[ 13.19531879]] Loss_Validation:  [[ 11.04377075]]\n",
      "Loop 6648 Loss_Train:  [[ 13.19531869]] Loss_Validation:  [[ 11.04377666]]\n",
      "Loop 6649 Loss_Train:  [[ 13.19531859]] Loss_Validation:  [[ 11.04378255]]\n",
      "Loop 6650 Loss_Train:  [[ 13.19531849]] Loss_Validation:  [[ 11.04378845]]\n",
      "Loop 6651 Loss_Train:  [[ 13.19531839]] Loss_Validation:  [[ 11.04379434]]\n",
      "Loop 6652 Loss_Train:  [[ 13.19531829]] Loss_Validation:  [[ 11.04380022]]\n",
      "Loop 6653 Loss_Train:  [[ 13.19531819]] Loss_Validation:  [[ 11.04380611]]\n",
      "Loop 6654 Loss_Train:  [[ 13.19531809]] Loss_Validation:  [[ 11.04381198]]\n",
      "Loop 6655 Loss_Train:  [[ 13.19531799]] Loss_Validation:  [[ 11.04381786]]\n",
      "Loop 6656 Loss_Train:  [[ 13.19531789]] Loss_Validation:  [[ 11.04382373]]\n",
      "Loop 6657 Loss_Train:  [[ 13.19531779]] Loss_Validation:  [[ 11.04382959]]\n",
      "Loop 6658 Loss_Train:  [[ 13.19531769]] Loss_Validation:  [[ 11.04383546]]\n",
      "Loop 6659 Loss_Train:  [[ 13.19531759]] Loss_Validation:  [[ 11.04384131]]\n",
      "Loop 6660 Loss_Train:  [[ 13.19531749]] Loss_Validation:  [[ 11.04384717]]\n",
      "Loop 6661 Loss_Train:  [[ 13.19531739]] Loss_Validation:  [[ 11.04385302]]\n",
      "Loop 6662 Loss_Train:  [[ 13.19531729]] Loss_Validation:  [[ 11.04385886]]\n",
      "Loop 6663 Loss_Train:  [[ 13.19531719]] Loss_Validation:  [[ 11.04386471]]\n",
      "Loop 6664 Loss_Train:  [[ 13.19531709]] Loss_Validation:  [[ 11.04387054]]\n",
      "Loop 6665 Loss_Train:  [[ 13.19531699]] Loss_Validation:  [[ 11.04387638]]\n",
      "Loop 6666 Loss_Train:  [[ 13.19531689]] Loss_Validation:  [[ 11.04388221]]\n",
      "Loop 6667 Loss_Train:  [[ 13.19531679]] Loss_Validation:  [[ 11.04388803]]\n",
      "Loop 6668 Loss_Train:  [[ 13.1953167]] Loss_Validation:  [[ 11.04389385]]\n",
      "Loop 6669 Loss_Train:  [[ 13.1953166]] Loss_Validation:  [[ 11.04389967]]\n",
      "Loop 6670 Loss_Train:  [[ 13.1953165]] Loss_Validation:  [[ 11.04390549]]\n",
      "Loop 6671 Loss_Train:  [[ 13.1953164]] Loss_Validation:  [[ 11.0439113]]\n",
      "Loop 6672 Loss_Train:  [[ 13.1953163]] Loss_Validation:  [[ 11.0439171]]\n",
      "Loop 6673 Loss_Train:  [[ 13.19531621]] Loss_Validation:  [[ 11.0439229]]\n",
      "Loop 6674 Loss_Train:  [[ 13.19531611]] Loss_Validation:  [[ 11.0439287]]\n",
      "Loop 6675 Loss_Train:  [[ 13.19531601]] Loss_Validation:  [[ 11.0439345]]\n",
      "Loop 6676 Loss_Train:  [[ 13.19531591]] Loss_Validation:  [[ 11.04394029]]\n",
      "Loop 6677 Loss_Train:  [[ 13.19531582]] Loss_Validation:  [[ 11.04394607]]\n",
      "Loop 6678 Loss_Train:  [[ 13.19531572]] Loss_Validation:  [[ 11.04395186]]\n",
      "Loop 6679 Loss_Train:  [[ 13.19531562]] Loss_Validation:  [[ 11.04395763]]\n",
      "Loop 6680 Loss_Train:  [[ 13.19531553]] Loss_Validation:  [[ 11.04396341]]\n",
      "Loop 6681 Loss_Train:  [[ 13.19531543]] Loss_Validation:  [[ 11.04396918]]\n",
      "Loop 6682 Loss_Train:  [[ 13.19531533]] Loss_Validation:  [[ 11.04397494]]\n",
      "Loop 6683 Loss_Train:  [[ 13.19531524]] Loss_Validation:  [[ 11.04398071]]\n",
      "Loop 6684 Loss_Train:  [[ 13.19531514]] Loss_Validation:  [[ 11.04398646]]\n",
      "Loop 6685 Loss_Train:  [[ 13.19531505]] Loss_Validation:  [[ 11.04399222]]\n",
      "Loop 6686 Loss_Train:  [[ 13.19531495]] Loss_Validation:  [[ 11.04399797]]\n",
      "Loop 6687 Loss_Train:  [[ 13.19531486]] Loss_Validation:  [[ 11.04400372]]\n",
      "Loop 6688 Loss_Train:  [[ 13.19531476]] Loss_Validation:  [[ 11.04400946]]\n",
      "Loop 6689 Loss_Train:  [[ 13.19531466]] Loss_Validation:  [[ 11.0440152]]\n",
      "Loop 6690 Loss_Train:  [[ 13.19531457]] Loss_Validation:  [[ 11.04402093]]\n",
      "Loop 6691 Loss_Train:  [[ 13.19531447]] Loss_Validation:  [[ 11.04402666]]\n",
      "Loop 6692 Loss_Train:  [[ 13.19531438]] Loss_Validation:  [[ 11.04403239]]\n",
      "Loop 6693 Loss_Train:  [[ 13.19531428]] Loss_Validation:  [[ 11.04403811]]\n",
      "Loop 6694 Loss_Train:  [[ 13.19531419]] Loss_Validation:  [[ 11.04404383]]\n",
      "Loop 6695 Loss_Train:  [[ 13.1953141]] Loss_Validation:  [[ 11.04404955]]\n",
      "Loop 6696 Loss_Train:  [[ 13.195314]] Loss_Validation:  [[ 11.04405526]]\n",
      "Loop 6697 Loss_Train:  [[ 13.19531391]] Loss_Validation:  [[ 11.04406097]]\n",
      "Loop 6698 Loss_Train:  [[ 13.19531381]] Loss_Validation:  [[ 11.04406667]]\n",
      "Loop 6699 Loss_Train:  [[ 13.19531372]] Loss_Validation:  [[ 11.04407237]]\n",
      "Loop 6700 Loss_Train:  [[ 13.19531362]] Loss_Validation:  [[ 11.04407807]]\n",
      "Loop 6701 Loss_Train:  [[ 13.19531353]] Loss_Validation:  [[ 11.04408376]]\n",
      "Loop 6702 Loss_Train:  [[ 13.19531344]] Loss_Validation:  [[ 11.04408945]]\n",
      "Loop 6703 Loss_Train:  [[ 13.19531334]] Loss_Validation:  [[ 11.04409513]]\n",
      "Loop 6704 Loss_Train:  [[ 13.19531325]] Loss_Validation:  [[ 11.04410081]]\n",
      "Loop 6705 Loss_Train:  [[ 13.19531316]] Loss_Validation:  [[ 11.04410649]]\n",
      "Loop 6706 Loss_Train:  [[ 13.19531306]] Loss_Validation:  [[ 11.04411216]]\n",
      "Loop 6707 Loss_Train:  [[ 13.19531297]] Loss_Validation:  [[ 11.04411783]]\n",
      "Loop 6708 Loss_Train:  [[ 13.19531288]] Loss_Validation:  [[ 11.04412349]]\n",
      "Loop 6709 Loss_Train:  [[ 13.19531279]] Loss_Validation:  [[ 11.04412915]]\n",
      "Loop 6710 Loss_Train:  [[ 13.19531269]] Loss_Validation:  [[ 11.04413481]]\n",
      "Loop 6711 Loss_Train:  [[ 13.1953126]] Loss_Validation:  [[ 11.04414046]]\n",
      "Loop 6712 Loss_Train:  [[ 13.19531251]] Loss_Validation:  [[ 11.04414611]]\n",
      "Loop 6713 Loss_Train:  [[ 13.19531242]] Loss_Validation:  [[ 11.04415176]]\n",
      "Loop 6714 Loss_Train:  [[ 13.19531232]] Loss_Validation:  [[ 11.0441574]]\n",
      "Loop 6715 Loss_Train:  [[ 13.19531223]] Loss_Validation:  [[ 11.04416303]]\n",
      "Loop 6716 Loss_Train:  [[ 13.19531214]] Loss_Validation:  [[ 11.04416867]]\n",
      "Loop 6717 Loss_Train:  [[ 13.19531205]] Loss_Validation:  [[ 11.0441743]]\n",
      "Loop 6718 Loss_Train:  [[ 13.19531196]] Loss_Validation:  [[ 11.04417992]]\n",
      "Loop 6719 Loss_Train:  [[ 13.19531187]] Loss_Validation:  [[ 11.04418555]]\n",
      "Loop 6720 Loss_Train:  [[ 13.19531178]] Loss_Validation:  [[ 11.04419116]]\n",
      "Loop 6721 Loss_Train:  [[ 13.19531168]] Loss_Validation:  [[ 11.04419678]]\n",
      "Loop 6722 Loss_Train:  [[ 13.19531159]] Loss_Validation:  [[ 11.04420239]]\n",
      "Loop 6723 Loss_Train:  [[ 13.1953115]] Loss_Validation:  [[ 11.044208]]\n",
      "Loop 6724 Loss_Train:  [[ 13.19531141]] Loss_Validation:  [[ 11.0442136]]\n",
      "Loop 6725 Loss_Train:  [[ 13.19531132]] Loss_Validation:  [[ 11.0442192]]\n",
      "Loop 6726 Loss_Train:  [[ 13.19531123]] Loss_Validation:  [[ 11.04422479]]\n",
      "Loop 6727 Loss_Train:  [[ 13.19531114]] Loss_Validation:  [[ 11.04423038]]\n",
      "Loop 6728 Loss_Train:  [[ 13.19531105]] Loss_Validation:  [[ 11.04423597]]\n",
      "Loop 6729 Loss_Train:  [[ 13.19531096]] Loss_Validation:  [[ 11.04424155]]\n",
      "Loop 6730 Loss_Train:  [[ 13.19531087]] Loss_Validation:  [[ 11.04424713]]\n",
      "Loop 6731 Loss_Train:  [[ 13.19531078]] Loss_Validation:  [[ 11.04425271]]\n",
      "Loop 6732 Loss_Train:  [[ 13.19531069]] Loss_Validation:  [[ 11.04425828]]\n",
      "Loop 6733 Loss_Train:  [[ 13.1953106]] Loss_Validation:  [[ 11.04426385]]\n",
      "Loop 6734 Loss_Train:  [[ 13.19531051]] Loss_Validation:  [[ 11.04426942]]\n",
      "Loop 6735 Loss_Train:  [[ 13.19531042]] Loss_Validation:  [[ 11.04427498]]\n",
      "Loop 6736 Loss_Train:  [[ 13.19531033]] Loss_Validation:  [[ 11.04428053]]\n",
      "Loop 6737 Loss_Train:  [[ 13.19531025]] Loss_Validation:  [[ 11.04428609]]\n",
      "Loop 6738 Loss_Train:  [[ 13.19531016]] Loss_Validation:  [[ 11.04429164]]\n",
      "Loop 6739 Loss_Train:  [[ 13.19531007]] Loss_Validation:  [[ 11.04429718]]\n",
      "Loop 6740 Loss_Train:  [[ 13.19530998]] Loss_Validation:  [[ 11.04430272]]\n",
      "Loop 6741 Loss_Train:  [[ 13.19530989]] Loss_Validation:  [[ 11.04430826]]\n",
      "Loop 6742 Loss_Train:  [[ 13.1953098]] Loss_Validation:  [[ 11.0443138]]\n",
      "Loop 6743 Loss_Train:  [[ 13.19530971]] Loss_Validation:  [[ 11.04431933]]\n",
      "Loop 6744 Loss_Train:  [[ 13.19530963]] Loss_Validation:  [[ 11.04432485]]\n",
      "Loop 6745 Loss_Train:  [[ 13.19530954]] Loss_Validation:  [[ 11.04433037]]\n",
      "Loop 6746 Loss_Train:  [[ 13.19530945]] Loss_Validation:  [[ 11.04433589]]\n",
      "Loop 6747 Loss_Train:  [[ 13.19530936]] Loss_Validation:  [[ 11.04434141]]\n",
      "Loop 6748 Loss_Train:  [[ 13.19530927]] Loss_Validation:  [[ 11.04434692]]\n",
      "Loop 6749 Loss_Train:  [[ 13.19530919]] Loss_Validation:  [[ 11.04435243]]\n",
      "Loop 6750 Loss_Train:  [[ 13.1953091]] Loss_Validation:  [[ 11.04435793]]\n",
      "Loop 6751 Loss_Train:  [[ 13.19530901]] Loss_Validation:  [[ 11.04436343]]\n",
      "Loop 6752 Loss_Train:  [[ 13.19530893]] Loss_Validation:  [[ 11.04436893]]\n",
      "Loop 6753 Loss_Train:  [[ 13.19530884]] Loss_Validation:  [[ 11.04437442]]\n",
      "Loop 6754 Loss_Train:  [[ 13.19530875]] Loss_Validation:  [[ 11.04437991]]\n",
      "Loop 6755 Loss_Train:  [[ 13.19530867]] Loss_Validation:  [[ 11.0443854]]\n",
      "Loop 6756 Loss_Train:  [[ 13.19530858]] Loss_Validation:  [[ 11.04439088]]\n",
      "Loop 6757 Loss_Train:  [[ 13.19530849]] Loss_Validation:  [[ 11.04439635]]\n",
      "Loop 6758 Loss_Train:  [[ 13.19530841]] Loss_Validation:  [[ 11.04440183]]\n",
      "Loop 6759 Loss_Train:  [[ 13.19530832]] Loss_Validation:  [[ 11.0444073]]\n",
      "Loop 6760 Loss_Train:  [[ 13.19530823]] Loss_Validation:  [[ 11.04441276]]\n",
      "Loop 6761 Loss_Train:  [[ 13.19530815]] Loss_Validation:  [[ 11.04441823]]\n",
      "Loop 6762 Loss_Train:  [[ 13.19530806]] Loss_Validation:  [[ 11.04442369]]\n",
      "Loop 6763 Loss_Train:  [[ 13.19530798]] Loss_Validation:  [[ 11.04442914]]\n",
      "Loop 6764 Loss_Train:  [[ 13.19530789]] Loss_Validation:  [[ 11.04443459]]\n",
      "Loop 6765 Loss_Train:  [[ 13.19530781]] Loss_Validation:  [[ 11.04444004]]\n",
      "Loop 6766 Loss_Train:  [[ 13.19530772]] Loss_Validation:  [[ 11.04444548]]\n",
      "Loop 6767 Loss_Train:  [[ 13.19530763]] Loss_Validation:  [[ 11.04445092]]\n",
      "Loop 6768 Loss_Train:  [[ 13.19530755]] Loss_Validation:  [[ 11.04445636]]\n",
      "Loop 6769 Loss_Train:  [[ 13.19530746]] Loss_Validation:  [[ 11.04446179]]\n",
      "Loop 6770 Loss_Train:  [[ 13.19530738]] Loss_Validation:  [[ 11.04446722]]\n",
      "Loop 6771 Loss_Train:  [[ 13.1953073]] Loss_Validation:  [[ 11.04447265]]\n",
      "Loop 6772 Loss_Train:  [[ 13.19530721]] Loss_Validation:  [[ 11.04447807]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 6773 Loss_Train:  [[ 13.19530713]] Loss_Validation:  [[ 11.04448349]]\n",
      "Loop 6774 Loss_Train:  [[ 13.19530704]] Loss_Validation:  [[ 11.0444889]]\n",
      "Loop 6775 Loss_Train:  [[ 13.19530696]] Loss_Validation:  [[ 11.04449431]]\n",
      "Loop 6776 Loss_Train:  [[ 13.19530687]] Loss_Validation:  [[ 11.04449972]]\n",
      "Loop 6777 Loss_Train:  [[ 13.19530679]] Loss_Validation:  [[ 11.04450512]]\n",
      "Loop 6778 Loss_Train:  [[ 13.19530671]] Loss_Validation:  [[ 11.04451052]]\n",
      "Loop 6779 Loss_Train:  [[ 13.19530662]] Loss_Validation:  [[ 11.04451592]]\n",
      "Loop 6780 Loss_Train:  [[ 13.19530654]] Loss_Validation:  [[ 11.04452131]]\n",
      "Loop 6781 Loss_Train:  [[ 13.19530645]] Loss_Validation:  [[ 11.0445267]]\n",
      "Loop 6782 Loss_Train:  [[ 13.19530637]] Loss_Validation:  [[ 11.04453208]]\n",
      "Loop 6783 Loss_Train:  [[ 13.19530629]] Loss_Validation:  [[ 11.04453746]]\n",
      "Loop 6784 Loss_Train:  [[ 13.19530621]] Loss_Validation:  [[ 11.04454284]]\n",
      "Loop 6785 Loss_Train:  [[ 13.19530612]] Loss_Validation:  [[ 11.04454821]]\n",
      "Loop 6786 Loss_Train:  [[ 13.19530604]] Loss_Validation:  [[ 11.04455358]]\n",
      "Loop 6787 Loss_Train:  [[ 13.19530596]] Loss_Validation:  [[ 11.04455895]]\n",
      "Loop 6788 Loss_Train:  [[ 13.19530587]] Loss_Validation:  [[ 11.04456431]]\n",
      "Loop 6789 Loss_Train:  [[ 13.19530579]] Loss_Validation:  [[ 11.04456967]]\n",
      "Loop 6790 Loss_Train:  [[ 13.19530571]] Loss_Validation:  [[ 11.04457502]]\n",
      "Loop 6791 Loss_Train:  [[ 13.19530563]] Loss_Validation:  [[ 11.04458038]]\n",
      "Loop 6792 Loss_Train:  [[ 13.19530554]] Loss_Validation:  [[ 11.04458572]]\n",
      "Loop 6793 Loss_Train:  [[ 13.19530546]] Loss_Validation:  [[ 11.04459107]]\n",
      "Loop 6794 Loss_Train:  [[ 13.19530538]] Loss_Validation:  [[ 11.04459641]]\n",
      "Loop 6795 Loss_Train:  [[ 13.1953053]] Loss_Validation:  [[ 11.04460175]]\n",
      "Loop 6796 Loss_Train:  [[ 13.19530522]] Loss_Validation:  [[ 11.04460708]]\n",
      "Loop 6797 Loss_Train:  [[ 13.19530514]] Loss_Validation:  [[ 11.04461241]]\n",
      "Loop 6798 Loss_Train:  [[ 13.19530505]] Loss_Validation:  [[ 11.04461773]]\n",
      "Loop 6799 Loss_Train:  [[ 13.19530497]] Loss_Validation:  [[ 11.04462306]]\n",
      "Loop 6800 Loss_Train:  [[ 13.19530489]] Loss_Validation:  [[ 11.04462837]]\n",
      "Loop 6801 Loss_Train:  [[ 13.19530481]] Loss_Validation:  [[ 11.04463369]]\n",
      "Loop 6802 Loss_Train:  [[ 13.19530473]] Loss_Validation:  [[ 11.044639]]\n",
      "Loop 6803 Loss_Train:  [[ 13.19530465]] Loss_Validation:  [[ 11.04464431]]\n",
      "Loop 6804 Loss_Train:  [[ 13.19530457]] Loss_Validation:  [[ 11.04464961]]\n",
      "Loop 6805 Loss_Train:  [[ 13.19530449]] Loss_Validation:  [[ 11.04465491]]\n",
      "Loop 6806 Loss_Train:  [[ 13.19530441]] Loss_Validation:  [[ 11.04466021]]\n",
      "Loop 6807 Loss_Train:  [[ 13.19530433]] Loss_Validation:  [[ 11.0446655]]\n",
      "Loop 6808 Loss_Train:  [[ 13.19530425]] Loss_Validation:  [[ 11.04467079]]\n",
      "Loop 6809 Loss_Train:  [[ 13.19530417]] Loss_Validation:  [[ 11.04467608]]\n",
      "Loop 6810 Loss_Train:  [[ 13.19530409]] Loss_Validation:  [[ 11.04468136]]\n",
      "Loop 6811 Loss_Train:  [[ 13.19530401]] Loss_Validation:  [[ 11.04468664]]\n",
      "Loop 6812 Loss_Train:  [[ 13.19530393]] Loss_Validation:  [[ 11.04469191]]\n",
      "Loop 6813 Loss_Train:  [[ 13.19530385]] Loss_Validation:  [[ 11.04469718]]\n",
      "Loop 6814 Loss_Train:  [[ 13.19530377]] Loss_Validation:  [[ 11.04470245]]\n",
      "Loop 6815 Loss_Train:  [[ 13.19530369]] Loss_Validation:  [[ 11.04470772]]\n",
      "Loop 6816 Loss_Train:  [[ 13.19530361]] Loss_Validation:  [[ 11.04471298]]\n",
      "Loop 6817 Loss_Train:  [[ 13.19530353]] Loss_Validation:  [[ 11.04471823]]\n",
      "Loop 6818 Loss_Train:  [[ 13.19530345]] Loss_Validation:  [[ 11.04472349]]\n",
      "Loop 6819 Loss_Train:  [[ 13.19530337]] Loss_Validation:  [[ 11.04472874]]\n",
      "Loop 6820 Loss_Train:  [[ 13.19530329]] Loss_Validation:  [[ 11.04473398]]\n",
      "Loop 6821 Loss_Train:  [[ 13.19530321]] Loss_Validation:  [[ 11.04473923]]\n",
      "Loop 6822 Loss_Train:  [[ 13.19530313]] Loss_Validation:  [[ 11.04474446]]\n",
      "Loop 6823 Loss_Train:  [[ 13.19530305]] Loss_Validation:  [[ 11.0447497]]\n",
      "Loop 6824 Loss_Train:  [[ 13.19530298]] Loss_Validation:  [[ 11.04475493]]\n",
      "Loop 6825 Loss_Train:  [[ 13.1953029]] Loss_Validation:  [[ 11.04476016]]\n",
      "Loop 6826 Loss_Train:  [[ 13.19530282]] Loss_Validation:  [[ 11.04476538]]\n",
      "Loop 6827 Loss_Train:  [[ 13.19530274]] Loss_Validation:  [[ 11.04477061]]\n",
      "Loop 6828 Loss_Train:  [[ 13.19530266]] Loss_Validation:  [[ 11.04477582]]\n",
      "Loop 6829 Loss_Train:  [[ 13.19530259]] Loss_Validation:  [[ 11.04478104]]\n",
      "Loop 6830 Loss_Train:  [[ 13.19530251]] Loss_Validation:  [[ 11.04478625]]\n",
      "Loop 6831 Loss_Train:  [[ 13.19530243]] Loss_Validation:  [[ 11.04479145]]\n",
      "Loop 6832 Loss_Train:  [[ 13.19530235]] Loss_Validation:  [[ 11.04479666]]\n",
      "Loop 6833 Loss_Train:  [[ 13.19530228]] Loss_Validation:  [[ 11.04480186]]\n",
      "Loop 6834 Loss_Train:  [[ 13.1953022]] Loss_Validation:  [[ 11.04480705]]\n",
      "Loop 6835 Loss_Train:  [[ 13.19530212]] Loss_Validation:  [[ 11.04481225]]\n",
      "Loop 6836 Loss_Train:  [[ 13.19530204]] Loss_Validation:  [[ 11.04481743]]\n",
      "Loop 6837 Loss_Train:  [[ 13.19530197]] Loss_Validation:  [[ 11.04482262]]\n",
      "Loop 6838 Loss_Train:  [[ 13.19530189]] Loss_Validation:  [[ 11.0448278]]\n",
      "Loop 6839 Loss_Train:  [[ 13.19530181]] Loss_Validation:  [[ 11.04483298]]\n",
      "Loop 6840 Loss_Train:  [[ 13.19530174]] Loss_Validation:  [[ 11.04483816]]\n",
      "Loop 6841 Loss_Train:  [[ 13.19530166]] Loss_Validation:  [[ 11.04484333]]\n",
      "Loop 6842 Loss_Train:  [[ 13.19530158]] Loss_Validation:  [[ 11.04484849]]\n",
      "Loop 6843 Loss_Train:  [[ 13.19530151]] Loss_Validation:  [[ 11.04485366]]\n",
      "Loop 6844 Loss_Train:  [[ 13.19530143]] Loss_Validation:  [[ 11.04485882]]\n",
      "Loop 6845 Loss_Train:  [[ 13.19530135]] Loss_Validation:  [[ 11.04486398]]\n",
      "Loop 6846 Loss_Train:  [[ 13.19530128]] Loss_Validation:  [[ 11.04486913]]\n",
      "Loop 6847 Loss_Train:  [[ 13.1953012]] Loss_Validation:  [[ 11.04487428]]\n",
      "Loop 6848 Loss_Train:  [[ 13.19530113]] Loss_Validation:  [[ 11.04487943]]\n",
      "Loop 6849 Loss_Train:  [[ 13.19530105]] Loss_Validation:  [[ 11.04488457]]\n",
      "Loop 6850 Loss_Train:  [[ 13.19530098]] Loss_Validation:  [[ 11.04488971]]\n",
      "Loop 6851 Loss_Train:  [[ 13.1953009]] Loss_Validation:  [[ 11.04489484]]\n",
      "Loop 6852 Loss_Train:  [[ 13.19530082]] Loss_Validation:  [[ 11.04489998]]\n",
      "Loop 6853 Loss_Train:  [[ 13.19530075]] Loss_Validation:  [[ 11.0449051]]\n",
      "Loop 6854 Loss_Train:  [[ 13.19530067]] Loss_Validation:  [[ 11.04491023]]\n",
      "Loop 6855 Loss_Train:  [[ 13.1953006]] Loss_Validation:  [[ 11.04491535]]\n",
      "Loop 6856 Loss_Train:  [[ 13.19530052]] Loss_Validation:  [[ 11.04492047]]\n",
      "Loop 6857 Loss_Train:  [[ 13.19530045]] Loss_Validation:  [[ 11.04492559]]\n",
      "Loop 6858 Loss_Train:  [[ 13.19530037]] Loss_Validation:  [[ 11.0449307]]\n",
      "Loop 6859 Loss_Train:  [[ 13.1953003]] Loss_Validation:  [[ 11.0449358]]\n",
      "Loop 6860 Loss_Train:  [[ 13.19530023]] Loss_Validation:  [[ 11.04494091]]\n",
      "Loop 6861 Loss_Train:  [[ 13.19530015]] Loss_Validation:  [[ 11.04494601]]\n",
      "Loop 6862 Loss_Train:  [[ 13.19530008]] Loss_Validation:  [[ 11.04495111]]\n",
      "Loop 6863 Loss_Train:  [[ 13.1953]] Loss_Validation:  [[ 11.0449562]]\n",
      "Loop 6864 Loss_Train:  [[ 13.19529993]] Loss_Validation:  [[ 11.04496129]]\n",
      "Loop 6865 Loss_Train:  [[ 13.19529985]] Loss_Validation:  [[ 11.04496638]]\n",
      "Loop 6866 Loss_Train:  [[ 13.19529978]] Loss_Validation:  [[ 11.04497146]]\n",
      "Loop 6867 Loss_Train:  [[ 13.19529971]] Loss_Validation:  [[ 11.04497654]]\n",
      "Loop 6868 Loss_Train:  [[ 13.19529963]] Loss_Validation:  [[ 11.04498162]]\n",
      "Loop 6869 Loss_Train:  [[ 13.19529956]] Loss_Validation:  [[ 11.04498669]]\n",
      "Loop 6870 Loss_Train:  [[ 13.19529949]] Loss_Validation:  [[ 11.04499176]]\n",
      "Loop 6871 Loss_Train:  [[ 13.19529941]] Loss_Validation:  [[ 11.04499683]]\n",
      "Loop 6872 Loss_Train:  [[ 13.19529934]] Loss_Validation:  [[ 11.04500189]]\n",
      "Loop 6873 Loss_Train:  [[ 13.19529927]] Loss_Validation:  [[ 11.04500695]]\n",
      "Loop 6874 Loss_Train:  [[ 13.19529919]] Loss_Validation:  [[ 11.045012]]\n",
      "Loop 6875 Loss_Train:  [[ 13.19529912]] Loss_Validation:  [[ 11.04501705]]\n",
      "Loop 6876 Loss_Train:  [[ 13.19529905]] Loss_Validation:  [[ 11.0450221]]\n",
      "Loop 6877 Loss_Train:  [[ 13.19529898]] Loss_Validation:  [[ 11.04502715]]\n",
      "Loop 6878 Loss_Train:  [[ 13.1952989]] Loss_Validation:  [[ 11.04503219]]\n",
      "Loop 6879 Loss_Train:  [[ 13.19529883]] Loss_Validation:  [[ 11.04503723]]\n",
      "Loop 6880 Loss_Train:  [[ 13.19529876]] Loss_Validation:  [[ 11.04504226]]\n",
      "Loop 6881 Loss_Train:  [[ 13.19529869]] Loss_Validation:  [[ 11.04504729]]\n",
      "Loop 6882 Loss_Train:  [[ 13.19529861]] Loss_Validation:  [[ 11.04505232]]\n",
      "Loop 6883 Loss_Train:  [[ 13.19529854]] Loss_Validation:  [[ 11.04505735]]\n",
      "Loop 6884 Loss_Train:  [[ 13.19529847]] Loss_Validation:  [[ 11.04506237]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 6885 Loss_Train:  [[ 13.1952984]] Loss_Validation:  [[ 11.04506739]]\n",
      "Loop 6886 Loss_Train:  [[ 13.19529833]] Loss_Validation:  [[ 11.0450724]]\n",
      "Loop 6887 Loss_Train:  [[ 13.19529825]] Loss_Validation:  [[ 11.04507741]]\n",
      "Loop 6888 Loss_Train:  [[ 13.19529818]] Loss_Validation:  [[ 11.04508242]]\n",
      "Loop 6889 Loss_Train:  [[ 13.19529811]] Loss_Validation:  [[ 11.04508742]]\n",
      "Loop 6890 Loss_Train:  [[ 13.19529804]] Loss_Validation:  [[ 11.04509242]]\n",
      "Loop 6891 Loss_Train:  [[ 13.19529797]] Loss_Validation:  [[ 11.04509742]]\n",
      "Loop 6892 Loss_Train:  [[ 13.1952979]] Loss_Validation:  [[ 11.04510241]]\n",
      "Loop 6893 Loss_Train:  [[ 13.19529783]] Loss_Validation:  [[ 11.0451074]]\n",
      "Loop 6894 Loss_Train:  [[ 13.19529776]] Loss_Validation:  [[ 11.04511239]]\n",
      "Loop 6895 Loss_Train:  [[ 13.19529768]] Loss_Validation:  [[ 11.04511737]]\n",
      "Loop 6896 Loss_Train:  [[ 13.19529761]] Loss_Validation:  [[ 11.04512235]]\n",
      "Loop 6897 Loss_Train:  [[ 13.19529754]] Loss_Validation:  [[ 11.04512733]]\n",
      "Loop 6898 Loss_Train:  [[ 13.19529747]] Loss_Validation:  [[ 11.0451323]]\n",
      "Loop 6899 Loss_Train:  [[ 13.1952974]] Loss_Validation:  [[ 11.04513727]]\n",
      "Loop 6900 Loss_Train:  [[ 13.19529733]] Loss_Validation:  [[ 11.04514224]]\n",
      "Loop 6901 Loss_Train:  [[ 13.19529726]] Loss_Validation:  [[ 11.0451472]]\n",
      "Loop 6902 Loss_Train:  [[ 13.19529719]] Loss_Validation:  [[ 11.04515216]]\n",
      "Loop 6903 Loss_Train:  [[ 13.19529712]] Loss_Validation:  [[ 11.04515712]]\n",
      "Loop 6904 Loss_Train:  [[ 13.19529705]] Loss_Validation:  [[ 11.04516207]]\n",
      "Loop 6905 Loss_Train:  [[ 13.19529698]] Loss_Validation:  [[ 11.04516702]]\n",
      "Loop 6906 Loss_Train:  [[ 13.19529691]] Loss_Validation:  [[ 11.04517196]]\n",
      "Loop 6907 Loss_Train:  [[ 13.19529684]] Loss_Validation:  [[ 11.04517691]]\n",
      "Loop 6908 Loss_Train:  [[ 13.19529677]] Loss_Validation:  [[ 11.04518185]]\n",
      "Loop 6909 Loss_Train:  [[ 13.1952967]] Loss_Validation:  [[ 11.04518678]]\n",
      "Loop 6910 Loss_Train:  [[ 13.19529663]] Loss_Validation:  [[ 11.04519171]]\n",
      "Loop 6911 Loss_Train:  [[ 13.19529657]] Loss_Validation:  [[ 11.04519664]]\n",
      "Loop 6912 Loss_Train:  [[ 13.1952965]] Loss_Validation:  [[ 11.04520157]]\n",
      "Loop 6913 Loss_Train:  [[ 13.19529643]] Loss_Validation:  [[ 11.04520649]]\n",
      "Loop 6914 Loss_Train:  [[ 13.19529636]] Loss_Validation:  [[ 11.04521141]]\n",
      "Loop 6915 Loss_Train:  [[ 13.19529629]] Loss_Validation:  [[ 11.04521632]]\n",
      "Loop 6916 Loss_Train:  [[ 13.19529622]] Loss_Validation:  [[ 11.04522124]]\n",
      "Loop 6917 Loss_Train:  [[ 13.19529615]] Loss_Validation:  [[ 11.04522615]]\n",
      "Loop 6918 Loss_Train:  [[ 13.19529608]] Loss_Validation:  [[ 11.04523105]]\n",
      "Loop 6919 Loss_Train:  [[ 13.19529602]] Loss_Validation:  [[ 11.04523595]]\n",
      "Loop 6920 Loss_Train:  [[ 13.19529595]] Loss_Validation:  [[ 11.04524085]]\n",
      "Loop 6921 Loss_Train:  [[ 13.19529588]] Loss_Validation:  [[ 11.04524575]]\n",
      "Loop 6922 Loss_Train:  [[ 13.19529581]] Loss_Validation:  [[ 11.04525064]]\n",
      "Loop 6923 Loss_Train:  [[ 13.19529574]] Loss_Validation:  [[ 11.04525553]]\n",
      "Loop 6924 Loss_Train:  [[ 13.19529567]] Loss_Validation:  [[ 11.04526041]]\n",
      "Loop 6925 Loss_Train:  [[ 13.19529561]] Loss_Validation:  [[ 11.04526529]]\n",
      "Loop 6926 Loss_Train:  [[ 13.19529554]] Loss_Validation:  [[ 11.04527017]]\n",
      "Loop 6927 Loss_Train:  [[ 13.19529547]] Loss_Validation:  [[ 11.04527505]]\n",
      "Loop 6928 Loss_Train:  [[ 13.1952954]] Loss_Validation:  [[ 11.04527992]]\n",
      "Loop 6929 Loss_Train:  [[ 13.19529534]] Loss_Validation:  [[ 11.04528479]]\n",
      "Loop 6930 Loss_Train:  [[ 13.19529527]] Loss_Validation:  [[ 11.04528965]]\n",
      "Loop 6931 Loss_Train:  [[ 13.1952952]] Loss_Validation:  [[ 11.04529452]]\n",
      "Loop 6932 Loss_Train:  [[ 13.19529513]] Loss_Validation:  [[ 11.04529937]]\n",
      "Loop 6933 Loss_Train:  [[ 13.19529507]] Loss_Validation:  [[ 11.04530423]]\n",
      "Loop 6934 Loss_Train:  [[ 13.195295]] Loss_Validation:  [[ 11.04530908]]\n",
      "Loop 6935 Loss_Train:  [[ 13.19529493]] Loss_Validation:  [[ 11.04531393]]\n",
      "Loop 6936 Loss_Train:  [[ 13.19529487]] Loss_Validation:  [[ 11.04531877]]\n",
      "Loop 6937 Loss_Train:  [[ 13.1952948]] Loss_Validation:  [[ 11.04532362]]\n",
      "Loop 6938 Loss_Train:  [[ 13.19529473]] Loss_Validation:  [[ 11.04532846]]\n",
      "Loop 6939 Loss_Train:  [[ 13.19529467]] Loss_Validation:  [[ 11.04533329]]\n",
      "Loop 6940 Loss_Train:  [[ 13.1952946]] Loss_Validation:  [[ 11.04533812]]\n",
      "Loop 6941 Loss_Train:  [[ 13.19529453]] Loss_Validation:  [[ 11.04534295]]\n",
      "Loop 6942 Loss_Train:  [[ 13.19529447]] Loss_Validation:  [[ 11.04534778]]\n",
      "Loop 6943 Loss_Train:  [[ 13.1952944]] Loss_Validation:  [[ 11.0453526]]\n",
      "Loop 6944 Loss_Train:  [[ 13.19529434]] Loss_Validation:  [[ 11.04535742]]\n",
      "Loop 6945 Loss_Train:  [[ 13.19529427]] Loss_Validation:  [[ 11.04536223]]\n",
      "Loop 6946 Loss_Train:  [[ 13.1952942]] Loss_Validation:  [[ 11.04536704]]\n",
      "Loop 6947 Loss_Train:  [[ 13.19529414]] Loss_Validation:  [[ 11.04537185]]\n",
      "Loop 6948 Loss_Train:  [[ 13.19529407]] Loss_Validation:  [[ 11.04537666]]\n",
      "Loop 6949 Loss_Train:  [[ 13.19529401]] Loss_Validation:  [[ 11.04538146]]\n",
      "Loop 6950 Loss_Train:  [[ 13.19529394]] Loss_Validation:  [[ 11.04538626]]\n",
      "Loop 6951 Loss_Train:  [[ 13.19529388]] Loss_Validation:  [[ 11.04539106]]\n",
      "Loop 6952 Loss_Train:  [[ 13.19529381]] Loss_Validation:  [[ 11.04539585]]\n",
      "Loop 6953 Loss_Train:  [[ 13.19529375]] Loss_Validation:  [[ 11.04540064]]\n",
      "Loop 6954 Loss_Train:  [[ 13.19529368]] Loss_Validation:  [[ 11.04540542]]\n",
      "Loop 6955 Loss_Train:  [[ 13.19529362]] Loss_Validation:  [[ 11.0454102]]\n",
      "Loop 6956 Loss_Train:  [[ 13.19529355]] Loss_Validation:  [[ 11.04541498]]\n",
      "Loop 6957 Loss_Train:  [[ 13.19529349]] Loss_Validation:  [[ 11.04541976]]\n",
      "Loop 6958 Loss_Train:  [[ 13.19529342]] Loss_Validation:  [[ 11.04542453]]\n",
      "Loop 6959 Loss_Train:  [[ 13.19529336]] Loss_Validation:  [[ 11.0454293]]\n",
      "Loop 6960 Loss_Train:  [[ 13.19529329]] Loss_Validation:  [[ 11.04543407]]\n",
      "Loop 6961 Loss_Train:  [[ 13.19529323]] Loss_Validation:  [[ 11.04543883]]\n",
      "Loop 6962 Loss_Train:  [[ 13.19529316]] Loss_Validation:  [[ 11.04544359]]\n",
      "Loop 6963 Loss_Train:  [[ 13.1952931]] Loss_Validation:  [[ 11.04544835]]\n",
      "Loop 6964 Loss_Train:  [[ 13.19529304]] Loss_Validation:  [[ 11.0454531]]\n",
      "Loop 6965 Loss_Train:  [[ 13.19529297]] Loss_Validation:  [[ 11.04545785]]\n",
      "Loop 6966 Loss_Train:  [[ 13.19529291]] Loss_Validation:  [[ 11.0454626]]\n",
      "Loop 6967 Loss_Train:  [[ 13.19529284]] Loss_Validation:  [[ 11.04546734]]\n",
      "Loop 6968 Loss_Train:  [[ 13.19529278]] Loss_Validation:  [[ 11.04547208]]\n",
      "Loop 6969 Loss_Train:  [[ 13.19529272]] Loss_Validation:  [[ 11.04547682]]\n",
      "Loop 6970 Loss_Train:  [[ 13.19529265]] Loss_Validation:  [[ 11.04548155]]\n",
      "Loop 6971 Loss_Train:  [[ 13.19529259]] Loss_Validation:  [[ 11.04548628]]\n",
      "Loop 6972 Loss_Train:  [[ 13.19529253]] Loss_Validation:  [[ 11.04549101]]\n",
      "Loop 6973 Loss_Train:  [[ 13.19529246]] Loss_Validation:  [[ 11.04549573]]\n",
      "Loop 6974 Loss_Train:  [[ 13.1952924]] Loss_Validation:  [[ 11.04550045]]\n",
      "Loop 6975 Loss_Train:  [[ 13.19529234]] Loss_Validation:  [[ 11.04550517]]\n",
      "Loop 6976 Loss_Train:  [[ 13.19529227]] Loss_Validation:  [[ 11.04550988]]\n",
      "Loop 6977 Loss_Train:  [[ 13.19529221]] Loss_Validation:  [[ 11.04551459]]\n",
      "Loop 6978 Loss_Train:  [[ 13.19529215]] Loss_Validation:  [[ 11.0455193]]\n",
      "Loop 6979 Loss_Train:  [[ 13.19529209]] Loss_Validation:  [[ 11.04552401]]\n",
      "Loop 6980 Loss_Train:  [[ 13.19529202]] Loss_Validation:  [[ 11.04552871]]\n",
      "Loop 6981 Loss_Train:  [[ 13.19529196]] Loss_Validation:  [[ 11.04553341]]\n",
      "Loop 6982 Loss_Train:  [[ 13.1952919]] Loss_Validation:  [[ 11.0455381]]\n",
      "Loop 6983 Loss_Train:  [[ 13.19529184]] Loss_Validation:  [[ 11.04554279]]\n",
      "Loop 6984 Loss_Train:  [[ 13.19529177]] Loss_Validation:  [[ 11.04554748]]\n",
      "Loop 6985 Loss_Train:  [[ 13.19529171]] Loss_Validation:  [[ 11.04555217]]\n",
      "Loop 6986 Loss_Train:  [[ 13.19529165]] Loss_Validation:  [[ 11.04555685]]\n",
      "Loop 6987 Loss_Train:  [[ 13.19529159]] Loss_Validation:  [[ 11.04556153]]\n",
      "Loop 6988 Loss_Train:  [[ 13.19529153]] Loss_Validation:  [[ 11.0455662]]\n",
      "Loop 6989 Loss_Train:  [[ 13.19529146]] Loss_Validation:  [[ 11.04557087]]\n",
      "Loop 6990 Loss_Train:  [[ 13.1952914]] Loss_Validation:  [[ 11.04557554]]\n",
      "Loop 6991 Loss_Train:  [[ 13.19529134]] Loss_Validation:  [[ 11.04558021]]\n",
      "Loop 6992 Loss_Train:  [[ 13.19529128]] Loss_Validation:  [[ 11.04558487]]\n",
      "Loop 6993 Loss_Train:  [[ 13.19529122]] Loss_Validation:  [[ 11.04558953]]\n",
      "Loop 6994 Loss_Train:  [[ 13.19529116]] Loss_Validation:  [[ 11.04559419]]\n",
      "Loop 6995 Loss_Train:  [[ 13.19529109]] Loss_Validation:  [[ 11.04559884]]\n",
      "Loop 6996 Loss_Train:  [[ 13.19529103]] Loss_Validation:  [[ 11.04560349]]\n",
      "Loop 6997 Loss_Train:  [[ 13.19529097]] Loss_Validation:  [[ 11.04560814]]\n",
      "Loop 6998 Loss_Train:  [[ 13.19529091]] Loss_Validation:  [[ 11.04561278]]\n",
      "Loop 6999 Loss_Train:  [[ 13.19529085]] Loss_Validation:  [[ 11.04561742]]\n",
      "Loop 7000 Loss_Train:  [[ 13.19529079]] Loss_Validation:  [[ 11.04562206]]\n",
      "Loop 7001 Loss_Train:  [[ 13.19529073]] Loss_Validation:  [[ 11.04562669]]\n",
      "Loop 7002 Loss_Train:  [[ 13.19529067]] Loss_Validation:  [[ 11.04563132]]\n",
      "Loop 7003 Loss_Train:  [[ 13.19529061]] Loss_Validation:  [[ 11.04563595]]\n",
      "Loop 7004 Loss_Train:  [[ 13.19529055]] Loss_Validation:  [[ 11.04564057]]\n",
      "Loop 7005 Loss_Train:  [[ 13.19529049]] Loss_Validation:  [[ 11.0456452]]\n",
      "Loop 7006 Loss_Train:  [[ 13.19529043]] Loss_Validation:  [[ 11.04564981]]\n",
      "Loop 7007 Loss_Train:  [[ 13.19529037]] Loss_Validation:  [[ 11.04565443]]\n",
      "Loop 7008 Loss_Train:  [[ 13.1952903]] Loss_Validation:  [[ 11.04565904]]\n",
      "Loop 7009 Loss_Train:  [[ 13.19529024]] Loss_Validation:  [[ 11.04566365]]\n",
      "Loop 7010 Loss_Train:  [[ 13.19529018]] Loss_Validation:  [[ 11.04566825]]\n",
      "Loop 7011 Loss_Train:  [[ 13.19529012]] Loss_Validation:  [[ 11.04567286]]\n",
      "Loop 7012 Loss_Train:  [[ 13.19529007]] Loss_Validation:  [[ 11.04567746]]\n",
      "Loop 7013 Loss_Train:  [[ 13.19529001]] Loss_Validation:  [[ 11.04568205]]\n",
      "Loop 7014 Loss_Train:  [[ 13.19528995]] Loss_Validation:  [[ 11.04568665]]\n",
      "Loop 7015 Loss_Train:  [[ 13.19528989]] Loss_Validation:  [[ 11.04569123]]\n",
      "Loop 7016 Loss_Train:  [[ 13.19528983]] Loss_Validation:  [[ 11.04569582]]\n",
      "Loop 7017 Loss_Train:  [[ 13.19528977]] Loss_Validation:  [[ 11.0457004]]\n",
      "Loop 7018 Loss_Train:  [[ 13.19528971]] Loss_Validation:  [[ 11.04570499]]\n",
      "Loop 7019 Loss_Train:  [[ 13.19528965]] Loss_Validation:  [[ 11.04570956]]\n",
      "Loop 7020 Loss_Train:  [[ 13.19528959]] Loss_Validation:  [[ 11.04571414]]\n",
      "Loop 7021 Loss_Train:  [[ 13.19528953]] Loss_Validation:  [[ 11.04571871]]\n",
      "Loop 7022 Loss_Train:  [[ 13.19528947]] Loss_Validation:  [[ 11.04572327]]\n",
      "Loop 7023 Loss_Train:  [[ 13.19528941]] Loss_Validation:  [[ 11.04572784]]\n",
      "Loop 7024 Loss_Train:  [[ 13.19528935]] Loss_Validation:  [[ 11.0457324]]\n",
      "Loop 7025 Loss_Train:  [[ 13.1952893]] Loss_Validation:  [[ 11.04573696]]\n",
      "Loop 7026 Loss_Train:  [[ 13.19528924]] Loss_Validation:  [[ 11.04574151]]\n",
      "Loop 7027 Loss_Train:  [[ 13.19528918]] Loss_Validation:  [[ 11.04574607]]\n",
      "Loop 7028 Loss_Train:  [[ 13.19528912]] Loss_Validation:  [[ 11.04575062]]\n",
      "Loop 7029 Loss_Train:  [[ 13.19528906]] Loss_Validation:  [[ 11.04575516]]\n",
      "Loop 7030 Loss_Train:  [[ 13.195289]] Loss_Validation:  [[ 11.0457597]]\n",
      "Loop 7031 Loss_Train:  [[ 13.19528894]] Loss_Validation:  [[ 11.04576424]]\n",
      "Loop 7032 Loss_Train:  [[ 13.19528889]] Loss_Validation:  [[ 11.04576878]]\n",
      "Loop 7033 Loss_Train:  [[ 13.19528883]] Loss_Validation:  [[ 11.04577331]]\n",
      "Loop 7034 Loss_Train:  [[ 13.19528877]] Loss_Validation:  [[ 11.04577784]]\n",
      "Loop 7035 Loss_Train:  [[ 13.19528871]] Loss_Validation:  [[ 11.04578237]]\n",
      "Loop 7036 Loss_Train:  [[ 13.19528865]] Loss_Validation:  [[ 11.0457869]]\n",
      "Loop 7037 Loss_Train:  [[ 13.1952886]] Loss_Validation:  [[ 11.04579142]]\n",
      "Loop 7038 Loss_Train:  [[ 13.19528854]] Loss_Validation:  [[ 11.04579593]]\n",
      "Loop 7039 Loss_Train:  [[ 13.19528848]] Loss_Validation:  [[ 11.04580045]]\n",
      "Loop 7040 Loss_Train:  [[ 13.19528842]] Loss_Validation:  [[ 11.04580496]]\n",
      "Loop 7041 Loss_Train:  [[ 13.19528837]] Loss_Validation:  [[ 11.04580947]]\n",
      "Loop 7042 Loss_Train:  [[ 13.19528831]] Loss_Validation:  [[ 11.04581397]]\n",
      "Loop 7043 Loss_Train:  [[ 13.19528825]] Loss_Validation:  [[ 11.04581848]]\n",
      "Loop 7044 Loss_Train:  [[ 13.1952882]] Loss_Validation:  [[ 11.04582298]]\n",
      "Loop 7045 Loss_Train:  [[ 13.19528814]] Loss_Validation:  [[ 11.04582747]]\n",
      "Loop 7046 Loss_Train:  [[ 13.19528808]] Loss_Validation:  [[ 11.04583197]]\n",
      "Loop 7047 Loss_Train:  [[ 13.19528802]] Loss_Validation:  [[ 11.04583646]]\n",
      "Loop 7048 Loss_Train:  [[ 13.19528797]] Loss_Validation:  [[ 11.04584094]]\n",
      "Loop 7049 Loss_Train:  [[ 13.19528791]] Loss_Validation:  [[ 11.04584543]]\n",
      "Loop 7050 Loss_Train:  [[ 13.19528785]] Loss_Validation:  [[ 11.04584991]]\n",
      "Loop 7051 Loss_Train:  [[ 13.1952878]] Loss_Validation:  [[ 11.04585439]]\n",
      "Loop 7052 Loss_Train:  [[ 13.19528774]] Loss_Validation:  [[ 11.04585886]]\n",
      "Loop 7053 Loss_Train:  [[ 13.19528769]] Loss_Validation:  [[ 11.04586333]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 7054 Loss_Train:  [[ 13.19528763]] Loss_Validation:  [[ 11.0458678]]\n",
      "Loop 7055 Loss_Train:  [[ 13.19528757]] Loss_Validation:  [[ 11.04587227]]\n",
      "Loop 7056 Loss_Train:  [[ 13.19528752]] Loss_Validation:  [[ 11.04587673]]\n",
      "Loop 7057 Loss_Train:  [[ 13.19528746]] Loss_Validation:  [[ 11.04588119]]\n",
      "Loop 7058 Loss_Train:  [[ 13.1952874]] Loss_Validation:  [[ 11.04588564]]\n",
      "Loop 7059 Loss_Train:  [[ 13.19528735]] Loss_Validation:  [[ 11.0458901]]\n",
      "Loop 7060 Loss_Train:  [[ 13.19528729]] Loss_Validation:  [[ 11.04589455]]\n",
      "Loop 7061 Loss_Train:  [[ 13.19528724]] Loss_Validation:  [[ 11.04589899]]\n",
      "Loop 7062 Loss_Train:  [[ 13.19528718]] Loss_Validation:  [[ 11.04590344]]\n",
      "Loop 7063 Loss_Train:  [[ 13.19528713]] Loss_Validation:  [[ 11.04590788]]\n",
      "Loop 7064 Loss_Train:  [[ 13.19528707]] Loss_Validation:  [[ 11.04591232]]\n",
      "Loop 7065 Loss_Train:  [[ 13.19528701]] Loss_Validation:  [[ 11.04591675]]\n",
      "Loop 7066 Loss_Train:  [[ 13.19528696]] Loss_Validation:  [[ 11.04592118]]\n",
      "Loop 7067 Loss_Train:  [[ 13.1952869]] Loss_Validation:  [[ 11.04592561]]\n",
      "Loop 7068 Loss_Train:  [[ 13.19528685]] Loss_Validation:  [[ 11.04593004]]\n",
      "Loop 7069 Loss_Train:  [[ 13.19528679]] Loss_Validation:  [[ 11.04593446]]\n",
      "Loop 7070 Loss_Train:  [[ 13.19528674]] Loss_Validation:  [[ 11.04593888]]\n",
      "Loop 7071 Loss_Train:  [[ 13.19528668]] Loss_Validation:  [[ 11.0459433]]\n",
      "Loop 7072 Loss_Train:  [[ 13.19528663]] Loss_Validation:  [[ 11.04594771]]\n",
      "Loop 7073 Loss_Train:  [[ 13.19528657]] Loss_Validation:  [[ 11.04595212]]\n",
      "Loop 7074 Loss_Train:  [[ 13.19528652]] Loss_Validation:  [[ 11.04595653]]\n",
      "Loop 7075 Loss_Train:  [[ 13.19528646]] Loss_Validation:  [[ 11.04596094]]\n",
      "Loop 7076 Loss_Train:  [[ 13.19528641]] Loss_Validation:  [[ 11.04596534]]\n",
      "Loop 7077 Loss_Train:  [[ 13.19528636]] Loss_Validation:  [[ 11.04596974]]\n",
      "Loop 7078 Loss_Train:  [[ 13.1952863]] Loss_Validation:  [[ 11.04597413]]\n",
      "Loop 7079 Loss_Train:  [[ 13.19528625]] Loss_Validation:  [[ 11.04597852]]\n",
      "Loop 7080 Loss_Train:  [[ 13.19528619]] Loss_Validation:  [[ 11.04598291]]\n",
      "Loop 7081 Loss_Train:  [[ 13.19528614]] Loss_Validation:  [[ 11.0459873]]\n",
      "Loop 7082 Loss_Train:  [[ 13.19528608]] Loss_Validation:  [[ 11.04599168]]\n",
      "Loop 7083 Loss_Train:  [[ 13.19528603]] Loss_Validation:  [[ 11.04599606]]\n",
      "Loop 7084 Loss_Train:  [[ 13.19528598]] Loss_Validation:  [[ 11.04600044]]\n",
      "Loop 7085 Loss_Train:  [[ 13.19528592]] Loss_Validation:  [[ 11.04600482]]\n",
      "Loop 7086 Loss_Train:  [[ 13.19528587]] Loss_Validation:  [[ 11.04600919]]\n",
      "Loop 7087 Loss_Train:  [[ 13.19528582]] Loss_Validation:  [[ 11.04601356]]\n",
      "Loop 7088 Loss_Train:  [[ 13.19528576]] Loss_Validation:  [[ 11.04601792]]\n",
      "Loop 7089 Loss_Train:  [[ 13.19528571]] Loss_Validation:  [[ 11.04602228]]\n",
      "Loop 7090 Loss_Train:  [[ 13.19528565]] Loss_Validation:  [[ 11.04602664]]\n",
      "Loop 7091 Loss_Train:  [[ 13.1952856]] Loss_Validation:  [[ 11.046031]]\n",
      "Loop 7092 Loss_Train:  [[ 13.19528555]] Loss_Validation:  [[ 11.04603535]]\n",
      "Loop 7093 Loss_Train:  [[ 13.19528549]] Loss_Validation:  [[ 11.0460397]]\n",
      "Loop 7094 Loss_Train:  [[ 13.19528544]] Loss_Validation:  [[ 11.04604405]]\n",
      "Loop 7095 Loss_Train:  [[ 13.19528539]] Loss_Validation:  [[ 11.0460484]]\n",
      "Loop 7096 Loss_Train:  [[ 13.19528534]] Loss_Validation:  [[ 11.04605274]]\n",
      "Loop 7097 Loss_Train:  [[ 13.19528528]] Loss_Validation:  [[ 11.04605708]]\n",
      "Loop 7098 Loss_Train:  [[ 13.19528523]] Loss_Validation:  [[ 11.04606141]]\n",
      "Loop 7099 Loss_Train:  [[ 13.19528518]] Loss_Validation:  [[ 11.04606575]]\n",
      "Loop 7100 Loss_Train:  [[ 13.19528512]] Loss_Validation:  [[ 11.04607008]]\n",
      "Loop 7101 Loss_Train:  [[ 13.19528507]] Loss_Validation:  [[ 11.0460744]]\n",
      "Loop 7102 Loss_Train:  [[ 13.19528502]] Loss_Validation:  [[ 11.04607873]]\n",
      "Loop 7103 Loss_Train:  [[ 13.19528497]] Loss_Validation:  [[ 11.04608305]]\n",
      "Loop 7104 Loss_Train:  [[ 13.19528491]] Loss_Validation:  [[ 11.04608736]]\n",
      "Loop 7105 Loss_Train:  [[ 13.19528486]] Loss_Validation:  [[ 11.04609168]]\n",
      "Loop 7106 Loss_Train:  [[ 13.19528481]] Loss_Validation:  [[ 11.04609599]]\n",
      "Loop 7107 Loss_Train:  [[ 13.19528476]] Loss_Validation:  [[ 11.0461003]]\n",
      "Loop 7108 Loss_Train:  [[ 13.19528471]] Loss_Validation:  [[ 11.04610461]]\n",
      "Loop 7109 Loss_Train:  [[ 13.19528465]] Loss_Validation:  [[ 11.04610891]]\n",
      "Loop 7110 Loss_Train:  [[ 13.1952846]] Loss_Validation:  [[ 11.04611321]]\n",
      "Loop 7111 Loss_Train:  [[ 13.19528455]] Loss_Validation:  [[ 11.04611751]]\n",
      "Loop 7112 Loss_Train:  [[ 13.1952845]] Loss_Validation:  [[ 11.0461218]]\n",
      "Loop 7113 Loss_Train:  [[ 13.19528445]] Loss_Validation:  [[ 11.04612609]]\n",
      "Loop 7114 Loss_Train:  [[ 13.19528439]] Loss_Validation:  [[ 11.04613038]]\n",
      "Loop 7115 Loss_Train:  [[ 13.19528434]] Loss_Validation:  [[ 11.04613467]]\n",
      "Loop 7116 Loss_Train:  [[ 13.19528429]] Loss_Validation:  [[ 11.04613895]]\n",
      "Loop 7117 Loss_Train:  [[ 13.19528424]] Loss_Validation:  [[ 11.04614323]]\n",
      "Loop 7118 Loss_Train:  [[ 13.19528419]] Loss_Validation:  [[ 11.04614751]]\n",
      "Loop 7119 Loss_Train:  [[ 13.19528414]] Loss_Validation:  [[ 11.04615178]]\n",
      "Loop 7120 Loss_Train:  [[ 13.19528409]] Loss_Validation:  [[ 11.04615605]]\n",
      "Loop 7121 Loss_Train:  [[ 13.19528404]] Loss_Validation:  [[ 11.04616032]]\n",
      "Loop 7122 Loss_Train:  [[ 13.19528398]] Loss_Validation:  [[ 11.04616458]]\n",
      "Loop 7123 Loss_Train:  [[ 13.19528393]] Loss_Validation:  [[ 11.04616884]]\n",
      "Loop 7124 Loss_Train:  [[ 13.19528388]] Loss_Validation:  [[ 11.0461731]]\n",
      "Loop 7125 Loss_Train:  [[ 13.19528383]] Loss_Validation:  [[ 11.04617736]]\n",
      "Loop 7126 Loss_Train:  [[ 13.19528378]] Loss_Validation:  [[ 11.04618161]]\n",
      "Loop 7127 Loss_Train:  [[ 13.19528373]] Loss_Validation:  [[ 11.04618586]]\n",
      "Loop 7128 Loss_Train:  [[ 13.19528368]] Loss_Validation:  [[ 11.04619011]]\n",
      "Loop 7129 Loss_Train:  [[ 13.19528363]] Loss_Validation:  [[ 11.04619435]]\n",
      "Loop 7130 Loss_Train:  [[ 13.19528358]] Loss_Validation:  [[ 11.0461986]]\n",
      "Loop 7131 Loss_Train:  [[ 13.19528353]] Loss_Validation:  [[ 11.04620283]]\n",
      "Loop 7132 Loss_Train:  [[ 13.19528348]] Loss_Validation:  [[ 11.04620707]]\n",
      "Loop 7133 Loss_Train:  [[ 13.19528343]] Loss_Validation:  [[ 11.0462113]]\n",
      "Loop 7134 Loss_Train:  [[ 13.19528338]] Loss_Validation:  [[ 11.04621553]]\n",
      "Loop 7135 Loss_Train:  [[ 13.19528333]] Loss_Validation:  [[ 11.04621976]]\n",
      "Loop 7136 Loss_Train:  [[ 13.19528328]] Loss_Validation:  [[ 11.04622398]]\n",
      "Loop 7137 Loss_Train:  [[ 13.19528323]] Loss_Validation:  [[ 11.04622821]]\n",
      "Loop 7138 Loss_Train:  [[ 13.19528318]] Loss_Validation:  [[ 11.04623242]]\n",
      "Loop 7139 Loss_Train:  [[ 13.19528313]] Loss_Validation:  [[ 11.04623664]]\n",
      "Loop 7140 Loss_Train:  [[ 13.19528308]] Loss_Validation:  [[ 11.04624085]]\n",
      "Loop 7141 Loss_Train:  [[ 13.19528303]] Loss_Validation:  [[ 11.04624506]]\n",
      "Loop 7142 Loss_Train:  [[ 13.19528298]] Loss_Validation:  [[ 11.04624927]]\n",
      "Loop 7143 Loss_Train:  [[ 13.19528293]] Loss_Validation:  [[ 11.04625347]]\n",
      "Loop 7144 Loss_Train:  [[ 13.19528288]] Loss_Validation:  [[ 11.04625767]]\n",
      "Loop 7145 Loss_Train:  [[ 13.19528283]] Loss_Validation:  [[ 11.04626187]]\n",
      "Loop 7146 Loss_Train:  [[ 13.19528278]] Loss_Validation:  [[ 11.04626607]]\n",
      "Loop 7147 Loss_Train:  [[ 13.19528273]] Loss_Validation:  [[ 11.04627026]]\n",
      "Loop 7148 Loss_Train:  [[ 13.19528268]] Loss_Validation:  [[ 11.04627445]]\n",
      "Loop 7149 Loss_Train:  [[ 13.19528263]] Loss_Validation:  [[ 11.04627863]]\n",
      "Loop 7150 Loss_Train:  [[ 13.19528258]] Loss_Validation:  [[ 11.04628282]]\n",
      "Loop 7151 Loss_Train:  [[ 13.19528254]] Loss_Validation:  [[ 11.046287]]\n",
      "Loop 7152 Loss_Train:  [[ 13.19528249]] Loss_Validation:  [[ 11.04629118]]\n",
      "Loop 7153 Loss_Train:  [[ 13.19528244]] Loss_Validation:  [[ 11.04629535]]\n",
      "Loop 7154 Loss_Train:  [[ 13.19528239]] Loss_Validation:  [[ 11.04629952]]\n",
      "Loop 7155 Loss_Train:  [[ 13.19528234]] Loss_Validation:  [[ 11.04630369]]\n",
      "Loop 7156 Loss_Train:  [[ 13.19528229]] Loss_Validation:  [[ 11.04630786]]\n",
      "Loop 7157 Loss_Train:  [[ 13.19528224]] Loss_Validation:  [[ 11.04631202]]\n",
      "Loop 7158 Loss_Train:  [[ 13.19528219]] Loss_Validation:  [[ 11.04631619]]\n",
      "Loop 7159 Loss_Train:  [[ 13.19528215]] Loss_Validation:  [[ 11.04632034]]\n",
      "Loop 7160 Loss_Train:  [[ 13.1952821]] Loss_Validation:  [[ 11.0463245]]\n",
      "Loop 7161 Loss_Train:  [[ 13.19528205]] Loss_Validation:  [[ 11.04632865]]\n",
      "Loop 7162 Loss_Train:  [[ 13.195282]] Loss_Validation:  [[ 11.0463328]]\n",
      "Loop 7163 Loss_Train:  [[ 13.19528195]] Loss_Validation:  [[ 11.04633695]]\n",
      "Loop 7164 Loss_Train:  [[ 13.19528191]] Loss_Validation:  [[ 11.04634109]]\n",
      "Loop 7165 Loss_Train:  [[ 13.19528186]] Loss_Validation:  [[ 11.04634523]]\n",
      "Loop 7166 Loss_Train:  [[ 13.19528181]] Loss_Validation:  [[ 11.04634937]]\n",
      "Loop 7167 Loss_Train:  [[ 13.19528176]] Loss_Validation:  [[ 11.0463535]]\n",
      "Loop 7168 Loss_Train:  [[ 13.19528171]] Loss_Validation:  [[ 11.04635764]]\n",
      "Loop 7169 Loss_Train:  [[ 13.19528167]] Loss_Validation:  [[ 11.04636177]]\n",
      "Loop 7170 Loss_Train:  [[ 13.19528162]] Loss_Validation:  [[ 11.04636589]]\n",
      "Loop 7171 Loss_Train:  [[ 13.19528157]] Loss_Validation:  [[ 11.04637002]]\n",
      "Loop 7172 Loss_Train:  [[ 13.19528152]] Loss_Validation:  [[ 11.04637414]]\n",
      "Loop 7173 Loss_Train:  [[ 13.19528148]] Loss_Validation:  [[ 11.04637826]]\n",
      "Loop 7174 Loss_Train:  [[ 13.19528143]] Loss_Validation:  [[ 11.04638237]]\n",
      "Loop 7175 Loss_Train:  [[ 13.19528138]] Loss_Validation:  [[ 11.04638648]]\n",
      "Loop 7176 Loss_Train:  [[ 13.19528133]] Loss_Validation:  [[ 11.04639059]]\n",
      "Loop 7177 Loss_Train:  [[ 13.19528129]] Loss_Validation:  [[ 11.0463947]]\n",
      "Loop 7178 Loss_Train:  [[ 13.19528124]] Loss_Validation:  [[ 11.0463988]]\n",
      "Loop 7179 Loss_Train:  [[ 13.19528119]] Loss_Validation:  [[ 11.04640291]]\n",
      "Loop 7180 Loss_Train:  [[ 13.19528115]] Loss_Validation:  [[ 11.046407]]\n",
      "Loop 7181 Loss_Train:  [[ 13.1952811]] Loss_Validation:  [[ 11.0464111]]\n",
      "Loop 7182 Loss_Train:  [[ 13.19528105]] Loss_Validation:  [[ 11.04641519]]\n",
      "Loop 7183 Loss_Train:  [[ 13.19528101]] Loss_Validation:  [[ 11.04641928]]\n",
      "Loop 7184 Loss_Train:  [[ 13.19528096]] Loss_Validation:  [[ 11.04642337]]\n",
      "Loop 7185 Loss_Train:  [[ 13.19528091]] Loss_Validation:  [[ 11.04642745]]\n",
      "Loop 7186 Loss_Train:  [[ 13.19528087]] Loss_Validation:  [[ 11.04643154]]\n",
      "Loop 7187 Loss_Train:  [[ 13.19528082]] Loss_Validation:  [[ 11.04643562]]\n",
      "Loop 7188 Loss_Train:  [[ 13.19528077]] Loss_Validation:  [[ 11.04643969]]\n",
      "Loop 7189 Loss_Train:  [[ 13.19528073]] Loss_Validation:  [[ 11.04644376]]\n",
      "Loop 7190 Loss_Train:  [[ 13.19528068]] Loss_Validation:  [[ 11.04644783]]\n",
      "Loop 7191 Loss_Train:  [[ 13.19528063]] Loss_Validation:  [[ 11.0464519]]\n",
      "Loop 7192 Loss_Train:  [[ 13.19528059]] Loss_Validation:  [[ 11.04645597]]\n",
      "Loop 7193 Loss_Train:  [[ 13.19528054]] Loss_Validation:  [[ 11.04646003]]\n",
      "Loop 7194 Loss_Train:  [[ 13.1952805]] Loss_Validation:  [[ 11.04646409]]\n",
      "Loop 7195 Loss_Train:  [[ 13.19528045]] Loss_Validation:  [[ 11.04646815]]\n",
      "Loop 7196 Loss_Train:  [[ 13.1952804]] Loss_Validation:  [[ 11.0464722]]\n",
      "Loop 7197 Loss_Train:  [[ 13.19528036]] Loss_Validation:  [[ 11.04647625]]\n",
      "Loop 7198 Loss_Train:  [[ 13.19528031]] Loss_Validation:  [[ 11.0464803]]\n",
      "Loop 7199 Loss_Train:  [[ 13.19528027]] Loss_Validation:  [[ 11.04648434]]\n",
      "Loop 7200 Loss_Train:  [[ 13.19528022]] Loss_Validation:  [[ 11.04648839]]\n",
      "Loop 7201 Loss_Train:  [[ 13.19528018]] Loss_Validation:  [[ 11.04649243]]\n",
      "Loop 7202 Loss_Train:  [[ 13.19528013]] Loss_Validation:  [[ 11.04649646]]\n",
      "Loop 7203 Loss_Train:  [[ 13.19528008]] Loss_Validation:  [[ 11.0465005]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 7204 Loss_Train:  [[ 13.19528004]] Loss_Validation:  [[ 11.04650453]]\n",
      "Loop 7205 Loss_Train:  [[ 13.19527999]] Loss_Validation:  [[ 11.04650856]]\n",
      "Loop 7206 Loss_Train:  [[ 13.19527995]] Loss_Validation:  [[ 11.04651258]]\n",
      "Loop 7207 Loss_Train:  [[ 13.1952799]] Loss_Validation:  [[ 11.04651661]]\n",
      "Loop 7208 Loss_Train:  [[ 13.19527986]] Loss_Validation:  [[ 11.04652063]]\n",
      "Loop 7209 Loss_Train:  [[ 13.19527981]] Loss_Validation:  [[ 11.04652464]]\n",
      "Loop 7210 Loss_Train:  [[ 13.19527977]] Loss_Validation:  [[ 11.04652866]]\n",
      "Loop 7211 Loss_Train:  [[ 13.19527972]] Loss_Validation:  [[ 11.04653267]]\n",
      "Loop 7212 Loss_Train:  [[ 13.19527968]] Loss_Validation:  [[ 11.04653668]]\n",
      "Loop 7213 Loss_Train:  [[ 13.19527963]] Loss_Validation:  [[ 11.04654069]]\n",
      "Loop 7214 Loss_Train:  [[ 13.19527959]] Loss_Validation:  [[ 11.04654469]]\n",
      "Loop 7215 Loss_Train:  [[ 13.19527954]] Loss_Validation:  [[ 11.04654869]]\n",
      "Loop 7216 Loss_Train:  [[ 13.1952795]] Loss_Validation:  [[ 11.04655269]]\n",
      "Loop 7217 Loss_Train:  [[ 13.19527946]] Loss_Validation:  [[ 11.04655669]]\n",
      "Loop 7218 Loss_Train:  [[ 13.19527941]] Loss_Validation:  [[ 11.04656068]]\n",
      "Loop 7219 Loss_Train:  [[ 13.19527937]] Loss_Validation:  [[ 11.04656467]]\n",
      "Loop 7220 Loss_Train:  [[ 13.19527932]] Loss_Validation:  [[ 11.04656866]]\n",
      "Loop 7221 Loss_Train:  [[ 13.19527928]] Loss_Validation:  [[ 11.04657264]]\n",
      "Loop 7222 Loss_Train:  [[ 13.19527923]] Loss_Validation:  [[ 11.04657662]]\n",
      "Loop 7223 Loss_Train:  [[ 13.19527919]] Loss_Validation:  [[ 11.0465806]]\n",
      "Loop 7224 Loss_Train:  [[ 13.19527915]] Loss_Validation:  [[ 11.04658458]]\n",
      "Loop 7225 Loss_Train:  [[ 13.1952791]] Loss_Validation:  [[ 11.04658855]]\n",
      "Loop 7226 Loss_Train:  [[ 13.19527906]] Loss_Validation:  [[ 11.04659253]]\n",
      "Loop 7227 Loss_Train:  [[ 13.19527901]] Loss_Validation:  [[ 11.04659649]]\n",
      "Loop 7228 Loss_Train:  [[ 13.19527897]] Loss_Validation:  [[ 11.04660046]]\n",
      "Loop 7229 Loss_Train:  [[ 13.19527893]] Loss_Validation:  [[ 11.04660442]]\n",
      "Loop 7230 Loss_Train:  [[ 13.19527888]] Loss_Validation:  [[ 11.04660838]]\n",
      "Loop 7231 Loss_Train:  [[ 13.19527884]] Loss_Validation:  [[ 11.04661234]]\n",
      "Loop 7232 Loss_Train:  [[ 13.1952788]] Loss_Validation:  [[ 11.04661629]]\n",
      "Loop 7233 Loss_Train:  [[ 13.19527875]] Loss_Validation:  [[ 11.04662025]]\n",
      "Loop 7234 Loss_Train:  [[ 13.19527871]] Loss_Validation:  [[ 11.0466242]]\n",
      "Loop 7235 Loss_Train:  [[ 13.19527866]] Loss_Validation:  [[ 11.04662814]]\n",
      "Loop 7236 Loss_Train:  [[ 13.19527862]] Loss_Validation:  [[ 11.04663209]]\n",
      "Loop 7237 Loss_Train:  [[ 13.19527858]] Loss_Validation:  [[ 11.04663603]]\n",
      "Loop 7238 Loss_Train:  [[ 13.19527853]] Loss_Validation:  [[ 11.04663997]]\n",
      "Loop 7239 Loss_Train:  [[ 13.19527849]] Loss_Validation:  [[ 11.0466439]]\n",
      "Loop 7240 Loss_Train:  [[ 13.19527845]] Loss_Validation:  [[ 11.04664783]]\n",
      "Loop 7241 Loss_Train:  [[ 13.19527841]] Loss_Validation:  [[ 11.04665177]]\n",
      "Loop 7242 Loss_Train:  [[ 13.19527836]] Loss_Validation:  [[ 11.04665569]]\n",
      "Loop 7243 Loss_Train:  [[ 13.19527832]] Loss_Validation:  [[ 11.04665962]]\n",
      "Loop 7244 Loss_Train:  [[ 13.19527828]] Loss_Validation:  [[ 11.04666354]]\n",
      "Loop 7245 Loss_Train:  [[ 13.19527823]] Loss_Validation:  [[ 11.04666746]]\n",
      "Loop 7246 Loss_Train:  [[ 13.19527819]] Loss_Validation:  [[ 11.04667138]]\n",
      "Loop 7247 Loss_Train:  [[ 13.19527815]] Loss_Validation:  [[ 11.04667529]]\n",
      "Loop 7248 Loss_Train:  [[ 13.19527811]] Loss_Validation:  [[ 11.0466792]]\n",
      "Loop 7249 Loss_Train:  [[ 13.19527806]] Loss_Validation:  [[ 11.04668311]]\n",
      "Loop 7250 Loss_Train:  [[ 13.19527802]] Loss_Validation:  [[ 11.04668702]]\n",
      "Loop 7251 Loss_Train:  [[ 13.19527798]] Loss_Validation:  [[ 11.04669092]]\n",
      "Loop 7252 Loss_Train:  [[ 13.19527794]] Loss_Validation:  [[ 11.04669482]]\n",
      "Loop 7253 Loss_Train:  [[ 13.19527789]] Loss_Validation:  [[ 11.04669872]]\n",
      "Loop 7254 Loss_Train:  [[ 13.19527785]] Loss_Validation:  [[ 11.04670262]]\n",
      "Loop 7255 Loss_Train:  [[ 13.19527781]] Loss_Validation:  [[ 11.04670651]]\n",
      "Loop 7256 Loss_Train:  [[ 13.19527777]] Loss_Validation:  [[ 11.0467104]]\n",
      "Loop 7257 Loss_Train:  [[ 13.19527773]] Loss_Validation:  [[ 11.04671429]]\n",
      "Loop 7258 Loss_Train:  [[ 13.19527768]] Loss_Validation:  [[ 11.04671817]]\n",
      "Loop 7259 Loss_Train:  [[ 13.19527764]] Loss_Validation:  [[ 11.04672205]]\n",
      "Loop 7260 Loss_Train:  [[ 13.1952776]] Loss_Validation:  [[ 11.04672593]]\n",
      "Loop 7261 Loss_Train:  [[ 13.19527756]] Loss_Validation:  [[ 11.04672981]]\n",
      "Loop 7262 Loss_Train:  [[ 13.19527752]] Loss_Validation:  [[ 11.04673368]]\n",
      "Loop 7263 Loss_Train:  [[ 13.19527748]] Loss_Validation:  [[ 11.04673755]]\n",
      "Loop 7264 Loss_Train:  [[ 13.19527743]] Loss_Validation:  [[ 11.04674142]]\n",
      "Loop 7265 Loss_Train:  [[ 13.19527739]] Loss_Validation:  [[ 11.04674529]]\n",
      "Loop 7266 Loss_Train:  [[ 13.19527735]] Loss_Validation:  [[ 11.04674915]]\n",
      "Loop 7267 Loss_Train:  [[ 13.19527731]] Loss_Validation:  [[ 11.04675301]]\n",
      "Loop 7268 Loss_Train:  [[ 13.19527727]] Loss_Validation:  [[ 11.04675687]]\n",
      "Loop 7269 Loss_Train:  [[ 13.19527723]] Loss_Validation:  [[ 11.04676073]]\n",
      "Loop 7270 Loss_Train:  [[ 13.19527719]] Loss_Validation:  [[ 11.04676458]]\n",
      "Loop 7271 Loss_Train:  [[ 13.19527714]] Loss_Validation:  [[ 11.04676843]]\n",
      "Loop 7272 Loss_Train:  [[ 13.1952771]] Loss_Validation:  [[ 11.04677228]]\n",
      "Loop 7273 Loss_Train:  [[ 13.19527706]] Loss_Validation:  [[ 11.04677612]]\n",
      "Loop 7274 Loss_Train:  [[ 13.19527702]] Loss_Validation:  [[ 11.04677997]]\n",
      "Loop 7275 Loss_Train:  [[ 13.19527698]] Loss_Validation:  [[ 11.04678381]]\n",
      "Loop 7276 Loss_Train:  [[ 13.19527694]] Loss_Validation:  [[ 11.04678764]]\n",
      "Loop 7277 Loss_Train:  [[ 13.1952769]] Loss_Validation:  [[ 11.04679148]]\n",
      "Loop 7278 Loss_Train:  [[ 13.19527686]] Loss_Validation:  [[ 11.04679531]]\n",
      "Loop 7279 Loss_Train:  [[ 13.19527682]] Loss_Validation:  [[ 11.04679914]]\n",
      "Loop 7280 Loss_Train:  [[ 13.19527678]] Loss_Validation:  [[ 11.04680296]]\n",
      "Loop 7281 Loss_Train:  [[ 13.19527674]] Loss_Validation:  [[ 11.04680679]]\n",
      "Loop 7282 Loss_Train:  [[ 13.19527669]] Loss_Validation:  [[ 11.04681061]]\n",
      "Loop 7283 Loss_Train:  [[ 13.19527665]] Loss_Validation:  [[ 11.04681443]]\n",
      "Loop 7284 Loss_Train:  [[ 13.19527661]] Loss_Validation:  [[ 11.04681824]]\n",
      "Loop 7285 Loss_Train:  [[ 13.19527657]] Loss_Validation:  [[ 11.04682206]]\n",
      "Loop 7286 Loss_Train:  [[ 13.19527653]] Loss_Validation:  [[ 11.04682587]]\n",
      "Loop 7287 Loss_Train:  [[ 13.19527649]] Loss_Validation:  [[ 11.04682968]]\n",
      "Loop 7288 Loss_Train:  [[ 13.19527645]] Loss_Validation:  [[ 11.04683348]]\n",
      "Loop 7289 Loss_Train:  [[ 13.19527641]] Loss_Validation:  [[ 11.04683729]]\n",
      "Loop 7290 Loss_Train:  [[ 13.19527637]] Loss_Validation:  [[ 11.04684109]]\n",
      "Loop 7291 Loss_Train:  [[ 13.19527633]] Loss_Validation:  [[ 11.04684488]]\n",
      "Loop 7292 Loss_Train:  [[ 13.19527629]] Loss_Validation:  [[ 11.04684868]]\n",
      "Loop 7293 Loss_Train:  [[ 13.19527625]] Loss_Validation:  [[ 11.04685247]]\n",
      "Loop 7294 Loss_Train:  [[ 13.19527621]] Loss_Validation:  [[ 11.04685626]]\n",
      "Loop 7295 Loss_Train:  [[ 13.19527617]] Loss_Validation:  [[ 11.04686005]]\n",
      "Loop 7296 Loss_Train:  [[ 13.19527613]] Loss_Validation:  [[ 11.04686383]]\n",
      "Loop 7297 Loss_Train:  [[ 13.19527609]] Loss_Validation:  [[ 11.04686762]]\n",
      "Loop 7298 Loss_Train:  [[ 13.19527605]] Loss_Validation:  [[ 11.0468714]]\n",
      "Loop 7299 Loss_Train:  [[ 13.19527601]] Loss_Validation:  [[ 11.04687517]]\n",
      "Loop 7300 Loss_Train:  [[ 13.19527598]] Loss_Validation:  [[ 11.04687895]]\n",
      "Loop 7301 Loss_Train:  [[ 13.19527594]] Loss_Validation:  [[ 11.04688272]]\n",
      "Loop 7302 Loss_Train:  [[ 13.1952759]] Loss_Validation:  [[ 11.04688649]]\n",
      "Loop 7303 Loss_Train:  [[ 13.19527586]] Loss_Validation:  [[ 11.04689025]]\n",
      "Loop 7304 Loss_Train:  [[ 13.19527582]] Loss_Validation:  [[ 11.04689402]]\n",
      "Loop 7305 Loss_Train:  [[ 13.19527578]] Loss_Validation:  [[ 11.04689778]]\n",
      "Loop 7306 Loss_Train:  [[ 13.19527574]] Loss_Validation:  [[ 11.04690154]]\n",
      "Loop 7307 Loss_Train:  [[ 13.1952757]] Loss_Validation:  [[ 11.04690529]]\n",
      "Loop 7308 Loss_Train:  [[ 13.19527566]] Loss_Validation:  [[ 11.04690905]]\n",
      "Loop 7309 Loss_Train:  [[ 13.19527562]] Loss_Validation:  [[ 11.0469128]]\n",
      "Loop 7310 Loss_Train:  [[ 13.19527558]] Loss_Validation:  [[ 11.04691655]]\n",
      "Loop 7311 Loss_Train:  [[ 13.19527554]] Loss_Validation:  [[ 11.04692029]]\n",
      "Loop 7312 Loss_Train:  [[ 13.19527551]] Loss_Validation:  [[ 11.04692404]]\n",
      "Loop 7313 Loss_Train:  [[ 13.19527547]] Loss_Validation:  [[ 11.04692778]]\n",
      "Loop 7314 Loss_Train:  [[ 13.19527543]] Loss_Validation:  [[ 11.04693152]]\n",
      "Loop 7315 Loss_Train:  [[ 13.19527539]] Loss_Validation:  [[ 11.04693525]]\n",
      "Loop 7316 Loss_Train:  [[ 13.19527535]] Loss_Validation:  [[ 11.04693898]]\n",
      "Loop 7317 Loss_Train:  [[ 13.19527531]] Loss_Validation:  [[ 11.04694272]]\n",
      "Loop 7318 Loss_Train:  [[ 13.19527527]] Loss_Validation:  [[ 11.04694644]]\n",
      "Loop 7319 Loss_Train:  [[ 13.19527524]] Loss_Validation:  [[ 11.04695017]]\n",
      "Loop 7320 Loss_Train:  [[ 13.1952752]] Loss_Validation:  [[ 11.04695389]]\n",
      "Loop 7321 Loss_Train:  [[ 13.19527516]] Loss_Validation:  [[ 11.04695761]]\n",
      "Loop 7322 Loss_Train:  [[ 13.19527512]] Loss_Validation:  [[ 11.04696133]]\n",
      "Loop 7323 Loss_Train:  [[ 13.19527508]] Loss_Validation:  [[ 11.04696504]]\n",
      "Loop 7324 Loss_Train:  [[ 13.19527504]] Loss_Validation:  [[ 11.04696876]]\n",
      "Loop 7325 Loss_Train:  [[ 13.19527501]] Loss_Validation:  [[ 11.04697247]]\n",
      "Loop 7326 Loss_Train:  [[ 13.19527497]] Loss_Validation:  [[ 11.04697617]]\n",
      "Loop 7327 Loss_Train:  [[ 13.19527493]] Loss_Validation:  [[ 11.04697988]]\n",
      "Loop 7328 Loss_Train:  [[ 13.19527489]] Loss_Validation:  [[ 11.04698358]]\n",
      "Loop 7329 Loss_Train:  [[ 13.19527485]] Loss_Validation:  [[ 11.04698728]]\n",
      "Loop 7330 Loss_Train:  [[ 13.19527482]] Loss_Validation:  [[ 11.04699098]]\n",
      "Loop 7331 Loss_Train:  [[ 13.19527478]] Loss_Validation:  [[ 11.04699467]]\n",
      "Loop 7332 Loss_Train:  [[ 13.19527474]] Loss_Validation:  [[ 11.04699837]]\n",
      "Loop 7333 Loss_Train:  [[ 13.1952747]] Loss_Validation:  [[ 11.04700206]]\n",
      "Loop 7334 Loss_Train:  [[ 13.19527467]] Loss_Validation:  [[ 11.04700574]]\n",
      "Loop 7335 Loss_Train:  [[ 13.19527463]] Loss_Validation:  [[ 11.04700943]]\n",
      "Loop 7336 Loss_Train:  [[ 13.19527459]] Loss_Validation:  [[ 11.04701311]]\n",
      "Loop 7337 Loss_Train:  [[ 13.19527455]] Loss_Validation:  [[ 11.04701679]]\n",
      "Loop 7338 Loss_Train:  [[ 13.19527452]] Loss_Validation:  [[ 11.04702047]]\n",
      "Loop 7339 Loss_Train:  [[ 13.19527448]] Loss_Validation:  [[ 11.04702414]]\n",
      "Loop 7340 Loss_Train:  [[ 13.19527444]] Loss_Validation:  [[ 11.04702781]]\n",
      "Loop 7341 Loss_Train:  [[ 13.1952744]] Loss_Validation:  [[ 11.04703148]]\n",
      "Loop 7342 Loss_Train:  [[ 13.19527437]] Loss_Validation:  [[ 11.04703515]]\n",
      "Loop 7343 Loss_Train:  [[ 13.19527433]] Loss_Validation:  [[ 11.04703882]]\n",
      "Loop 7344 Loss_Train:  [[ 13.19527429]] Loss_Validation:  [[ 11.04704248]]\n",
      "Loop 7345 Loss_Train:  [[ 13.19527426]] Loss_Validation:  [[ 11.04704614]]\n",
      "Loop 7346 Loss_Train:  [[ 13.19527422]] Loss_Validation:  [[ 11.04704979]]\n",
      "Loop 7347 Loss_Train:  [[ 13.19527418]] Loss_Validation:  [[ 11.04705345]]\n",
      "Loop 7348 Loss_Train:  [[ 13.19527414]] Loss_Validation:  [[ 11.0470571]]\n",
      "Loop 7349 Loss_Train:  [[ 13.19527411]] Loss_Validation:  [[ 11.04706075]]\n",
      "Loop 7350 Loss_Train:  [[ 13.19527407]] Loss_Validation:  [[ 11.0470644]]\n",
      "Loop 7351 Loss_Train:  [[ 13.19527403]] Loss_Validation:  [[ 11.04706804]]\n",
      "Loop 7352 Loss_Train:  [[ 13.195274]] Loss_Validation:  [[ 11.04707168]]\n",
      "Loop 7353 Loss_Train:  [[ 13.19527396]] Loss_Validation:  [[ 11.04707532]]\n",
      "Loop 7354 Loss_Train:  [[ 13.19527392]] Loss_Validation:  [[ 11.04707896]]\n",
      "Loop 7355 Loss_Train:  [[ 13.19527389]] Loss_Validation:  [[ 11.04708259]]\n",
      "Loop 7356 Loss_Train:  [[ 13.19527385]] Loss_Validation:  [[ 11.04708623]]\n",
      "Loop 7357 Loss_Train:  [[ 13.19527382]] Loss_Validation:  [[ 11.04708985]]\n",
      "Loop 7358 Loss_Train:  [[ 13.19527378]] Loss_Validation:  [[ 11.04709348]]\n",
      "Loop 7359 Loss_Train:  [[ 13.19527374]] Loss_Validation:  [[ 11.04709711]]\n",
      "Loop 7360 Loss_Train:  [[ 13.19527371]] Loss_Validation:  [[ 11.04710073]]\n",
      "Loop 7361 Loss_Train:  [[ 13.19527367]] Loss_Validation:  [[ 11.04710435]]\n",
      "Loop 7362 Loss_Train:  [[ 13.19527363]] Loss_Validation:  [[ 11.04710796]]\n",
      "Loop 7363 Loss_Train:  [[ 13.1952736]] Loss_Validation:  [[ 11.04711158]]\n",
      "Loop 7364 Loss_Train:  [[ 13.19527356]] Loss_Validation:  [[ 11.04711519]]\n",
      "Loop 7365 Loss_Train:  [[ 13.19527353]] Loss_Validation:  [[ 11.0471188]]\n",
      "Loop 7366 Loss_Train:  [[ 13.19527349]] Loss_Validation:  [[ 11.04712241]]\n",
      "Loop 7367 Loss_Train:  [[ 13.19527345]] Loss_Validation:  [[ 11.04712601]]\n",
      "Loop 7368 Loss_Train:  [[ 13.19527342]] Loss_Validation:  [[ 11.04712961]]\n",
      "Loop 7369 Loss_Train:  [[ 13.19527338]] Loss_Validation:  [[ 11.04713321]]\n",
      "Loop 7370 Loss_Train:  [[ 13.19527335]] Loss_Validation:  [[ 11.04713681]]\n",
      "Loop 7371 Loss_Train:  [[ 13.19527331]] Loss_Validation:  [[ 11.04714041]]\n",
      "Loop 7372 Loss_Train:  [[ 13.19527328]] Loss_Validation:  [[ 11.047144]]\n",
      "Loop 7373 Loss_Train:  [[ 13.19527324]] Loss_Validation:  [[ 11.04714759]]\n",
      "Loop 7374 Loss_Train:  [[ 13.1952732]] Loss_Validation:  [[ 11.04715118]]\n",
      "Loop 7375 Loss_Train:  [[ 13.19527317]] Loss_Validation:  [[ 11.04715476]]\n",
      "Loop 7376 Loss_Train:  [[ 13.19527313]] Loss_Validation:  [[ 11.04715834]]\n",
      "Loop 7377 Loss_Train:  [[ 13.1952731]] Loss_Validation:  [[ 11.04716192]]\n",
      "Loop 7378 Loss_Train:  [[ 13.19527306]] Loss_Validation:  [[ 11.0471655]]\n",
      "Loop 7379 Loss_Train:  [[ 13.19527303]] Loss_Validation:  [[ 11.04716907]]\n",
      "Loop 7380 Loss_Train:  [[ 13.19527299]] Loss_Validation:  [[ 11.04717265]]\n",
      "Loop 7381 Loss_Train:  [[ 13.19527296]] Loss_Validation:  [[ 11.04717622]]\n",
      "Loop 7382 Loss_Train:  [[ 13.19527292]] Loss_Validation:  [[ 11.04717978]]\n",
      "Loop 7383 Loss_Train:  [[ 13.19527289]] Loss_Validation:  [[ 11.04718335]]\n",
      "Loop 7384 Loss_Train:  [[ 13.19527285]] Loss_Validation:  [[ 11.04718691]]\n",
      "Loop 7385 Loss_Train:  [[ 13.19527282]] Loss_Validation:  [[ 11.04719047]]\n",
      "Loop 7386 Loss_Train:  [[ 13.19527278]] Loss_Validation:  [[ 11.04719403]]\n",
      "Loop 7387 Loss_Train:  [[ 13.19527275]] Loss_Validation:  [[ 11.04719759]]\n",
      "Loop 7388 Loss_Train:  [[ 13.19527271]] Loss_Validation:  [[ 11.04720114]]\n",
      "Loop 7389 Loss_Train:  [[ 13.19527268]] Loss_Validation:  [[ 11.04720469]]\n",
      "Loop 7390 Loss_Train:  [[ 13.19527264]] Loss_Validation:  [[ 11.04720824]]\n",
      "Loop 7391 Loss_Train:  [[ 13.19527261]] Loss_Validation:  [[ 11.04721178]]\n",
      "Loop 7392 Loss_Train:  [[ 13.19527257]] Loss_Validation:  [[ 11.04721533]]\n",
      "Loop 7393 Loss_Train:  [[ 13.19527254]] Loss_Validation:  [[ 11.04721887]]\n",
      "Loop 7394 Loss_Train:  [[ 13.19527251]] Loss_Validation:  [[ 11.04722241]]\n",
      "Loop 7395 Loss_Train:  [[ 13.19527247]] Loss_Validation:  [[ 11.04722594]]\n",
      "Loop 7396 Loss_Train:  [[ 13.19527244]] Loss_Validation:  [[ 11.04722948]]\n",
      "Loop 7397 Loss_Train:  [[ 13.1952724]] Loss_Validation:  [[ 11.04723301]]\n",
      "Loop 7398 Loss_Train:  [[ 13.19527237]] Loss_Validation:  [[ 11.04723653]]\n",
      "Loop 7399 Loss_Train:  [[ 13.19527233]] Loss_Validation:  [[ 11.04724006]]\n",
      "Loop 7400 Loss_Train:  [[ 13.1952723]] Loss_Validation:  [[ 11.04724358]]\n",
      "Loop 7401 Loss_Train:  [[ 13.19527227]] Loss_Validation:  [[ 11.04724711]]\n",
      "Loop 7402 Loss_Train:  [[ 13.19527223]] Loss_Validation:  [[ 11.04725062]]\n",
      "Loop 7403 Loss_Train:  [[ 13.1952722]] Loss_Validation:  [[ 11.04725414]]\n",
      "Loop 7404 Loss_Train:  [[ 13.19527216]] Loss_Validation:  [[ 11.04725766]]\n",
      "Loop 7405 Loss_Train:  [[ 13.19527213]] Loss_Validation:  [[ 11.04726117]]\n",
      "Loop 7406 Loss_Train:  [[ 13.1952721]] Loss_Validation:  [[ 11.04726468]]\n",
      "Loop 7407 Loss_Train:  [[ 13.19527206]] Loss_Validation:  [[ 11.04726818]]\n",
      "Loop 7408 Loss_Train:  [[ 13.19527203]] Loss_Validation:  [[ 11.04727169]]\n",
      "Loop 7409 Loss_Train:  [[ 13.19527199]] Loss_Validation:  [[ 11.04727519]]\n",
      "Loop 7410 Loss_Train:  [[ 13.19527196]] Loss_Validation:  [[ 11.04727869]]\n",
      "Loop 7411 Loss_Train:  [[ 13.19527193]] Loss_Validation:  [[ 11.04728219]]\n",
      "Loop 7412 Loss_Train:  [[ 13.19527189]] Loss_Validation:  [[ 11.04728568]]\n",
      "Loop 7413 Loss_Train:  [[ 13.19527186]] Loss_Validation:  [[ 11.04728917]]\n",
      "Loop 7414 Loss_Train:  [[ 13.19527183]] Loss_Validation:  [[ 11.04729266]]\n",
      "Loop 7415 Loss_Train:  [[ 13.19527179]] Loss_Validation:  [[ 11.04729615]]\n",
      "Loop 7416 Loss_Train:  [[ 13.19527176]] Loss_Validation:  [[ 11.04729964]]\n",
      "Loop 7417 Loss_Train:  [[ 13.19527173]] Loss_Validation:  [[ 11.04730312]]\n",
      "Loop 7418 Loss_Train:  [[ 13.19527169]] Loss_Validation:  [[ 11.0473066]]\n",
      "Loop 7419 Loss_Train:  [[ 13.19527166]] Loss_Validation:  [[ 11.04731008]]\n",
      "Loop 7420 Loss_Train:  [[ 13.19527163]] Loss_Validation:  [[ 11.04731355]]\n",
      "Loop 7421 Loss_Train:  [[ 13.19527159]] Loss_Validation:  [[ 11.04731703]]\n",
      "Loop 7422 Loss_Train:  [[ 13.19527156]] Loss_Validation:  [[ 11.0473205]]\n",
      "Loop 7423 Loss_Train:  [[ 13.19527153]] Loss_Validation:  [[ 11.04732397]]\n",
      "Loop 7424 Loss_Train:  [[ 13.19527149]] Loss_Validation:  [[ 11.04732743]]\n",
      "Loop 7425 Loss_Train:  [[ 13.19527146]] Loss_Validation:  [[ 11.0473309]]\n",
      "Loop 7426 Loss_Train:  [[ 13.19527143]] Loss_Validation:  [[ 11.04733436]]\n",
      "Loop 7427 Loss_Train:  [[ 13.19527139]] Loss_Validation:  [[ 11.04733782]]\n",
      "Loop 7428 Loss_Train:  [[ 13.19527136]] Loss_Validation:  [[ 11.04734127]]\n",
      "Loop 7429 Loss_Train:  [[ 13.19527133]] Loss_Validation:  [[ 11.04734473]]\n",
      "Loop 7430 Loss_Train:  [[ 13.1952713]] Loss_Validation:  [[ 11.04734818]]\n",
      "Loop 7431 Loss_Train:  [[ 13.19527126]] Loss_Validation:  [[ 11.04735163]]\n",
      "Loop 7432 Loss_Train:  [[ 13.19527123]] Loss_Validation:  [[ 11.04735508]]\n",
      "Loop 7433 Loss_Train:  [[ 13.1952712]] Loss_Validation:  [[ 11.04735852]]\n",
      "Loop 7434 Loss_Train:  [[ 13.19527117]] Loss_Validation:  [[ 11.04736196]]\n",
      "Loop 7435 Loss_Train:  [[ 13.19527113]] Loss_Validation:  [[ 11.0473654]]\n",
      "Loop 7436 Loss_Train:  [[ 13.1952711]] Loss_Validation:  [[ 11.04736884]]\n",
      "Loop 7437 Loss_Train:  [[ 13.19527107]] Loss_Validation:  [[ 11.04737228]]\n",
      "Loop 7438 Loss_Train:  [[ 13.19527104]] Loss_Validation:  [[ 11.04737571]]\n",
      "Loop 7439 Loss_Train:  [[ 13.195271]] Loss_Validation:  [[ 11.04737914]]\n",
      "Loop 7440 Loss_Train:  [[ 13.19527097]] Loss_Validation:  [[ 11.04738257]]\n",
      "Loop 7441 Loss_Train:  [[ 13.19527094]] Loss_Validation:  [[ 11.04738599]]\n",
      "Loop 7442 Loss_Train:  [[ 13.19527091]] Loss_Validation:  [[ 11.04738942]]\n",
      "Loop 7443 Loss_Train:  [[ 13.19527087]] Loss_Validation:  [[ 11.04739284]]\n",
      "Loop 7444 Loss_Train:  [[ 13.19527084]] Loss_Validation:  [[ 11.04739626]]\n",
      "Loop 7445 Loss_Train:  [[ 13.19527081]] Loss_Validation:  [[ 11.04739967]]\n",
      "Loop 7446 Loss_Train:  [[ 13.19527078]] Loss_Validation:  [[ 11.04740309]]\n",
      "Loop 7447 Loss_Train:  [[ 13.19527075]] Loss_Validation:  [[ 11.0474065]]\n",
      "Loop 7448 Loss_Train:  [[ 13.19527071]] Loss_Validation:  [[ 11.04740991]]\n",
      "Loop 7449 Loss_Train:  [[ 13.19527068]] Loss_Validation:  [[ 11.04741332]]\n",
      "Loop 7450 Loss_Train:  [[ 13.19527065]] Loss_Validation:  [[ 11.04741672]]\n",
      "Loop 7451 Loss_Train:  [[ 13.19527062]] Loss_Validation:  [[ 11.04742012]]\n",
      "Loop 7452 Loss_Train:  [[ 13.19527059]] Loss_Validation:  [[ 11.04742352]]\n",
      "Loop 7453 Loss_Train:  [[ 13.19527056]] Loss_Validation:  [[ 11.04742692]]\n",
      "Loop 7454 Loss_Train:  [[ 13.19527052]] Loss_Validation:  [[ 11.04743032]]\n",
      "Loop 7455 Loss_Train:  [[ 13.19527049]] Loss_Validation:  [[ 11.04743371]]\n",
      "Loop 7456 Loss_Train:  [[ 13.19527046]] Loss_Validation:  [[ 11.0474371]]\n",
      "Loop 7457 Loss_Train:  [[ 13.19527043]] Loss_Validation:  [[ 11.04744049]]\n",
      "Loop 7458 Loss_Train:  [[ 13.1952704]] Loss_Validation:  [[ 11.04744388]]\n",
      "Loop 7459 Loss_Train:  [[ 13.19527037]] Loss_Validation:  [[ 11.04744726]]\n",
      "Loop 7460 Loss_Train:  [[ 13.19527033]] Loss_Validation:  [[ 11.04745064]]\n",
      "Loop 7461 Loss_Train:  [[ 13.1952703]] Loss_Validation:  [[ 11.04745402]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 7462 Loss_Train:  [[ 13.19527027]] Loss_Validation:  [[ 11.0474574]]\n",
      "Loop 7463 Loss_Train:  [[ 13.19527024]] Loss_Validation:  [[ 11.04746077]]\n",
      "Loop 7464 Loss_Train:  [[ 13.19527021]] Loss_Validation:  [[ 11.04746414]]\n",
      "Loop 7465 Loss_Train:  [[ 13.19527018]] Loss_Validation:  [[ 11.04746751]]\n",
      "Loop 7466 Loss_Train:  [[ 13.19527015]] Loss_Validation:  [[ 11.04747088]]\n",
      "Loop 7467 Loss_Train:  [[ 13.19527012]] Loss_Validation:  [[ 11.04747425]]\n",
      "Loop 7468 Loss_Train:  [[ 13.19527009]] Loss_Validation:  [[ 11.04747761]]\n",
      "Loop 7469 Loss_Train:  [[ 13.19527005]] Loss_Validation:  [[ 11.04748097]]\n",
      "Loop 7470 Loss_Train:  [[ 13.19527002]] Loss_Validation:  [[ 11.04748433]]\n",
      "Loop 7471 Loss_Train:  [[ 13.19526999]] Loss_Validation:  [[ 11.04748768]]\n",
      "Loop 7472 Loss_Train:  [[ 13.19526996]] Loss_Validation:  [[ 11.04749104]]\n",
      "Loop 7473 Loss_Train:  [[ 13.19526993]] Loss_Validation:  [[ 11.04749439]]\n",
      "Loop 7474 Loss_Train:  [[ 13.1952699]] Loss_Validation:  [[ 11.04749774]]\n",
      "Loop 7475 Loss_Train:  [[ 13.19526987]] Loss_Validation:  [[ 11.04750108]]\n",
      "Loop 7476 Loss_Train:  [[ 13.19526984]] Loss_Validation:  [[ 11.04750443]]\n",
      "Loop 7477 Loss_Train:  [[ 13.19526981]] Loss_Validation:  [[ 11.04750777]]\n",
      "Loop 7478 Loss_Train:  [[ 13.19526978]] Loss_Validation:  [[ 11.04751111]]\n",
      "Loop 7479 Loss_Train:  [[ 13.19526975]] Loss_Validation:  [[ 11.04751445]]\n",
      "Loop 7480 Loss_Train:  [[ 13.19526972]] Loss_Validation:  [[ 11.04751778]]\n",
      "Loop 7481 Loss_Train:  [[ 13.19526969]] Loss_Validation:  [[ 11.04752112]]\n",
      "Loop 7482 Loss_Train:  [[ 13.19526966]] Loss_Validation:  [[ 11.04752445]]\n",
      "Loop 7483 Loss_Train:  [[ 13.19526963]] Loss_Validation:  [[ 11.04752778]]\n",
      "Loop 7484 Loss_Train:  [[ 13.1952696]] Loss_Validation:  [[ 11.0475311]]\n",
      "Loop 7485 Loss_Train:  [[ 13.19526956]] Loss_Validation:  [[ 11.04753443]]\n",
      "Loop 7486 Loss_Train:  [[ 13.19526953]] Loss_Validation:  [[ 11.04753775]]\n",
      "Loop 7487 Loss_Train:  [[ 13.1952695]] Loss_Validation:  [[ 11.04754107]]\n",
      "Loop 7488 Loss_Train:  [[ 13.19526947]] Loss_Validation:  [[ 11.04754438]]\n",
      "Loop 7489 Loss_Train:  [[ 13.19526944]] Loss_Validation:  [[ 11.0475477]]\n",
      "Loop 7490 Loss_Train:  [[ 13.19526941]] Loss_Validation:  [[ 11.04755101]]\n",
      "Loop 7491 Loss_Train:  [[ 13.19526938]] Loss_Validation:  [[ 11.04755432]]\n",
      "Loop 7492 Loss_Train:  [[ 13.19526935]] Loss_Validation:  [[ 11.04755763]]\n",
      "Loop 7493 Loss_Train:  [[ 13.19526932]] Loss_Validation:  [[ 11.04756093]]\n",
      "Loop 7494 Loss_Train:  [[ 13.19526929]] Loss_Validation:  [[ 11.04756424]]\n",
      "Loop 7495 Loss_Train:  [[ 13.19526926]] Loss_Validation:  [[ 11.04756754]]\n",
      "Loop 7496 Loss_Train:  [[ 13.19526923]] Loss_Validation:  [[ 11.04757084]]\n",
      "Loop 7497 Loss_Train:  [[ 13.19526921]] Loss_Validation:  [[ 11.04757413]]\n",
      "Loop 7498 Loss_Train:  [[ 13.19526918]] Loss_Validation:  [[ 11.04757743]]\n",
      "Loop 7499 Loss_Train:  [[ 13.19526915]] Loss_Validation:  [[ 11.04758072]]\n",
      "Loop 7500 Loss_Train:  [[ 13.19526912]] Loss_Validation:  [[ 11.04758401]]\n",
      "Loop 7501 Loss_Train:  [[ 13.19526909]] Loss_Validation:  [[ 11.0475873]]\n",
      "Loop 7502 Loss_Train:  [[ 13.19526906]] Loss_Validation:  [[ 11.04759058]]\n",
      "Loop 7503 Loss_Train:  [[ 13.19526903]] Loss_Validation:  [[ 11.04759387]]\n",
      "Loop 7504 Loss_Train:  [[ 13.195269]] Loss_Validation:  [[ 11.04759715]]\n",
      "Loop 7505 Loss_Train:  [[ 13.19526897]] Loss_Validation:  [[ 11.04760042]]\n",
      "Loop 7506 Loss_Train:  [[ 13.19526894]] Loss_Validation:  [[ 11.0476037]]\n",
      "Loop 7507 Loss_Train:  [[ 13.19526891]] Loss_Validation:  [[ 11.04760697]]\n",
      "Loop 7508 Loss_Train:  [[ 13.19526888]] Loss_Validation:  [[ 11.04761025]]\n",
      "Loop 7509 Loss_Train:  [[ 13.19526885]] Loss_Validation:  [[ 11.04761352]]\n",
      "Loop 7510 Loss_Train:  [[ 13.19526882]] Loss_Validation:  [[ 11.04761678]]\n",
      "Loop 7511 Loss_Train:  [[ 13.19526879]] Loss_Validation:  [[ 11.04762005]]\n",
      "Loop 7512 Loss_Train:  [[ 13.19526876]] Loss_Validation:  [[ 11.04762331]]\n",
      "Loop 7513 Loss_Train:  [[ 13.19526874]] Loss_Validation:  [[ 11.04762657]]\n",
      "Loop 7514 Loss_Train:  [[ 13.19526871]] Loss_Validation:  [[ 11.04762983]]\n",
      "Loop 7515 Loss_Train:  [[ 13.19526868]] Loss_Validation:  [[ 11.04763308]]\n",
      "Loop 7516 Loss_Train:  [[ 13.19526865]] Loss_Validation:  [[ 11.04763634]]\n",
      "Loop 7517 Loss_Train:  [[ 13.19526862]] Loss_Validation:  [[ 11.04763959]]\n",
      "Loop 7518 Loss_Train:  [[ 13.19526859]] Loss_Validation:  [[ 11.04764284]]\n",
      "Loop 7519 Loss_Train:  [[ 13.19526856]] Loss_Validation:  [[ 11.04764609]]\n",
      "Loop 7520 Loss_Train:  [[ 13.19526853]] Loss_Validation:  [[ 11.04764933]]\n",
      "Loop 7521 Loss_Train:  [[ 13.1952685]] Loss_Validation:  [[ 11.04765257]]\n",
      "Loop 7522 Loss_Train:  [[ 13.19526848]] Loss_Validation:  [[ 11.04765581]]\n",
      "Loop 7523 Loss_Train:  [[ 13.19526845]] Loss_Validation:  [[ 11.04765905]]\n",
      "Loop 7524 Loss_Train:  [[ 13.19526842]] Loss_Validation:  [[ 11.04766229]]\n",
      "Loop 7525 Loss_Train:  [[ 13.19526839]] Loss_Validation:  [[ 11.04766552]]\n",
      "Loop 7526 Loss_Train:  [[ 13.19526836]] Loss_Validation:  [[ 11.04766875]]\n",
      "Loop 7527 Loss_Train:  [[ 13.19526833]] Loss_Validation:  [[ 11.04767198]]\n",
      "Loop 7528 Loss_Train:  [[ 13.1952683]] Loss_Validation:  [[ 11.04767521]]\n",
      "Loop 7529 Loss_Train:  [[ 13.19526828]] Loss_Validation:  [[ 11.04767843]]\n",
      "Loop 7530 Loss_Train:  [[ 13.19526825]] Loss_Validation:  [[ 11.04768166]]\n",
      "Loop 7531 Loss_Train:  [[ 13.19526822]] Loss_Validation:  [[ 11.04768488]]\n",
      "Loop 7532 Loss_Train:  [[ 13.19526819]] Loss_Validation:  [[ 11.0476881]]\n",
      "Loop 7533 Loss_Train:  [[ 13.19526816]] Loss_Validation:  [[ 11.04769131]]\n",
      "Loop 7534 Loss_Train:  [[ 13.19526813]] Loss_Validation:  [[ 11.04769452]]\n",
      "Loop 7535 Loss_Train:  [[ 13.19526811]] Loss_Validation:  [[ 11.04769774]]\n",
      "Loop 7536 Loss_Train:  [[ 13.19526808]] Loss_Validation:  [[ 11.04770095]]\n",
      "Loop 7537 Loss_Train:  [[ 13.19526805]] Loss_Validation:  [[ 11.04770415]]\n",
      "Loop 7538 Loss_Train:  [[ 13.19526802]] Loss_Validation:  [[ 11.04770736]]\n",
      "Loop 7539 Loss_Train:  [[ 13.19526799]] Loss_Validation:  [[ 11.04771056]]\n",
      "Loop 7540 Loss_Train:  [[ 13.19526797]] Loss_Validation:  [[ 11.04771376]]\n",
      "Loop 7541 Loss_Train:  [[ 13.19526794]] Loss_Validation:  [[ 11.04771696]]\n",
      "Loop 7542 Loss_Train:  [[ 13.19526791]] Loss_Validation:  [[ 11.04772016]]\n",
      "Loop 7543 Loss_Train:  [[ 13.19526788]] Loss_Validation:  [[ 11.04772335]]\n",
      "Loop 7544 Loss_Train:  [[ 13.19526785]] Loss_Validation:  [[ 11.04772654]]\n",
      "Loop 7545 Loss_Train:  [[ 13.19526783]] Loss_Validation:  [[ 11.04772973]]\n",
      "Loop 7546 Loss_Train:  [[ 13.1952678]] Loss_Validation:  [[ 11.04773292]]\n",
      "Loop 7547 Loss_Train:  [[ 13.19526777]] Loss_Validation:  [[ 11.0477361]]\n",
      "Loop 7548 Loss_Train:  [[ 13.19526774]] Loss_Validation:  [[ 11.04773929]]\n",
      "Loop 7549 Loss_Train:  [[ 13.19526772]] Loss_Validation:  [[ 11.04774247]]\n",
      "Loop 7550 Loss_Train:  [[ 13.19526769]] Loss_Validation:  [[ 11.04774564]]\n",
      "Loop 7551 Loss_Train:  [[ 13.19526766]] Loss_Validation:  [[ 11.04774882]]\n",
      "Loop 7552 Loss_Train:  [[ 13.19526763]] Loss_Validation:  [[ 11.047752]]\n",
      "Loop 7553 Loss_Train:  [[ 13.19526761]] Loss_Validation:  [[ 11.04775517]]\n",
      "Loop 7554 Loss_Train:  [[ 13.19526758]] Loss_Validation:  [[ 11.04775834]]\n",
      "Loop 7555 Loss_Train:  [[ 13.19526755]] Loss_Validation:  [[ 11.0477615]]\n",
      "Loop 7556 Loss_Train:  [[ 13.19526752]] Loss_Validation:  [[ 11.04776467]]\n",
      "Loop 7557 Loss_Train:  [[ 13.1952675]] Loss_Validation:  [[ 11.04776783]]\n",
      "Loop 7558 Loss_Train:  [[ 13.19526747]] Loss_Validation:  [[ 11.04777099]]\n",
      "Loop 7559 Loss_Train:  [[ 13.19526744]] Loss_Validation:  [[ 11.04777415]]\n",
      "Loop 7560 Loss_Train:  [[ 13.19526742]] Loss_Validation:  [[ 11.04777731]]\n",
      "Loop 7561 Loss_Train:  [[ 13.19526739]] Loss_Validation:  [[ 11.04778047]]\n",
      "Loop 7562 Loss_Train:  [[ 13.19526736]] Loss_Validation:  [[ 11.04778362]]\n",
      "Loop 7563 Loss_Train:  [[ 13.19526733]] Loss_Validation:  [[ 11.04778677]]\n",
      "Loop 7564 Loss_Train:  [[ 13.19526731]] Loss_Validation:  [[ 11.04778992]]\n",
      "Loop 7565 Loss_Train:  [[ 13.19526728]] Loss_Validation:  [[ 11.04779306]]\n",
      "Loop 7566 Loss_Train:  [[ 13.19526725]] Loss_Validation:  [[ 11.04779621]]\n",
      "Loop 7567 Loss_Train:  [[ 13.19526723]] Loss_Validation:  [[ 11.04779935]]\n",
      "Loop 7568 Loss_Train:  [[ 13.1952672]] Loss_Validation:  [[ 11.04780249]]\n",
      "Loop 7569 Loss_Train:  [[ 13.19526717]] Loss_Validation:  [[ 11.04780562]]\n",
      "Loop 7570 Loss_Train:  [[ 13.19526715]] Loss_Validation:  [[ 11.04780876]]\n",
      "Loop 7571 Loss_Train:  [[ 13.19526712]] Loss_Validation:  [[ 11.04781189]]\n",
      "Loop 7572 Loss_Train:  [[ 13.19526709]] Loss_Validation:  [[ 11.04781502]]\n",
      "Loop 7573 Loss_Train:  [[ 13.19526707]] Loss_Validation:  [[ 11.04781815]]\n",
      "Loop 7574 Loss_Train:  [[ 13.19526704]] Loss_Validation:  [[ 11.04782128]]\n",
      "Loop 7575 Loss_Train:  [[ 13.19526701]] Loss_Validation:  [[ 11.0478244]]\n",
      "Loop 7576 Loss_Train:  [[ 13.19526699]] Loss_Validation:  [[ 11.04782752]]\n",
      "Loop 7577 Loss_Train:  [[ 13.19526696]] Loss_Validation:  [[ 11.04783064]]\n",
      "Loop 7578 Loss_Train:  [[ 13.19526693]] Loss_Validation:  [[ 11.04783376]]\n",
      "Loop 7579 Loss_Train:  [[ 13.19526691]] Loss_Validation:  [[ 11.04783688]]\n",
      "Loop 7580 Loss_Train:  [[ 13.19526688]] Loss_Validation:  [[ 11.04783999]]\n",
      "Loop 7581 Loss_Train:  [[ 13.19526685]] Loss_Validation:  [[ 11.0478431]]\n",
      "Loop 7582 Loss_Train:  [[ 13.19526683]] Loss_Validation:  [[ 11.04784621]]\n",
      "Loop 7583 Loss_Train:  [[ 13.1952668]] Loss_Validation:  [[ 11.04784932]]\n",
      "Loop 7584 Loss_Train:  [[ 13.19526677]] Loss_Validation:  [[ 11.04785243]]\n",
      "Loop 7585 Loss_Train:  [[ 13.19526675]] Loss_Validation:  [[ 11.04785553]]\n",
      "Loop 7586 Loss_Train:  [[ 13.19526672]] Loss_Validation:  [[ 11.04785863]]\n",
      "Loop 7587 Loss_Train:  [[ 13.1952667]] Loss_Validation:  [[ 11.04786173]]\n",
      "Loop 7588 Loss_Train:  [[ 13.19526667]] Loss_Validation:  [[ 11.04786482]]\n",
      "Loop 7589 Loss_Train:  [[ 13.19526664]] Loss_Validation:  [[ 11.04786792]]\n",
      "Loop 7590 Loss_Train:  [[ 13.19526662]] Loss_Validation:  [[ 11.04787101]]\n",
      "Loop 7591 Loss_Train:  [[ 13.19526659]] Loss_Validation:  [[ 11.0478741]]\n",
      "Loop 7592 Loss_Train:  [[ 13.19526657]] Loss_Validation:  [[ 11.04787719]]\n",
      "Loop 7593 Loss_Train:  [[ 13.19526654]] Loss_Validation:  [[ 11.04788028]]\n",
      "Loop 7594 Loss_Train:  [[ 13.19526651]] Loss_Validation:  [[ 11.04788336]]\n",
      "Loop 7595 Loss_Train:  [[ 13.19526649]] Loss_Validation:  [[ 11.04788644]]\n",
      "Loop 7596 Loss_Train:  [[ 13.19526646]] Loss_Validation:  [[ 11.04788952]]\n",
      "Loop 7597 Loss_Train:  [[ 13.19526644]] Loss_Validation:  [[ 11.0478926]]\n",
      "Loop 7598 Loss_Train:  [[ 13.19526641]] Loss_Validation:  [[ 11.04789567]]\n",
      "Loop 7599 Loss_Train:  [[ 13.19526639]] Loss_Validation:  [[ 11.04789875]]\n",
      "Loop 7600 Loss_Train:  [[ 13.19526636]] Loss_Validation:  [[ 11.04790182]]\n",
      "Loop 7601 Loss_Train:  [[ 13.19526633]] Loss_Validation:  [[ 11.04790489]]\n",
      "Loop 7602 Loss_Train:  [[ 13.19526631]] Loss_Validation:  [[ 11.04790795]]\n",
      "Loop 7603 Loss_Train:  [[ 13.19526628]] Loss_Validation:  [[ 11.04791102]]\n",
      "Loop 7604 Loss_Train:  [[ 13.19526626]] Loss_Validation:  [[ 11.04791408]]\n",
      "Loop 7605 Loss_Train:  [[ 13.19526623]] Loss_Validation:  [[ 11.04791714]]\n",
      "Loop 7606 Loss_Train:  [[ 13.19526621]] Loss_Validation:  [[ 11.0479202]]\n",
      "Loop 7607 Loss_Train:  [[ 13.19526618]] Loss_Validation:  [[ 11.04792326]]\n",
      "Loop 7608 Loss_Train:  [[ 13.19526616]] Loss_Validation:  [[ 11.04792631]]\n",
      "Loop 7609 Loss_Train:  [[ 13.19526613]] Loss_Validation:  [[ 11.04792936]]\n",
      "Loop 7610 Loss_Train:  [[ 13.19526611]] Loss_Validation:  [[ 11.04793241]]\n",
      "Loop 7611 Loss_Train:  [[ 13.19526608]] Loss_Validation:  [[ 11.04793546]]\n",
      "Loop 7612 Loss_Train:  [[ 13.19526606]] Loss_Validation:  [[ 11.04793851]]\n",
      "Loop 7613 Loss_Train:  [[ 13.19526603]] Loss_Validation:  [[ 11.04794155]]\n",
      "Loop 7614 Loss_Train:  [[ 13.195266]] Loss_Validation:  [[ 11.04794459]]\n",
      "Loop 7615 Loss_Train:  [[ 13.19526598]] Loss_Validation:  [[ 11.04794763]]\n",
      "Loop 7616 Loss_Train:  [[ 13.19526595]] Loss_Validation:  [[ 11.04795067]]\n",
      "Loop 7617 Loss_Train:  [[ 13.19526593]] Loss_Validation:  [[ 11.0479537]]\n",
      "Loop 7618 Loss_Train:  [[ 13.1952659]] Loss_Validation:  [[ 11.04795674]]\n",
      "Loop 7619 Loss_Train:  [[ 13.19526588]] Loss_Validation:  [[ 11.04795977]]\n",
      "Loop 7620 Loss_Train:  [[ 13.19526585]] Loss_Validation:  [[ 11.0479628]]\n",
      "Loop 7621 Loss_Train:  [[ 13.19526583]] Loss_Validation:  [[ 11.04796582]]\n",
      "Loop 7622 Loss_Train:  [[ 13.19526581]] Loss_Validation:  [[ 11.04796885]]\n",
      "Loop 7623 Loss_Train:  [[ 13.19526578]] Loss_Validation:  [[ 11.04797187]]\n",
      "Loop 7624 Loss_Train:  [[ 13.19526576]] Loss_Validation:  [[ 11.04797489]]\n",
      "Loop 7625 Loss_Train:  [[ 13.19526573]] Loss_Validation:  [[ 11.04797791]]\n",
      "Loop 7626 Loss_Train:  [[ 13.19526571]] Loss_Validation:  [[ 11.04798093]]\n",
      "Loop 7627 Loss_Train:  [[ 13.19526568]] Loss_Validation:  [[ 11.04798394]]\n",
      "Loop 7628 Loss_Train:  [[ 13.19526566]] Loss_Validation:  [[ 11.04798696]]\n",
      "Loop 7629 Loss_Train:  [[ 13.19526563]] Loss_Validation:  [[ 11.04798997]]\n",
      "Loop 7630 Loss_Train:  [[ 13.19526561]] Loss_Validation:  [[ 11.04799297]]\n",
      "Loop 7631 Loss_Train:  [[ 13.19526558]] Loss_Validation:  [[ 11.04799598]]\n",
      "Loop 7632 Loss_Train:  [[ 13.19526556]] Loss_Validation:  [[ 11.04799899]]\n",
      "Loop 7633 Loss_Train:  [[ 13.19526553]] Loss_Validation:  [[ 11.04800199]]\n",
      "Loop 7634 Loss_Train:  [[ 13.19526551]] Loss_Validation:  [[ 11.04800499]]\n",
      "Loop 7635 Loss_Train:  [[ 13.19526549]] Loss_Validation:  [[ 11.04800799]]\n",
      "Loop 7636 Loss_Train:  [[ 13.19526546]] Loss_Validation:  [[ 11.04801098]]\n",
      "Loop 7637 Loss_Train:  [[ 13.19526544]] Loss_Validation:  [[ 11.04801398]]\n",
      "Loop 7638 Loss_Train:  [[ 13.19526541]] Loss_Validation:  [[ 11.04801697]]\n",
      "Loop 7639 Loss_Train:  [[ 13.19526539]] Loss_Validation:  [[ 11.04801996]]\n",
      "Loop 7640 Loss_Train:  [[ 13.19526536]] Loss_Validation:  [[ 11.04802295]]\n",
      "Loop 7641 Loss_Train:  [[ 13.19526534]] Loss_Validation:  [[ 11.04802593]]\n",
      "Loop 7642 Loss_Train:  [[ 13.19526532]] Loss_Validation:  [[ 11.04802891]]\n",
      "Loop 7643 Loss_Train:  [[ 13.19526529]] Loss_Validation:  [[ 11.0480319]]\n",
      "Loop 7644 Loss_Train:  [[ 13.19526527]] Loss_Validation:  [[ 11.04803488]]\n",
      "Loop 7645 Loss_Train:  [[ 13.19526524]] Loss_Validation:  [[ 11.04803785]]\n",
      "Loop 7646 Loss_Train:  [[ 13.19526522]] Loss_Validation:  [[ 11.04804083]]\n",
      "Loop 7647 Loss_Train:  [[ 13.1952652]] Loss_Validation:  [[ 11.0480438]]\n",
      "Loop 7648 Loss_Train:  [[ 13.19526517]] Loss_Validation:  [[ 11.04804677]]\n",
      "Loop 7649 Loss_Train:  [[ 13.19526515]] Loss_Validation:  [[ 11.04804974]]\n",
      "Loop 7650 Loss_Train:  [[ 13.19526512]] Loss_Validation:  [[ 11.04805271]]\n",
      "Loop 7651 Loss_Train:  [[ 13.1952651]] Loss_Validation:  [[ 11.04805567]]\n",
      "Loop 7652 Loss_Train:  [[ 13.19526508]] Loss_Validation:  [[ 11.04805864]]\n",
      "Loop 7653 Loss_Train:  [[ 13.19526505]] Loss_Validation:  [[ 11.0480616]]\n",
      "Loop 7654 Loss_Train:  [[ 13.19526503]] Loss_Validation:  [[ 11.04806456]]\n",
      "Loop 7655 Loss_Train:  [[ 13.195265]] Loss_Validation:  [[ 11.04806752]]\n",
      "Loop 7656 Loss_Train:  [[ 13.19526498]] Loss_Validation:  [[ 11.04807047]]\n",
      "Loop 7657 Loss_Train:  [[ 13.19526496]] Loss_Validation:  [[ 11.04807342]]\n",
      "Loop 7658 Loss_Train:  [[ 13.19526493]] Loss_Validation:  [[ 11.04807637]]\n",
      "Loop 7659 Loss_Train:  [[ 13.19526491]] Loss_Validation:  [[ 11.04807932]]\n",
      "Loop 7660 Loss_Train:  [[ 13.19526489]] Loss_Validation:  [[ 11.04808227]]\n",
      "Loop 7661 Loss_Train:  [[ 13.19526486]] Loss_Validation:  [[ 11.04808522]]\n",
      "Loop 7662 Loss_Train:  [[ 13.19526484]] Loss_Validation:  [[ 11.04808816]]\n",
      "Loop 7663 Loss_Train:  [[ 13.19526482]] Loss_Validation:  [[ 11.0480911]]\n",
      "Loop 7664 Loss_Train:  [[ 13.19526479]] Loss_Validation:  [[ 11.04809404]]\n",
      "Loop 7665 Loss_Train:  [[ 13.19526477]] Loss_Validation:  [[ 11.04809697]]\n",
      "Loop 7666 Loss_Train:  [[ 13.19526475]] Loss_Validation:  [[ 11.04809991]]\n",
      "Loop 7667 Loss_Train:  [[ 13.19526472]] Loss_Validation:  [[ 11.04810284]]\n",
      "Loop 7668 Loss_Train:  [[ 13.1952647]] Loss_Validation:  [[ 11.04810577]]\n",
      "Loop 7669 Loss_Train:  [[ 13.19526468]] Loss_Validation:  [[ 11.0481087]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 7670 Loss_Train:  [[ 13.19526465]] Loss_Validation:  [[ 11.04811163]]\n",
      "Loop 7671 Loss_Train:  [[ 13.19526463]] Loss_Validation:  [[ 11.04811455]]\n",
      "Loop 7672 Loss_Train:  [[ 13.19526461]] Loss_Validation:  [[ 11.04811748]]\n",
      "Loop 7673 Loss_Train:  [[ 13.19526458]] Loss_Validation:  [[ 11.0481204]]\n",
      "Loop 7674 Loss_Train:  [[ 13.19526456]] Loss_Validation:  [[ 11.04812331]]\n",
      "Loop 7675 Loss_Train:  [[ 13.19526454]] Loss_Validation:  [[ 11.04812623]]\n",
      "Loop 7676 Loss_Train:  [[ 13.19526452]] Loss_Validation:  [[ 11.04812915]]\n",
      "Loop 7677 Loss_Train:  [[ 13.19526449]] Loss_Validation:  [[ 11.04813206]]\n",
      "Loop 7678 Loss_Train:  [[ 13.19526447]] Loss_Validation:  [[ 11.04813497]]\n",
      "Loop 7679 Loss_Train:  [[ 13.19526445]] Loss_Validation:  [[ 11.04813788]]\n",
      "Loop 7680 Loss_Train:  [[ 13.19526442]] Loss_Validation:  [[ 11.04814078]]\n",
      "Loop 7681 Loss_Train:  [[ 13.1952644]] Loss_Validation:  [[ 11.04814369]]\n",
      "Loop 7682 Loss_Train:  [[ 13.19526438]] Loss_Validation:  [[ 11.04814659]]\n",
      "Loop 7683 Loss_Train:  [[ 13.19526436]] Loss_Validation:  [[ 11.04814949]]\n",
      "Loop 7684 Loss_Train:  [[ 13.19526433]] Loss_Validation:  [[ 11.04815239]]\n",
      "Loop 7685 Loss_Train:  [[ 13.19526431]] Loss_Validation:  [[ 11.04815529]]\n",
      "Loop 7686 Loss_Train:  [[ 13.19526429]] Loss_Validation:  [[ 11.04815818]]\n",
      "Loop 7687 Loss_Train:  [[ 13.19526426]] Loss_Validation:  [[ 11.04816108]]\n",
      "Loop 7688 Loss_Train:  [[ 13.19526424]] Loss_Validation:  [[ 11.04816397]]\n",
      "Loop 7689 Loss_Train:  [[ 13.19526422]] Loss_Validation:  [[ 11.04816685]]\n",
      "Loop 7690 Loss_Train:  [[ 13.1952642]] Loss_Validation:  [[ 11.04816974]]\n",
      "Loop 7691 Loss_Train:  [[ 13.19526417]] Loss_Validation:  [[ 11.04817263]]\n",
      "Loop 7692 Loss_Train:  [[ 13.19526415]] Loss_Validation:  [[ 11.04817551]]\n",
      "Loop 7693 Loss_Train:  [[ 13.19526413]] Loss_Validation:  [[ 11.04817839]]\n",
      "Loop 7694 Loss_Train:  [[ 13.19526411]] Loss_Validation:  [[ 11.04818127]]\n",
      "Loop 7695 Loss_Train:  [[ 13.19526408]] Loss_Validation:  [[ 11.04818415]]\n",
      "Loop 7696 Loss_Train:  [[ 13.19526406]] Loss_Validation:  [[ 11.04818702]]\n",
      "Loop 7697 Loss_Train:  [[ 13.19526404]] Loss_Validation:  [[ 11.04818989]]\n",
      "Loop 7698 Loss_Train:  [[ 13.19526402]] Loss_Validation:  [[ 11.04819276]]\n",
      "Loop 7699 Loss_Train:  [[ 13.195264]] Loss_Validation:  [[ 11.04819563]]\n",
      "Loop 7700 Loss_Train:  [[ 13.19526397]] Loss_Validation:  [[ 11.0481985]]\n",
      "Loop 7701 Loss_Train:  [[ 13.19526395]] Loss_Validation:  [[ 11.04820136]]\n",
      "Loop 7702 Loss_Train:  [[ 13.19526393]] Loss_Validation:  [[ 11.04820423]]\n",
      "Loop 7703 Loss_Train:  [[ 13.19526391]] Loss_Validation:  [[ 11.04820709]]\n",
      "Loop 7704 Loss_Train:  [[ 13.19526388]] Loss_Validation:  [[ 11.04820995]]\n",
      "Loop 7705 Loss_Train:  [[ 13.19526386]] Loss_Validation:  [[ 11.0482128]]\n",
      "Loop 7706 Loss_Train:  [[ 13.19526384]] Loss_Validation:  [[ 11.04821566]]\n",
      "Loop 7707 Loss_Train:  [[ 13.19526382]] Loss_Validation:  [[ 11.04821851]]\n",
      "Loop 7708 Loss_Train:  [[ 13.1952638]] Loss_Validation:  [[ 11.04822136]]\n",
      "Loop 7709 Loss_Train:  [[ 13.19526377]] Loss_Validation:  [[ 11.04822421]]\n",
      "Loop 7710 Loss_Train:  [[ 13.19526375]] Loss_Validation:  [[ 11.04822706]]\n",
      "Loop 7711 Loss_Train:  [[ 13.19526373]] Loss_Validation:  [[ 11.04822991]]\n",
      "Loop 7712 Loss_Train:  [[ 13.19526371]] Loss_Validation:  [[ 11.04823275]]\n",
      "Loop 7713 Loss_Train:  [[ 13.19526369]] Loss_Validation:  [[ 11.04823559]]\n",
      "Loop 7714 Loss_Train:  [[ 13.19526367]] Loss_Validation:  [[ 11.04823843]]\n",
      "Loop 7715 Loss_Train:  [[ 13.19526364]] Loss_Validation:  [[ 11.04824127]]\n",
      "Loop 7716 Loss_Train:  [[ 13.19526362]] Loss_Validation:  [[ 11.0482441]]\n",
      "Loop 7717 Loss_Train:  [[ 13.1952636]] Loss_Validation:  [[ 11.04824694]]\n",
      "Loop 7718 Loss_Train:  [[ 13.19526358]] Loss_Validation:  [[ 11.04824977]]\n",
      "Loop 7719 Loss_Train:  [[ 13.19526356]] Loss_Validation:  [[ 11.0482526]]\n",
      "Loop 7720 Loss_Train:  [[ 13.19526354]] Loss_Validation:  [[ 11.04825543]]\n",
      "Loop 7721 Loss_Train:  [[ 13.19526351]] Loss_Validation:  [[ 11.04825825]]\n",
      "Loop 7722 Loss_Train:  [[ 13.19526349]] Loss_Validation:  [[ 11.04826107]]\n",
      "Loop 7723 Loss_Train:  [[ 13.19526347]] Loss_Validation:  [[ 11.0482639]]\n",
      "Loop 7724 Loss_Train:  [[ 13.19526345]] Loss_Validation:  [[ 11.04826672]]\n",
      "Loop 7725 Loss_Train:  [[ 13.19526343]] Loss_Validation:  [[ 11.04826953]]\n",
      "Loop 7726 Loss_Train:  [[ 13.19526341]] Loss_Validation:  [[ 11.04827235]]\n",
      "Loop 7727 Loss_Train:  [[ 13.19526339]] Loss_Validation:  [[ 11.04827516]]\n",
      "Loop 7728 Loss_Train:  [[ 13.19526336]] Loss_Validation:  [[ 11.04827798]]\n",
      "Loop 7729 Loss_Train:  [[ 13.19526334]] Loss_Validation:  [[ 11.04828079]]\n",
      "Loop 7730 Loss_Train:  [[ 13.19526332]] Loss_Validation:  [[ 11.0482836]]\n",
      "Loop 7731 Loss_Train:  [[ 13.1952633]] Loss_Validation:  [[ 11.0482864]]\n",
      "Loop 7732 Loss_Train:  [[ 13.19526328]] Loss_Validation:  [[ 11.04828921]]\n",
      "Loop 7733 Loss_Train:  [[ 13.19526326]] Loss_Validation:  [[ 11.04829201]]\n",
      "Loop 7734 Loss_Train:  [[ 13.19526324]] Loss_Validation:  [[ 11.04829481]]\n",
      "Loop 7735 Loss_Train:  [[ 13.19526322]] Loss_Validation:  [[ 11.04829761]]\n",
      "Loop 7736 Loss_Train:  [[ 13.19526319]] Loss_Validation:  [[ 11.0483004]]\n",
      "Loop 7737 Loss_Train:  [[ 13.19526317]] Loss_Validation:  [[ 11.0483032]]\n",
      "Loop 7738 Loss_Train:  [[ 13.19526315]] Loss_Validation:  [[ 11.04830599]]\n",
      "Loop 7739 Loss_Train:  [[ 13.19526313]] Loss_Validation:  [[ 11.04830878]]\n",
      "Loop 7740 Loss_Train:  [[ 13.19526311]] Loss_Validation:  [[ 11.04831157]]\n",
      "Loop 7741 Loss_Train:  [[ 13.19526309]] Loss_Validation:  [[ 11.04831436]]\n",
      "Loop 7742 Loss_Train:  [[ 13.19526307]] Loss_Validation:  [[ 11.04831714]]\n",
      "Loop 7743 Loss_Train:  [[ 13.19526305]] Loss_Validation:  [[ 11.04831993]]\n",
      "Loop 7744 Loss_Train:  [[ 13.19526303]] Loss_Validation:  [[ 11.04832271]]\n",
      "Loop 7745 Loss_Train:  [[ 13.19526301]] Loss_Validation:  [[ 11.04832549]]\n",
      "Loop 7746 Loss_Train:  [[ 13.19526299]] Loss_Validation:  [[ 11.04832827]]\n",
      "Loop 7747 Loss_Train:  [[ 13.19526296]] Loss_Validation:  [[ 11.04833104]]\n",
      "Loop 7748 Loss_Train:  [[ 13.19526294]] Loss_Validation:  [[ 11.04833382]]\n",
      "Loop 7749 Loss_Train:  [[ 13.19526292]] Loss_Validation:  [[ 11.04833659]]\n",
      "Loop 7750 Loss_Train:  [[ 13.1952629]] Loss_Validation:  [[ 11.04833936]]\n",
      "Loop 7751 Loss_Train:  [[ 13.19526288]] Loss_Validation:  [[ 11.04834213]]\n",
      "Loop 7752 Loss_Train:  [[ 13.19526286]] Loss_Validation:  [[ 11.04834489]]\n",
      "Loop 7753 Loss_Train:  [[ 13.19526284]] Loss_Validation:  [[ 11.04834766]]\n",
      "Loop 7754 Loss_Train:  [[ 13.19526282]] Loss_Validation:  [[ 11.04835042]]\n",
      "Loop 7755 Loss_Train:  [[ 13.1952628]] Loss_Validation:  [[ 11.04835318]]\n",
      "Loop 7756 Loss_Train:  [[ 13.19526278]] Loss_Validation:  [[ 11.04835594]]\n",
      "Loop 7757 Loss_Train:  [[ 13.19526276]] Loss_Validation:  [[ 11.04835869]]\n",
      "Loop 7758 Loss_Train:  [[ 13.19526274]] Loss_Validation:  [[ 11.04836145]]\n",
      "Loop 7759 Loss_Train:  [[ 13.19526272]] Loss_Validation:  [[ 11.0483642]]\n",
      "Loop 7760 Loss_Train:  [[ 13.1952627]] Loss_Validation:  [[ 11.04836695]]\n",
      "Loop 7761 Loss_Train:  [[ 13.19526268]] Loss_Validation:  [[ 11.0483697]]\n",
      "Loop 7762 Loss_Train:  [[ 13.19526266]] Loss_Validation:  [[ 11.04837245]]\n",
      "Loop 7763 Loss_Train:  [[ 13.19526264]] Loss_Validation:  [[ 11.04837519]]\n",
      "Loop 7764 Loss_Train:  [[ 13.19526262]] Loss_Validation:  [[ 11.04837794]]\n",
      "Loop 7765 Loss_Train:  [[ 13.1952626]] Loss_Validation:  [[ 11.04838068]]\n",
      "Loop 7766 Loss_Train:  [[ 13.19526258]] Loss_Validation:  [[ 11.04838342]]\n",
      "Loop 7767 Loss_Train:  [[ 13.19526256]] Loss_Validation:  [[ 11.04838616]]\n",
      "Loop 7768 Loss_Train:  [[ 13.19526254]] Loss_Validation:  [[ 11.04838889]]\n",
      "Loop 7769 Loss_Train:  [[ 13.19526252]] Loss_Validation:  [[ 11.04839163]]\n",
      "Loop 7770 Loss_Train:  [[ 13.1952625]] Loss_Validation:  [[ 11.04839436]]\n",
      "Loop 7771 Loss_Train:  [[ 13.19526248]] Loss_Validation:  [[ 11.04839709]]\n",
      "Loop 7772 Loss_Train:  [[ 13.19526246]] Loss_Validation:  [[ 11.04839982]]\n",
      "Loop 7773 Loss_Train:  [[ 13.19526244]] Loss_Validation:  [[ 11.04840254]]\n",
      "Loop 7774 Loss_Train:  [[ 13.19526242]] Loss_Validation:  [[ 11.04840527]]\n",
      "Loop 7775 Loss_Train:  [[ 13.1952624]] Loss_Validation:  [[ 11.04840799]]\n",
      "Loop 7776 Loss_Train:  [[ 13.19526238]] Loss_Validation:  [[ 11.04841071]]\n",
      "Loop 7777 Loss_Train:  [[ 13.19526236]] Loss_Validation:  [[ 11.04841343]]\n",
      "Loop 7778 Loss_Train:  [[ 13.19526234]] Loss_Validation:  [[ 11.04841615]]\n",
      "Loop 7779 Loss_Train:  [[ 13.19526232]] Loss_Validation:  [[ 11.04841886]]\n",
      "Loop 7780 Loss_Train:  [[ 13.1952623]] Loss_Validation:  [[ 11.04842157]]\n",
      "Loop 7781 Loss_Train:  [[ 13.19526228]] Loss_Validation:  [[ 11.04842429]]\n",
      "Loop 7782 Loss_Train:  [[ 13.19526226]] Loss_Validation:  [[ 11.048427]]\n",
      "Loop 7783 Loss_Train:  [[ 13.19526224]] Loss_Validation:  [[ 11.0484297]]\n",
      "Loop 7784 Loss_Train:  [[ 13.19526222]] Loss_Validation:  [[ 11.04843241]]\n",
      "Loop 7785 Loss_Train:  [[ 13.1952622]] Loss_Validation:  [[ 11.04843511]]\n",
      "Loop 7786 Loss_Train:  [[ 13.19526218]] Loss_Validation:  [[ 11.04843782]]\n",
      "Loop 7787 Loss_Train:  [[ 13.19526216]] Loss_Validation:  [[ 11.04844052]]\n",
      "Loop 7788 Loss_Train:  [[ 13.19526214]] Loss_Validation:  [[ 11.04844321]]\n",
      "Loop 7789 Loss_Train:  [[ 13.19526212]] Loss_Validation:  [[ 11.04844591]]\n",
      "Loop 7790 Loss_Train:  [[ 13.1952621]] Loss_Validation:  [[ 11.04844861]]\n",
      "Loop 7791 Loss_Train:  [[ 13.19526208]] Loss_Validation:  [[ 11.0484513]]\n",
      "Loop 7792 Loss_Train:  [[ 13.19526206]] Loss_Validation:  [[ 11.04845399]]\n",
      "Loop 7793 Loss_Train:  [[ 13.19526204]] Loss_Validation:  [[ 11.04845668]]\n",
      "Loop 7794 Loss_Train:  [[ 13.19526202]] Loss_Validation:  [[ 11.04845937]]\n",
      "Loop 7795 Loss_Train:  [[ 13.195262]] Loss_Validation:  [[ 11.04846205]]\n",
      "Loop 7796 Loss_Train:  [[ 13.19526198]] Loss_Validation:  [[ 11.04846473]]\n",
      "Loop 7797 Loss_Train:  [[ 13.19526196]] Loss_Validation:  [[ 11.04846742]]\n",
      "Loop 7798 Loss_Train:  [[ 13.19526194]] Loss_Validation:  [[ 11.0484701]]\n",
      "Loop 7799 Loss_Train:  [[ 13.19526193]] Loss_Validation:  [[ 11.04847277]]\n",
      "Loop 7800 Loss_Train:  [[ 13.19526191]] Loss_Validation:  [[ 11.04847545]]\n",
      "Loop 7801 Loss_Train:  [[ 13.19526189]] Loss_Validation:  [[ 11.04847812]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 7802 Loss_Train:  [[ 13.19526187]] Loss_Validation:  [[ 11.0484808]]\n",
      "Loop 7803 Loss_Train:  [[ 13.19526185]] Loss_Validation:  [[ 11.04848347]]\n",
      "Loop 7804 Loss_Train:  [[ 13.19526183]] Loss_Validation:  [[ 11.04848614]]\n",
      "Loop 7805 Loss_Train:  [[ 13.19526181]] Loss_Validation:  [[ 11.0484888]]\n",
      "Loop 7806 Loss_Train:  [[ 13.19526179]] Loss_Validation:  [[ 11.04849147]]\n",
      "Loop 7807 Loss_Train:  [[ 13.19526177]] Loss_Validation:  [[ 11.04849413]]\n",
      "Loop 7808 Loss_Train:  [[ 13.19526175]] Loss_Validation:  [[ 11.04849679]]\n",
      "Loop 7809 Loss_Train:  [[ 13.19526173]] Loss_Validation:  [[ 11.04849945]]\n",
      "Loop 7810 Loss_Train:  [[ 13.19526172]] Loss_Validation:  [[ 11.04850211]]\n",
      "Loop 7811 Loss_Train:  [[ 13.1952617]] Loss_Validation:  [[ 11.04850477]]\n",
      "Loop 7812 Loss_Train:  [[ 13.19526168]] Loss_Validation:  [[ 11.04850742]]\n",
      "Loop 7813 Loss_Train:  [[ 13.19526166]] Loss_Validation:  [[ 11.04851007]]\n",
      "Loop 7814 Loss_Train:  [[ 13.19526164]] Loss_Validation:  [[ 11.04851272]]\n",
      "Loop 7815 Loss_Train:  [[ 13.19526162]] Loss_Validation:  [[ 11.04851537]]\n",
      "Loop 7816 Loss_Train:  [[ 13.1952616]] Loss_Validation:  [[ 11.04851802]]\n",
      "Loop 7817 Loss_Train:  [[ 13.19526158]] Loss_Validation:  [[ 11.04852066]]\n",
      "Loop 7818 Loss_Train:  [[ 13.19526156]] Loss_Validation:  [[ 11.04852331]]\n",
      "Loop 7819 Loss_Train:  [[ 13.19526155]] Loss_Validation:  [[ 11.04852595]]\n",
      "Loop 7820 Loss_Train:  [[ 13.19526153]] Loss_Validation:  [[ 11.04852859]]\n",
      "Loop 7821 Loss_Train:  [[ 13.19526151]] Loss_Validation:  [[ 11.04853123]]\n",
      "Loop 7822 Loss_Train:  [[ 13.19526149]] Loss_Validation:  [[ 11.04853386]]\n",
      "Loop 7823 Loss_Train:  [[ 13.19526147]] Loss_Validation:  [[ 11.0485365]]\n",
      "Loop 7824 Loss_Train:  [[ 13.19526145]] Loss_Validation:  [[ 11.04853913]]\n",
      "Loop 7825 Loss_Train:  [[ 13.19526143]] Loss_Validation:  [[ 11.04854176]]\n",
      "Loop 7826 Loss_Train:  [[ 13.19526142]] Loss_Validation:  [[ 11.04854439]]\n",
      "Loop 7827 Loss_Train:  [[ 13.1952614]] Loss_Validation:  [[ 11.04854701]]\n",
      "Loop 7828 Loss_Train:  [[ 13.19526138]] Loss_Validation:  [[ 11.04854964]]\n",
      "Loop 7829 Loss_Train:  [[ 13.19526136]] Loss_Validation:  [[ 11.04855226]]\n",
      "Loop 7830 Loss_Train:  [[ 13.19526134]] Loss_Validation:  [[ 11.04855488]]\n",
      "Loop 7831 Loss_Train:  [[ 13.19526132]] Loss_Validation:  [[ 11.0485575]]\n",
      "Loop 7832 Loss_Train:  [[ 13.19526131]] Loss_Validation:  [[ 11.04856012]]\n",
      "Loop 7833 Loss_Train:  [[ 13.19526129]] Loss_Validation:  [[ 11.04856274]]\n",
      "Loop 7834 Loss_Train:  [[ 13.19526127]] Loss_Validation:  [[ 11.04856535]]\n",
      "Loop 7835 Loss_Train:  [[ 13.19526125]] Loss_Validation:  [[ 11.04856796]]\n",
      "Loop 7836 Loss_Train:  [[ 13.19526123]] Loss_Validation:  [[ 11.04857058]]\n",
      "Loop 7837 Loss_Train:  [[ 13.19526121]] Loss_Validation:  [[ 11.04857318]]\n",
      "Loop 7838 Loss_Train:  [[ 13.1952612]] Loss_Validation:  [[ 11.04857579]]\n",
      "Loop 7839 Loss_Train:  [[ 13.19526118]] Loss_Validation:  [[ 11.0485784]]\n",
      "Loop 7840 Loss_Train:  [[ 13.19526116]] Loss_Validation:  [[ 11.048581]]\n",
      "Loop 7841 Loss_Train:  [[ 13.19526114]] Loss_Validation:  [[ 11.0485836]]\n",
      "Loop 7842 Loss_Train:  [[ 13.19526112]] Loss_Validation:  [[ 11.0485862]]\n",
      "Loop 7843 Loss_Train:  [[ 13.1952611]] Loss_Validation:  [[ 11.0485888]]\n",
      "Loop 7844 Loss_Train:  [[ 13.19526109]] Loss_Validation:  [[ 11.0485914]]\n",
      "Loop 7845 Loss_Train:  [[ 13.19526107]] Loss_Validation:  [[ 11.04859399]]\n",
      "Loop 7846 Loss_Train:  [[ 13.19526105]] Loss_Validation:  [[ 11.04859658]]\n",
      "Loop 7847 Loss_Train:  [[ 13.19526103]] Loss_Validation:  [[ 11.04859917]]\n",
      "Loop 7848 Loss_Train:  [[ 13.19526101]] Loss_Validation:  [[ 11.04860176]]\n",
      "Loop 7849 Loss_Train:  [[ 13.195261]] Loss_Validation:  [[ 11.04860435]]\n",
      "Loop 7850 Loss_Train:  [[ 13.19526098]] Loss_Validation:  [[ 11.04860694]]\n",
      "Loop 7851 Loss_Train:  [[ 13.19526096]] Loss_Validation:  [[ 11.04860952]]\n",
      "Loop 7852 Loss_Train:  [[ 13.19526094]] Loss_Validation:  [[ 11.0486121]]\n",
      "Loop 7853 Loss_Train:  [[ 13.19526093]] Loss_Validation:  [[ 11.04861468]]\n",
      "Loop 7854 Loss_Train:  [[ 13.19526091]] Loss_Validation:  [[ 11.04861726]]\n",
      "Loop 7855 Loss_Train:  [[ 13.19526089]] Loss_Validation:  [[ 11.04861984]]\n",
      "Loop 7856 Loss_Train:  [[ 13.19526087]] Loss_Validation:  [[ 11.04862241]]\n",
      "Loop 7857 Loss_Train:  [[ 13.19526085]] Loss_Validation:  [[ 11.04862499]]\n",
      "Loop 7858 Loss_Train:  [[ 13.19526084]] Loss_Validation:  [[ 11.04862756]]\n",
      "Loop 7859 Loss_Train:  [[ 13.19526082]] Loss_Validation:  [[ 11.04863013]]\n",
      "Loop 7860 Loss_Train:  [[ 13.1952608]] Loss_Validation:  [[ 11.04863269]]\n",
      "Loop 7861 Loss_Train:  [[ 13.19526078]] Loss_Validation:  [[ 11.04863526]]\n",
      "Loop 7862 Loss_Train:  [[ 13.19526077]] Loss_Validation:  [[ 11.04863782]]\n",
      "Loop 7863 Loss_Train:  [[ 13.19526075]] Loss_Validation:  [[ 11.04864039]]\n",
      "Loop 7864 Loss_Train:  [[ 13.19526073]] Loss_Validation:  [[ 11.04864295]]\n",
      "Loop 7865 Loss_Train:  [[ 13.19526071]] Loss_Validation:  [[ 11.04864551]]\n",
      "Loop 7866 Loss_Train:  [[ 13.1952607]] Loss_Validation:  [[ 11.04864806]]\n",
      "Loop 7867 Loss_Train:  [[ 13.19526068]] Loss_Validation:  [[ 11.04865062]]\n",
      "Loop 7868 Loss_Train:  [[ 13.19526066]] Loss_Validation:  [[ 11.04865317]]\n",
      "Loop 7869 Loss_Train:  [[ 13.19526064]] Loss_Validation:  [[ 11.04865573]]\n",
      "Loop 7870 Loss_Train:  [[ 13.19526063]] Loss_Validation:  [[ 11.04865828]]\n",
      "Loop 7871 Loss_Train:  [[ 13.19526061]] Loss_Validation:  [[ 11.04866082]]\n",
      "Loop 7872 Loss_Train:  [[ 13.19526059]] Loss_Validation:  [[ 11.04866337]]\n",
      "Loop 7873 Loss_Train:  [[ 13.19526057]] Loss_Validation:  [[ 11.04866592]]\n",
      "Loop 7874 Loss_Train:  [[ 13.19526056]] Loss_Validation:  [[ 11.04866846]]\n",
      "Loop 7875 Loss_Train:  [[ 13.19526054]] Loss_Validation:  [[ 11.048671]]\n",
      "Loop 7876 Loss_Train:  [[ 13.19526052]] Loss_Validation:  [[ 11.04867354]]\n",
      "Loop 7877 Loss_Train:  [[ 13.19526051]] Loss_Validation:  [[ 11.04867608]]\n",
      "Loop 7878 Loss_Train:  [[ 13.19526049]] Loss_Validation:  [[ 11.04867861]]\n",
      "Loop 7879 Loss_Train:  [[ 13.19526047]] Loss_Validation:  [[ 11.04868115]]\n",
      "Loop 7880 Loss_Train:  [[ 13.19526045]] Loss_Validation:  [[ 11.04868368]]\n",
      "Loop 7881 Loss_Train:  [[ 13.19526044]] Loss_Validation:  [[ 11.04868621]]\n",
      "Loop 7882 Loss_Train:  [[ 13.19526042]] Loss_Validation:  [[ 11.04868874]]\n",
      "Loop 7883 Loss_Train:  [[ 13.1952604]] Loss_Validation:  [[ 11.04869127]]\n",
      "Loop 7884 Loss_Train:  [[ 13.19526039]] Loss_Validation:  [[ 11.0486938]]\n",
      "Loop 7885 Loss_Train:  [[ 13.19526037]] Loss_Validation:  [[ 11.04869632]]\n",
      "Loop 7886 Loss_Train:  [[ 13.19526035]] Loss_Validation:  [[ 11.04869884]]\n",
      "Loop 7887 Loss_Train:  [[ 13.19526033]] Loss_Validation:  [[ 11.04870136]]\n",
      "Loop 7888 Loss_Train:  [[ 13.19526032]] Loss_Validation:  [[ 11.04870388]]\n",
      "Loop 7889 Loss_Train:  [[ 13.1952603]] Loss_Validation:  [[ 11.0487064]]\n",
      "Loop 7890 Loss_Train:  [[ 13.19526028]] Loss_Validation:  [[ 11.04870891]]\n",
      "Loop 7891 Loss_Train:  [[ 13.19526027]] Loss_Validation:  [[ 11.04871143]]\n",
      "Loop 7892 Loss_Train:  [[ 13.19526025]] Loss_Validation:  [[ 11.04871394]]\n",
      "Loop 7893 Loss_Train:  [[ 13.19526023]] Loss_Validation:  [[ 11.04871645]]\n",
      "Loop 7894 Loss_Train:  [[ 13.19526022]] Loss_Validation:  [[ 11.04871896]]\n",
      "Loop 7895 Loss_Train:  [[ 13.1952602]] Loss_Validation:  [[ 11.04872146]]\n",
      "Loop 7896 Loss_Train:  [[ 13.19526018]] Loss_Validation:  [[ 11.04872397]]\n",
      "Loop 7897 Loss_Train:  [[ 13.19526017]] Loss_Validation:  [[ 11.04872647]]\n",
      "Loop 7898 Loss_Train:  [[ 13.19526015]] Loss_Validation:  [[ 11.04872897]]\n",
      "Loop 7899 Loss_Train:  [[ 13.19526013]] Loss_Validation:  [[ 11.04873147]]\n",
      "Loop 7900 Loss_Train:  [[ 13.19526012]] Loss_Validation:  [[ 11.04873397]]\n",
      "Loop 7901 Loss_Train:  [[ 13.1952601]] Loss_Validation:  [[ 11.04873647]]\n",
      "Loop 7902 Loss_Train:  [[ 13.19526008]] Loss_Validation:  [[ 11.04873896]]\n",
      "Loop 7903 Loss_Train:  [[ 13.19526007]] Loss_Validation:  [[ 11.04874146]]\n",
      "Loop 7904 Loss_Train:  [[ 13.19526005]] Loss_Validation:  [[ 11.04874395]]\n",
      "Loop 7905 Loss_Train:  [[ 13.19526003]] Loss_Validation:  [[ 11.04874644]]\n",
      "Loop 7906 Loss_Train:  [[ 13.19526002]] Loss_Validation:  [[ 11.04874892]]\n",
      "Loop 7907 Loss_Train:  [[ 13.19526]] Loss_Validation:  [[ 11.04875141]]\n",
      "Loop 7908 Loss_Train:  [[ 13.19525998]] Loss_Validation:  [[ 11.04875389]]\n",
      "Loop 7909 Loss_Train:  [[ 13.19525997]] Loss_Validation:  [[ 11.04875638]]\n",
      "Loop 7910 Loss_Train:  [[ 13.19525995]] Loss_Validation:  [[ 11.04875886]]\n",
      "Loop 7911 Loss_Train:  [[ 13.19525993]] Loss_Validation:  [[ 11.04876134]]\n",
      "Loop 7912 Loss_Train:  [[ 13.19525992]] Loss_Validation:  [[ 11.04876381]]\n",
      "Loop 7913 Loss_Train:  [[ 13.1952599]] Loss_Validation:  [[ 11.04876629]]\n",
      "Loop 7914 Loss_Train:  [[ 13.19525989]] Loss_Validation:  [[ 11.04876876]]\n",
      "Loop 7915 Loss_Train:  [[ 13.19525987]] Loss_Validation:  [[ 11.04877124]]\n",
      "Loop 7916 Loss_Train:  [[ 13.19525985]] Loss_Validation:  [[ 11.04877371]]\n",
      "Loop 7917 Loss_Train:  [[ 13.19525984]] Loss_Validation:  [[ 11.04877618]]\n",
      "Loop 7918 Loss_Train:  [[ 13.19525982]] Loss_Validation:  [[ 11.04877864]]\n",
      "Loop 7919 Loss_Train:  [[ 13.1952598]] Loss_Validation:  [[ 11.04878111]]\n",
      "Loop 7920 Loss_Train:  [[ 13.19525979]] Loss_Validation:  [[ 11.04878357]]\n",
      "Loop 7921 Loss_Train:  [[ 13.19525977]] Loss_Validation:  [[ 11.04878603]]\n",
      "Loop 7922 Loss_Train:  [[ 13.19525976]] Loss_Validation:  [[ 11.0487885]]\n",
      "Loop 7923 Loss_Train:  [[ 13.19525974]] Loss_Validation:  [[ 11.04879095]]\n",
      "Loop 7924 Loss_Train:  [[ 13.19525972]] Loss_Validation:  [[ 11.04879341]]\n",
      "Loop 7925 Loss_Train:  [[ 13.19525971]] Loss_Validation:  [[ 11.04879587]]\n",
      "Loop 7926 Loss_Train:  [[ 13.19525969]] Loss_Validation:  [[ 11.04879832]]\n",
      "Loop 7927 Loss_Train:  [[ 13.19525968]] Loss_Validation:  [[ 11.04880077]]\n",
      "Loop 7928 Loss_Train:  [[ 13.19525966]] Loss_Validation:  [[ 11.04880322]]\n",
      "Loop 7929 Loss_Train:  [[ 13.19525964]] Loss_Validation:  [[ 11.04880567]]\n",
      "Loop 7930 Loss_Train:  [[ 13.19525963]] Loss_Validation:  [[ 11.04880812]]\n",
      "Loop 7931 Loss_Train:  [[ 13.19525961]] Loss_Validation:  [[ 11.04881056]]\n",
      "Loop 7932 Loss_Train:  [[ 13.1952596]] Loss_Validation:  [[ 11.04881301]]\n",
      "Loop 7933 Loss_Train:  [[ 13.19525958]] Loss_Validation:  [[ 11.04881545]]\n",
      "Loop 7934 Loss_Train:  [[ 13.19525956]] Loss_Validation:  [[ 11.04881789]]\n",
      "Loop 7935 Loss_Train:  [[ 13.19525955]] Loss_Validation:  [[ 11.04882033]]\n",
      "Loop 7936 Loss_Train:  [[ 13.19525953]] Loss_Validation:  [[ 11.04882276]]\n",
      "Loop 7937 Loss_Train:  [[ 13.19525952]] Loss_Validation:  [[ 11.0488252]]\n",
      "Loop 7938 Loss_Train:  [[ 13.1952595]] Loss_Validation:  [[ 11.04882763]]\n",
      "Loop 7939 Loss_Train:  [[ 13.19525948]] Loss_Validation:  [[ 11.04883007]]\n",
      "Loop 7940 Loss_Train:  [[ 13.19525947]] Loss_Validation:  [[ 11.0488325]]\n",
      "Loop 7941 Loss_Train:  [[ 13.19525945]] Loss_Validation:  [[ 11.04883492]]\n",
      "Loop 7942 Loss_Train:  [[ 13.19525944]] Loss_Validation:  [[ 11.04883735]]\n",
      "Loop 7943 Loss_Train:  [[ 13.19525942]] Loss_Validation:  [[ 11.04883978]]\n",
      "Loop 7944 Loss_Train:  [[ 13.19525941]] Loss_Validation:  [[ 11.0488422]]\n",
      "Loop 7945 Loss_Train:  [[ 13.19525939]] Loss_Validation:  [[ 11.04884462]]\n",
      "Loop 7946 Loss_Train:  [[ 13.19525938]] Loss_Validation:  [[ 11.04884704]]\n",
      "Loop 7947 Loss_Train:  [[ 13.19525936]] Loss_Validation:  [[ 11.04884946]]\n",
      "Loop 7948 Loss_Train:  [[ 13.19525934]] Loss_Validation:  [[ 11.04885188]]\n",
      "Loop 7949 Loss_Train:  [[ 13.19525933]] Loss_Validation:  [[ 11.04885429]]\n",
      "Loop 7950 Loss_Train:  [[ 13.19525931]] Loss_Validation:  [[ 11.0488567]]\n",
      "Loop 7951 Loss_Train:  [[ 13.1952593]] Loss_Validation:  [[ 11.04885912]]\n",
      "Loop 7952 Loss_Train:  [[ 13.19525928]] Loss_Validation:  [[ 11.04886153]]\n",
      "Loop 7953 Loss_Train:  [[ 13.19525927]] Loss_Validation:  [[ 11.04886394]]\n",
      "Loop 7954 Loss_Train:  [[ 13.19525925]] Loss_Validation:  [[ 11.04886634]]\n",
      "Loop 7955 Loss_Train:  [[ 13.19525924]] Loss_Validation:  [[ 11.04886875]]\n",
      "Loop 7956 Loss_Train:  [[ 13.19525922]] Loss_Validation:  [[ 11.04887115]]\n",
      "Loop 7957 Loss_Train:  [[ 13.1952592]] Loss_Validation:  [[ 11.04887355]]\n",
      "Loop 7958 Loss_Train:  [[ 13.19525919]] Loss_Validation:  [[ 11.04887595]]\n",
      "Loop 7959 Loss_Train:  [[ 13.19525917]] Loss_Validation:  [[ 11.04887835]]\n",
      "Loop 7960 Loss_Train:  [[ 13.19525916]] Loss_Validation:  [[ 11.04888075]]\n",
      "Loop 7961 Loss_Train:  [[ 13.19525914]] Loss_Validation:  [[ 11.04888314]]\n",
      "Loop 7962 Loss_Train:  [[ 13.19525913]] Loss_Validation:  [[ 11.04888554]]\n",
      "Loop 7963 Loss_Train:  [[ 13.19525911]] Loss_Validation:  [[ 11.04888793]]\n",
      "Loop 7964 Loss_Train:  [[ 13.1952591]] Loss_Validation:  [[ 11.04889032]]\n",
      "Loop 7965 Loss_Train:  [[ 13.19525908]] Loss_Validation:  [[ 11.04889271]]\n",
      "Loop 7966 Loss_Train:  [[ 13.19525907]] Loss_Validation:  [[ 11.04889509]]\n",
      "Loop 7967 Loss_Train:  [[ 13.19525905]] Loss_Validation:  [[ 11.04889748]]\n",
      "Loop 7968 Loss_Train:  [[ 13.19525904]] Loss_Validation:  [[ 11.04889986]]\n",
      "Loop 7969 Loss_Train:  [[ 13.19525902]] Loss_Validation:  [[ 11.04890225]]\n",
      "Loop 7970 Loss_Train:  [[ 13.19525901]] Loss_Validation:  [[ 11.04890463]]\n",
      "Loop 7971 Loss_Train:  [[ 13.19525899]] Loss_Validation:  [[ 11.048907]]\n",
      "Loop 7972 Loss_Train:  [[ 13.19525898]] Loss_Validation:  [[ 11.04890938]]\n",
      "Loop 7973 Loss_Train:  [[ 13.19525896]] Loss_Validation:  [[ 11.04891176]]\n",
      "Loop 7974 Loss_Train:  [[ 13.19525895]] Loss_Validation:  [[ 11.04891413]]\n",
      "Loop 7975 Loss_Train:  [[ 13.19525893]] Loss_Validation:  [[ 11.0489165]]\n",
      "Loop 7976 Loss_Train:  [[ 13.19525892]] Loss_Validation:  [[ 11.04891887]]\n",
      "Loop 7977 Loss_Train:  [[ 13.1952589]] Loss_Validation:  [[ 11.04892124]]\n",
      "Loop 7978 Loss_Train:  [[ 13.19525889]] Loss_Validation:  [[ 11.04892361]]\n",
      "Loop 7979 Loss_Train:  [[ 13.19525887]] Loss_Validation:  [[ 11.04892598]]\n",
      "Loop 7980 Loss_Train:  [[ 13.19525886]] Loss_Validation:  [[ 11.04892834]]\n",
      "Loop 7981 Loss_Train:  [[ 13.19525884]] Loss_Validation:  [[ 11.0489307]]\n",
      "Loop 7982 Loss_Train:  [[ 13.19525883]] Loss_Validation:  [[ 11.04893306]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 7983 Loss_Train:  [[ 13.19525881]] Loss_Validation:  [[ 11.04893542]]\n",
      "Loop 7984 Loss_Train:  [[ 13.1952588]] Loss_Validation:  [[ 11.04893778]]\n",
      "Loop 7985 Loss_Train:  [[ 13.19525878]] Loss_Validation:  [[ 11.04894014]]\n",
      "Loop 7986 Loss_Train:  [[ 13.19525877]] Loss_Validation:  [[ 11.04894249]]\n",
      "Loop 7987 Loss_Train:  [[ 13.19525875]] Loss_Validation:  [[ 11.04894484]]\n",
      "Loop 7988 Loss_Train:  [[ 13.19525874]] Loss_Validation:  [[ 11.04894719]]\n",
      "Loop 7989 Loss_Train:  [[ 13.19525873]] Loss_Validation:  [[ 11.04894954]]\n",
      "Loop 7990 Loss_Train:  [[ 13.19525871]] Loss_Validation:  [[ 11.04895189]]\n",
      "Loop 7991 Loss_Train:  [[ 13.1952587]] Loss_Validation:  [[ 11.04895424]]\n",
      "Loop 7992 Loss_Train:  [[ 13.19525868]] Loss_Validation:  [[ 11.04895658]]\n",
      "Loop 7993 Loss_Train:  [[ 13.19525867]] Loss_Validation:  [[ 11.04895893]]\n",
      "Loop 7994 Loss_Train:  [[ 13.19525865]] Loss_Validation:  [[ 11.04896127]]\n",
      "Loop 7995 Loss_Train:  [[ 13.19525864]] Loss_Validation:  [[ 11.04896361]]\n",
      "Loop 7996 Loss_Train:  [[ 13.19525862]] Loss_Validation:  [[ 11.04896594]]\n",
      "Loop 7997 Loss_Train:  [[ 13.19525861]] Loss_Validation:  [[ 11.04896828]]\n",
      "Loop 7998 Loss_Train:  [[ 13.19525859]] Loss_Validation:  [[ 11.04897062]]\n",
      "Loop 7999 Loss_Train:  [[ 13.19525858]] Loss_Validation:  [[ 11.04897295]]\n",
      "Loop 8000 Loss_Train:  [[ 13.19525857]] Loss_Validation:  [[ 11.04897528]]\n",
      "Loop 8001 Loss_Train:  [[ 13.19525855]] Loss_Validation:  [[ 11.04897761]]\n",
      "Loop 8002 Loss_Train:  [[ 13.19525854]] Loss_Validation:  [[ 11.04897994]]\n",
      "Loop 8003 Loss_Train:  [[ 13.19525852]] Loss_Validation:  [[ 11.04898227]]\n",
      "Loop 8004 Loss_Train:  [[ 13.19525851]] Loss_Validation:  [[ 11.04898459]]\n",
      "Loop 8005 Loss_Train:  [[ 13.19525849]] Loss_Validation:  [[ 11.04898692]]\n",
      "Loop 8006 Loss_Train:  [[ 13.19525848]] Loss_Validation:  [[ 11.04898924]]\n",
      "Loop 8007 Loss_Train:  [[ 13.19525847]] Loss_Validation:  [[ 11.04899156]]\n",
      "Loop 8008 Loss_Train:  [[ 13.19525845]] Loss_Validation:  [[ 11.04899388]]\n",
      "Loop 8009 Loss_Train:  [[ 13.19525844]] Loss_Validation:  [[ 11.04899619]]\n",
      "Loop 8010 Loss_Train:  [[ 13.19525842]] Loss_Validation:  [[ 11.04899851]]\n",
      "Loop 8011 Loss_Train:  [[ 13.19525841]] Loss_Validation:  [[ 11.04900082]]\n",
      "Loop 8012 Loss_Train:  [[ 13.19525839]] Loss_Validation:  [[ 11.04900314]]\n",
      "Loop 8013 Loss_Train:  [[ 13.19525838]] Loss_Validation:  [[ 11.04900545]]\n",
      "Loop 8014 Loss_Train:  [[ 13.19525837]] Loss_Validation:  [[ 11.04900776]]\n",
      "Loop 8015 Loss_Train:  [[ 13.19525835]] Loss_Validation:  [[ 11.04901006]]\n",
      "Loop 8016 Loss_Train:  [[ 13.19525834]] Loss_Validation:  [[ 11.04901237]]\n",
      "Loop 8017 Loss_Train:  [[ 13.19525832]] Loss_Validation:  [[ 11.04901467]]\n",
      "Loop 8018 Loss_Train:  [[ 13.19525831]] Loss_Validation:  [[ 11.04901698]]\n",
      "Loop 8019 Loss_Train:  [[ 13.1952583]] Loss_Validation:  [[ 11.04901928]]\n",
      "Loop 8020 Loss_Train:  [[ 13.19525828]] Loss_Validation:  [[ 11.04902158]]\n",
      "Loop 8021 Loss_Train:  [[ 13.19525827]] Loss_Validation:  [[ 11.04902388]]\n",
      "Loop 8022 Loss_Train:  [[ 13.19525825]] Loss_Validation:  [[ 11.04902617]]\n",
      "Loop 8023 Loss_Train:  [[ 13.19525824]] Loss_Validation:  [[ 11.04902847]]\n",
      "Loop 8024 Loss_Train:  [[ 13.19525823]] Loss_Validation:  [[ 11.04903076]]\n",
      "Loop 8025 Loss_Train:  [[ 13.19525821]] Loss_Validation:  [[ 11.04903305]]\n",
      "Loop 8026 Loss_Train:  [[ 13.1952582]] Loss_Validation:  [[ 11.04903534]]\n",
      "Loop 8027 Loss_Train:  [[ 13.19525818]] Loss_Validation:  [[ 11.04903763]]\n",
      "Loop 8028 Loss_Train:  [[ 13.19525817]] Loss_Validation:  [[ 11.04903992]]\n",
      "Loop 8029 Loss_Train:  [[ 13.19525816]] Loss_Validation:  [[ 11.04904221]]\n",
      "Loop 8030 Loss_Train:  [[ 13.19525814]] Loss_Validation:  [[ 11.04904449]]\n",
      "Loop 8031 Loss_Train:  [[ 13.19525813]] Loss_Validation:  [[ 11.04904677]]\n",
      "Loop 8032 Loss_Train:  [[ 13.19525811]] Loss_Validation:  [[ 11.04904905]]\n",
      "Loop 8033 Loss_Train:  [[ 13.1952581]] Loss_Validation:  [[ 11.04905133]]\n",
      "Loop 8034 Loss_Train:  [[ 13.19525809]] Loss_Validation:  [[ 11.04905361]]\n",
      "Loop 8035 Loss_Train:  [[ 13.19525807]] Loss_Validation:  [[ 11.04905589]]\n",
      "Loop 8036 Loss_Train:  [[ 13.19525806]] Loss_Validation:  [[ 11.04905816]]\n",
      "Loop 8037 Loss_Train:  [[ 13.19525805]] Loss_Validation:  [[ 11.04906043]]\n",
      "Loop 8038 Loss_Train:  [[ 13.19525803]] Loss_Validation:  [[ 11.0490627]]\n",
      "Loop 8039 Loss_Train:  [[ 13.19525802]] Loss_Validation:  [[ 11.04906497]]\n",
      "Loop 8040 Loss_Train:  [[ 13.19525801]] Loss_Validation:  [[ 11.04906724]]\n",
      "Loop 8041 Loss_Train:  [[ 13.19525799]] Loss_Validation:  [[ 11.04906951]]\n",
      "Loop 8042 Loss_Train:  [[ 13.19525798]] Loss_Validation:  [[ 11.04907177]]\n",
      "Loop 8043 Loss_Train:  [[ 13.19525796]] Loss_Validation:  [[ 11.04907404]]\n",
      "Loop 8044 Loss_Train:  [[ 13.19525795]] Loss_Validation:  [[ 11.0490763]]\n",
      "Loop 8045 Loss_Train:  [[ 13.19525794]] Loss_Validation:  [[ 11.04907856]]\n",
      "Loop 8046 Loss_Train:  [[ 13.19525792]] Loss_Validation:  [[ 11.04908082]]\n",
      "Loop 8047 Loss_Train:  [[ 13.19525791]] Loss_Validation:  [[ 11.04908308]]\n",
      "Loop 8048 Loss_Train:  [[ 13.1952579]] Loss_Validation:  [[ 11.04908533]]\n",
      "Loop 8049 Loss_Train:  [[ 13.19525788]] Loss_Validation:  [[ 11.04908759]]\n",
      "Loop 8050 Loss_Train:  [[ 13.19525787]] Loss_Validation:  [[ 11.04908984]]\n",
      "Loop 8051 Loss_Train:  [[ 13.19525786]] Loss_Validation:  [[ 11.04909209]]\n",
      "Loop 8052 Loss_Train:  [[ 13.19525784]] Loss_Validation:  [[ 11.04909434]]\n",
      "Loop 8053 Loss_Train:  [[ 13.19525783]] Loss_Validation:  [[ 11.04909659]]\n",
      "Loop 8054 Loss_Train:  [[ 13.19525782]] Loss_Validation:  [[ 11.04909883]]\n",
      "Loop 8055 Loss_Train:  [[ 13.1952578]] Loss_Validation:  [[ 11.04910108]]\n",
      "Loop 8056 Loss_Train:  [[ 13.19525779]] Loss_Validation:  [[ 11.04910332]]\n",
      "Loop 8057 Loss_Train:  [[ 13.19525778]] Loss_Validation:  [[ 11.04910556]]\n",
      "Loop 8058 Loss_Train:  [[ 13.19525776]] Loss_Validation:  [[ 11.0491078]]\n",
      "Loop 8059 Loss_Train:  [[ 13.19525775]] Loss_Validation:  [[ 11.04911004]]\n",
      "Loop 8060 Loss_Train:  [[ 13.19525774]] Loss_Validation:  [[ 11.04911228]]\n",
      "Loop 8061 Loss_Train:  [[ 13.19525772]] Loss_Validation:  [[ 11.04911452]]\n",
      "Loop 8062 Loss_Train:  [[ 13.19525771]] Loss_Validation:  [[ 11.04911675]]\n",
      "Loop 8063 Loss_Train:  [[ 13.1952577]] Loss_Validation:  [[ 11.04911898]]\n",
      "Loop 8064 Loss_Train:  [[ 13.19525768]] Loss_Validation:  [[ 11.04912121]]\n",
      "Loop 8065 Loss_Train:  [[ 13.19525767]] Loss_Validation:  [[ 11.04912344]]\n",
      "Loop 8066 Loss_Train:  [[ 13.19525766]] Loss_Validation:  [[ 11.04912567]]\n",
      "Loop 8067 Loss_Train:  [[ 13.19525764]] Loss_Validation:  [[ 11.0491279]]\n",
      "Loop 8068 Loss_Train:  [[ 13.19525763]] Loss_Validation:  [[ 11.04913012]]\n",
      "Loop 8069 Loss_Train:  [[ 13.19525762]] Loss_Validation:  [[ 11.04913235]]\n",
      "Loop 8070 Loss_Train:  [[ 13.19525761]] Loss_Validation:  [[ 11.04913457]]\n",
      "Loop 8071 Loss_Train:  [[ 13.19525759]] Loss_Validation:  [[ 11.04913679]]\n",
      "Loop 8072 Loss_Train:  [[ 13.19525758]] Loss_Validation:  [[ 11.04913901]]\n",
      "Loop 8073 Loss_Train:  [[ 13.19525757]] Loss_Validation:  [[ 11.04914122]]\n",
      "Loop 8074 Loss_Train:  [[ 13.19525755]] Loss_Validation:  [[ 11.04914344]]\n",
      "Loop 8075 Loss_Train:  [[ 13.19525754]] Loss_Validation:  [[ 11.04914565]]\n",
      "Loop 8076 Loss_Train:  [[ 13.19525753]] Loss_Validation:  [[ 11.04914787]]\n",
      "Loop 8077 Loss_Train:  [[ 13.19525751]] Loss_Validation:  [[ 11.04915008]]\n",
      "Loop 8078 Loss_Train:  [[ 13.1952575]] Loss_Validation:  [[ 11.04915229]]\n",
      "Loop 8079 Loss_Train:  [[ 13.19525749]] Loss_Validation:  [[ 11.0491545]]\n",
      "Loop 8080 Loss_Train:  [[ 13.19525748]] Loss_Validation:  [[ 11.0491567]]\n",
      "Loop 8081 Loss_Train:  [[ 13.19525746]] Loss_Validation:  [[ 11.04915891]]\n",
      "Loop 8082 Loss_Train:  [[ 13.19525745]] Loss_Validation:  [[ 11.04916111]]\n",
      "Loop 8083 Loss_Train:  [[ 13.19525744]] Loss_Validation:  [[ 11.04916331]]\n",
      "Loop 8084 Loss_Train:  [[ 13.19525742]] Loss_Validation:  [[ 11.04916551]]\n",
      "Loop 8085 Loss_Train:  [[ 13.19525741]] Loss_Validation:  [[ 11.04916771]]\n",
      "Loop 8086 Loss_Train:  [[ 13.1952574]] Loss_Validation:  [[ 11.04916991]]\n",
      "Loop 8087 Loss_Train:  [[ 13.19525739]] Loss_Validation:  [[ 11.04917211]]\n",
      "Loop 8088 Loss_Train:  [[ 13.19525737]] Loss_Validation:  [[ 11.0491743]]\n",
      "Loop 8089 Loss_Train:  [[ 13.19525736]] Loss_Validation:  [[ 11.04917649]]\n",
      "Loop 8090 Loss_Train:  [[ 13.19525735]] Loss_Validation:  [[ 11.04917868]]\n",
      "Loop 8091 Loss_Train:  [[ 13.19525734]] Loss_Validation:  [[ 11.04918087]]\n",
      "Loop 8092 Loss_Train:  [[ 13.19525732]] Loss_Validation:  [[ 11.04918306]]\n",
      "Loop 8093 Loss_Train:  [[ 13.19525731]] Loss_Validation:  [[ 11.04918525]]\n",
      "Loop 8094 Loss_Train:  [[ 13.1952573]] Loss_Validation:  [[ 11.04918743]]\n",
      "Loop 8095 Loss_Train:  [[ 13.19525729]] Loss_Validation:  [[ 11.04918962]]\n",
      "Loop 8096 Loss_Train:  [[ 13.19525727]] Loss_Validation:  [[ 11.0491918]]\n",
      "Loop 8097 Loss_Train:  [[ 13.19525726]] Loss_Validation:  [[ 11.04919398]]\n",
      "Loop 8098 Loss_Train:  [[ 13.19525725]] Loss_Validation:  [[ 11.04919616]]\n",
      "Loop 8099 Loss_Train:  [[ 13.19525724]] Loss_Validation:  [[ 11.04919834]]\n",
      "Loop 8100 Loss_Train:  [[ 13.19525722]] Loss_Validation:  [[ 11.04920052]]\n",
      "Loop 8101 Loss_Train:  [[ 13.19525721]] Loss_Validation:  [[ 11.04920269]]\n",
      "Loop 8102 Loss_Train:  [[ 13.1952572]] Loss_Validation:  [[ 11.04920486]]\n",
      "Loop 8103 Loss_Train:  [[ 13.19525719]] Loss_Validation:  [[ 11.04920704]]\n",
      "Loop 8104 Loss_Train:  [[ 13.19525717]] Loss_Validation:  [[ 11.04920921]]\n",
      "Loop 8105 Loss_Train:  [[ 13.19525716]] Loss_Validation:  [[ 11.04921137]]\n",
      "Loop 8106 Loss_Train:  [[ 13.19525715]] Loss_Validation:  [[ 11.04921354]]\n",
      "Loop 8107 Loss_Train:  [[ 13.19525714]] Loss_Validation:  [[ 11.04921571]]\n",
      "Loop 8108 Loss_Train:  [[ 13.19525712]] Loss_Validation:  [[ 11.04921787]]\n",
      "Loop 8109 Loss_Train:  [[ 13.19525711]] Loss_Validation:  [[ 11.04922004]]\n",
      "Loop 8110 Loss_Train:  [[ 13.1952571]] Loss_Validation:  [[ 11.0492222]]\n",
      "Loop 8111 Loss_Train:  [[ 13.19525709]] Loss_Validation:  [[ 11.04922436]]\n",
      "Loop 8112 Loss_Train:  [[ 13.19525707]] Loss_Validation:  [[ 11.04922651]]\n",
      "Loop 8113 Loss_Train:  [[ 13.19525706]] Loss_Validation:  [[ 11.04922867]]\n",
      "Loop 8114 Loss_Train:  [[ 13.19525705]] Loss_Validation:  [[ 11.04923083]]\n",
      "Loop 8115 Loss_Train:  [[ 13.19525704]] Loss_Validation:  [[ 11.04923298]]\n",
      "Loop 8116 Loss_Train:  [[ 13.19525702]] Loss_Validation:  [[ 11.04923513]]\n",
      "Loop 8117 Loss_Train:  [[ 13.19525701]] Loss_Validation:  [[ 11.04923728]]\n",
      "Loop 8118 Loss_Train:  [[ 13.195257]] Loss_Validation:  [[ 11.04923943]]\n",
      "Loop 8119 Loss_Train:  [[ 13.19525699]] Loss_Validation:  [[ 11.04924158]]\n",
      "Loop 8120 Loss_Train:  [[ 13.19525698]] Loss_Validation:  [[ 11.04924373]]\n",
      "Loop 8121 Loss_Train:  [[ 13.19525696]] Loss_Validation:  [[ 11.04924587]]\n",
      "Loop 8122 Loss_Train:  [[ 13.19525695]] Loss_Validation:  [[ 11.04924802]]\n",
      "Loop 8123 Loss_Train:  [[ 13.19525694]] Loss_Validation:  [[ 11.04925016]]\n",
      "Loop 8124 Loss_Train:  [[ 13.19525693]] Loss_Validation:  [[ 11.0492523]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 8125 Loss_Train:  [[ 13.19525692]] Loss_Validation:  [[ 11.04925444]]\n",
      "Loop 8126 Loss_Train:  [[ 13.1952569]] Loss_Validation:  [[ 11.04925658]]\n",
      "Loop 8127 Loss_Train:  [[ 13.19525689]] Loss_Validation:  [[ 11.04925871]]\n",
      "Loop 8128 Loss_Train:  [[ 13.19525688]] Loss_Validation:  [[ 11.04926085]]\n",
      "Loop 8129 Loss_Train:  [[ 13.19525687]] Loss_Validation:  [[ 11.04926298]]\n",
      "Loop 8130 Loss_Train:  [[ 13.19525686]] Loss_Validation:  [[ 11.04926511]]\n",
      "Loop 8131 Loss_Train:  [[ 13.19525684]] Loss_Validation:  [[ 11.04926724]]\n",
      "Loop 8132 Loss_Train:  [[ 13.19525683]] Loss_Validation:  [[ 11.04926937]]\n",
      "Loop 8133 Loss_Train:  [[ 13.19525682]] Loss_Validation:  [[ 11.0492715]]\n",
      "Loop 8134 Loss_Train:  [[ 13.19525681]] Loss_Validation:  [[ 11.04927362]]\n",
      "Loop 8135 Loss_Train:  [[ 13.1952568]] Loss_Validation:  [[ 11.04927575]]\n",
      "Loop 8136 Loss_Train:  [[ 13.19525678]] Loss_Validation:  [[ 11.04927787]]\n",
      "Loop 8137 Loss_Train:  [[ 13.19525677]] Loss_Validation:  [[ 11.04927999]]\n",
      "Loop 8138 Loss_Train:  [[ 13.19525676]] Loss_Validation:  [[ 11.04928211]]\n",
      "Loop 8139 Loss_Train:  [[ 13.19525675]] Loss_Validation:  [[ 11.04928423]]\n",
      "Loop 8140 Loss_Train:  [[ 13.19525674]] Loss_Validation:  [[ 11.04928635]]\n",
      "Loop 8141 Loss_Train:  [[ 13.19525673]] Loss_Validation:  [[ 11.04928846]]\n",
      "Loop 8142 Loss_Train:  [[ 13.19525671]] Loss_Validation:  [[ 11.04929058]]\n",
      "Loop 8143 Loss_Train:  [[ 13.1952567]] Loss_Validation:  [[ 11.04929269]]\n",
      "Loop 8144 Loss_Train:  [[ 13.19525669]] Loss_Validation:  [[ 11.0492948]]\n",
      "Loop 8145 Loss_Train:  [[ 13.19525668]] Loss_Validation:  [[ 11.04929691]]\n",
      "Loop 8146 Loss_Train:  [[ 13.19525667]] Loss_Validation:  [[ 11.04929902]]\n",
      "Loop 8147 Loss_Train:  [[ 13.19525665]] Loss_Validation:  [[ 11.04930113]]\n",
      "Loop 8148 Loss_Train:  [[ 13.19525664]] Loss_Validation:  [[ 11.04930323]]\n",
      "Loop 8149 Loss_Train:  [[ 13.19525663]] Loss_Validation:  [[ 11.04930534]]\n",
      "Loop 8150 Loss_Train:  [[ 13.19525662]] Loss_Validation:  [[ 11.04930744]]\n",
      "Loop 8151 Loss_Train:  [[ 13.19525661]] Loss_Validation:  [[ 11.04930954]]\n",
      "Loop 8152 Loss_Train:  [[ 13.1952566]] Loss_Validation:  [[ 11.04931164]]\n",
      "Loop 8153 Loss_Train:  [[ 13.19525659]] Loss_Validation:  [[ 11.04931374]]\n",
      "Loop 8154 Loss_Train:  [[ 13.19525657]] Loss_Validation:  [[ 11.04931584]]\n",
      "Loop 8155 Loss_Train:  [[ 13.19525656]] Loss_Validation:  [[ 11.04931793]]\n",
      "Loop 8156 Loss_Train:  [[ 13.19525655]] Loss_Validation:  [[ 11.04932002]]\n",
      "Loop 8157 Loss_Train:  [[ 13.19525654]] Loss_Validation:  [[ 11.04932212]]\n",
      "Loop 8158 Loss_Train:  [[ 13.19525653]] Loss_Validation:  [[ 11.04932421]]\n",
      "Loop 8159 Loss_Train:  [[ 13.19525652]] Loss_Validation:  [[ 11.0493263]]\n",
      "Loop 8160 Loss_Train:  [[ 13.1952565]] Loss_Validation:  [[ 11.04932839]]\n",
      "Loop 8161 Loss_Train:  [[ 13.19525649]] Loss_Validation:  [[ 11.04933047]]\n",
      "Loop 8162 Loss_Train:  [[ 13.19525648]] Loss_Validation:  [[ 11.04933256]]\n",
      "Loop 8163 Loss_Train:  [[ 13.19525647]] Loss_Validation:  [[ 11.04933464]]\n",
      "Loop 8164 Loss_Train:  [[ 13.19525646]] Loss_Validation:  [[ 11.04933672]]\n",
      "Loop 8165 Loss_Train:  [[ 13.19525645]] Loss_Validation:  [[ 11.0493388]]\n",
      "Loop 8166 Loss_Train:  [[ 13.19525644]] Loss_Validation:  [[ 11.04934088]]\n",
      "Loop 8167 Loss_Train:  [[ 13.19525642]] Loss_Validation:  [[ 11.04934296]]\n",
      "Loop 8168 Loss_Train:  [[ 13.19525641]] Loss_Validation:  [[ 11.04934504]]\n",
      "Loop 8169 Loss_Train:  [[ 13.1952564]] Loss_Validation:  [[ 11.04934711]]\n",
      "Loop 8170 Loss_Train:  [[ 13.19525639]] Loss_Validation:  [[ 11.04934919]]\n",
      "Loop 8171 Loss_Train:  [[ 13.19525638]] Loss_Validation:  [[ 11.04935126]]\n",
      "Loop 8172 Loss_Train:  [[ 13.19525637]] Loss_Validation:  [[ 11.04935333]]\n",
      "Loop 8173 Loss_Train:  [[ 13.19525636]] Loss_Validation:  [[ 11.0493554]]\n",
      "Loop 8174 Loss_Train:  [[ 13.19525635]] Loss_Validation:  [[ 11.04935747]]\n",
      "Loop 8175 Loss_Train:  [[ 13.19525633]] Loss_Validation:  [[ 11.04935953]]\n",
      "Loop 8176 Loss_Train:  [[ 13.19525632]] Loss_Validation:  [[ 11.0493616]]\n",
      "Loop 8177 Loss_Train:  [[ 13.19525631]] Loss_Validation:  [[ 11.04936366]]\n",
      "Loop 8178 Loss_Train:  [[ 13.1952563]] Loss_Validation:  [[ 11.04936573]]\n",
      "Loop 8179 Loss_Train:  [[ 13.19525629]] Loss_Validation:  [[ 11.04936779]]\n",
      "Loop 8180 Loss_Train:  [[ 13.19525628]] Loss_Validation:  [[ 11.04936985]]\n",
      "Loop 8181 Loss_Train:  [[ 13.19525627]] Loss_Validation:  [[ 11.0493719]]\n",
      "Loop 8182 Loss_Train:  [[ 13.19525626]] Loss_Validation:  [[ 11.04937396]]\n",
      "Loop 8183 Loss_Train:  [[ 13.19525625]] Loss_Validation:  [[ 11.04937602]]\n",
      "Loop 8184 Loss_Train:  [[ 13.19525623]] Loss_Validation:  [[ 11.04937807]]\n",
      "Loop 8185 Loss_Train:  [[ 13.19525622]] Loss_Validation:  [[ 11.04938012]]\n",
      "Loop 8186 Loss_Train:  [[ 13.19525621]] Loss_Validation:  [[ 11.04938217]]\n",
      "Loop 8187 Loss_Train:  [[ 13.1952562]] Loss_Validation:  [[ 11.04938422]]\n",
      "Loop 8188 Loss_Train:  [[ 13.19525619]] Loss_Validation:  [[ 11.04938627]]\n",
      "Loop 8189 Loss_Train:  [[ 13.19525618]] Loss_Validation:  [[ 11.04938832]]\n",
      "Loop 8190 Loss_Train:  [[ 13.19525617]] Loss_Validation:  [[ 11.04939036]]\n",
      "Loop 8191 Loss_Train:  [[ 13.19525616]] Loss_Validation:  [[ 11.04939241]]\n",
      "Loop 8192 Loss_Train:  [[ 13.19525615]] Loss_Validation:  [[ 11.04939445]]\n",
      "Loop 8193 Loss_Train:  [[ 13.19525614]] Loss_Validation:  [[ 11.04939649]]\n",
      "Loop 8194 Loss_Train:  [[ 13.19525612]] Loss_Validation:  [[ 11.04939853]]\n",
      "Loop 8195 Loss_Train:  [[ 13.19525611]] Loss_Validation:  [[ 11.04940057]]\n",
      "Loop 8196 Loss_Train:  [[ 13.1952561]] Loss_Validation:  [[ 11.0494026]]\n",
      "Loop 8197 Loss_Train:  [[ 13.19525609]] Loss_Validation:  [[ 11.04940464]]\n",
      "Loop 8198 Loss_Train:  [[ 13.19525608]] Loss_Validation:  [[ 11.04940667]]\n",
      "Loop 8199 Loss_Train:  [[ 13.19525607]] Loss_Validation:  [[ 11.04940871]]\n",
      "Loop 8200 Loss_Train:  [[ 13.19525606]] Loss_Validation:  [[ 11.04941074]]\n",
      "Loop 8201 Loss_Train:  [[ 13.19525605]] Loss_Validation:  [[ 11.04941277]]\n",
      "Loop 8202 Loss_Train:  [[ 13.19525604]] Loss_Validation:  [[ 11.0494148]]\n",
      "Loop 8203 Loss_Train:  [[ 13.19525603]] Loss_Validation:  [[ 11.04941682]]\n",
      "Loop 8204 Loss_Train:  [[ 13.19525602]] Loss_Validation:  [[ 11.04941885]]\n",
      "Loop 8205 Loss_Train:  [[ 13.19525601]] Loss_Validation:  [[ 11.04942087]]\n",
      "Loop 8206 Loss_Train:  [[ 13.19525599]] Loss_Validation:  [[ 11.0494229]]\n",
      "Loop 8207 Loss_Train:  [[ 13.19525598]] Loss_Validation:  [[ 11.04942492]]\n",
      "Loop 8208 Loss_Train:  [[ 13.19525597]] Loss_Validation:  [[ 11.04942694]]\n",
      "Loop 8209 Loss_Train:  [[ 13.19525596]] Loss_Validation:  [[ 11.04942896]]\n",
      "Loop 8210 Loss_Train:  [[ 13.19525595]] Loss_Validation:  [[ 11.04943097]]\n",
      "Loop 8211 Loss_Train:  [[ 13.19525594]] Loss_Validation:  [[ 11.04943299]]\n",
      "Loop 8212 Loss_Train:  [[ 13.19525593]] Loss_Validation:  [[ 11.049435]]\n",
      "Loop 8213 Loss_Train:  [[ 13.19525592]] Loss_Validation:  [[ 11.04943702]]\n",
      "Loop 8214 Loss_Train:  [[ 13.19525591]] Loss_Validation:  [[ 11.04943903]]\n",
      "Loop 8215 Loss_Train:  [[ 13.1952559]] Loss_Validation:  [[ 11.04944104]]\n",
      "Loop 8216 Loss_Train:  [[ 13.19525589]] Loss_Validation:  [[ 11.04944305]]\n",
      "Loop 8217 Loss_Train:  [[ 13.19525588]] Loss_Validation:  [[ 11.04944506]]\n",
      "Loop 8218 Loss_Train:  [[ 13.19525587]] Loss_Validation:  [[ 11.04944706]]\n",
      "Loop 8219 Loss_Train:  [[ 13.19525586]] Loss_Validation:  [[ 11.04944907]]\n",
      "Loop 8220 Loss_Train:  [[ 13.19525585]] Loss_Validation:  [[ 11.04945107]]\n",
      "Loop 8221 Loss_Train:  [[ 13.19525584]] Loss_Validation:  [[ 11.04945307]]\n",
      "Loop 8222 Loss_Train:  [[ 13.19525583]] Loss_Validation:  [[ 11.04945507]]\n",
      "Loop 8223 Loss_Train:  [[ 13.19525581]] Loss_Validation:  [[ 11.04945707]]\n",
      "Loop 8224 Loss_Train:  [[ 13.1952558]] Loss_Validation:  [[ 11.04945907]]\n",
      "Loop 8225 Loss_Train:  [[ 13.19525579]] Loss_Validation:  [[ 11.04946107]]\n",
      "Loop 8226 Loss_Train:  [[ 13.19525578]] Loss_Validation:  [[ 11.04946306]]\n",
      "Loop 8227 Loss_Train:  [[ 13.19525577]] Loss_Validation:  [[ 11.04946506]]\n",
      "Loop 8228 Loss_Train:  [[ 13.19525576]] Loss_Validation:  [[ 11.04946705]]\n",
      "Loop 8229 Loss_Train:  [[ 13.19525575]] Loss_Validation:  [[ 11.04946904]]\n",
      "Loop 8230 Loss_Train:  [[ 13.19525574]] Loss_Validation:  [[ 11.04947103]]\n",
      "Loop 8231 Loss_Train:  [[ 13.19525573]] Loss_Validation:  [[ 11.04947302]]\n",
      "Loop 8232 Loss_Train:  [[ 13.19525572]] Loss_Validation:  [[ 11.049475]]\n",
      "Loop 8233 Loss_Train:  [[ 13.19525571]] Loss_Validation:  [[ 11.04947699]]\n",
      "Loop 8234 Loss_Train:  [[ 13.1952557]] Loss_Validation:  [[ 11.04947897]]\n",
      "Loop 8235 Loss_Train:  [[ 13.19525569]] Loss_Validation:  [[ 11.04948096]]\n",
      "Loop 8236 Loss_Train:  [[ 13.19525568]] Loss_Validation:  [[ 11.04948294]]\n",
      "Loop 8237 Loss_Train:  [[ 13.19525567]] Loss_Validation:  [[ 11.04948492]]\n",
      "Loop 8238 Loss_Train:  [[ 13.19525566]] Loss_Validation:  [[ 11.0494869]]\n",
      "Loop 8239 Loss_Train:  [[ 13.19525565]] Loss_Validation:  [[ 11.04948887]]\n",
      "Loop 8240 Loss_Train:  [[ 13.19525564]] Loss_Validation:  [[ 11.04949085]]\n",
      "Loop 8241 Loss_Train:  [[ 13.19525563]] Loss_Validation:  [[ 11.04949282]]\n",
      "Loop 8242 Loss_Train:  [[ 13.19525562]] Loss_Validation:  [[ 11.0494948]]\n",
      "Loop 8243 Loss_Train:  [[ 13.19525561]] Loss_Validation:  [[ 11.04949677]]\n",
      "Loop 8244 Loss_Train:  [[ 13.1952556]] Loss_Validation:  [[ 11.04949874]]\n",
      "Loop 8245 Loss_Train:  [[ 13.19525559]] Loss_Validation:  [[ 11.04950071]]\n",
      "Loop 8246 Loss_Train:  [[ 13.19525558]] Loss_Validation:  [[ 11.04950268]]\n",
      "Loop 8247 Loss_Train:  [[ 13.19525557]] Loss_Validation:  [[ 11.04950464]]\n",
      "Loop 8248 Loss_Train:  [[ 13.19525556]] Loss_Validation:  [[ 11.04950661]]\n",
      "Loop 8249 Loss_Train:  [[ 13.19525555]] Loss_Validation:  [[ 11.04950857]]\n",
      "Loop 8250 Loss_Train:  [[ 13.19525554]] Loss_Validation:  [[ 11.04951053]]\n",
      "Loop 8251 Loss_Train:  [[ 13.19525553]] Loss_Validation:  [[ 11.04951249]]\n",
      "Loop 8252 Loss_Train:  [[ 13.19525552]] Loss_Validation:  [[ 11.04951445]]\n",
      "Loop 8253 Loss_Train:  [[ 13.19525551]] Loss_Validation:  [[ 11.04951641]]\n",
      "Loop 8254 Loss_Train:  [[ 13.1952555]] Loss_Validation:  [[ 11.04951837]]\n",
      "Loop 8255 Loss_Train:  [[ 13.19525549]] Loss_Validation:  [[ 11.04952032]]\n",
      "Loop 8256 Loss_Train:  [[ 13.19525548]] Loss_Validation:  [[ 11.04952228]]\n",
      "Loop 8257 Loss_Train:  [[ 13.19525547]] Loss_Validation:  [[ 11.04952423]]\n",
      "Loop 8258 Loss_Train:  [[ 13.19525546]] Loss_Validation:  [[ 11.04952618]]\n",
      "Loop 8259 Loss_Train:  [[ 13.19525545]] Loss_Validation:  [[ 11.04952813]]\n",
      "Loop 8260 Loss_Train:  [[ 13.19525544]] Loss_Validation:  [[ 11.04953008]]\n",
      "Loop 8261 Loss_Train:  [[ 13.19525543]] Loss_Validation:  [[ 11.04953203]]\n",
      "Loop 8262 Loss_Train:  [[ 13.19525542]] Loss_Validation:  [[ 11.04953398]]\n",
      "Loop 8263 Loss_Train:  [[ 13.19525541]] Loss_Validation:  [[ 11.04953592]]\n",
      "Loop 8264 Loss_Train:  [[ 13.1952554]] Loss_Validation:  [[ 11.04953786]]\n",
      "Loop 8265 Loss_Train:  [[ 13.19525539]] Loss_Validation:  [[ 11.04953981]]\n",
      "Loop 8266 Loss_Train:  [[ 13.19525538]] Loss_Validation:  [[ 11.04954175]]\n",
      "Loop 8267 Loss_Train:  [[ 13.19525537]] Loss_Validation:  [[ 11.04954369]]\n",
      "Loop 8268 Loss_Train:  [[ 13.19525536]] Loss_Validation:  [[ 11.04954562]]\n",
      "Loop 8269 Loss_Train:  [[ 13.19525535]] Loss_Validation:  [[ 11.04954756]]\n",
      "Loop 8270 Loss_Train:  [[ 13.19525534]] Loss_Validation:  [[ 11.0495495]]\n",
      "Loop 8271 Loss_Train:  [[ 13.19525533]] Loss_Validation:  [[ 11.04955143]]\n",
      "Loop 8272 Loss_Train:  [[ 13.19525532]] Loss_Validation:  [[ 11.04955336]]\n",
      "Loop 8273 Loss_Train:  [[ 13.19525531]] Loss_Validation:  [[ 11.0495553]]\n",
      "Loop 8274 Loss_Train:  [[ 13.1952553]] Loss_Validation:  [[ 11.04955723]]\n",
      "Loop 8275 Loss_Train:  [[ 13.19525529]] Loss_Validation:  [[ 11.04955915]]\n",
      "Loop 8276 Loss_Train:  [[ 13.19525528]] Loss_Validation:  [[ 11.04956108]]\n",
      "Loop 8277 Loss_Train:  [[ 13.19525527]] Loss_Validation:  [[ 11.04956301]]\n",
      "Loop 8278 Loss_Train:  [[ 13.19525526]] Loss_Validation:  [[ 11.04956493]]\n",
      "Loop 8279 Loss_Train:  [[ 13.19525525]] Loss_Validation:  [[ 11.04956686]]\n",
      "Loop 8280 Loss_Train:  [[ 13.19525524]] Loss_Validation:  [[ 11.04956878]]\n",
      "Loop 8281 Loss_Train:  [[ 13.19525523]] Loss_Validation:  [[ 11.0495707]]\n",
      "Loop 8282 Loss_Train:  [[ 13.19525522]] Loss_Validation:  [[ 11.04957262]]\n",
      "Loop 8283 Loss_Train:  [[ 13.19525521]] Loss_Validation:  [[ 11.04957454]]\n",
      "Loop 8284 Loss_Train:  [[ 13.1952552]] Loss_Validation:  [[ 11.04957645]]\n",
      "Loop 8285 Loss_Train:  [[ 13.19525519]] Loss_Validation:  [[ 11.04957837]]\n",
      "Loop 8286 Loss_Train:  [[ 13.19525518]] Loss_Validation:  [[ 11.04958028]]\n",
      "Loop 8287 Loss_Train:  [[ 13.19525517]] Loss_Validation:  [[ 11.0495822]]\n",
      "Loop 8288 Loss_Train:  [[ 13.19525517]] Loss_Validation:  [[ 11.04958411]]\n",
      "Loop 8289 Loss_Train:  [[ 13.19525516]] Loss_Validation:  [[ 11.04958602]]\n",
      "Loop 8290 Loss_Train:  [[ 13.19525515]] Loss_Validation:  [[ 11.04958793]]\n",
      "Loop 8291 Loss_Train:  [[ 13.19525514]] Loss_Validation:  [[ 11.04958983]]\n",
      "Loop 8292 Loss_Train:  [[ 13.19525513]] Loss_Validation:  [[ 11.04959174]]\n",
      "Loop 8293 Loss_Train:  [[ 13.19525512]] Loss_Validation:  [[ 11.04959364]]\n",
      "Loop 8294 Loss_Train:  [[ 13.19525511]] Loss_Validation:  [[ 11.04959555]]\n",
      "Loop 8295 Loss_Train:  [[ 13.1952551]] Loss_Validation:  [[ 11.04959745]]\n",
      "Loop 8296 Loss_Train:  [[ 13.19525509]] Loss_Validation:  [[ 11.04959935]]\n",
      "Loop 8297 Loss_Train:  [[ 13.19525508]] Loss_Validation:  [[ 11.04960125]]\n",
      "Loop 8298 Loss_Train:  [[ 13.19525507]] Loss_Validation:  [[ 11.04960315]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 8299 Loss_Train:  [[ 13.19525506]] Loss_Validation:  [[ 11.04960505]]\n",
      "Loop 8300 Loss_Train:  [[ 13.19525505]] Loss_Validation:  [[ 11.04960694]]\n",
      "Loop 8301 Loss_Train:  [[ 13.19525504]] Loss_Validation:  [[ 11.04960884]]\n",
      "Loop 8302 Loss_Train:  [[ 13.19525503]] Loss_Validation:  [[ 11.04961073]]\n",
      "Loop 8303 Loss_Train:  [[ 13.19525502]] Loss_Validation:  [[ 11.04961262]]\n",
      "Loop 8304 Loss_Train:  [[ 13.19525501]] Loss_Validation:  [[ 11.04961451]]\n",
      "Loop 8305 Loss_Train:  [[ 13.195255]] Loss_Validation:  [[ 11.0496164]]\n",
      "Loop 8306 Loss_Train:  [[ 13.195255]] Loss_Validation:  [[ 11.04961829]]\n",
      "Loop 8307 Loss_Train:  [[ 13.19525499]] Loss_Validation:  [[ 11.04962018]]\n",
      "Loop 8308 Loss_Train:  [[ 13.19525498]] Loss_Validation:  [[ 11.04962206]]\n",
      "Loop 8309 Loss_Train:  [[ 13.19525497]] Loss_Validation:  [[ 11.04962395]]\n",
      "Loop 8310 Loss_Train:  [[ 13.19525496]] Loss_Validation:  [[ 11.04962583]]\n",
      "Loop 8311 Loss_Train:  [[ 13.19525495]] Loss_Validation:  [[ 11.04962771]]\n",
      "Loop 8312 Loss_Train:  [[ 13.19525494]] Loss_Validation:  [[ 11.04962959]]\n",
      "Loop 8313 Loss_Train:  [[ 13.19525493]] Loss_Validation:  [[ 11.04963147]]\n",
      "Loop 8314 Loss_Train:  [[ 13.19525492]] Loss_Validation:  [[ 11.04963335]]\n",
      "Loop 8315 Loss_Train:  [[ 13.19525491]] Loss_Validation:  [[ 11.04963522]]\n",
      "Loop 8316 Loss_Train:  [[ 13.1952549]] Loss_Validation:  [[ 11.0496371]]\n",
      "Loop 8317 Loss_Train:  [[ 13.19525489]] Loss_Validation:  [[ 11.04963897]]\n",
      "Loop 8318 Loss_Train:  [[ 13.19525489]] Loss_Validation:  [[ 11.04964084]]\n",
      "Loop 8319 Loss_Train:  [[ 13.19525488]] Loss_Validation:  [[ 11.04964271]]\n",
      "Loop 8320 Loss_Train:  [[ 13.19525487]] Loss_Validation:  [[ 11.04964458]]\n",
      "Loop 8321 Loss_Train:  [[ 13.19525486]] Loss_Validation:  [[ 11.04964645]]\n",
      "Loop 8322 Loss_Train:  [[ 13.19525485]] Loss_Validation:  [[ 11.04964832]]\n",
      "Loop 8323 Loss_Train:  [[ 13.19525484]] Loss_Validation:  [[ 11.04965019]]\n",
      "Loop 8324 Loss_Train:  [[ 13.19525483]] Loss_Validation:  [[ 11.04965205]]\n",
      "Loop 8325 Loss_Train:  [[ 13.19525482]] Loss_Validation:  [[ 11.04965391]]\n",
      "Loop 8326 Loss_Train:  [[ 13.19525481]] Loss_Validation:  [[ 11.04965578]]\n",
      "Loop 8327 Loss_Train:  [[ 13.1952548]] Loss_Validation:  [[ 11.04965764]]\n",
      "Loop 8328 Loss_Train:  [[ 13.19525479]] Loss_Validation:  [[ 11.0496595]]\n",
      "Loop 8329 Loss_Train:  [[ 13.19525479]] Loss_Validation:  [[ 11.04966135]]\n",
      "Loop 8330 Loss_Train:  [[ 13.19525478]] Loss_Validation:  [[ 11.04966321]]\n",
      "Loop 8331 Loss_Train:  [[ 13.19525477]] Loss_Validation:  [[ 11.04966507]]\n",
      "Loop 8332 Loss_Train:  [[ 13.19525476]] Loss_Validation:  [[ 11.04966692]]\n",
      "Loop 8333 Loss_Train:  [[ 13.19525475]] Loss_Validation:  [[ 11.04966877]]\n",
      "Loop 8334 Loss_Train:  [[ 13.19525474]] Loss_Validation:  [[ 11.04967063]]\n",
      "Loop 8335 Loss_Train:  [[ 13.19525473]] Loss_Validation:  [[ 11.04967248]]\n",
      "Loop 8336 Loss_Train:  [[ 13.19525472]] Loss_Validation:  [[ 11.04967432]]\n",
      "Loop 8337 Loss_Train:  [[ 13.19525471]] Loss_Validation:  [[ 11.04967617]]\n",
      "Loop 8338 Loss_Train:  [[ 13.19525471]] Loss_Validation:  [[ 11.04967802]]\n",
      "Loop 8339 Loss_Train:  [[ 13.1952547]] Loss_Validation:  [[ 11.04967986]]\n",
      "Loop 8340 Loss_Train:  [[ 13.19525469]] Loss_Validation:  [[ 11.04968171]]\n",
      "Loop 8341 Loss_Train:  [[ 13.19525468]] Loss_Validation:  [[ 11.04968355]]\n",
      "Loop 8342 Loss_Train:  [[ 13.19525467]] Loss_Validation:  [[ 11.04968539]]\n",
      "Loop 8343 Loss_Train:  [[ 13.19525466]] Loss_Validation:  [[ 11.04968723]]\n",
      "Loop 8344 Loss_Train:  [[ 13.19525465]] Loss_Validation:  [[ 11.04968907]]\n",
      "Loop 8345 Loss_Train:  [[ 13.19525464]] Loss_Validation:  [[ 11.04969091]]\n",
      "Loop 8346 Loss_Train:  [[ 13.19525463]] Loss_Validation:  [[ 11.04969275]]\n",
      "Loop 8347 Loss_Train:  [[ 13.19525463]] Loss_Validation:  [[ 11.04969458]]\n",
      "Loop 8348 Loss_Train:  [[ 13.19525462]] Loss_Validation:  [[ 11.04969642]]\n",
      "Loop 8349 Loss_Train:  [[ 13.19525461]] Loss_Validation:  [[ 11.04969825]]\n",
      "Loop 8350 Loss_Train:  [[ 13.1952546]] Loss_Validation:  [[ 11.04970008]]\n",
      "Loop 8351 Loss_Train:  [[ 13.19525459]] Loss_Validation:  [[ 11.04970191]]\n",
      "Loop 8352 Loss_Train:  [[ 13.19525458]] Loss_Validation:  [[ 11.04970374]]\n",
      "Loop 8353 Loss_Train:  [[ 13.19525457]] Loss_Validation:  [[ 11.04970557]]\n",
      "Loop 8354 Loss_Train:  [[ 13.19525456]] Loss_Validation:  [[ 11.04970739]]\n",
      "Loop 8355 Loss_Train:  [[ 13.19525456]] Loss_Validation:  [[ 11.04970922]]\n",
      "Loop 8356 Loss_Train:  [[ 13.19525455]] Loss_Validation:  [[ 11.04971104]]\n",
      "Loop 8357 Loss_Train:  [[ 13.19525454]] Loss_Validation:  [[ 11.04971286]]\n",
      "Loop 8358 Loss_Train:  [[ 13.19525453]] Loss_Validation:  [[ 11.04971469]]\n",
      "Loop 8359 Loss_Train:  [[ 13.19525452]] Loss_Validation:  [[ 11.04971651]]\n",
      "Loop 8360 Loss_Train:  [[ 13.19525451]] Loss_Validation:  [[ 11.04971832]]\n",
      "Loop 8361 Loss_Train:  [[ 13.1952545]] Loss_Validation:  [[ 11.04972014]]\n",
      "Loop 8362 Loss_Train:  [[ 13.1952545]] Loss_Validation:  [[ 11.04972196]]\n",
      "Loop 8363 Loss_Train:  [[ 13.19525449]] Loss_Validation:  [[ 11.04972377]]\n",
      "Loop 8364 Loss_Train:  [[ 13.19525448]] Loss_Validation:  [[ 11.04972559]]\n",
      "Loop 8365 Loss_Train:  [[ 13.19525447]] Loss_Validation:  [[ 11.0497274]]\n",
      "Loop 8366 Loss_Train:  [[ 13.19525446]] Loss_Validation:  [[ 11.04972921]]\n",
      "Loop 8367 Loss_Train:  [[ 13.19525445]] Loss_Validation:  [[ 11.04973102]]\n",
      "Loop 8368 Loss_Train:  [[ 13.19525444]] Loss_Validation:  [[ 11.04973283]]\n",
      "Loop 8369 Loss_Train:  [[ 13.19525444]] Loss_Validation:  [[ 11.04973464]]\n",
      "Loop 8370 Loss_Train:  [[ 13.19525443]] Loss_Validation:  [[ 11.04973644]]\n",
      "Loop 8371 Loss_Train:  [[ 13.19525442]] Loss_Validation:  [[ 11.04973825]]\n",
      "Loop 8372 Loss_Train:  [[ 13.19525441]] Loss_Validation:  [[ 11.04974005]]\n",
      "Loop 8373 Loss_Train:  [[ 13.1952544]] Loss_Validation:  [[ 11.04974185]]\n",
      "Loop 8374 Loss_Train:  [[ 13.19525439]] Loss_Validation:  [[ 11.04974366]]\n",
      "Loop 8375 Loss_Train:  [[ 13.19525439]] Loss_Validation:  [[ 11.04974546]]\n",
      "Loop 8376 Loss_Train:  [[ 13.19525438]] Loss_Validation:  [[ 11.04974725]]\n",
      "Loop 8377 Loss_Train:  [[ 13.19525437]] Loss_Validation:  [[ 11.04974905]]\n",
      "Loop 8378 Loss_Train:  [[ 13.19525436]] Loss_Validation:  [[ 11.04975085]]\n",
      "Loop 8379 Loss_Train:  [[ 13.19525435]] Loss_Validation:  [[ 11.04975264]]\n",
      "Loop 8380 Loss_Train:  [[ 13.19525434]] Loss_Validation:  [[ 11.04975444]]\n",
      "Loop 8381 Loss_Train:  [[ 13.19525434]] Loss_Validation:  [[ 11.04975623]]\n",
      "Loop 8382 Loss_Train:  [[ 13.19525433]] Loss_Validation:  [[ 11.04975802]]\n",
      "Loop 8383 Loss_Train:  [[ 13.19525432]] Loss_Validation:  [[ 11.04975981]]\n",
      "Loop 8384 Loss_Train:  [[ 13.19525431]] Loss_Validation:  [[ 11.0497616]]\n",
      "Loop 8385 Loss_Train:  [[ 13.1952543]] Loss_Validation:  [[ 11.04976339]]\n",
      "Loop 8386 Loss_Train:  [[ 13.19525429]] Loss_Validation:  [[ 11.04976517]]\n",
      "Loop 8387 Loss_Train:  [[ 13.19525429]] Loss_Validation:  [[ 11.04976696]]\n",
      "Loop 8388 Loss_Train:  [[ 13.19525428]] Loss_Validation:  [[ 11.04976874]]\n",
      "Loop 8389 Loss_Train:  [[ 13.19525427]] Loss_Validation:  [[ 11.04977053]]\n",
      "Loop 8390 Loss_Train:  [[ 13.19525426]] Loss_Validation:  [[ 11.04977231]]\n",
      "Loop 8391 Loss_Train:  [[ 13.19525425]] Loss_Validation:  [[ 11.04977409]]\n",
      "Loop 8392 Loss_Train:  [[ 13.19525424]] Loss_Validation:  [[ 11.04977587]]\n",
      "Loop 8393 Loss_Train:  [[ 13.19525424]] Loss_Validation:  [[ 11.04977765]]\n",
      "Loop 8394 Loss_Train:  [[ 13.19525423]] Loss_Validation:  [[ 11.04977942]]\n",
      "Loop 8395 Loss_Train:  [[ 13.19525422]] Loss_Validation:  [[ 11.0497812]]\n",
      "Loop 8396 Loss_Train:  [[ 13.19525421]] Loss_Validation:  [[ 11.04978297]]\n",
      "Loop 8397 Loss_Train:  [[ 13.1952542]] Loss_Validation:  [[ 11.04978474]]\n",
      "Loop 8398 Loss_Train:  [[ 13.1952542]] Loss_Validation:  [[ 11.04978652]]\n",
      "Loop 8399 Loss_Train:  [[ 13.19525419]] Loss_Validation:  [[ 11.04978829]]\n",
      "Loop 8400 Loss_Train:  [[ 13.19525418]] Loss_Validation:  [[ 11.04979006]]\n",
      "Loop 8401 Loss_Train:  [[ 13.19525417]] Loss_Validation:  [[ 11.04979182]]\n",
      "Loop 8402 Loss_Train:  [[ 13.19525416]] Loss_Validation:  [[ 11.04979359]]\n",
      "Loop 8403 Loss_Train:  [[ 13.19525415]] Loss_Validation:  [[ 11.04979536]]\n",
      "Loop 8404 Loss_Train:  [[ 13.19525415]] Loss_Validation:  [[ 11.04979712]]\n",
      "Loop 8405 Loss_Train:  [[ 13.19525414]] Loss_Validation:  [[ 11.04979888]]\n",
      "Loop 8406 Loss_Train:  [[ 13.19525413]] Loss_Validation:  [[ 11.04980065]]\n",
      "Loop 8407 Loss_Train:  [[ 13.19525412]] Loss_Validation:  [[ 11.04980241]]\n",
      "Loop 8408 Loss_Train:  [[ 13.19525411]] Loss_Validation:  [[ 11.04980417]]\n",
      "Loop 8409 Loss_Train:  [[ 13.19525411]] Loss_Validation:  [[ 11.04980592]]\n",
      "Loop 8410 Loss_Train:  [[ 13.1952541]] Loss_Validation:  [[ 11.04980768]]\n",
      "Loop 8411 Loss_Train:  [[ 13.19525409]] Loss_Validation:  [[ 11.04980944]]\n",
      "Loop 8412 Loss_Train:  [[ 13.19525408]] Loss_Validation:  [[ 11.04981119]]\n",
      "Loop 8413 Loss_Train:  [[ 13.19525407]] Loss_Validation:  [[ 11.04981294]]\n",
      "Loop 8414 Loss_Train:  [[ 13.19525407]] Loss_Validation:  [[ 11.0498147]]\n",
      "Loop 8415 Loss_Train:  [[ 13.19525406]] Loss_Validation:  [[ 11.04981645]]\n",
      "Loop 8416 Loss_Train:  [[ 13.19525405]] Loss_Validation:  [[ 11.0498182]]\n",
      "Loop 8417 Loss_Train:  [[ 13.19525404]] Loss_Validation:  [[ 11.04981995]]\n",
      "Loop 8418 Loss_Train:  [[ 13.19525403]] Loss_Validation:  [[ 11.04982169]]\n",
      "Loop 8419 Loss_Train:  [[ 13.19525403]] Loss_Validation:  [[ 11.04982344]]\n",
      "Loop 8420 Loss_Train:  [[ 13.19525402]] Loss_Validation:  [[ 11.04982518]]\n",
      "Loop 8421 Loss_Train:  [[ 13.19525401]] Loss_Validation:  [[ 11.04982693]]\n",
      "Loop 8422 Loss_Train:  [[ 13.195254]] Loss_Validation:  [[ 11.04982867]]\n",
      "Loop 8423 Loss_Train:  [[ 13.195254]] Loss_Validation:  [[ 11.04983041]]\n",
      "Loop 8424 Loss_Train:  [[ 13.19525399]] Loss_Validation:  [[ 11.04983215]]\n",
      "Loop 8425 Loss_Train:  [[ 13.19525398]] Loss_Validation:  [[ 11.04983389]]\n",
      "Loop 8426 Loss_Train:  [[ 13.19525397]] Loss_Validation:  [[ 11.04983563]]\n",
      "Loop 8427 Loss_Train:  [[ 13.19525396]] Loss_Validation:  [[ 11.04983737]]\n",
      "Loop 8428 Loss_Train:  [[ 13.19525396]] Loss_Validation:  [[ 11.0498391]]\n",
      "Loop 8429 Loss_Train:  [[ 13.19525395]] Loss_Validation:  [[ 11.04984084]]\n",
      "Loop 8430 Loss_Train:  [[ 13.19525394]] Loss_Validation:  [[ 11.04984257]]\n",
      "Loop 8431 Loss_Train:  [[ 13.19525393]] Loss_Validation:  [[ 11.0498443]]\n",
      "Loop 8432 Loss_Train:  [[ 13.19525392]] Loss_Validation:  [[ 11.04984603]]\n",
      "Loop 8433 Loss_Train:  [[ 13.19525392]] Loss_Validation:  [[ 11.04984776]]\n",
      "Loop 8434 Loss_Train:  [[ 13.19525391]] Loss_Validation:  [[ 11.04984949]]\n",
      "Loop 8435 Loss_Train:  [[ 13.1952539]] Loss_Validation:  [[ 11.04985121]]\n",
      "Loop 8436 Loss_Train:  [[ 13.19525389]] Loss_Validation:  [[ 11.04985294]]\n",
      "Loop 8437 Loss_Train:  [[ 13.19525389]] Loss_Validation:  [[ 11.04985467]]\n",
      "Loop 8438 Loss_Train:  [[ 13.19525388]] Loss_Validation:  [[ 11.04985639]]\n",
      "Loop 8439 Loss_Train:  [[ 13.19525387]] Loss_Validation:  [[ 11.04985811]]\n",
      "Loop 8440 Loss_Train:  [[ 13.19525386]] Loss_Validation:  [[ 11.04985983]]\n",
      "Loop 8441 Loss_Train:  [[ 13.19525386]] Loss_Validation:  [[ 11.04986155]]\n",
      "Loop 8442 Loss_Train:  [[ 13.19525385]] Loss_Validation:  [[ 11.04986327]]\n",
      "Loop 8443 Loss_Train:  [[ 13.19525384]] Loss_Validation:  [[ 11.04986499]]\n",
      "Loop 8444 Loss_Train:  [[ 13.19525383]] Loss_Validation:  [[ 11.0498667]]\n",
      "Loop 8445 Loss_Train:  [[ 13.19525383]] Loss_Validation:  [[ 11.04986842]]\n",
      "Loop 8446 Loss_Train:  [[ 13.19525382]] Loss_Validation:  [[ 11.04987013]]\n",
      "Loop 8447 Loss_Train:  [[ 13.19525381]] Loss_Validation:  [[ 11.04987185]]\n",
      "Loop 8448 Loss_Train:  [[ 13.1952538]] Loss_Validation:  [[ 11.04987356]]\n",
      "Loop 8449 Loss_Train:  [[ 13.19525379]] Loss_Validation:  [[ 11.04987527]]\n",
      "Loop 8450 Loss_Train:  [[ 13.19525379]] Loss_Validation:  [[ 11.04987698]]\n",
      "Loop 8451 Loss_Train:  [[ 13.19525378]] Loss_Validation:  [[ 11.04987868]]\n",
      "Loop 8452 Loss_Train:  [[ 13.19525377]] Loss_Validation:  [[ 11.04988039]]\n",
      "Loop 8453 Loss_Train:  [[ 13.19525376]] Loss_Validation:  [[ 11.0498821]]\n",
      "Loop 8454 Loss_Train:  [[ 13.19525376]] Loss_Validation:  [[ 11.0498838]]\n",
      "Loop 8455 Loss_Train:  [[ 13.19525375]] Loss_Validation:  [[ 11.0498855]]\n",
      "Loop 8456 Loss_Train:  [[ 13.19525374]] Loss_Validation:  [[ 11.04988721]]\n",
      "Loop 8457 Loss_Train:  [[ 13.19525373]] Loss_Validation:  [[ 11.04988891]]\n",
      "Loop 8458 Loss_Train:  [[ 13.19525373]] Loss_Validation:  [[ 11.04989061]]\n",
      "Loop 8459 Loss_Train:  [[ 13.19525372]] Loss_Validation:  [[ 11.04989231]]\n",
      "Loop 8460 Loss_Train:  [[ 13.19525371]] Loss_Validation:  [[ 11.049894]]\n",
      "Loop 8461 Loss_Train:  [[ 13.1952537]] Loss_Validation:  [[ 11.0498957]]\n",
      "Loop 8462 Loss_Train:  [[ 13.1952537]] Loss_Validation:  [[ 11.04989739]]\n",
      "Loop 8463 Loss_Train:  [[ 13.19525369]] Loss_Validation:  [[ 11.04989909]]\n",
      "Loop 8464 Loss_Train:  [[ 13.19525368]] Loss_Validation:  [[ 11.04990078]]\n",
      "Loop 8465 Loss_Train:  [[ 13.19525368]] Loss_Validation:  [[ 11.04990247]]\n",
      "Loop 8466 Loss_Train:  [[ 13.19525367]] Loss_Validation:  [[ 11.04990416]]\n",
      "Loop 8467 Loss_Train:  [[ 13.19525366]] Loss_Validation:  [[ 11.04990585]]\n",
      "Loop 8468 Loss_Train:  [[ 13.19525365]] Loss_Validation:  [[ 11.04990754]]\n",
      "Loop 8469 Loss_Train:  [[ 13.19525365]] Loss_Validation:  [[ 11.04990923]]\n",
      "Loop 8470 Loss_Train:  [[ 13.19525364]] Loss_Validation:  [[ 11.04991091]]\n",
      "Loop 8471 Loss_Train:  [[ 13.19525363]] Loss_Validation:  [[ 11.0499126]]\n",
      "Loop 8472 Loss_Train:  [[ 13.19525362]] Loss_Validation:  [[ 11.04991428]]\n",
      "Loop 8473 Loss_Train:  [[ 13.19525362]] Loss_Validation:  [[ 11.04991596]]\n",
      "Loop 8474 Loss_Train:  [[ 13.19525361]] Loss_Validation:  [[ 11.04991764]]\n",
      "Loop 8475 Loss_Train:  [[ 13.1952536]] Loss_Validation:  [[ 11.04991932]]\n",
      "Loop 8476 Loss_Train:  [[ 13.19525359]] Loss_Validation:  [[ 11.049921]]\n",
      "Loop 8477 Loss_Train:  [[ 13.19525359]] Loss_Validation:  [[ 11.04992268]]\n",
      "Loop 8478 Loss_Train:  [[ 13.19525358]] Loss_Validation:  [[ 11.04992436]]\n",
      "Loop 8479 Loss_Train:  [[ 13.19525357]] Loss_Validation:  [[ 11.04992603]]\n",
      "Loop 8480 Loss_Train:  [[ 13.19525357]] Loss_Validation:  [[ 11.04992771]]\n",
      "Loop 8481 Loss_Train:  [[ 13.19525356]] Loss_Validation:  [[ 11.04992938]]\n",
      "Loop 8482 Loss_Train:  [[ 13.19525355]] Loss_Validation:  [[ 11.04993105]]\n",
      "Loop 8483 Loss_Train:  [[ 13.19525354]] Loss_Validation:  [[ 11.04993272]]\n",
      "Loop 8484 Loss_Train:  [[ 13.19525354]] Loss_Validation:  [[ 11.04993439]]\n",
      "Loop 8485 Loss_Train:  [[ 13.19525353]] Loss_Validation:  [[ 11.04993606]]\n",
      "Loop 8486 Loss_Train:  [[ 13.19525352]] Loss_Validation:  [[ 11.04993773]]\n",
      "Loop 8487 Loss_Train:  [[ 13.19525351]] Loss_Validation:  [[ 11.04993939]]\n",
      "Loop 8488 Loss_Train:  [[ 13.19525351]] Loss_Validation:  [[ 11.04994106]]\n",
      "Loop 8489 Loss_Train:  [[ 13.1952535]] Loss_Validation:  [[ 11.04994272]]\n",
      "Loop 8490 Loss_Train:  [[ 13.19525349]] Loss_Validation:  [[ 11.04994438]]\n",
      "Loop 8491 Loss_Train:  [[ 13.19525349]] Loss_Validation:  [[ 11.04994604]]\n",
      "Loop 8492 Loss_Train:  [[ 13.19525348]] Loss_Validation:  [[ 11.0499477]]\n",
      "Loop 8493 Loss_Train:  [[ 13.19525347]] Loss_Validation:  [[ 11.04994936]]\n",
      "Loop 8494 Loss_Train:  [[ 13.19525347]] Loss_Validation:  [[ 11.04995102]]\n",
      "Loop 8495 Loss_Train:  [[ 13.19525346]] Loss_Validation:  [[ 11.04995268]]\n",
      "Loop 8496 Loss_Train:  [[ 13.19525345]] Loss_Validation:  [[ 11.04995433]]\n",
      "Loop 8497 Loss_Train:  [[ 13.19525344]] Loss_Validation:  [[ 11.04995599]]\n",
      "Loop 8498 Loss_Train:  [[ 13.19525344]] Loss_Validation:  [[ 11.04995764]]\n",
      "Loop 8499 Loss_Train:  [[ 13.19525343]] Loss_Validation:  [[ 11.04995929]]\n",
      "Loop 8500 Loss_Train:  [[ 13.19525342]] Loss_Validation:  [[ 11.04996094]]\n",
      "Loop 8501 Loss_Train:  [[ 13.19525342]] Loss_Validation:  [[ 11.04996259]]\n",
      "Loop 8502 Loss_Train:  [[ 13.19525341]] Loss_Validation:  [[ 11.04996424]]\n",
      "Loop 8503 Loss_Train:  [[ 13.1952534]] Loss_Validation:  [[ 11.04996589]]\n",
      "Loop 8504 Loss_Train:  [[ 13.19525339]] Loss_Validation:  [[ 11.04996754]]\n",
      "Loop 8505 Loss_Train:  [[ 13.19525339]] Loss_Validation:  [[ 11.04996918]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 8506 Loss_Train:  [[ 13.19525338]] Loss_Validation:  [[ 11.04997083]]\n",
      "Loop 8507 Loss_Train:  [[ 13.19525337]] Loss_Validation:  [[ 11.04997247]]\n",
      "Loop 8508 Loss_Train:  [[ 13.19525337]] Loss_Validation:  [[ 11.04997411]]\n",
      "Loop 8509 Loss_Train:  [[ 13.19525336]] Loss_Validation:  [[ 11.04997575]]\n",
      "Loop 8510 Loss_Train:  [[ 13.19525335]] Loss_Validation:  [[ 11.04997739]]\n",
      "Loop 8511 Loss_Train:  [[ 13.19525335]] Loss_Validation:  [[ 11.04997903]]\n",
      "Loop 8512 Loss_Train:  [[ 13.19525334]] Loss_Validation:  [[ 11.04998067]]\n",
      "Loop 8513 Loss_Train:  [[ 13.19525333]] Loss_Validation:  [[ 11.04998231]]\n",
      "Loop 8514 Loss_Train:  [[ 13.19525333]] Loss_Validation:  [[ 11.04998394]]\n",
      "Loop 8515 Loss_Train:  [[ 13.19525332]] Loss_Validation:  [[ 11.04998557]]\n",
      "Loop 8516 Loss_Train:  [[ 13.19525331]] Loss_Validation:  [[ 11.04998721]]\n",
      "Loop 8517 Loss_Train:  [[ 13.1952533]] Loss_Validation:  [[ 11.04998884]]\n",
      "Loop 8518 Loss_Train:  [[ 13.1952533]] Loss_Validation:  [[ 11.04999047]]\n",
      "Loop 8519 Loss_Train:  [[ 13.19525329]] Loss_Validation:  [[ 11.0499921]]\n",
      "Loop 8520 Loss_Train:  [[ 13.19525328]] Loss_Validation:  [[ 11.04999373]]\n",
      "Loop 8521 Loss_Train:  [[ 13.19525328]] Loss_Validation:  [[ 11.04999536]]\n",
      "Loop 8522 Loss_Train:  [[ 13.19525327]] Loss_Validation:  [[ 11.04999698]]\n",
      "Loop 8523 Loss_Train:  [[ 13.19525326]] Loss_Validation:  [[ 11.04999861]]\n",
      "Loop 8524 Loss_Train:  [[ 13.19525326]] Loss_Validation:  [[ 11.05000023]]\n",
      "Loop 8525 Loss_Train:  [[ 13.19525325]] Loss_Validation:  [[ 11.05000185]]\n",
      "Loop 8526 Loss_Train:  [[ 13.19525324]] Loss_Validation:  [[ 11.05000348]]\n",
      "Loop 8527 Loss_Train:  [[ 13.19525324]] Loss_Validation:  [[ 11.0500051]]\n",
      "Loop 8528 Loss_Train:  [[ 13.19525323]] Loss_Validation:  [[ 11.05000672]]\n",
      "Loop 8529 Loss_Train:  [[ 13.19525322]] Loss_Validation:  [[ 11.05000833]]\n",
      "Loop 8530 Loss_Train:  [[ 13.19525322]] Loss_Validation:  [[ 11.05000995]]\n",
      "Loop 8531 Loss_Train:  [[ 13.19525321]] Loss_Validation:  [[ 11.05001157]]\n",
      "Loop 8532 Loss_Train:  [[ 13.1952532]] Loss_Validation:  [[ 11.05001318]]\n",
      "Loop 8533 Loss_Train:  [[ 13.1952532]] Loss_Validation:  [[ 11.0500148]]\n",
      "Loop 8534 Loss_Train:  [[ 13.19525319]] Loss_Validation:  [[ 11.05001641]]\n",
      "Loop 8535 Loss_Train:  [[ 13.19525318]] Loss_Validation:  [[ 11.05001802]]\n",
      "Loop 8536 Loss_Train:  [[ 13.19525318]] Loss_Validation:  [[ 11.05001963]]\n",
      "Loop 8537 Loss_Train:  [[ 13.19525317]] Loss_Validation:  [[ 11.05002124]]\n",
      "Loop 8538 Loss_Train:  [[ 13.19525316]] Loss_Validation:  [[ 11.05002285]]\n",
      "Loop 8539 Loss_Train:  [[ 13.19525316]] Loss_Validation:  [[ 11.05002446]]\n",
      "Loop 8540 Loss_Train:  [[ 13.19525315]] Loss_Validation:  [[ 11.05002606]]\n",
      "Loop 8541 Loss_Train:  [[ 13.19525314]] Loss_Validation:  [[ 11.05002767]]\n",
      "Loop 8542 Loss_Train:  [[ 13.19525314]] Loss_Validation:  [[ 11.05002927]]\n",
      "Loop 8543 Loss_Train:  [[ 13.19525313]] Loss_Validation:  [[ 11.05003087]]\n",
      "Loop 8544 Loss_Train:  [[ 13.19525312]] Loss_Validation:  [[ 11.05003247]]\n",
      "Loop 8545 Loss_Train:  [[ 13.19525312]] Loss_Validation:  [[ 11.05003407]]\n",
      "Loop 8546 Loss_Train:  [[ 13.19525311]] Loss_Validation:  [[ 11.05003567]]\n",
      "Loop 8547 Loss_Train:  [[ 13.1952531]] Loss_Validation:  [[ 11.05003727]]\n",
      "Loop 8548 Loss_Train:  [[ 13.1952531]] Loss_Validation:  [[ 11.05003887]]\n",
      "Loop 8549 Loss_Train:  [[ 13.19525309]] Loss_Validation:  [[ 11.05004047]]\n",
      "Loop 8550 Loss_Train:  [[ 13.19525308]] Loss_Validation:  [[ 11.05004206]]\n",
      "Loop 8551 Loss_Train:  [[ 13.19525308]] Loss_Validation:  [[ 11.05004365]]\n",
      "Loop 8552 Loss_Train:  [[ 13.19525307]] Loss_Validation:  [[ 11.05004525]]\n",
      "Loop 8553 Loss_Train:  [[ 13.19525306]] Loss_Validation:  [[ 11.05004684]]\n",
      "Loop 8554 Loss_Train:  [[ 13.19525306]] Loss_Validation:  [[ 11.05004843]]\n",
      "Loop 8555 Loss_Train:  [[ 13.19525305]] Loss_Validation:  [[ 11.05005002]]\n",
      "Loop 8556 Loss_Train:  [[ 13.19525304]] Loss_Validation:  [[ 11.05005161]]\n",
      "Loop 8557 Loss_Train:  [[ 13.19525304]] Loss_Validation:  [[ 11.0500532]]\n",
      "Loop 8558 Loss_Train:  [[ 13.19525303]] Loss_Validation:  [[ 11.05005478]]\n",
      "Loop 8559 Loss_Train:  [[ 13.19525302]] Loss_Validation:  [[ 11.05005637]]\n",
      "Loop 8560 Loss_Train:  [[ 13.19525302]] Loss_Validation:  [[ 11.05005795]]\n",
      "Loop 8561 Loss_Train:  [[ 13.19525301]] Loss_Validation:  [[ 11.05005953]]\n",
      "Loop 8562 Loss_Train:  [[ 13.19525301]] Loss_Validation:  [[ 11.05006112]]\n",
      "Loop 8563 Loss_Train:  [[ 13.195253]] Loss_Validation:  [[ 11.0500627]]\n",
      "Loop 8564 Loss_Train:  [[ 13.19525299]] Loss_Validation:  [[ 11.05006428]]\n",
      "Loop 8565 Loss_Train:  [[ 13.19525299]] Loss_Validation:  [[ 11.05006585]]\n",
      "Loop 8566 Loss_Train:  [[ 13.19525298]] Loss_Validation:  [[ 11.05006743]]\n",
      "Loop 8567 Loss_Train:  [[ 13.19525297]] Loss_Validation:  [[ 11.05006901]]\n",
      "Loop 8568 Loss_Train:  [[ 13.19525297]] Loss_Validation:  [[ 11.05007058]]\n",
      "Loop 8569 Loss_Train:  [[ 13.19525296]] Loss_Validation:  [[ 11.05007216]]\n",
      "Loop 8570 Loss_Train:  [[ 13.19525295]] Loss_Validation:  [[ 11.05007373]]\n",
      "Loop 8571 Loss_Train:  [[ 13.19525295]] Loss_Validation:  [[ 11.0500753]]\n",
      "Loop 8572 Loss_Train:  [[ 13.19525294]] Loss_Validation:  [[ 11.05007687]]\n",
      "Loop 8573 Loss_Train:  [[ 13.19525294]] Loss_Validation:  [[ 11.05007844]]\n",
      "Loop 8574 Loss_Train:  [[ 13.19525293]] Loss_Validation:  [[ 11.05008001]]\n",
      "Loop 8575 Loss_Train:  [[ 13.19525292]] Loss_Validation:  [[ 11.05008158]]\n",
      "Loop 8576 Loss_Train:  [[ 13.19525292]] Loss_Validation:  [[ 11.05008315]]\n",
      "Loop 8577 Loss_Train:  [[ 13.19525291]] Loss_Validation:  [[ 11.05008471]]\n",
      "Loop 8578 Loss_Train:  [[ 13.1952529]] Loss_Validation:  [[ 11.05008628]]\n",
      "Loop 8579 Loss_Train:  [[ 13.1952529]] Loss_Validation:  [[ 11.05008784]]\n",
      "Loop 8580 Loss_Train:  [[ 13.19525289]] Loss_Validation:  [[ 11.0500894]]\n",
      "Loop 8581 Loss_Train:  [[ 13.19525288]] Loss_Validation:  [[ 11.05009096]]\n",
      "Loop 8582 Loss_Train:  [[ 13.19525288]] Loss_Validation:  [[ 11.05009252]]\n",
      "Loop 8583 Loss_Train:  [[ 13.19525287]] Loss_Validation:  [[ 11.05009408]]\n",
      "Loop 8584 Loss_Train:  [[ 13.19525287]] Loss_Validation:  [[ 11.05009564]]\n",
      "Loop 8585 Loss_Train:  [[ 13.19525286]] Loss_Validation:  [[ 11.0500972]]\n",
      "Loop 8586 Loss_Train:  [[ 13.19525285]] Loss_Validation:  [[ 11.05009875]]\n",
      "Loop 8587 Loss_Train:  [[ 13.19525285]] Loss_Validation:  [[ 11.05010031]]\n",
      "Loop 8588 Loss_Train:  [[ 13.19525284]] Loss_Validation:  [[ 11.05010186]]\n",
      "Loop 8589 Loss_Train:  [[ 13.19525284]] Loss_Validation:  [[ 11.05010341]]\n",
      "Loop 8590 Loss_Train:  [[ 13.19525283]] Loss_Validation:  [[ 11.05010496]]\n",
      "Loop 8591 Loss_Train:  [[ 13.19525282]] Loss_Validation:  [[ 11.05010652]]\n",
      "Loop 8592 Loss_Train:  [[ 13.19525282]] Loss_Validation:  [[ 11.05010806]]\n",
      "Loop 8593 Loss_Train:  [[ 13.19525281]] Loss_Validation:  [[ 11.05010961]]\n",
      "Loop 8594 Loss_Train:  [[ 13.1952528]] Loss_Validation:  [[ 11.05011116]]\n",
      "Loop 8595 Loss_Train:  [[ 13.1952528]] Loss_Validation:  [[ 11.05011271]]\n",
      "Loop 8596 Loss_Train:  [[ 13.19525279]] Loss_Validation:  [[ 11.05011425]]\n",
      "Loop 8597 Loss_Train:  [[ 13.19525279]] Loss_Validation:  [[ 11.05011579]]\n",
      "Loop 8598 Loss_Train:  [[ 13.19525278]] Loss_Validation:  [[ 11.05011734]]\n",
      "Loop 8599 Loss_Train:  [[ 13.19525277]] Loss_Validation:  [[ 11.05011888]]\n",
      "Loop 8600 Loss_Train:  [[ 13.19525277]] Loss_Validation:  [[ 11.05012042]]\n",
      "Loop 8601 Loss_Train:  [[ 13.19525276]] Loss_Validation:  [[ 11.05012196]]\n",
      "Loop 8602 Loss_Train:  [[ 13.19525276]] Loss_Validation:  [[ 11.0501235]]\n",
      "Loop 8603 Loss_Train:  [[ 13.19525275]] Loss_Validation:  [[ 11.05012504]]\n",
      "Loop 8604 Loss_Train:  [[ 13.19525274]] Loss_Validation:  [[ 11.05012657]]\n",
      "Loop 8605 Loss_Train:  [[ 13.19525274]] Loss_Validation:  [[ 11.05012811]]\n",
      "Loop 8606 Loss_Train:  [[ 13.19525273]] Loss_Validation:  [[ 11.05012964]]\n",
      "Loop 8607 Loss_Train:  [[ 13.19525273]] Loss_Validation:  [[ 11.05013118]]\n",
      "Loop 8608 Loss_Train:  [[ 13.19525272]] Loss_Validation:  [[ 11.05013271]]\n",
      "Loop 8609 Loss_Train:  [[ 13.19525271]] Loss_Validation:  [[ 11.05013424]]\n",
      "Loop 8610 Loss_Train:  [[ 13.19525271]] Loss_Validation:  [[ 11.05013577]]\n",
      "Loop 8611 Loss_Train:  [[ 13.1952527]] Loss_Validation:  [[ 11.0501373]]\n",
      "Loop 8612 Loss_Train:  [[ 13.1952527]] Loss_Validation:  [[ 11.05013883]]\n",
      "Loop 8613 Loss_Train:  [[ 13.19525269]] Loss_Validation:  [[ 11.05014035]]\n",
      "Loop 8614 Loss_Train:  [[ 13.19525268]] Loss_Validation:  [[ 11.05014188]]\n",
      "Loop 8615 Loss_Train:  [[ 13.19525268]] Loss_Validation:  [[ 11.0501434]]\n",
      "Loop 8616 Loss_Train:  [[ 13.19525267]] Loss_Validation:  [[ 11.05014493]]\n",
      "Loop 8617 Loss_Train:  [[ 13.19525267]] Loss_Validation:  [[ 11.05014645]]\n",
      "Loop 8618 Loss_Train:  [[ 13.19525266]] Loss_Validation:  [[ 11.05014797]]\n",
      "Loop 8619 Loss_Train:  [[ 13.19525265]] Loss_Validation:  [[ 11.05014949]]\n",
      "Loop 8620 Loss_Train:  [[ 13.19525265]] Loss_Validation:  [[ 11.05015101]]\n",
      "Loop 8621 Loss_Train:  [[ 13.19525264]] Loss_Validation:  [[ 11.05015253]]\n",
      "Loop 8622 Loss_Train:  [[ 13.19525264]] Loss_Validation:  [[ 11.05015405]]\n",
      "Loop 8623 Loss_Train:  [[ 13.19525263]] Loss_Validation:  [[ 11.05015557]]\n",
      "Loop 8624 Loss_Train:  [[ 13.19525262]] Loss_Validation:  [[ 11.05015708]]\n",
      "Loop 8625 Loss_Train:  [[ 13.19525262]] Loss_Validation:  [[ 11.0501586]]\n",
      "Loop 8626 Loss_Train:  [[ 13.19525261]] Loss_Validation:  [[ 11.05016011]]\n",
      "Loop 8627 Loss_Train:  [[ 13.19525261]] Loss_Validation:  [[ 11.05016162]]\n",
      "Loop 8628 Loss_Train:  [[ 13.1952526]] Loss_Validation:  [[ 11.05016313]]\n",
      "Loop 8629 Loss_Train:  [[ 13.19525259]] Loss_Validation:  [[ 11.05016464]]\n",
      "Loop 8630 Loss_Train:  [[ 13.19525259]] Loss_Validation:  [[ 11.05016615]]\n",
      "Loop 8631 Loss_Train:  [[ 13.19525258]] Loss_Validation:  [[ 11.05016766]]\n",
      "Loop 8632 Loss_Train:  [[ 13.19525258]] Loss_Validation:  [[ 11.05016917]]\n",
      "Loop 8633 Loss_Train:  [[ 13.19525257]] Loss_Validation:  [[ 11.05017067]]\n",
      "Loop 8634 Loss_Train:  [[ 13.19525257]] Loss_Validation:  [[ 11.05017218]]\n",
      "Loop 8635 Loss_Train:  [[ 13.19525256]] Loss_Validation:  [[ 11.05017368]]\n",
      "Loop 8636 Loss_Train:  [[ 13.19525255]] Loss_Validation:  [[ 11.05017518]]\n",
      "Loop 8637 Loss_Train:  [[ 13.19525255]] Loss_Validation:  [[ 11.05017669]]\n",
      "Loop 8638 Loss_Train:  [[ 13.19525254]] Loss_Validation:  [[ 11.05017819]]\n",
      "Loop 8639 Loss_Train:  [[ 13.19525254]] Loss_Validation:  [[ 11.05017969]]\n",
      "Loop 8640 Loss_Train:  [[ 13.19525253]] Loss_Validation:  [[ 11.05018119]]\n",
      "Loop 8641 Loss_Train:  [[ 13.19525253]] Loss_Validation:  [[ 11.05018268]]\n",
      "Loop 8642 Loss_Train:  [[ 13.19525252]] Loss_Validation:  [[ 11.05018418]]\n",
      "Loop 8643 Loss_Train:  [[ 13.19525251]] Loss_Validation:  [[ 11.05018568]]\n",
      "Loop 8644 Loss_Train:  [[ 13.19525251]] Loss_Validation:  [[ 11.05018717]]\n",
      "Loop 8645 Loss_Train:  [[ 13.1952525]] Loss_Validation:  [[ 11.05018866]]\n",
      "Loop 8646 Loss_Train:  [[ 13.1952525]] Loss_Validation:  [[ 11.05019016]]\n",
      "Loop 8647 Loss_Train:  [[ 13.19525249]] Loss_Validation:  [[ 11.05019165]]\n",
      "Loop 8648 Loss_Train:  [[ 13.19525249]] Loss_Validation:  [[ 11.05019314]]\n",
      "Loop 8649 Loss_Train:  [[ 13.19525248]] Loss_Validation:  [[ 11.05019463]]\n",
      "Loop 8650 Loss_Train:  [[ 13.19525247]] Loss_Validation:  [[ 11.05019612]]\n",
      "Loop 8651 Loss_Train:  [[ 13.19525247]] Loss_Validation:  [[ 11.0501976]]\n",
      "Loop 8652 Loss_Train:  [[ 13.19525246]] Loss_Validation:  [[ 11.05019909]]\n",
      "Loop 8653 Loss_Train:  [[ 13.19525246]] Loss_Validation:  [[ 11.05020058]]\n",
      "Loop 8654 Loss_Train:  [[ 13.19525245]] Loss_Validation:  [[ 11.05020206]]\n",
      "Loop 8655 Loss_Train:  [[ 13.19525245]] Loss_Validation:  [[ 11.05020354]]\n",
      "Loop 8656 Loss_Train:  [[ 13.19525244]] Loss_Validation:  [[ 11.05020503]]\n",
      "Loop 8657 Loss_Train:  [[ 13.19525243]] Loss_Validation:  [[ 11.05020651]]\n",
      "Loop 8658 Loss_Train:  [[ 13.19525243]] Loss_Validation:  [[ 11.05020799]]\n",
      "Loop 8659 Loss_Train:  [[ 13.19525242]] Loss_Validation:  [[ 11.05020947]]\n",
      "Loop 8660 Loss_Train:  [[ 13.19525242]] Loss_Validation:  [[ 11.05021094]]\n",
      "Loop 8661 Loss_Train:  [[ 13.19525241]] Loss_Validation:  [[ 11.05021242]]\n",
      "Loop 8662 Loss_Train:  [[ 13.19525241]] Loss_Validation:  [[ 11.0502139]]\n",
      "Loop 8663 Loss_Train:  [[ 13.1952524]] Loss_Validation:  [[ 11.05021537]]\n",
      "Loop 8664 Loss_Train:  [[ 13.1952524]] Loss_Validation:  [[ 11.05021685]]\n",
      "Loop 8665 Loss_Train:  [[ 13.19525239]] Loss_Validation:  [[ 11.05021832]]\n",
      "Loop 8666 Loss_Train:  [[ 13.19525238]] Loss_Validation:  [[ 11.05021979]]\n",
      "Loop 8667 Loss_Train:  [[ 13.19525238]] Loss_Validation:  [[ 11.05022126]]\n",
      "Loop 8668 Loss_Train:  [[ 13.19525237]] Loss_Validation:  [[ 11.05022273]]\n",
      "Loop 8669 Loss_Train:  [[ 13.19525237]] Loss_Validation:  [[ 11.0502242]]\n",
      "Loop 8670 Loss_Train:  [[ 13.19525236]] Loss_Validation:  [[ 11.05022567]]\n",
      "Loop 8671 Loss_Train:  [[ 13.19525236]] Loss_Validation:  [[ 11.05022714]]\n",
      "Loop 8672 Loss_Train:  [[ 13.19525235]] Loss_Validation:  [[ 11.0502286]]\n",
      "Loop 8673 Loss_Train:  [[ 13.19525235]] Loss_Validation:  [[ 11.05023007]]\n",
      "Loop 8674 Loss_Train:  [[ 13.19525234]] Loss_Validation:  [[ 11.05023153]]\n",
      "Loop 8675 Loss_Train:  [[ 13.19525233]] Loss_Validation:  [[ 11.05023299]]\n",
      "Loop 8676 Loss_Train:  [[ 13.19525233]] Loss_Validation:  [[ 11.05023446]]\n",
      "Loop 8677 Loss_Train:  [[ 13.19525232]] Loss_Validation:  [[ 11.05023592]]\n",
      "Loop 8678 Loss_Train:  [[ 13.19525232]] Loss_Validation:  [[ 11.05023738]]\n",
      "Loop 8679 Loss_Train:  [[ 13.19525231]] Loss_Validation:  [[ 11.05023884]]\n",
      "Loop 8680 Loss_Train:  [[ 13.19525231]] Loss_Validation:  [[ 11.05024029]]\n",
      "Loop 8681 Loss_Train:  [[ 13.1952523]] Loss_Validation:  [[ 11.05024175]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 8682 Loss_Train:  [[ 13.1952523]] Loss_Validation:  [[ 11.05024321]]\n",
      "Loop 8683 Loss_Train:  [[ 13.19525229]] Loss_Validation:  [[ 11.05024466]]\n",
      "Loop 8684 Loss_Train:  [[ 13.19525229]] Loss_Validation:  [[ 11.05024611]]\n",
      "Loop 8685 Loss_Train:  [[ 13.19525228]] Loss_Validation:  [[ 11.05024757]]\n",
      "Loop 8686 Loss_Train:  [[ 13.19525227]] Loss_Validation:  [[ 11.05024902]]\n",
      "Loop 8687 Loss_Train:  [[ 13.19525227]] Loss_Validation:  [[ 11.05025047]]\n",
      "Loop 8688 Loss_Train:  [[ 13.19525226]] Loss_Validation:  [[ 11.05025192]]\n",
      "Loop 8689 Loss_Train:  [[ 13.19525226]] Loss_Validation:  [[ 11.05025337]]\n",
      "Loop 8690 Loss_Train:  [[ 13.19525225]] Loss_Validation:  [[ 11.05025482]]\n",
      "Loop 8691 Loss_Train:  [[ 13.19525225]] Loss_Validation:  [[ 11.05025626]]\n",
      "Loop 8692 Loss_Train:  [[ 13.19525224]] Loss_Validation:  [[ 11.05025771]]\n",
      "Loop 8693 Loss_Train:  [[ 13.19525224]] Loss_Validation:  [[ 11.05025915]]\n",
      "Loop 8694 Loss_Train:  [[ 13.19525223]] Loss_Validation:  [[ 11.0502606]]\n",
      "Loop 8695 Loss_Train:  [[ 13.19525223]] Loss_Validation:  [[ 11.05026204]]\n",
      "Loop 8696 Loss_Train:  [[ 13.19525222]] Loss_Validation:  [[ 11.05026348]]\n",
      "Loop 8697 Loss_Train:  [[ 13.19525222]] Loss_Validation:  [[ 11.05026492]]\n",
      "Loop 8698 Loss_Train:  [[ 13.19525221]] Loss_Validation:  [[ 11.05026636]]\n",
      "Loop 8699 Loss_Train:  [[ 13.19525221]] Loss_Validation:  [[ 11.0502678]]\n",
      "Loop 8700 Loss_Train:  [[ 13.1952522]] Loss_Validation:  [[ 11.05026924]]\n",
      "Loop 8701 Loss_Train:  [[ 13.19525219]] Loss_Validation:  [[ 11.05027068]]\n",
      "Loop 8702 Loss_Train:  [[ 13.19525219]] Loss_Validation:  [[ 11.05027211]]\n",
      "Loop 8703 Loss_Train:  [[ 13.19525218]] Loss_Validation:  [[ 11.05027355]]\n",
      "Loop 8704 Loss_Train:  [[ 13.19525218]] Loss_Validation:  [[ 11.05027498]]\n",
      "Loop 8705 Loss_Train:  [[ 13.19525217]] Loss_Validation:  [[ 11.05027641]]\n",
      "Loop 8706 Loss_Train:  [[ 13.19525217]] Loss_Validation:  [[ 11.05027785]]\n",
      "Loop 8707 Loss_Train:  [[ 13.19525216]] Loss_Validation:  [[ 11.05027928]]\n",
      "Loop 8708 Loss_Train:  [[ 13.19525216]] Loss_Validation:  [[ 11.05028071]]\n",
      "Loop 8709 Loss_Train:  [[ 13.19525215]] Loss_Validation:  [[ 11.05028213]]\n",
      "Loop 8710 Loss_Train:  [[ 13.19525215]] Loss_Validation:  [[ 11.05028356]]\n",
      "Loop 8711 Loss_Train:  [[ 13.19525214]] Loss_Validation:  [[ 11.05028499]]\n",
      "Loop 8712 Loss_Train:  [[ 13.19525214]] Loss_Validation:  [[ 11.05028642]]\n",
      "Loop 8713 Loss_Train:  [[ 13.19525213]] Loss_Validation:  [[ 11.05028784]]\n",
      "Loop 8714 Loss_Train:  [[ 13.19525213]] Loss_Validation:  [[ 11.05028926]]\n",
      "Loop 8715 Loss_Train:  [[ 13.19525212]] Loss_Validation:  [[ 11.05029069]]\n",
      "Loop 8716 Loss_Train:  [[ 13.19525212]] Loss_Validation:  [[ 11.05029211]]\n",
      "Loop 8717 Loss_Train:  [[ 13.19525211]] Loss_Validation:  [[ 11.05029353]]\n",
      "Loop 8718 Loss_Train:  [[ 13.19525211]] Loss_Validation:  [[ 11.05029495]]\n",
      "Loop 8719 Loss_Train:  [[ 13.1952521]] Loss_Validation:  [[ 11.05029637]]\n",
      "Loop 8720 Loss_Train:  [[ 13.1952521]] Loss_Validation:  [[ 11.05029779]]\n",
      "Loop 8721 Loss_Train:  [[ 13.19525209]] Loss_Validation:  [[ 11.0502992]]\n",
      "Loop 8722 Loss_Train:  [[ 13.19525209]] Loss_Validation:  [[ 11.05030062]]\n",
      "Loop 8723 Loss_Train:  [[ 13.19525208]] Loss_Validation:  [[ 11.05030204]]\n",
      "Loop 8724 Loss_Train:  [[ 13.19525208]] Loss_Validation:  [[ 11.05030345]]\n",
      "Loop 8725 Loss_Train:  [[ 13.19525207]] Loss_Validation:  [[ 11.05030486]]\n",
      "Loop 8726 Loss_Train:  [[ 13.19525207]] Loss_Validation:  [[ 11.05030627]]\n",
      "Loop 8727 Loss_Train:  [[ 13.19525206]] Loss_Validation:  [[ 11.05030769]]\n",
      "Loop 8728 Loss_Train:  [[ 13.19525206]] Loss_Validation:  [[ 11.0503091]]\n",
      "Loop 8729 Loss_Train:  [[ 13.19525205]] Loss_Validation:  [[ 11.05031051]]\n",
      "Loop 8730 Loss_Train:  [[ 13.19525205]] Loss_Validation:  [[ 11.05031191]]\n",
      "Loop 8731 Loss_Train:  [[ 13.19525204]] Loss_Validation:  [[ 11.05031332]]\n",
      "Loop 8732 Loss_Train:  [[ 13.19525204]] Loss_Validation:  [[ 11.05031473]]\n",
      "Loop 8733 Loss_Train:  [[ 13.19525203]] Loss_Validation:  [[ 11.05031613]]\n",
      "Loop 8734 Loss_Train:  [[ 13.19525202]] Loss_Validation:  [[ 11.05031754]]\n",
      "Loop 8735 Loss_Train:  [[ 13.19525202]] Loss_Validation:  [[ 11.05031894]]\n",
      "Loop 8736 Loss_Train:  [[ 13.19525201]] Loss_Validation:  [[ 11.05032034]]\n",
      "Loop 8737 Loss_Train:  [[ 13.19525201]] Loss_Validation:  [[ 11.05032174]]\n",
      "Loop 8738 Loss_Train:  [[ 13.195252]] Loss_Validation:  [[ 11.05032314]]\n",
      "Loop 8739 Loss_Train:  [[ 13.195252]] Loss_Validation:  [[ 11.05032454]]\n",
      "Loop 8740 Loss_Train:  [[ 13.19525199]] Loss_Validation:  [[ 11.05032594]]\n",
      "Loop 8741 Loss_Train:  [[ 13.19525199]] Loss_Validation:  [[ 11.05032734]]\n",
      "Loop 8742 Loss_Train:  [[ 13.19525198]] Loss_Validation:  [[ 11.05032874]]\n",
      "Loop 8743 Loss_Train:  [[ 13.19525198]] Loss_Validation:  [[ 11.05033013]]\n",
      "Loop 8744 Loss_Train:  [[ 13.19525198]] Loss_Validation:  [[ 11.05033153]]\n",
      "Loop 8745 Loss_Train:  [[ 13.19525197]] Loss_Validation:  [[ 11.05033292]]\n",
      "Loop 8746 Loss_Train:  [[ 13.19525197]] Loss_Validation:  [[ 11.05033431]]\n",
      "Loop 8747 Loss_Train:  [[ 13.19525196]] Loss_Validation:  [[ 11.05033571]]\n",
      "Loop 8748 Loss_Train:  [[ 13.19525196]] Loss_Validation:  [[ 11.0503371]]\n",
      "Loop 8749 Loss_Train:  [[ 13.19525195]] Loss_Validation:  [[ 11.05033849]]\n",
      "Loop 8750 Loss_Train:  [[ 13.19525195]] Loss_Validation:  [[ 11.05033987]]\n",
      "Loop 8751 Loss_Train:  [[ 13.19525194]] Loss_Validation:  [[ 11.05034126]]\n",
      "Loop 8752 Loss_Train:  [[ 13.19525194]] Loss_Validation:  [[ 11.05034265]]\n",
      "Loop 8753 Loss_Train:  [[ 13.19525193]] Loss_Validation:  [[ 11.05034404]]\n",
      "Loop 8754 Loss_Train:  [[ 13.19525193]] Loss_Validation:  [[ 11.05034542]]\n",
      "Loop 8755 Loss_Train:  [[ 13.19525192]] Loss_Validation:  [[ 11.0503468]]\n",
      "Loop 8756 Loss_Train:  [[ 13.19525192]] Loss_Validation:  [[ 11.05034819]]\n",
      "Loop 8757 Loss_Train:  [[ 13.19525191]] Loss_Validation:  [[ 11.05034957]]\n",
      "Loop 8758 Loss_Train:  [[ 13.19525191]] Loss_Validation:  [[ 11.05035095]]\n",
      "Loop 8759 Loss_Train:  [[ 13.1952519]] Loss_Validation:  [[ 11.05035233]]\n",
      "Loop 8760 Loss_Train:  [[ 13.1952519]] Loss_Validation:  [[ 11.05035371]]\n",
      "Loop 8761 Loss_Train:  [[ 13.19525189]] Loss_Validation:  [[ 11.05035509]]\n",
      "Loop 8762 Loss_Train:  [[ 13.19525189]] Loss_Validation:  [[ 11.05035647]]\n",
      "Loop 8763 Loss_Train:  [[ 13.19525188]] Loss_Validation:  [[ 11.05035784]]\n",
      "Loop 8764 Loss_Train:  [[ 13.19525188]] Loss_Validation:  [[ 11.05035922]]\n",
      "Loop 8765 Loss_Train:  [[ 13.19525187]] Loss_Validation:  [[ 11.05036059]]\n",
      "Loop 8766 Loss_Train:  [[ 13.19525187]] Loss_Validation:  [[ 11.05036197]]\n",
      "Loop 8767 Loss_Train:  [[ 13.19525186]] Loss_Validation:  [[ 11.05036334]]\n",
      "Loop 8768 Loss_Train:  [[ 13.19525186]] Loss_Validation:  [[ 11.05036471]]\n",
      "Loop 8769 Loss_Train:  [[ 13.19525185]] Loss_Validation:  [[ 11.05036608]]\n",
      "Loop 8770 Loss_Train:  [[ 13.19525185]] Loss_Validation:  [[ 11.05036745]]\n",
      "Loop 8771 Loss_Train:  [[ 13.19525184]] Loss_Validation:  [[ 11.05036882]]\n",
      "Loop 8772 Loss_Train:  [[ 13.19525184]] Loss_Validation:  [[ 11.05037019]]\n",
      "Loop 8773 Loss_Train:  [[ 13.19525183]] Loss_Validation:  [[ 11.05037156]]\n",
      "Loop 8774 Loss_Train:  [[ 13.19525183]] Loss_Validation:  [[ 11.05037292]]\n",
      "Loop 8775 Loss_Train:  [[ 13.19525182]] Loss_Validation:  [[ 11.05037429]]\n",
      "Loop 8776 Loss_Train:  [[ 13.19525182]] Loss_Validation:  [[ 11.05037565]]\n",
      "Loop 8777 Loss_Train:  [[ 13.19525182]] Loss_Validation:  [[ 11.05037701]]\n",
      "Loop 8778 Loss_Train:  [[ 13.19525181]] Loss_Validation:  [[ 11.05037838]]\n",
      "Loop 8779 Loss_Train:  [[ 13.19525181]] Loss_Validation:  [[ 11.05037974]]\n",
      "Loop 8780 Loss_Train:  [[ 13.1952518]] Loss_Validation:  [[ 11.0503811]]\n",
      "Loop 8781 Loss_Train:  [[ 13.1952518]] Loss_Validation:  [[ 11.05038246]]\n",
      "Loop 8782 Loss_Train:  [[ 13.19525179]] Loss_Validation:  [[ 11.05038382]]\n",
      "Loop 8783 Loss_Train:  [[ 13.19525179]] Loss_Validation:  [[ 11.05038517]]\n",
      "Loop 8784 Loss_Train:  [[ 13.19525178]] Loss_Validation:  [[ 11.05038653]]\n",
      "Loop 8785 Loss_Train:  [[ 13.19525178]] Loss_Validation:  [[ 11.05038789]]\n",
      "Loop 8786 Loss_Train:  [[ 13.19525177]] Loss_Validation:  [[ 11.05038924]]\n",
      "Loop 8787 Loss_Train:  [[ 13.19525177]] Loss_Validation:  [[ 11.05039059]]\n",
      "Loop 8788 Loss_Train:  [[ 13.19525176]] Loss_Validation:  [[ 11.05039195]]\n",
      "Loop 8789 Loss_Train:  [[ 13.19525176]] Loss_Validation:  [[ 11.0503933]]\n",
      "Loop 8790 Loss_Train:  [[ 13.19525175]] Loss_Validation:  [[ 11.05039465]]\n",
      "Loop 8791 Loss_Train:  [[ 13.19525175]] Loss_Validation:  [[ 11.050396]]\n",
      "Loop 8792 Loss_Train:  [[ 13.19525175]] Loss_Validation:  [[ 11.05039735]]\n",
      "Loop 8793 Loss_Train:  [[ 13.19525174]] Loss_Validation:  [[ 11.0503987]]\n",
      "Loop 8794 Loss_Train:  [[ 13.19525174]] Loss_Validation:  [[ 11.05040004]]\n",
      "Loop 8795 Loss_Train:  [[ 13.19525173]] Loss_Validation:  [[ 11.05040139]]\n",
      "Loop 8796 Loss_Train:  [[ 13.19525173]] Loss_Validation:  [[ 11.05040274]]\n",
      "Loop 8797 Loss_Train:  [[ 13.19525172]] Loss_Validation:  [[ 11.05040408]]\n",
      "Loop 8798 Loss_Train:  [[ 13.19525172]] Loss_Validation:  [[ 11.05040542]]\n",
      "Loop 8799 Loss_Train:  [[ 13.19525171]] Loss_Validation:  [[ 11.05040677]]\n",
      "Loop 8800 Loss_Train:  [[ 13.19525171]] Loss_Validation:  [[ 11.05040811]]\n",
      "Loop 8801 Loss_Train:  [[ 13.1952517]] Loss_Validation:  [[ 11.05040945]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 8802 Loss_Train:  [[ 13.1952517]] Loss_Validation:  [[ 11.05041079]]\n",
      "Loop 8803 Loss_Train:  [[ 13.19525169]] Loss_Validation:  [[ 11.05041213]]\n",
      "Loop 8804 Loss_Train:  [[ 13.19525169]] Loss_Validation:  [[ 11.05041347]]\n",
      "Loop 8805 Loss_Train:  [[ 13.19525169]] Loss_Validation:  [[ 11.0504148]]\n",
      "Loop 8806 Loss_Train:  [[ 13.19525168]] Loss_Validation:  [[ 11.05041614]]\n",
      "Loop 8807 Loss_Train:  [[ 13.19525168]] Loss_Validation:  [[ 11.05041747]]\n",
      "Loop 8808 Loss_Train:  [[ 13.19525167]] Loss_Validation:  [[ 11.05041881]]\n",
      "Loop 8809 Loss_Train:  [[ 13.19525167]] Loss_Validation:  [[ 11.05042014]]\n",
      "Loop 8810 Loss_Train:  [[ 13.19525166]] Loss_Validation:  [[ 11.05042147]]\n",
      "Loop 8811 Loss_Train:  [[ 13.19525166]] Loss_Validation:  [[ 11.0504228]]\n",
      "Loop 8812 Loss_Train:  [[ 13.19525165]] Loss_Validation:  [[ 11.05042414]]\n",
      "Loop 8813 Loss_Train:  [[ 13.19525165]] Loss_Validation:  [[ 11.05042546]]\n",
      "Loop 8814 Loss_Train:  [[ 13.19525165]] Loss_Validation:  [[ 11.05042679]]\n",
      "Loop 8815 Loss_Train:  [[ 13.19525164]] Loss_Validation:  [[ 11.05042812]]\n",
      "Loop 8816 Loss_Train:  [[ 13.19525164]] Loss_Validation:  [[ 11.05042945]]\n",
      "Loop 8817 Loss_Train:  [[ 13.19525163]] Loss_Validation:  [[ 11.05043077]]\n",
      "Loop 8818 Loss_Train:  [[ 13.19525163]] Loss_Validation:  [[ 11.0504321]]\n",
      "Loop 8819 Loss_Train:  [[ 13.19525162]] Loss_Validation:  [[ 11.05043342]]\n",
      "Loop 8820 Loss_Train:  [[ 13.19525162]] Loss_Validation:  [[ 11.05043475]]\n",
      "Loop 8821 Loss_Train:  [[ 13.19525161]] Loss_Validation:  [[ 11.05043607]]\n",
      "Loop 8822 Loss_Train:  [[ 13.19525161]] Loss_Validation:  [[ 11.05043739]]\n",
      "Loop 8823 Loss_Train:  [[ 13.1952516]] Loss_Validation:  [[ 11.05043871]]\n",
      "Loop 8824 Loss_Train:  [[ 13.1952516]] Loss_Validation:  [[ 11.05044003]]\n",
      "Loop 8825 Loss_Train:  [[ 13.1952516]] Loss_Validation:  [[ 11.05044135]]\n",
      "Loop 8826 Loss_Train:  [[ 13.19525159]] Loss_Validation:  [[ 11.05044267]]\n",
      "Loop 8827 Loss_Train:  [[ 13.19525159]] Loss_Validation:  [[ 11.05044398]]\n",
      "Loop 8828 Loss_Train:  [[ 13.19525158]] Loss_Validation:  [[ 11.0504453]]\n",
      "Loop 8829 Loss_Train:  [[ 13.19525158]] Loss_Validation:  [[ 11.05044661]]\n",
      "Loop 8830 Loss_Train:  [[ 13.19525157]] Loss_Validation:  [[ 11.05044793]]\n",
      "Loop 8831 Loss_Train:  [[ 13.19525157]] Loss_Validation:  [[ 11.05044924]]\n",
      "Loop 8832 Loss_Train:  [[ 13.19525157]] Loss_Validation:  [[ 11.05045055]]\n",
      "Loop 8833 Loss_Train:  [[ 13.19525156]] Loss_Validation:  [[ 11.05045186]]\n",
      "Loop 8834 Loss_Train:  [[ 13.19525156]] Loss_Validation:  [[ 11.05045318]]\n",
      "Loop 8835 Loss_Train:  [[ 13.19525155]] Loss_Validation:  [[ 11.05045448]]\n",
      "Loop 8836 Loss_Train:  [[ 13.19525155]] Loss_Validation:  [[ 11.05045579]]\n",
      "Loop 8837 Loss_Train:  [[ 13.19525154]] Loss_Validation:  [[ 11.0504571]]\n",
      "Loop 8838 Loss_Train:  [[ 13.19525154]] Loss_Validation:  [[ 11.05045841]]\n",
      "Loop 8839 Loss_Train:  [[ 13.19525153]] Loss_Validation:  [[ 11.05045971]]\n",
      "Loop 8840 Loss_Train:  [[ 13.19525153]] Loss_Validation:  [[ 11.05046102]]\n",
      "Loop 8841 Loss_Train:  [[ 13.19525153]] Loss_Validation:  [[ 11.05046232]]\n",
      "Loop 8842 Loss_Train:  [[ 13.19525152]] Loss_Validation:  [[ 11.05046363]]\n",
      "Loop 8843 Loss_Train:  [[ 13.19525152]] Loss_Validation:  [[ 11.05046493]]\n",
      "Loop 8844 Loss_Train:  [[ 13.19525151]] Loss_Validation:  [[ 11.05046623]]\n",
      "Loop 8845 Loss_Train:  [[ 13.19525151]] Loss_Validation:  [[ 11.05046753]]\n",
      "Loop 8846 Loss_Train:  [[ 13.1952515]] Loss_Validation:  [[ 11.05046883]]\n",
      "Loop 8847 Loss_Train:  [[ 13.1952515]] Loss_Validation:  [[ 11.05047013]]\n",
      "Loop 8848 Loss_Train:  [[ 13.1952515]] Loss_Validation:  [[ 11.05047143]]\n",
      "Loop 8849 Loss_Train:  [[ 13.19525149]] Loss_Validation:  [[ 11.05047272]]\n",
      "Loop 8850 Loss_Train:  [[ 13.19525149]] Loss_Validation:  [[ 11.05047402]]\n",
      "Loop 8851 Loss_Train:  [[ 13.19525148]] Loss_Validation:  [[ 11.05047531]]\n",
      "Loop 8852 Loss_Train:  [[ 13.19525148]] Loss_Validation:  [[ 11.05047661]]\n",
      "Loop 8853 Loss_Train:  [[ 13.19525148]] Loss_Validation:  [[ 11.0504779]]\n",
      "Loop 8854 Loss_Train:  [[ 13.19525147]] Loss_Validation:  [[ 11.05047919]]\n",
      "Loop 8855 Loss_Train:  [[ 13.19525147]] Loss_Validation:  [[ 11.05048049]]\n",
      "Loop 8856 Loss_Train:  [[ 13.19525146]] Loss_Validation:  [[ 11.05048178]]\n",
      "Loop 8857 Loss_Train:  [[ 13.19525146]] Loss_Validation:  [[ 11.05048307]]\n",
      "Loop 8858 Loss_Train:  [[ 13.19525145]] Loss_Validation:  [[ 11.05048435]]\n",
      "Loop 8859 Loss_Train:  [[ 13.19525145]] Loss_Validation:  [[ 11.05048564]]\n",
      "Loop 8860 Loss_Train:  [[ 13.19525145]] Loss_Validation:  [[ 11.05048693]]\n",
      "Loop 8861 Loss_Train:  [[ 13.19525144]] Loss_Validation:  [[ 11.05048822]]\n",
      "Loop 8862 Loss_Train:  [[ 13.19525144]] Loss_Validation:  [[ 11.0504895]]\n",
      "Loop 8863 Loss_Train:  [[ 13.19525143]] Loss_Validation:  [[ 11.05049079]]\n",
      "Loop 8864 Loss_Train:  [[ 13.19525143]] Loss_Validation:  [[ 11.05049207]]\n",
      "Loop 8865 Loss_Train:  [[ 13.19525142]] Loss_Validation:  [[ 11.05049335]]\n",
      "Loop 8866 Loss_Train:  [[ 13.19525142]] Loss_Validation:  [[ 11.05049463]]\n",
      "Loop 8867 Loss_Train:  [[ 13.19525142]] Loss_Validation:  [[ 11.05049591]]\n",
      "Loop 8868 Loss_Train:  [[ 13.19525141]] Loss_Validation:  [[ 11.05049719]]\n",
      "Loop 8869 Loss_Train:  [[ 13.19525141]] Loss_Validation:  [[ 11.05049847]]\n",
      "Loop 8870 Loss_Train:  [[ 13.1952514]] Loss_Validation:  [[ 11.05049975]]\n",
      "Loop 8871 Loss_Train:  [[ 13.1952514]] Loss_Validation:  [[ 11.05050103]]\n",
      "Loop 8872 Loss_Train:  [[ 13.1952514]] Loss_Validation:  [[ 11.05050231]]\n",
      "Loop 8873 Loss_Train:  [[ 13.19525139]] Loss_Validation:  [[ 11.05050358]]\n",
      "Loop 8874 Loss_Train:  [[ 13.19525139]] Loss_Validation:  [[ 11.05050486]]\n",
      "Loop 8875 Loss_Train:  [[ 13.19525138]] Loss_Validation:  [[ 11.05050613]]\n",
      "Loop 8876 Loss_Train:  [[ 13.19525138]] Loss_Validation:  [[ 11.0505074]]\n",
      "Loop 8877 Loss_Train:  [[ 13.19525138]] Loss_Validation:  [[ 11.05050867]]\n",
      "Loop 8878 Loss_Train:  [[ 13.19525137]] Loss_Validation:  [[ 11.05050994]]\n",
      "Loop 8879 Loss_Train:  [[ 13.19525137]] Loss_Validation:  [[ 11.05051122]]\n",
      "Loop 8880 Loss_Train:  [[ 13.19525136]] Loss_Validation:  [[ 11.05051248]]\n",
      "Loop 8881 Loss_Train:  [[ 13.19525136]] Loss_Validation:  [[ 11.05051375]]\n",
      "Loop 8882 Loss_Train:  [[ 13.19525135]] Loss_Validation:  [[ 11.05051502]]\n",
      "Loop 8883 Loss_Train:  [[ 13.19525135]] Loss_Validation:  [[ 11.05051629]]\n",
      "Loop 8884 Loss_Train:  [[ 13.19525135]] Loss_Validation:  [[ 11.05051755]]\n",
      "Loop 8885 Loss_Train:  [[ 13.19525134]] Loss_Validation:  [[ 11.05051882]]\n",
      "Loop 8886 Loss_Train:  [[ 13.19525134]] Loss_Validation:  [[ 11.05052008]]\n",
      "Loop 8887 Loss_Train:  [[ 13.19525133]] Loss_Validation:  [[ 11.05052135]]\n",
      "Loop 8888 Loss_Train:  [[ 13.19525133]] Loss_Validation:  [[ 11.05052261]]\n",
      "Loop 8889 Loss_Train:  [[ 13.19525133]] Loss_Validation:  [[ 11.05052387]]\n",
      "Loop 8890 Loss_Train:  [[ 13.19525132]] Loss_Validation:  [[ 11.05052513]]\n",
      "Loop 8891 Loss_Train:  [[ 13.19525132]] Loss_Validation:  [[ 11.05052639]]\n",
      "Loop 8892 Loss_Train:  [[ 13.19525131]] Loss_Validation:  [[ 11.05052765]]\n",
      "Loop 8893 Loss_Train:  [[ 13.19525131]] Loss_Validation:  [[ 11.05052891]]\n",
      "Loop 8894 Loss_Train:  [[ 13.19525131]] Loss_Validation:  [[ 11.05053016]]\n",
      "Loop 8895 Loss_Train:  [[ 13.1952513]] Loss_Validation:  [[ 11.05053142]]\n",
      "Loop 8896 Loss_Train:  [[ 13.1952513]] Loss_Validation:  [[ 11.05053267]]\n",
      "Loop 8897 Loss_Train:  [[ 13.19525129]] Loss_Validation:  [[ 11.05053393]]\n",
      "Loop 8898 Loss_Train:  [[ 13.19525129]] Loss_Validation:  [[ 11.05053518]]\n",
      "Loop 8899 Loss_Train:  [[ 13.19525129]] Loss_Validation:  [[ 11.05053644]]\n",
      "Loop 8900 Loss_Train:  [[ 13.19525128]] Loss_Validation:  [[ 11.05053769]]\n",
      "Loop 8901 Loss_Train:  [[ 13.19525128]] Loss_Validation:  [[ 11.05053894]]\n",
      "Loop 8902 Loss_Train:  [[ 13.19525127]] Loss_Validation:  [[ 11.05054019]]\n",
      "Loop 8903 Loss_Train:  [[ 13.19525127]] Loss_Validation:  [[ 11.05054144]]\n",
      "Loop 8904 Loss_Train:  [[ 13.19525127]] Loss_Validation:  [[ 11.05054269]]\n",
      "Loop 8905 Loss_Train:  [[ 13.19525126]] Loss_Validation:  [[ 11.05054393]]\n",
      "Loop 8906 Loss_Train:  [[ 13.19525126]] Loss_Validation:  [[ 11.05054518]]\n",
      "Loop 8907 Loss_Train:  [[ 13.19525125]] Loss_Validation:  [[ 11.05054643]]\n",
      "Loop 8908 Loss_Train:  [[ 13.19525125]] Loss_Validation:  [[ 11.05054767]]\n",
      "Loop 8909 Loss_Train:  [[ 13.19525125]] Loss_Validation:  [[ 11.05054892]]\n",
      "Loop 8910 Loss_Train:  [[ 13.19525124]] Loss_Validation:  [[ 11.05055016]]\n",
      "Loop 8911 Loss_Train:  [[ 13.19525124]] Loss_Validation:  [[ 11.0505514]]\n",
      "Loop 8912 Loss_Train:  [[ 13.19525124]] Loss_Validation:  [[ 11.05055264]]\n",
      "Loop 8913 Loss_Train:  [[ 13.19525123]] Loss_Validation:  [[ 11.05055388]]\n",
      "Loop 8914 Loss_Train:  [[ 13.19525123]] Loss_Validation:  [[ 11.05055512]]\n",
      "Loop 8915 Loss_Train:  [[ 13.19525122]] Loss_Validation:  [[ 11.05055636]]\n",
      "Loop 8916 Loss_Train:  [[ 13.19525122]] Loss_Validation:  [[ 11.0505576]]\n",
      "Loop 8917 Loss_Train:  [[ 13.19525122]] Loss_Validation:  [[ 11.05055884]]\n",
      "Loop 8918 Loss_Train:  [[ 13.19525121]] Loss_Validation:  [[ 11.05056007]]\n",
      "Loop 8919 Loss_Train:  [[ 13.19525121]] Loss_Validation:  [[ 11.05056131]]\n",
      "Loop 8920 Loss_Train:  [[ 13.1952512]] Loss_Validation:  [[ 11.05056254]]\n",
      "Loop 8921 Loss_Train:  [[ 13.1952512]] Loss_Validation:  [[ 11.05056378]]\n",
      "Loop 8922 Loss_Train:  [[ 13.1952512]] Loss_Validation:  [[ 11.05056501]]\n",
      "Loop 8923 Loss_Train:  [[ 13.19525119]] Loss_Validation:  [[ 11.05056624]]\n",
      "Loop 8924 Loss_Train:  [[ 13.19525119]] Loss_Validation:  [[ 11.05056747]]\n",
      "Loop 8925 Loss_Train:  [[ 13.19525119]] Loss_Validation:  [[ 11.0505687]]\n",
      "Loop 8926 Loss_Train:  [[ 13.19525118]] Loss_Validation:  [[ 11.05056993]]\n",
      "Loop 8927 Loss_Train:  [[ 13.19525118]] Loss_Validation:  [[ 11.05057116]]\n",
      "Loop 8928 Loss_Train:  [[ 13.19525117]] Loss_Validation:  [[ 11.05057239]]\n",
      "Loop 8929 Loss_Train:  [[ 13.19525117]] Loss_Validation:  [[ 11.05057362]]\n",
      "Loop 8930 Loss_Train:  [[ 13.19525117]] Loss_Validation:  [[ 11.05057484]]\n",
      "Loop 8931 Loss_Train:  [[ 13.19525116]] Loss_Validation:  [[ 11.05057607]]\n",
      "Loop 8932 Loss_Train:  [[ 13.19525116]] Loss_Validation:  [[ 11.05057729]]\n",
      "Loop 8933 Loss_Train:  [[ 13.19525115]] Loss_Validation:  [[ 11.05057852]]\n",
      "Loop 8934 Loss_Train:  [[ 13.19525115]] Loss_Validation:  [[ 11.05057974]]\n",
      "Loop 8935 Loss_Train:  [[ 13.19525115]] Loss_Validation:  [[ 11.05058096]]\n",
      "Loop 8936 Loss_Train:  [[ 13.19525114]] Loss_Validation:  [[ 11.05058218]]\n",
      "Loop 8937 Loss_Train:  [[ 13.19525114]] Loss_Validation:  [[ 11.0505834]]\n",
      "Loop 8938 Loss_Train:  [[ 13.19525114]] Loss_Validation:  [[ 11.05058462]]\n",
      "Loop 8939 Loss_Train:  [[ 13.19525113]] Loss_Validation:  [[ 11.05058584]]\n",
      "Loop 8940 Loss_Train:  [[ 13.19525113]] Loss_Validation:  [[ 11.05058706]]\n",
      "Loop 8941 Loss_Train:  [[ 13.19525112]] Loss_Validation:  [[ 11.05058827]]\n",
      "Loop 8942 Loss_Train:  [[ 13.19525112]] Loss_Validation:  [[ 11.05058949]]\n",
      "Loop 8943 Loss_Train:  [[ 13.19525112]] Loss_Validation:  [[ 11.05059071]]\n",
      "Loop 8944 Loss_Train:  [[ 13.19525111]] Loss_Validation:  [[ 11.05059192]]\n",
      "Loop 8945 Loss_Train:  [[ 13.19525111]] Loss_Validation:  [[ 11.05059313]]\n",
      "Loop 8946 Loss_Train:  [[ 13.19525111]] Loss_Validation:  [[ 11.05059435]]\n",
      "Loop 8947 Loss_Train:  [[ 13.1952511]] Loss_Validation:  [[ 11.05059556]]\n",
      "Loop 8948 Loss_Train:  [[ 13.1952511]] Loss_Validation:  [[ 11.05059677]]\n",
      "Loop 8949 Loss_Train:  [[ 13.19525109]] Loss_Validation:  [[ 11.05059798]]\n",
      "Loop 8950 Loss_Train:  [[ 13.19525109]] Loss_Validation:  [[ 11.05059919]]\n",
      "Loop 8951 Loss_Train:  [[ 13.19525109]] Loss_Validation:  [[ 11.0506004]]\n",
      "Loop 8952 Loss_Train:  [[ 13.19525108]] Loss_Validation:  [[ 11.0506016]]\n",
      "Loop 8953 Loss_Train:  [[ 13.19525108]] Loss_Validation:  [[ 11.05060281]]\n",
      "Loop 8954 Loss_Train:  [[ 13.19525108]] Loss_Validation:  [[ 11.05060402]]\n",
      "Loop 8955 Loss_Train:  [[ 13.19525107]] Loss_Validation:  [[ 11.05060522]]\n",
      "Loop 8956 Loss_Train:  [[ 13.19525107]] Loss_Validation:  [[ 11.05060643]]\n",
      "Loop 8957 Loss_Train:  [[ 13.19525107]] Loss_Validation:  [[ 11.05060763]]\n",
      "Loop 8958 Loss_Train:  [[ 13.19525106]] Loss_Validation:  [[ 11.05060883]]\n",
      "Loop 8959 Loss_Train:  [[ 13.19525106]] Loss_Validation:  [[ 11.05061003]]\n",
      "Loop 8960 Loss_Train:  [[ 13.19525105]] Loss_Validation:  [[ 11.05061123]]\n",
      "Loop 8961 Loss_Train:  [[ 13.19525105]] Loss_Validation:  [[ 11.05061243]]\n",
      "Loop 8962 Loss_Train:  [[ 13.19525105]] Loss_Validation:  [[ 11.05061363]]\n",
      "Loop 8963 Loss_Train:  [[ 13.19525104]] Loss_Validation:  [[ 11.05061483]]\n",
      "Loop 8964 Loss_Train:  [[ 13.19525104]] Loss_Validation:  [[ 11.05061603]]\n",
      "Loop 8965 Loss_Train:  [[ 13.19525104]] Loss_Validation:  [[ 11.05061723]]\n",
      "Loop 8966 Loss_Train:  [[ 13.19525103]] Loss_Validation:  [[ 11.05061842]]\n",
      "Loop 8967 Loss_Train:  [[ 13.19525103]] Loss_Validation:  [[ 11.05061962]]\n",
      "Loop 8968 Loss_Train:  [[ 13.19525103]] Loss_Validation:  [[ 11.05062081]]\n",
      "Loop 8969 Loss_Train:  [[ 13.19525102]] Loss_Validation:  [[ 11.05062201]]\n",
      "Loop 8970 Loss_Train:  [[ 13.19525102]] Loss_Validation:  [[ 11.0506232]]\n",
      "Loop 8971 Loss_Train:  [[ 13.19525101]] Loss_Validation:  [[ 11.05062439]]\n",
      "Loop 8972 Loss_Train:  [[ 13.19525101]] Loss_Validation:  [[ 11.05062558]]\n",
      "Loop 8973 Loss_Train:  [[ 13.19525101]] Loss_Validation:  [[ 11.05062677]]\n",
      "Loop 8974 Loss_Train:  [[ 13.195251]] Loss_Validation:  [[ 11.05062796]]\n",
      "Loop 8975 Loss_Train:  [[ 13.195251]] Loss_Validation:  [[ 11.05062915]]\n",
      "Loop 8976 Loss_Train:  [[ 13.195251]] Loss_Validation:  [[ 11.05063034]]\n",
      "Loop 8977 Loss_Train:  [[ 13.19525099]] Loss_Validation:  [[ 11.05063152]]\n",
      "Loop 8978 Loss_Train:  [[ 13.19525099]] Loss_Validation:  [[ 11.05063271]]\n",
      "Loop 8979 Loss_Train:  [[ 13.19525099]] Loss_Validation:  [[ 11.05063389]]\n",
      "Loop 8980 Loss_Train:  [[ 13.19525098]] Loss_Validation:  [[ 11.05063508]]\n",
      "Loop 8981 Loss_Train:  [[ 13.19525098]] Loss_Validation:  [[ 11.05063626]]\n",
      "Loop 8982 Loss_Train:  [[ 13.19525098]] Loss_Validation:  [[ 11.05063745]]\n",
      "Loop 8983 Loss_Train:  [[ 13.19525097]] Loss_Validation:  [[ 11.05063863]]\n",
      "Loop 8984 Loss_Train:  [[ 13.19525097]] Loss_Validation:  [[ 11.05063981]]\n",
      "Loop 8985 Loss_Train:  [[ 13.19525097]] Loss_Validation:  [[ 11.05064099]]\n",
      "Loop 8986 Loss_Train:  [[ 13.19525096]] Loss_Validation:  [[ 11.05064217]]\n",
      "Loop 8987 Loss_Train:  [[ 13.19525096]] Loss_Validation:  [[ 11.05064335]]\n",
      "Loop 8988 Loss_Train:  [[ 13.19525095]] Loss_Validation:  [[ 11.05064452]]\n",
      "Loop 8989 Loss_Train:  [[ 13.19525095]] Loss_Validation:  [[ 11.0506457]]\n",
      "Loop 8990 Loss_Train:  [[ 13.19525095]] Loss_Validation:  [[ 11.05064688]]\n",
      "Loop 8991 Loss_Train:  [[ 13.19525094]] Loss_Validation:  [[ 11.05064805]]\n",
      "Loop 8992 Loss_Train:  [[ 13.19525094]] Loss_Validation:  [[ 11.05064923]]\n",
      "Loop 8993 Loss_Train:  [[ 13.19525094]] Loss_Validation:  [[ 11.0506504]]\n",
      "Loop 8994 Loss_Train:  [[ 13.19525093]] Loss_Validation:  [[ 11.05065157]]\n",
      "Loop 8995 Loss_Train:  [[ 13.19525093]] Loss_Validation:  [[ 11.05065275]]\n",
      "Loop 8996 Loss_Train:  [[ 13.19525093]] Loss_Validation:  [[ 11.05065392]]\n",
      "Loop 8997 Loss_Train:  [[ 13.19525092]] Loss_Validation:  [[ 11.05065509]]\n",
      "Loop 8998 Loss_Train:  [[ 13.19525092]] Loss_Validation:  [[ 11.05065626]]\n",
      "Loop 8999 Loss_Train:  [[ 13.19525092]] Loss_Validation:  [[ 11.05065743]]\n",
      "Loop 9000 Loss_Train:  [[ 13.19525091]] Loss_Validation:  [[ 11.05065859]]\n",
      "Loop 9001 Loss_Train:  [[ 13.19525091]] Loss_Validation:  [[ 11.05065976]]\n",
      "Loop 9002 Loss_Train:  [[ 13.19525091]] Loss_Validation:  [[ 11.05066093]]\n",
      "Loop 9003 Loss_Train:  [[ 13.1952509]] Loss_Validation:  [[ 11.05066209]]\n",
      "Loop 9004 Loss_Train:  [[ 13.1952509]] Loss_Validation:  [[ 11.05066326]]\n",
      "Loop 9005 Loss_Train:  [[ 13.1952509]] Loss_Validation:  [[ 11.05066442]]\n",
      "Loop 9006 Loss_Train:  [[ 13.19525089]] Loss_Validation:  [[ 11.05066559]]\n",
      "Loop 9007 Loss_Train:  [[ 13.19525089]] Loss_Validation:  [[ 11.05066675]]\n",
      "Loop 9008 Loss_Train:  [[ 13.19525089]] Loss_Validation:  [[ 11.05066791]]\n",
      "Loop 9009 Loss_Train:  [[ 13.19525088]] Loss_Validation:  [[ 11.05066907]]\n",
      "Loop 9010 Loss_Train:  [[ 13.19525088]] Loss_Validation:  [[ 11.05067023]]\n",
      "Loop 9011 Loss_Train:  [[ 13.19525088]] Loss_Validation:  [[ 11.05067139]]\n",
      "Loop 9012 Loss_Train:  [[ 13.19525087]] Loss_Validation:  [[ 11.05067255]]\n",
      "Loop 9013 Loss_Train:  [[ 13.19525087]] Loss_Validation:  [[ 11.05067371]]\n",
      "Loop 9014 Loss_Train:  [[ 13.19525087]] Loss_Validation:  [[ 11.05067486]]\n",
      "Loop 9015 Loss_Train:  [[ 13.19525086]] Loss_Validation:  [[ 11.05067602]]\n",
      "Loop 9016 Loss_Train:  [[ 13.19525086]] Loss_Validation:  [[ 11.05067717]]\n",
      "Loop 9017 Loss_Train:  [[ 13.19525086]] Loss_Validation:  [[ 11.05067833]]\n",
      "Loop 9018 Loss_Train:  [[ 13.19525085]] Loss_Validation:  [[ 11.05067948]]\n",
      "Loop 9019 Loss_Train:  [[ 13.19525085]] Loss_Validation:  [[ 11.05068063]]\n",
      "Loop 9020 Loss_Train:  [[ 13.19525085]] Loss_Validation:  [[ 11.05068179]]\n",
      "Loop 9021 Loss_Train:  [[ 13.19525084]] Loss_Validation:  [[ 11.05068294]]\n",
      "Loop 9022 Loss_Train:  [[ 13.19525084]] Loss_Validation:  [[ 11.05068409]]\n",
      "Loop 9023 Loss_Train:  [[ 13.19525084]] Loss_Validation:  [[ 11.05068524]]\n",
      "Loop 9024 Loss_Train:  [[ 13.19525083]] Loss_Validation:  [[ 11.05068639]]\n",
      "Loop 9025 Loss_Train:  [[ 13.19525083]] Loss_Validation:  [[ 11.05068753]]\n",
      "Loop 9026 Loss_Train:  [[ 13.19525083]] Loss_Validation:  [[ 11.05068868]]\n",
      "Loop 9027 Loss_Train:  [[ 13.19525082]] Loss_Validation:  [[ 11.05068983]]\n",
      "Loop 9028 Loss_Train:  [[ 13.19525082]] Loss_Validation:  [[ 11.05069097]]\n",
      "Loop 9029 Loss_Train:  [[ 13.19525082]] Loss_Validation:  [[ 11.05069212]]\n",
      "Loop 9030 Loss_Train:  [[ 13.19525081]] Loss_Validation:  [[ 11.05069326]]\n",
      "Loop 9031 Loss_Train:  [[ 13.19525081]] Loss_Validation:  [[ 11.05069441]]\n",
      "Loop 9032 Loss_Train:  [[ 13.19525081]] Loss_Validation:  [[ 11.05069555]]\n",
      "Loop 9033 Loss_Train:  [[ 13.1952508]] Loss_Validation:  [[ 11.05069669]]\n",
      "Loop 9034 Loss_Train:  [[ 13.1952508]] Loss_Validation:  [[ 11.05069783]]\n",
      "Loop 9035 Loss_Train:  [[ 13.1952508]] Loss_Validation:  [[ 11.05069897]]\n",
      "Loop 9036 Loss_Train:  [[ 13.19525079]] Loss_Validation:  [[ 11.05070011]]\n",
      "Loop 9037 Loss_Train:  [[ 13.19525079]] Loss_Validation:  [[ 11.05070125]]\n",
      "Loop 9038 Loss_Train:  [[ 13.19525079]] Loss_Validation:  [[ 11.05070239]]\n",
      "Loop 9039 Loss_Train:  [[ 13.19525078]] Loss_Validation:  [[ 11.05070352]]\n",
      "Loop 9040 Loss_Train:  [[ 13.19525078]] Loss_Validation:  [[ 11.05070466]]\n",
      "Loop 9041 Loss_Train:  [[ 13.19525078]] Loss_Validation:  [[ 11.0507058]]\n",
      "Loop 9042 Loss_Train:  [[ 13.19525077]] Loss_Validation:  [[ 11.05070693]]\n",
      "Loop 9043 Loss_Train:  [[ 13.19525077]] Loss_Validation:  [[ 11.05070806]]\n",
      "Loop 9044 Loss_Train:  [[ 13.19525077]] Loss_Validation:  [[ 11.0507092]]\n",
      "Loop 9045 Loss_Train:  [[ 13.19525076]] Loss_Validation:  [[ 11.05071033]]\n",
      "Loop 9046 Loss_Train:  [[ 13.19525076]] Loss_Validation:  [[ 11.05071146]]\n",
      "Loop 9047 Loss_Train:  [[ 13.19525076]] Loss_Validation:  [[ 11.05071259]]\n",
      "Loop 9048 Loss_Train:  [[ 13.19525075]] Loss_Validation:  [[ 11.05071372]]\n",
      "Loop 9049 Loss_Train:  [[ 13.19525075]] Loss_Validation:  [[ 11.05071485]]\n",
      "Loop 9050 Loss_Train:  [[ 13.19525075]] Loss_Validation:  [[ 11.05071598]]\n",
      "Loop 9051 Loss_Train:  [[ 13.19525074]] Loss_Validation:  [[ 11.05071711]]\n",
      "Loop 9052 Loss_Train:  [[ 13.19525074]] Loss_Validation:  [[ 11.05071823]]\n",
      "Loop 9053 Loss_Train:  [[ 13.19525074]] Loss_Validation:  [[ 11.05071936]]\n",
      "Loop 9054 Loss_Train:  [[ 13.19525073]] Loss_Validation:  [[ 11.05072048]]\n",
      "Loop 9055 Loss_Train:  [[ 13.19525073]] Loss_Validation:  [[ 11.05072161]]\n",
      "Loop 9056 Loss_Train:  [[ 13.19525073]] Loss_Validation:  [[ 11.05072273]]\n",
      "Loop 9057 Loss_Train:  [[ 13.19525073]] Loss_Validation:  [[ 11.05072385]]\n",
      "Loop 9058 Loss_Train:  [[ 13.19525072]] Loss_Validation:  [[ 11.05072498]]\n",
      "Loop 9059 Loss_Train:  [[ 13.19525072]] Loss_Validation:  [[ 11.0507261]]\n",
      "Loop 9060 Loss_Train:  [[ 13.19525072]] Loss_Validation:  [[ 11.05072722]]\n",
      "Loop 9061 Loss_Train:  [[ 13.19525071]] Loss_Validation:  [[ 11.05072834]]\n",
      "Loop 9062 Loss_Train:  [[ 13.19525071]] Loss_Validation:  [[ 11.05072946]]\n",
      "Loop 9063 Loss_Train:  [[ 13.19525071]] Loss_Validation:  [[ 11.05073057]]\n",
      "Loop 9064 Loss_Train:  [[ 13.1952507]] Loss_Validation:  [[ 11.05073169]]\n",
      "Loop 9065 Loss_Train:  [[ 13.1952507]] Loss_Validation:  [[ 11.05073281]]\n",
      "Loop 9066 Loss_Train:  [[ 13.1952507]] Loss_Validation:  [[ 11.05073392]]\n",
      "Loop 9067 Loss_Train:  [[ 13.19525069]] Loss_Validation:  [[ 11.05073504]]\n",
      "Loop 9068 Loss_Train:  [[ 13.19525069]] Loss_Validation:  [[ 11.05073615]]\n",
      "Loop 9069 Loss_Train:  [[ 13.19525069]] Loss_Validation:  [[ 11.05073727]]\n",
      "Loop 9070 Loss_Train:  [[ 13.19525068]] Loss_Validation:  [[ 11.05073838]]\n",
      "Loop 9071 Loss_Train:  [[ 13.19525068]] Loss_Validation:  [[ 11.05073949]]\n",
      "Loop 9072 Loss_Train:  [[ 13.19525068]] Loss_Validation:  [[ 11.0507406]]\n",
      "Loop 9073 Loss_Train:  [[ 13.19525068]] Loss_Validation:  [[ 11.05074171]]\n",
      "Loop 9074 Loss_Train:  [[ 13.19525067]] Loss_Validation:  [[ 11.05074282]]\n",
      "Loop 9075 Loss_Train:  [[ 13.19525067]] Loss_Validation:  [[ 11.05074393]]\n",
      "Loop 9076 Loss_Train:  [[ 13.19525067]] Loss_Validation:  [[ 11.05074504]]\n",
      "Loop 9077 Loss_Train:  [[ 13.19525066]] Loss_Validation:  [[ 11.05074615]]\n",
      "Loop 9078 Loss_Train:  [[ 13.19525066]] Loss_Validation:  [[ 11.05074725]]\n",
      "Loop 9079 Loss_Train:  [[ 13.19525066]] Loss_Validation:  [[ 11.05074836]]\n",
      "Loop 9080 Loss_Train:  [[ 13.19525065]] Loss_Validation:  [[ 11.05074947]]\n",
      "Loop 9081 Loss_Train:  [[ 13.19525065]] Loss_Validation:  [[ 11.05075057]]\n",
      "Loop 9082 Loss_Train:  [[ 13.19525065]] Loss_Validation:  [[ 11.05075167]]\n",
      "Loop 9083 Loss_Train:  [[ 13.19525064]] Loss_Validation:  [[ 11.05075278]]\n",
      "Loop 9084 Loss_Train:  [[ 13.19525064]] Loss_Validation:  [[ 11.05075388]]\n",
      "Loop 9085 Loss_Train:  [[ 13.19525064]] Loss_Validation:  [[ 11.05075498]]\n",
      "Loop 9086 Loss_Train:  [[ 13.19525064]] Loss_Validation:  [[ 11.05075608]]\n",
      "Loop 9087 Loss_Train:  [[ 13.19525063]] Loss_Validation:  [[ 11.05075718]]\n",
      "Loop 9088 Loss_Train:  [[ 13.19525063]] Loss_Validation:  [[ 11.05075828]]\n",
      "Loop 9089 Loss_Train:  [[ 13.19525063]] Loss_Validation:  [[ 11.05075938]]\n",
      "Loop 9090 Loss_Train:  [[ 13.19525062]] Loss_Validation:  [[ 11.05076047]]\n",
      "Loop 9091 Loss_Train:  [[ 13.19525062]] Loss_Validation:  [[ 11.05076157]]\n",
      "Loop 9092 Loss_Train:  [[ 13.19525062]] Loss_Validation:  [[ 11.05076267]]\n",
      "Loop 9093 Loss_Train:  [[ 13.19525061]] Loss_Validation:  [[ 11.05076376]]\n",
      "Loop 9094 Loss_Train:  [[ 13.19525061]] Loss_Validation:  [[ 11.05076486]]\n",
      "Loop 9095 Loss_Train:  [[ 13.19525061]] Loss_Validation:  [[ 11.05076595]]\n",
      "Loop 9096 Loss_Train:  [[ 13.19525061]] Loss_Validation:  [[ 11.05076704]]\n",
      "Loop 9097 Loss_Train:  [[ 13.1952506]] Loss_Validation:  [[ 11.05076813]]\n",
      "Loop 9098 Loss_Train:  [[ 13.1952506]] Loss_Validation:  [[ 11.05076923]]\n",
      "Loop 9099 Loss_Train:  [[ 13.1952506]] Loss_Validation:  [[ 11.05077032]]\n",
      "Loop 9100 Loss_Train:  [[ 13.19525059]] Loss_Validation:  [[ 11.05077141]]\n",
      "Loop 9101 Loss_Train:  [[ 13.19525059]] Loss_Validation:  [[ 11.0507725]]\n",
      "Loop 9102 Loss_Train:  [[ 13.19525059]] Loss_Validation:  [[ 11.05077358]]\n",
      "Loop 9103 Loss_Train:  [[ 13.19525058]] Loss_Validation:  [[ 11.05077467]]\n",
      "Loop 9104 Loss_Train:  [[ 13.19525058]] Loss_Validation:  [[ 11.05077576]]\n",
      "Loop 9105 Loss_Train:  [[ 13.19525058]] Loss_Validation:  [[ 11.05077684]]\n",
      "Loop 9106 Loss_Train:  [[ 13.19525058]] Loss_Validation:  [[ 11.05077793]]\n",
      "Loop 9107 Loss_Train:  [[ 13.19525057]] Loss_Validation:  [[ 11.05077901]]\n",
      "Loop 9108 Loss_Train:  [[ 13.19525057]] Loss_Validation:  [[ 11.0507801]]\n",
      "Loop 9109 Loss_Train:  [[ 13.19525057]] Loss_Validation:  [[ 11.05078118]]\n",
      "Loop 9110 Loss_Train:  [[ 13.19525056]] Loss_Validation:  [[ 11.05078226]]\n",
      "Loop 9111 Loss_Train:  [[ 13.19525056]] Loss_Validation:  [[ 11.05078334]]\n",
      "Loop 9112 Loss_Train:  [[ 13.19525056]] Loss_Validation:  [[ 11.05078443]]\n",
      "Loop 9113 Loss_Train:  [[ 13.19525056]] Loss_Validation:  [[ 11.05078551]]\n",
      "Loop 9114 Loss_Train:  [[ 13.19525055]] Loss_Validation:  [[ 11.05078658]]\n",
      "Loop 9115 Loss_Train:  [[ 13.19525055]] Loss_Validation:  [[ 11.05078766]]\n",
      "Loop 9116 Loss_Train:  [[ 13.19525055]] Loss_Validation:  [[ 11.05078874]]\n",
      "Loop 9117 Loss_Train:  [[ 13.19525054]] Loss_Validation:  [[ 11.05078982]]\n",
      "Loop 9118 Loss_Train:  [[ 13.19525054]] Loss_Validation:  [[ 11.05079089]]\n",
      "Loop 9119 Loss_Train:  [[ 13.19525054]] Loss_Validation:  [[ 11.05079197]]\n",
      "Loop 9120 Loss_Train:  [[ 13.19525053]] Loss_Validation:  [[ 11.05079304]]\n",
      "Loop 9121 Loss_Train:  [[ 13.19525053]] Loss_Validation:  [[ 11.05079412]]\n",
      "Loop 9122 Loss_Train:  [[ 13.19525053]] Loss_Validation:  [[ 11.05079519]]\n",
      "Loop 9123 Loss_Train:  [[ 13.19525053]] Loss_Validation:  [[ 11.05079627]]\n",
      "Loop 9124 Loss_Train:  [[ 13.19525052]] Loss_Validation:  [[ 11.05079734]]\n",
      "Loop 9125 Loss_Train:  [[ 13.19525052]] Loss_Validation:  [[ 11.05079841]]\n",
      "Loop 9126 Loss_Train:  [[ 13.19525052]] Loss_Validation:  [[ 11.05079948]]\n",
      "Loop 9127 Loss_Train:  [[ 13.19525051]] Loss_Validation:  [[ 11.05080055]]\n",
      "Loop 9128 Loss_Train:  [[ 13.19525051]] Loss_Validation:  [[ 11.05080162]]\n",
      "Loop 9129 Loss_Train:  [[ 13.19525051]] Loss_Validation:  [[ 11.05080268]]\n",
      "Loop 9130 Loss_Train:  [[ 13.19525051]] Loss_Validation:  [[ 11.05080375]]\n",
      "Loop 9131 Loss_Train:  [[ 13.1952505]] Loss_Validation:  [[ 11.05080482]]\n",
      "Loop 9132 Loss_Train:  [[ 13.1952505]] Loss_Validation:  [[ 11.05080588]]\n",
      "Loop 9133 Loss_Train:  [[ 13.1952505]] Loss_Validation:  [[ 11.05080695]]\n",
      "Loop 9134 Loss_Train:  [[ 13.19525049]] Loss_Validation:  [[ 11.05080801]]\n",
      "Loop 9135 Loss_Train:  [[ 13.19525049]] Loss_Validation:  [[ 11.05080908]]\n",
      "Loop 9136 Loss_Train:  [[ 13.19525049]] Loss_Validation:  [[ 11.05081014]]\n",
      "Loop 9137 Loss_Train:  [[ 13.19525049]] Loss_Validation:  [[ 11.0508112]]\n",
      "Loop 9138 Loss_Train:  [[ 13.19525048]] Loss_Validation:  [[ 11.05081227]]\n",
      "Loop 9139 Loss_Train:  [[ 13.19525048]] Loss_Validation:  [[ 11.05081333]]\n",
      "Loop 9140 Loss_Train:  [[ 13.19525048]] Loss_Validation:  [[ 11.05081439]]\n",
      "Loop 9141 Loss_Train:  [[ 13.19525048]] Loss_Validation:  [[ 11.05081545]]\n",
      "Loop 9142 Loss_Train:  [[ 13.19525047]] Loss_Validation:  [[ 11.0508165]]\n",
      "Loop 9143 Loss_Train:  [[ 13.19525047]] Loss_Validation:  [[ 11.05081756]]\n",
      "Loop 9144 Loss_Train:  [[ 13.19525047]] Loss_Validation:  [[ 11.05081862]]\n",
      "Loop 9145 Loss_Train:  [[ 13.19525046]] Loss_Validation:  [[ 11.05081967]]\n",
      "Loop 9146 Loss_Train:  [[ 13.19525046]] Loss_Validation:  [[ 11.05082073]]\n",
      "Loop 9147 Loss_Train:  [[ 13.19525046]] Loss_Validation:  [[ 11.05082179]]\n",
      "Loop 9148 Loss_Train:  [[ 13.19525046]] Loss_Validation:  [[ 11.05082284]]\n",
      "Loop 9149 Loss_Train:  [[ 13.19525045]] Loss_Validation:  [[ 11.05082389]]\n",
      "Loop 9150 Loss_Train:  [[ 13.19525045]] Loss_Validation:  [[ 11.05082495]]\n",
      "Loop 9151 Loss_Train:  [[ 13.19525045]] Loss_Validation:  [[ 11.050826]]\n",
      "Loop 9152 Loss_Train:  [[ 13.19525044]] Loss_Validation:  [[ 11.05082705]]\n",
      "Loop 9153 Loss_Train:  [[ 13.19525044]] Loss_Validation:  [[ 11.0508281]]\n",
      "Loop 9154 Loss_Train:  [[ 13.19525044]] Loss_Validation:  [[ 11.05082915]]\n",
      "Loop 9155 Loss_Train:  [[ 13.19525044]] Loss_Validation:  [[ 11.0508302]]\n",
      "Loop 9156 Loss_Train:  [[ 13.19525043]] Loss_Validation:  [[ 11.05083125]]\n",
      "Loop 9157 Loss_Train:  [[ 13.19525043]] Loss_Validation:  [[ 11.05083229]]\n",
      "Loop 9158 Loss_Train:  [[ 13.19525043]] Loss_Validation:  [[ 11.05083334]]\n",
      "Loop 9159 Loss_Train:  [[ 13.19525043]] Loss_Validation:  [[ 11.05083439]]\n",
      "Loop 9160 Loss_Train:  [[ 13.19525042]] Loss_Validation:  [[ 11.05083543]]\n",
      "Loop 9161 Loss_Train:  [[ 13.19525042]] Loss_Validation:  [[ 11.05083648]]\n",
      "Loop 9162 Loss_Train:  [[ 13.19525042]] Loss_Validation:  [[ 11.05083752]]\n",
      "Loop 9163 Loss_Train:  [[ 13.19525041]] Loss_Validation:  [[ 11.05083856]]\n",
      "Loop 9164 Loss_Train:  [[ 13.19525041]] Loss_Validation:  [[ 11.05083961]]\n",
      "Loop 9165 Loss_Train:  [[ 13.19525041]] Loss_Validation:  [[ 11.05084065]]\n",
      "Loop 9166 Loss_Train:  [[ 13.19525041]] Loss_Validation:  [[ 11.05084169]]\n",
      "Loop 9167 Loss_Train:  [[ 13.1952504]] Loss_Validation:  [[ 11.05084273]]\n",
      "Loop 9168 Loss_Train:  [[ 13.1952504]] Loss_Validation:  [[ 11.05084377]]\n",
      "Loop 9169 Loss_Train:  [[ 13.1952504]] Loss_Validation:  [[ 11.05084481]]\n",
      "Loop 9170 Loss_Train:  [[ 13.1952504]] Loss_Validation:  [[ 11.05084585]]\n",
      "Loop 9171 Loss_Train:  [[ 13.19525039]] Loss_Validation:  [[ 11.05084688]]\n",
      "Loop 9172 Loss_Train:  [[ 13.19525039]] Loss_Validation:  [[ 11.05084792]]\n",
      "Loop 9173 Loss_Train:  [[ 13.19525039]] Loss_Validation:  [[ 11.05084896]]\n",
      "Loop 9174 Loss_Train:  [[ 13.19525038]] Loss_Validation:  [[ 11.05084999]]\n",
      "Loop 9175 Loss_Train:  [[ 13.19525038]] Loss_Validation:  [[ 11.05085103]]\n",
      "Loop 9176 Loss_Train:  [[ 13.19525038]] Loss_Validation:  [[ 11.05085206]]\n",
      "Loop 9177 Loss_Train:  [[ 13.19525038]] Loss_Validation:  [[ 11.05085309]]\n",
      "Loop 9178 Loss_Train:  [[ 13.19525037]] Loss_Validation:  [[ 11.05085413]]\n",
      "Loop 9179 Loss_Train:  [[ 13.19525037]] Loss_Validation:  [[ 11.05085516]]\n",
      "Loop 9180 Loss_Train:  [[ 13.19525037]] Loss_Validation:  [[ 11.05085619]]\n",
      "Loop 9181 Loss_Train:  [[ 13.19525037]] Loss_Validation:  [[ 11.05085722]]\n",
      "Loop 9182 Loss_Train:  [[ 13.19525036]] Loss_Validation:  [[ 11.05085825]]\n",
      "Loop 9183 Loss_Train:  [[ 13.19525036]] Loss_Validation:  [[ 11.05085928]]\n",
      "Loop 9184 Loss_Train:  [[ 13.19525036]] Loss_Validation:  [[ 11.05086031]]\n",
      "Loop 9185 Loss_Train:  [[ 13.19525036]] Loss_Validation:  [[ 11.05086133]]\n",
      "Loop 9186 Loss_Train:  [[ 13.19525035]] Loss_Validation:  [[ 11.05086236]]\n",
      "Loop 9187 Loss_Train:  [[ 13.19525035]] Loss_Validation:  [[ 11.05086339]]\n",
      "Loop 9188 Loss_Train:  [[ 13.19525035]] Loss_Validation:  [[ 11.05086441]]\n",
      "Loop 9189 Loss_Train:  [[ 13.19525034]] Loss_Validation:  [[ 11.05086544]]\n",
      "Loop 9190 Loss_Train:  [[ 13.19525034]] Loss_Validation:  [[ 11.05086646]]\n",
      "Loop 9191 Loss_Train:  [[ 13.19525034]] Loss_Validation:  [[ 11.05086748]]\n",
      "Loop 9192 Loss_Train:  [[ 13.19525034]] Loss_Validation:  [[ 11.05086851]]\n",
      "Loop 9193 Loss_Train:  [[ 13.19525033]] Loss_Validation:  [[ 11.05086953]]\n",
      "Loop 9194 Loss_Train:  [[ 13.19525033]] Loss_Validation:  [[ 11.05087055]]\n",
      "Loop 9195 Loss_Train:  [[ 13.19525033]] Loss_Validation:  [[ 11.05087157]]\n",
      "Loop 9196 Loss_Train:  [[ 13.19525033]] Loss_Validation:  [[ 11.05087259]]\n",
      "Loop 9197 Loss_Train:  [[ 13.19525032]] Loss_Validation:  [[ 11.05087361]]\n",
      "Loop 9198 Loss_Train:  [[ 13.19525032]] Loss_Validation:  [[ 11.05087463]]\n",
      "Loop 9199 Loss_Train:  [[ 13.19525032]] Loss_Validation:  [[ 11.05087564]]\n",
      "Loop 9200 Loss_Train:  [[ 13.19525032]] Loss_Validation:  [[ 11.05087666]]\n",
      "Loop 9201 Loss_Train:  [[ 13.19525031]] Loss_Validation:  [[ 11.05087768]]\n",
      "Loop 9202 Loss_Train:  [[ 13.19525031]] Loss_Validation:  [[ 11.05087869]]\n",
      "Loop 9203 Loss_Train:  [[ 13.19525031]] Loss_Validation:  [[ 11.05087971]]\n",
      "Loop 9204 Loss_Train:  [[ 13.19525031]] Loss_Validation:  [[ 11.05088072]]\n",
      "Loop 9205 Loss_Train:  [[ 13.1952503]] Loss_Validation:  [[ 11.05088173]]\n",
      "Loop 9206 Loss_Train:  [[ 13.1952503]] Loss_Validation:  [[ 11.05088275]]\n",
      "Loop 9207 Loss_Train:  [[ 13.1952503]] Loss_Validation:  [[ 11.05088376]]\n",
      "Loop 9208 Loss_Train:  [[ 13.1952503]] Loss_Validation:  [[ 11.05088477]]\n",
      "Loop 9209 Loss_Train:  [[ 13.19525029]] Loss_Validation:  [[ 11.05088578]]\n",
      "Loop 9210 Loss_Train:  [[ 13.19525029]] Loss_Validation:  [[ 11.05088679]]\n",
      "Loop 9211 Loss_Train:  [[ 13.19525029]] Loss_Validation:  [[ 11.0508878]]\n",
      "Loop 9212 Loss_Train:  [[ 13.19525029]] Loss_Validation:  [[ 11.05088881]]\n",
      "Loop 9213 Loss_Train:  [[ 13.19525028]] Loss_Validation:  [[ 11.05088981]]\n",
      "Loop 9214 Loss_Train:  [[ 13.19525028]] Loss_Validation:  [[ 11.05089082]]\n",
      "Loop 9215 Loss_Train:  [[ 13.19525028]] Loss_Validation:  [[ 11.05089183]]\n",
      "Loop 9216 Loss_Train:  [[ 13.19525028]] Loss_Validation:  [[ 11.05089283]]\n",
      "Loop 9217 Loss_Train:  [[ 13.19525027]] Loss_Validation:  [[ 11.05089384]]\n",
      "Loop 9218 Loss_Train:  [[ 13.19525027]] Loss_Validation:  [[ 11.05089484]]\n",
      "Loop 9219 Loss_Train:  [[ 13.19525027]] Loss_Validation:  [[ 11.05089585]]\n",
      "Loop 9220 Loss_Train:  [[ 13.19525027]] Loss_Validation:  [[ 11.05089685]]\n",
      "Loop 9221 Loss_Train:  [[ 13.19525026]] Loss_Validation:  [[ 11.05089785]]\n",
      "Loop 9222 Loss_Train:  [[ 13.19525026]] Loss_Validation:  [[ 11.05089885]]\n",
      "Loop 9223 Loss_Train:  [[ 13.19525026]] Loss_Validation:  [[ 11.05089985]]\n",
      "Loop 9224 Loss_Train:  [[ 13.19525026]] Loss_Validation:  [[ 11.05090085]]\n",
      "Loop 9225 Loss_Train:  [[ 13.19525025]] Loss_Validation:  [[ 11.05090185]]\n",
      "Loop 9226 Loss_Train:  [[ 13.19525025]] Loss_Validation:  [[ 11.05090285]]\n",
      "Loop 9227 Loss_Train:  [[ 13.19525025]] Loss_Validation:  [[ 11.05090385]]\n",
      "Loop 9228 Loss_Train:  [[ 13.19525025]] Loss_Validation:  [[ 11.05090485]]\n",
      "Loop 9229 Loss_Train:  [[ 13.19525024]] Loss_Validation:  [[ 11.05090584]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 9230 Loss_Train:  [[ 13.19525024]] Loss_Validation:  [[ 11.05090684]]\n",
      "Loop 9231 Loss_Train:  [[ 13.19525024]] Loss_Validation:  [[ 11.05090783]]\n",
      "Loop 9232 Loss_Train:  [[ 13.19525024]] Loss_Validation:  [[ 11.05090883]]\n",
      "Loop 9233 Loss_Train:  [[ 13.19525023]] Loss_Validation:  [[ 11.05090982]]\n",
      "Loop 9234 Loss_Train:  [[ 13.19525023]] Loss_Validation:  [[ 11.05091082]]\n",
      "Loop 9235 Loss_Train:  [[ 13.19525023]] Loss_Validation:  [[ 11.05091181]]\n",
      "Loop 9236 Loss_Train:  [[ 13.19525023]] Loss_Validation:  [[ 11.0509128]]\n",
      "Loop 9237 Loss_Train:  [[ 13.19525022]] Loss_Validation:  [[ 11.05091379]]\n",
      "Loop 9238 Loss_Train:  [[ 13.19525022]] Loss_Validation:  [[ 11.05091478]]\n",
      "Loop 9239 Loss_Train:  [[ 13.19525022]] Loss_Validation:  [[ 11.05091577]]\n",
      "Loop 9240 Loss_Train:  [[ 13.19525022]] Loss_Validation:  [[ 11.05091676]]\n",
      "Loop 9241 Loss_Train:  [[ 13.19525021]] Loss_Validation:  [[ 11.05091775]]\n",
      "Loop 9242 Loss_Train:  [[ 13.19525021]] Loss_Validation:  [[ 11.05091874]]\n",
      "Loop 9243 Loss_Train:  [[ 13.19525021]] Loss_Validation:  [[ 11.05091972]]\n",
      "Loop 9244 Loss_Train:  [[ 13.19525021]] Loss_Validation:  [[ 11.05092071]]\n",
      "Loop 9245 Loss_Train:  [[ 13.1952502]] Loss_Validation:  [[ 11.05092169]]\n",
      "Loop 9246 Loss_Train:  [[ 13.1952502]] Loss_Validation:  [[ 11.05092268]]\n",
      "Loop 9247 Loss_Train:  [[ 13.1952502]] Loss_Validation:  [[ 11.05092366]]\n",
      "Loop 9248 Loss_Train:  [[ 13.1952502]] Loss_Validation:  [[ 11.05092465]]\n",
      "Loop 9249 Loss_Train:  [[ 13.19525019]] Loss_Validation:  [[ 11.05092563]]\n",
      "Loop 9250 Loss_Train:  [[ 13.19525019]] Loss_Validation:  [[ 11.05092661]]\n",
      "Loop 9251 Loss_Train:  [[ 13.19525019]] Loss_Validation:  [[ 11.05092759]]\n",
      "Loop 9252 Loss_Train:  [[ 13.19525019]] Loss_Validation:  [[ 11.05092857]]\n",
      "Loop 9253 Loss_Train:  [[ 13.19525018]] Loss_Validation:  [[ 11.05092955]]\n",
      "Loop 9254 Loss_Train:  [[ 13.19525018]] Loss_Validation:  [[ 11.05093053]]\n",
      "Loop 9255 Loss_Train:  [[ 13.19525018]] Loss_Validation:  [[ 11.05093151]]\n",
      "Loop 9256 Loss_Train:  [[ 13.19525018]] Loss_Validation:  [[ 11.05093249]]\n",
      "Loop 9257 Loss_Train:  [[ 13.19525018]] Loss_Validation:  [[ 11.05093347]]\n",
      "Loop 9258 Loss_Train:  [[ 13.19525017]] Loss_Validation:  [[ 11.05093444]]\n",
      "Loop 9259 Loss_Train:  [[ 13.19525017]] Loss_Validation:  [[ 11.05093542]]\n",
      "Loop 9260 Loss_Train:  [[ 13.19525017]] Loss_Validation:  [[ 11.0509364]]\n",
      "Loop 9261 Loss_Train:  [[ 13.19525017]] Loss_Validation:  [[ 11.05093737]]\n",
      "Loop 9262 Loss_Train:  [[ 13.19525016]] Loss_Validation:  [[ 11.05093834]]\n",
      "Loop 9263 Loss_Train:  [[ 13.19525016]] Loss_Validation:  [[ 11.05093932]]\n",
      "Loop 9264 Loss_Train:  [[ 13.19525016]] Loss_Validation:  [[ 11.05094029]]\n",
      "Loop 9265 Loss_Train:  [[ 13.19525016]] Loss_Validation:  [[ 11.05094126]]\n",
      "Loop 9266 Loss_Train:  [[ 13.19525015]] Loss_Validation:  [[ 11.05094223]]\n",
      "Loop 9267 Loss_Train:  [[ 13.19525015]] Loss_Validation:  [[ 11.0509432]]\n",
      "Loop 9268 Loss_Train:  [[ 13.19525015]] Loss_Validation:  [[ 11.05094417]]\n",
      "Loop 9269 Loss_Train:  [[ 13.19525015]] Loss_Validation:  [[ 11.05094514]]\n",
      "Loop 9270 Loss_Train:  [[ 13.19525014]] Loss_Validation:  [[ 11.05094611]]\n",
      "Loop 9271 Loss_Train:  [[ 13.19525014]] Loss_Validation:  [[ 11.05094708]]\n",
      "Loop 9272 Loss_Train:  [[ 13.19525014]] Loss_Validation:  [[ 11.05094805]]\n",
      "Loop 9273 Loss_Train:  [[ 13.19525014]] Loss_Validation:  [[ 11.05094901]]\n",
      "Loop 9274 Loss_Train:  [[ 13.19525014]] Loss_Validation:  [[ 11.05094998]]\n",
      "Loop 9275 Loss_Train:  [[ 13.19525013]] Loss_Validation:  [[ 11.05095095]]\n",
      "Loop 9276 Loss_Train:  [[ 13.19525013]] Loss_Validation:  [[ 11.05095191]]\n",
      "Loop 9277 Loss_Train:  [[ 13.19525013]] Loss_Validation:  [[ 11.05095287]]\n",
      "Loop 9278 Loss_Train:  [[ 13.19525013]] Loss_Validation:  [[ 11.05095384]]\n",
      "Loop 9279 Loss_Train:  [[ 13.19525012]] Loss_Validation:  [[ 11.0509548]]\n",
      "Loop 9280 Loss_Train:  [[ 13.19525012]] Loss_Validation:  [[ 11.05095576]]\n",
      "Loop 9281 Loss_Train:  [[ 13.19525012]] Loss_Validation:  [[ 11.05095672]]\n",
      "Loop 9282 Loss_Train:  [[ 13.19525012]] Loss_Validation:  [[ 11.05095768]]\n",
      "Loop 9283 Loss_Train:  [[ 13.19525011]] Loss_Validation:  [[ 11.05095864]]\n",
      "Loop 9284 Loss_Train:  [[ 13.19525011]] Loss_Validation:  [[ 11.0509596]]\n",
      "Loop 9285 Loss_Train:  [[ 13.19525011]] Loss_Validation:  [[ 11.05096056]]\n",
      "Loop 9286 Loss_Train:  [[ 13.19525011]] Loss_Validation:  [[ 11.05096152]]\n",
      "Loop 9287 Loss_Train:  [[ 13.19525011]] Loss_Validation:  [[ 11.05096248]]\n",
      "Loop 9288 Loss_Train:  [[ 13.1952501]] Loss_Validation:  [[ 11.05096343]]\n",
      "Loop 9289 Loss_Train:  [[ 13.1952501]] Loss_Validation:  [[ 11.05096439]]\n",
      "Loop 9290 Loss_Train:  [[ 13.1952501]] Loss_Validation:  [[ 11.05096534]]\n",
      "Loop 9291 Loss_Train:  [[ 13.1952501]] Loss_Validation:  [[ 11.0509663]]\n",
      "Loop 9292 Loss_Train:  [[ 13.19525009]] Loss_Validation:  [[ 11.05096725]]\n",
      "Loop 9293 Loss_Train:  [[ 13.19525009]] Loss_Validation:  [[ 11.05096821]]\n",
      "Loop 9294 Loss_Train:  [[ 13.19525009]] Loss_Validation:  [[ 11.05096916]]\n",
      "Loop 9295 Loss_Train:  [[ 13.19525009]] Loss_Validation:  [[ 11.05097011]]\n",
      "Loop 9296 Loss_Train:  [[ 13.19525009]] Loss_Validation:  [[ 11.05097106]]\n",
      "Loop 9297 Loss_Train:  [[ 13.19525008]] Loss_Validation:  [[ 11.05097201]]\n",
      "Loop 9298 Loss_Train:  [[ 13.19525008]] Loss_Validation:  [[ 11.05097296]]\n",
      "Loop 9299 Loss_Train:  [[ 13.19525008]] Loss_Validation:  [[ 11.05097391]]\n",
      "Loop 9300 Loss_Train:  [[ 13.19525008]] Loss_Validation:  [[ 11.05097486]]\n",
      "Loop 9301 Loss_Train:  [[ 13.19525007]] Loss_Validation:  [[ 11.05097581]]\n",
      "Loop 9302 Loss_Train:  [[ 13.19525007]] Loss_Validation:  [[ 11.05097676]]\n",
      "Loop 9303 Loss_Train:  [[ 13.19525007]] Loss_Validation:  [[ 11.0509777]]\n",
      "Loop 9304 Loss_Train:  [[ 13.19525007]] Loss_Validation:  [[ 11.05097865]]\n",
      "Loop 9305 Loss_Train:  [[ 13.19525007]] Loss_Validation:  [[ 11.05097959]]\n",
      "Loop 9306 Loss_Train:  [[ 13.19525006]] Loss_Validation:  [[ 11.05098054]]\n",
      "Loop 9307 Loss_Train:  [[ 13.19525006]] Loss_Validation:  [[ 11.05098148]]\n",
      "Loop 9308 Loss_Train:  [[ 13.19525006]] Loss_Validation:  [[ 11.05098243]]\n",
      "Loop 9309 Loss_Train:  [[ 13.19525006]] Loss_Validation:  [[ 11.05098337]]\n",
      "Loop 9310 Loss_Train:  [[ 13.19525005]] Loss_Validation:  [[ 11.05098431]]\n",
      "Loop 9311 Loss_Train:  [[ 13.19525005]] Loss_Validation:  [[ 11.05098525]]\n",
      "Loop 9312 Loss_Train:  [[ 13.19525005]] Loss_Validation:  [[ 11.05098619]]\n",
      "Loop 9313 Loss_Train:  [[ 13.19525005]] Loss_Validation:  [[ 11.05098713]]\n",
      "Loop 9314 Loss_Train:  [[ 13.19525005]] Loss_Validation:  [[ 11.05098807]]\n",
      "Loop 9315 Loss_Train:  [[ 13.19525004]] Loss_Validation:  [[ 11.05098901]]\n",
      "Loop 9316 Loss_Train:  [[ 13.19525004]] Loss_Validation:  [[ 11.05098995]]\n",
      "Loop 9317 Loss_Train:  [[ 13.19525004]] Loss_Validation:  [[ 11.05099089]]\n",
      "Loop 9318 Loss_Train:  [[ 13.19525004]] Loss_Validation:  [[ 11.05099182]]\n",
      "Loop 9319 Loss_Train:  [[ 13.19525003]] Loss_Validation:  [[ 11.05099276]]\n",
      "Loop 9320 Loss_Train:  [[ 13.19525003]] Loss_Validation:  [[ 11.0509937]]\n",
      "Loop 9321 Loss_Train:  [[ 13.19525003]] Loss_Validation:  [[ 11.05099463]]\n",
      "Loop 9322 Loss_Train:  [[ 13.19525003]] Loss_Validation:  [[ 11.05099556]]\n",
      "Loop 9323 Loss_Train:  [[ 13.19525003]] Loss_Validation:  [[ 11.0509965]]\n",
      "Loop 9324 Loss_Train:  [[ 13.19525002]] Loss_Validation:  [[ 11.05099743]]\n",
      "Loop 9325 Loss_Train:  [[ 13.19525002]] Loss_Validation:  [[ 11.05099836]]\n",
      "Loop 9326 Loss_Train:  [[ 13.19525002]] Loss_Validation:  [[ 11.0509993]]\n",
      "Loop 9327 Loss_Train:  [[ 13.19525002]] Loss_Validation:  [[ 11.05100023]]\n",
      "Loop 9328 Loss_Train:  [[ 13.19525001]] Loss_Validation:  [[ 11.05100116]]\n",
      "Loop 9329 Loss_Train:  [[ 13.19525001]] Loss_Validation:  [[ 11.05100209]]\n",
      "Loop 9330 Loss_Train:  [[ 13.19525001]] Loss_Validation:  [[ 11.05100302]]\n",
      "Loop 9331 Loss_Train:  [[ 13.19525001]] Loss_Validation:  [[ 11.05100394]]\n",
      "Loop 9332 Loss_Train:  [[ 13.19525001]] Loss_Validation:  [[ 11.05100487]]\n",
      "Loop 9333 Loss_Train:  [[ 13.19525]] Loss_Validation:  [[ 11.0510058]]\n",
      "Loop 9334 Loss_Train:  [[ 13.19525]] Loss_Validation:  [[ 11.05100673]]\n",
      "Loop 9335 Loss_Train:  [[ 13.19525]] Loss_Validation:  [[ 11.05100765]]\n",
      "Loop 9336 Loss_Train:  [[ 13.19525]] Loss_Validation:  [[ 11.05100858]]\n",
      "Loop 9337 Loss_Train:  [[ 13.19525]] Loss_Validation:  [[ 11.0510095]]\n",
      "Loop 9338 Loss_Train:  [[ 13.19524999]] Loss_Validation:  [[ 11.05101043]]\n",
      "Loop 9339 Loss_Train:  [[ 13.19524999]] Loss_Validation:  [[ 11.05101135]]\n",
      "Loop 9340 Loss_Train:  [[ 13.19524999]] Loss_Validation:  [[ 11.05101227]]\n",
      "Loop 9341 Loss_Train:  [[ 13.19524999]] Loss_Validation:  [[ 11.05101319]]\n",
      "Loop 9342 Loss_Train:  [[ 13.19524999]] Loss_Validation:  [[ 11.05101411]]\n",
      "Loop 9343 Loss_Train:  [[ 13.19524998]] Loss_Validation:  [[ 11.05101504]]\n",
      "Loop 9344 Loss_Train:  [[ 13.19524998]] Loss_Validation:  [[ 11.05101596]]\n",
      "Loop 9345 Loss_Train:  [[ 13.19524998]] Loss_Validation:  [[ 11.05101687]]\n",
      "Loop 9346 Loss_Train:  [[ 13.19524998]] Loss_Validation:  [[ 11.05101779]]\n",
      "Loop 9347 Loss_Train:  [[ 13.19524997]] Loss_Validation:  [[ 11.05101871]]\n",
      "Loop 9348 Loss_Train:  [[ 13.19524997]] Loss_Validation:  [[ 11.05101963]]\n",
      "Loop 9349 Loss_Train:  [[ 13.19524997]] Loss_Validation:  [[ 11.05102055]]\n",
      "Loop 9350 Loss_Train:  [[ 13.19524997]] Loss_Validation:  [[ 11.05102146]]\n",
      "Loop 9351 Loss_Train:  [[ 13.19524997]] Loss_Validation:  [[ 11.05102238]]\n",
      "Loop 9352 Loss_Train:  [[ 13.19524996]] Loss_Validation:  [[ 11.05102329]]\n",
      "Loop 9353 Loss_Train:  [[ 13.19524996]] Loss_Validation:  [[ 11.05102421]]\n",
      "Loop 9354 Loss_Train:  [[ 13.19524996]] Loss_Validation:  [[ 11.05102512]]\n",
      "Loop 9355 Loss_Train:  [[ 13.19524996]] Loss_Validation:  [[ 11.05102603]]\n",
      "Loop 9356 Loss_Train:  [[ 13.19524996]] Loss_Validation:  [[ 11.05102695]]\n",
      "Loop 9357 Loss_Train:  [[ 13.19524995]] Loss_Validation:  [[ 11.05102786]]\n",
      "Loop 9358 Loss_Train:  [[ 13.19524995]] Loss_Validation:  [[ 11.05102877]]\n",
      "Loop 9359 Loss_Train:  [[ 13.19524995]] Loss_Validation:  [[ 11.05102968]]\n",
      "Loop 9360 Loss_Train:  [[ 13.19524995]] Loss_Validation:  [[ 11.05103059]]\n",
      "Loop 9361 Loss_Train:  [[ 13.19524995]] Loss_Validation:  [[ 11.0510315]]\n",
      "Loop 9362 Loss_Train:  [[ 13.19524994]] Loss_Validation:  [[ 11.05103241]]\n",
      "Loop 9363 Loss_Train:  [[ 13.19524994]] Loss_Validation:  [[ 11.05103332]]\n",
      "Loop 9364 Loss_Train:  [[ 13.19524994]] Loss_Validation:  [[ 11.05103422]]\n",
      "Loop 9365 Loss_Train:  [[ 13.19524994]] Loss_Validation:  [[ 11.05103513]]\n",
      "Loop 9366 Loss_Train:  [[ 13.19524994]] Loss_Validation:  [[ 11.05103604]]\n",
      "Loop 9367 Loss_Train:  [[ 13.19524993]] Loss_Validation:  [[ 11.05103694]]\n",
      "Loop 9368 Loss_Train:  [[ 13.19524993]] Loss_Validation:  [[ 11.05103785]]\n",
      "Loop 9369 Loss_Train:  [[ 13.19524993]] Loss_Validation:  [[ 11.05103875]]\n",
      "Loop 9370 Loss_Train:  [[ 13.19524993]] Loss_Validation:  [[ 11.05103966]]\n",
      "Loop 9371 Loss_Train:  [[ 13.19524993]] Loss_Validation:  [[ 11.05104056]]\n",
      "Loop 9372 Loss_Train:  [[ 13.19524992]] Loss_Validation:  [[ 11.05104146]]\n",
      "Loop 9373 Loss_Train:  [[ 13.19524992]] Loss_Validation:  [[ 11.05104236]]\n",
      "Loop 9374 Loss_Train:  [[ 13.19524992]] Loss_Validation:  [[ 11.05104326]]\n",
      "Loop 9375 Loss_Train:  [[ 13.19524992]] Loss_Validation:  [[ 11.05104416]]\n",
      "Loop 9376 Loss_Train:  [[ 13.19524992]] Loss_Validation:  [[ 11.05104506]]\n",
      "Loop 9377 Loss_Train:  [[ 13.19524991]] Loss_Validation:  [[ 11.05104596]]\n",
      "Loop 9378 Loss_Train:  [[ 13.19524991]] Loss_Validation:  [[ 11.05104686]]\n",
      "Loop 9379 Loss_Train:  [[ 13.19524991]] Loss_Validation:  [[ 11.05104776]]\n",
      "Loop 9380 Loss_Train:  [[ 13.19524991]] Loss_Validation:  [[ 11.05104866]]\n",
      "Loop 9381 Loss_Train:  [[ 13.19524991]] Loss_Validation:  [[ 11.05104955]]\n",
      "Loop 9382 Loss_Train:  [[ 13.1952499]] Loss_Validation:  [[ 11.05105045]]\n",
      "Loop 9383 Loss_Train:  [[ 13.1952499]] Loss_Validation:  [[ 11.05105135]]\n",
      "Loop 9384 Loss_Train:  [[ 13.1952499]] Loss_Validation:  [[ 11.05105224]]\n",
      "Loop 9385 Loss_Train:  [[ 13.1952499]] Loss_Validation:  [[ 11.05105314]]\n",
      "Loop 9386 Loss_Train:  [[ 13.1952499]] Loss_Validation:  [[ 11.05105403]]\n",
      "Loop 9387 Loss_Train:  [[ 13.19524989]] Loss_Validation:  [[ 11.05105492]]\n",
      "Loop 9388 Loss_Train:  [[ 13.19524989]] Loss_Validation:  [[ 11.05105581]]\n",
      "Loop 9389 Loss_Train:  [[ 13.19524989]] Loss_Validation:  [[ 11.05105671]]\n",
      "Loop 9390 Loss_Train:  [[ 13.19524989]] Loss_Validation:  [[ 11.0510576]]\n",
      "Loop 9391 Loss_Train:  [[ 13.19524989]] Loss_Validation:  [[ 11.05105849]]\n",
      "Loop 9392 Loss_Train:  [[ 13.19524988]] Loss_Validation:  [[ 11.05105938]]\n",
      "Loop 9393 Loss_Train:  [[ 13.19524988]] Loss_Validation:  [[ 11.05106027]]\n",
      "Loop 9394 Loss_Train:  [[ 13.19524988]] Loss_Validation:  [[ 11.05106116]]\n",
      "Loop 9395 Loss_Train:  [[ 13.19524988]] Loss_Validation:  [[ 11.05106204]]\n",
      "Loop 9396 Loss_Train:  [[ 13.19524988]] Loss_Validation:  [[ 11.05106293]]\n",
      "Loop 9397 Loss_Train:  [[ 13.19524987]] Loss_Validation:  [[ 11.05106382]]\n",
      "Loop 9398 Loss_Train:  [[ 13.19524987]] Loss_Validation:  [[ 11.0510647]]\n",
      "Loop 9399 Loss_Train:  [[ 13.19524987]] Loss_Validation:  [[ 11.05106559]]\n",
      "Loop 9400 Loss_Train:  [[ 13.19524987]] Loss_Validation:  [[ 11.05106648]]\n",
      "Loop 9401 Loss_Train:  [[ 13.19524987]] Loss_Validation:  [[ 11.05106736]]\n",
      "Loop 9402 Loss_Train:  [[ 13.19524986]] Loss_Validation:  [[ 11.05106824]]\n",
      "Loop 9403 Loss_Train:  [[ 13.19524986]] Loss_Validation:  [[ 11.05106913]]\n",
      "Loop 9404 Loss_Train:  [[ 13.19524986]] Loss_Validation:  [[ 11.05107001]]\n",
      "Loop 9405 Loss_Train:  [[ 13.19524986]] Loss_Validation:  [[ 11.05107089]]\n",
      "Loop 9406 Loss_Train:  [[ 13.19524986]] Loss_Validation:  [[ 11.05107177]]\n",
      "Loop 9407 Loss_Train:  [[ 13.19524985]] Loss_Validation:  [[ 11.05107265]]\n",
      "Loop 9408 Loss_Train:  [[ 13.19524985]] Loss_Validation:  [[ 11.05107353]]\n",
      "Loop 9409 Loss_Train:  [[ 13.19524985]] Loss_Validation:  [[ 11.05107441]]\n",
      "Loop 9410 Loss_Train:  [[ 13.19524985]] Loss_Validation:  [[ 11.05107529]]\n",
      "Loop 9411 Loss_Train:  [[ 13.19524985]] Loss_Validation:  [[ 11.05107617]]\n",
      "Loop 9412 Loss_Train:  [[ 13.19524985]] Loss_Validation:  [[ 11.05107705]]\n",
      "Loop 9413 Loss_Train:  [[ 13.19524984]] Loss_Validation:  [[ 11.05107792]]\n",
      "Loop 9414 Loss_Train:  [[ 13.19524984]] Loss_Validation:  [[ 11.0510788]]\n",
      "Loop 9415 Loss_Train:  [[ 13.19524984]] Loss_Validation:  [[ 11.05107968]]\n",
      "Loop 9416 Loss_Train:  [[ 13.19524984]] Loss_Validation:  [[ 11.05108055]]\n",
      "Loop 9417 Loss_Train:  [[ 13.19524984]] Loss_Validation:  [[ 11.05108143]]\n",
      "Loop 9418 Loss_Train:  [[ 13.19524983]] Loss_Validation:  [[ 11.0510823]]\n",
      "Loop 9419 Loss_Train:  [[ 13.19524983]] Loss_Validation:  [[ 11.05108317]]\n",
      "Loop 9420 Loss_Train:  [[ 13.19524983]] Loss_Validation:  [[ 11.05108405]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 9421 Loss_Train:  [[ 13.19524983]] Loss_Validation:  [[ 11.05108492]]\n",
      "Loop 9422 Loss_Train:  [[ 13.19524983]] Loss_Validation:  [[ 11.05108579]]\n",
      "Loop 9423 Loss_Train:  [[ 13.19524982]] Loss_Validation:  [[ 11.05108666]]\n",
      "Loop 9424 Loss_Train:  [[ 13.19524982]] Loss_Validation:  [[ 11.05108753]]\n",
      "Loop 9425 Loss_Train:  [[ 13.19524982]] Loss_Validation:  [[ 11.0510884]]\n",
      "Loop 9426 Loss_Train:  [[ 13.19524982]] Loss_Validation:  [[ 11.05108927]]\n",
      "Loop 9427 Loss_Train:  [[ 13.19524982]] Loss_Validation:  [[ 11.05109014]]\n",
      "Loop 9428 Loss_Train:  [[ 13.19524982]] Loss_Validation:  [[ 11.05109101]]\n",
      "Loop 9429 Loss_Train:  [[ 13.19524981]] Loss_Validation:  [[ 11.05109188]]\n",
      "Loop 9430 Loss_Train:  [[ 13.19524981]] Loss_Validation:  [[ 11.05109274]]\n",
      "Loop 9431 Loss_Train:  [[ 13.19524981]] Loss_Validation:  [[ 11.05109361]]\n",
      "Loop 9432 Loss_Train:  [[ 13.19524981]] Loss_Validation:  [[ 11.05109447]]\n",
      "Loop 9433 Loss_Train:  [[ 13.19524981]] Loss_Validation:  [[ 11.05109534]]\n",
      "Loop 9434 Loss_Train:  [[ 13.1952498]] Loss_Validation:  [[ 11.0510962]]\n",
      "Loop 9435 Loss_Train:  [[ 13.1952498]] Loss_Validation:  [[ 11.05109707]]\n",
      "Loop 9436 Loss_Train:  [[ 13.1952498]] Loss_Validation:  [[ 11.05109793]]\n",
      "Loop 9437 Loss_Train:  [[ 13.1952498]] Loss_Validation:  [[ 11.05109879]]\n",
      "Loop 9438 Loss_Train:  [[ 13.1952498]] Loss_Validation:  [[ 11.05109965]]\n",
      "Loop 9439 Loss_Train:  [[ 13.19524979]] Loss_Validation:  [[ 11.05110052]]\n",
      "Loop 9440 Loss_Train:  [[ 13.19524979]] Loss_Validation:  [[ 11.05110138]]\n",
      "Loop 9441 Loss_Train:  [[ 13.19524979]] Loss_Validation:  [[ 11.05110224]]\n",
      "Loop 9442 Loss_Train:  [[ 13.19524979]] Loss_Validation:  [[ 11.0511031]]\n",
      "Loop 9443 Loss_Train:  [[ 13.19524979]] Loss_Validation:  [[ 11.05110396]]\n",
      "Loop 9444 Loss_Train:  [[ 13.19524979]] Loss_Validation:  [[ 11.05110481]]\n",
      "Loop 9445 Loss_Train:  [[ 13.19524978]] Loss_Validation:  [[ 11.05110567]]\n",
      "Loop 9446 Loss_Train:  [[ 13.19524978]] Loss_Validation:  [[ 11.05110653]]\n",
      "Loop 9447 Loss_Train:  [[ 13.19524978]] Loss_Validation:  [[ 11.05110739]]\n",
      "Loop 9448 Loss_Train:  [[ 13.19524978]] Loss_Validation:  [[ 11.05110824]]\n",
      "Loop 9449 Loss_Train:  [[ 13.19524978]] Loss_Validation:  [[ 11.0511091]]\n",
      "Loop 9450 Loss_Train:  [[ 13.19524977]] Loss_Validation:  [[ 11.05110995]]\n",
      "Loop 9451 Loss_Train:  [[ 13.19524977]] Loss_Validation:  [[ 11.05111081]]\n",
      "Loop 9452 Loss_Train:  [[ 13.19524977]] Loss_Validation:  [[ 11.05111166]]\n",
      "Loop 9453 Loss_Train:  [[ 13.19524977]] Loss_Validation:  [[ 11.05111251]]\n",
      "Loop 9454 Loss_Train:  [[ 13.19524977]] Loss_Validation:  [[ 11.05111337]]\n",
      "Loop 9455 Loss_Train:  [[ 13.19524977]] Loss_Validation:  [[ 11.05111422]]\n",
      "Loop 9456 Loss_Train:  [[ 13.19524976]] Loss_Validation:  [[ 11.05111507]]\n",
      "Loop 9457 Loss_Train:  [[ 13.19524976]] Loss_Validation:  [[ 11.05111592]]\n",
      "Loop 9458 Loss_Train:  [[ 13.19524976]] Loss_Validation:  [[ 11.05111677]]\n",
      "Loop 9459 Loss_Train:  [[ 13.19524976]] Loss_Validation:  [[ 11.05111762]]\n",
      "Loop 9460 Loss_Train:  [[ 13.19524976]] Loss_Validation:  [[ 11.05111847]]\n",
      "Loop 9461 Loss_Train:  [[ 13.19524976]] Loss_Validation:  [[ 11.05111932]]\n",
      "Loop 9462 Loss_Train:  [[ 13.19524975]] Loss_Validation:  [[ 11.05112016]]\n",
      "Loop 9463 Loss_Train:  [[ 13.19524975]] Loss_Validation:  [[ 11.05112101]]\n",
      "Loop 9464 Loss_Train:  [[ 13.19524975]] Loss_Validation:  [[ 11.05112186]]\n",
      "Loop 9465 Loss_Train:  [[ 13.19524975]] Loss_Validation:  [[ 11.0511227]]\n",
      "Loop 9466 Loss_Train:  [[ 13.19524975]] Loss_Validation:  [[ 11.05112355]]\n",
      "Loop 9467 Loss_Train:  [[ 13.19524974]] Loss_Validation:  [[ 11.05112439]]\n",
      "Loop 9468 Loss_Train:  [[ 13.19524974]] Loss_Validation:  [[ 11.05112524]]\n",
      "Loop 9469 Loss_Train:  [[ 13.19524974]] Loss_Validation:  [[ 11.05112608]]\n",
      "Loop 9470 Loss_Train:  [[ 13.19524974]] Loss_Validation:  [[ 11.05112692]]\n",
      "Loop 9471 Loss_Train:  [[ 13.19524974]] Loss_Validation:  [[ 11.05112777]]\n",
      "Loop 9472 Loss_Train:  [[ 13.19524974]] Loss_Validation:  [[ 11.05112861]]\n",
      "Loop 9473 Loss_Train:  [[ 13.19524973]] Loss_Validation:  [[ 11.05112945]]\n",
      "Loop 9474 Loss_Train:  [[ 13.19524973]] Loss_Validation:  [[ 11.05113029]]\n",
      "Loop 9475 Loss_Train:  [[ 13.19524973]] Loss_Validation:  [[ 11.05113113]]\n",
      "Loop 9476 Loss_Train:  [[ 13.19524973]] Loss_Validation:  [[ 11.05113197]]\n",
      "Loop 9477 Loss_Train:  [[ 13.19524973]] Loss_Validation:  [[ 11.05113281]]\n",
      "Loop 9478 Loss_Train:  [[ 13.19524973]] Loss_Validation:  [[ 11.05113365]]\n",
      "Loop 9479 Loss_Train:  [[ 13.19524972]] Loss_Validation:  [[ 11.05113449]]\n",
      "Loop 9480 Loss_Train:  [[ 13.19524972]] Loss_Validation:  [[ 11.05113532]]\n",
      "Loop 9481 Loss_Train:  [[ 13.19524972]] Loss_Validation:  [[ 11.05113616]]\n",
      "Loop 9482 Loss_Train:  [[ 13.19524972]] Loss_Validation:  [[ 11.051137]]\n",
      "Loop 9483 Loss_Train:  [[ 13.19524972]] Loss_Validation:  [[ 11.05113783]]\n",
      "Loop 9484 Loss_Train:  [[ 13.19524972]] Loss_Validation:  [[ 11.05113867]]\n",
      "Loop 9485 Loss_Train:  [[ 13.19524971]] Loss_Validation:  [[ 11.0511395]]\n",
      "Loop 9486 Loss_Train:  [[ 13.19524971]] Loss_Validation:  [[ 11.05114033]]\n",
      "Loop 9487 Loss_Train:  [[ 13.19524971]] Loss_Validation:  [[ 11.05114117]]\n",
      "Loop 9488 Loss_Train:  [[ 13.19524971]] Loss_Validation:  [[ 11.051142]]\n",
      "Loop 9489 Loss_Train:  [[ 13.19524971]] Loss_Validation:  [[ 11.05114283]]\n",
      "Loop 9490 Loss_Train:  [[ 13.1952497]] Loss_Validation:  [[ 11.05114366]]\n",
      "Loop 9491 Loss_Train:  [[ 13.1952497]] Loss_Validation:  [[ 11.05114449]]\n",
      "Loop 9492 Loss_Train:  [[ 13.1952497]] Loss_Validation:  [[ 11.05114532]]\n",
      "Loop 9493 Loss_Train:  [[ 13.1952497]] Loss_Validation:  [[ 11.05114615]]\n",
      "Loop 9494 Loss_Train:  [[ 13.1952497]] Loss_Validation:  [[ 11.05114698]]\n",
      "Loop 9495 Loss_Train:  [[ 13.1952497]] Loss_Validation:  [[ 11.05114781]]\n",
      "Loop 9496 Loss_Train:  [[ 13.19524969]] Loss_Validation:  [[ 11.05114864]]\n",
      "Loop 9497 Loss_Train:  [[ 13.19524969]] Loss_Validation:  [[ 11.05114947]]\n",
      "Loop 9498 Loss_Train:  [[ 13.19524969]] Loss_Validation:  [[ 11.05115029]]\n",
      "Loop 9499 Loss_Train:  [[ 13.19524969]] Loss_Validation:  [[ 11.05115112]]\n",
      "Loop 9500 Loss_Train:  [[ 13.19524969]] Loss_Validation:  [[ 11.05115194]]\n",
      "Loop 9501 Loss_Train:  [[ 13.19524969]] Loss_Validation:  [[ 11.05115277]]\n",
      "Loop 9502 Loss_Train:  [[ 13.19524968]] Loss_Validation:  [[ 11.05115359]]\n",
      "Loop 9503 Loss_Train:  [[ 13.19524968]] Loss_Validation:  [[ 11.05115442]]\n",
      "Loop 9504 Loss_Train:  [[ 13.19524968]] Loss_Validation:  [[ 11.05115524]]\n",
      "Loop 9505 Loss_Train:  [[ 13.19524968]] Loss_Validation:  [[ 11.05115606]]\n",
      "Loop 9506 Loss_Train:  [[ 13.19524968]] Loss_Validation:  [[ 11.05115689]]\n",
      "Loop 9507 Loss_Train:  [[ 13.19524968]] Loss_Validation:  [[ 11.05115771]]\n",
      "Loop 9508 Loss_Train:  [[ 13.19524967]] Loss_Validation:  [[ 11.05115853]]\n",
      "Loop 9509 Loss_Train:  [[ 13.19524967]] Loss_Validation:  [[ 11.05115935]]\n",
      "Loop 9510 Loss_Train:  [[ 13.19524967]] Loss_Validation:  [[ 11.05116017]]\n",
      "Loop 9511 Loss_Train:  [[ 13.19524967]] Loss_Validation:  [[ 11.05116099]]\n",
      "Loop 9512 Loss_Train:  [[ 13.19524967]] Loss_Validation:  [[ 11.05116181]]\n",
      "Loop 9513 Loss_Train:  [[ 13.19524967]] Loss_Validation:  [[ 11.05116263]]\n",
      "Loop 9514 Loss_Train:  [[ 13.19524966]] Loss_Validation:  [[ 11.05116344]]\n",
      "Loop 9515 Loss_Train:  [[ 13.19524966]] Loss_Validation:  [[ 11.05116426]]\n",
      "Loop 9516 Loss_Train:  [[ 13.19524966]] Loss_Validation:  [[ 11.05116508]]\n",
      "Loop 9517 Loss_Train:  [[ 13.19524966]] Loss_Validation:  [[ 11.05116589]]\n",
      "Loop 9518 Loss_Train:  [[ 13.19524966]] Loss_Validation:  [[ 11.05116671]]\n",
      "Loop 9519 Loss_Train:  [[ 13.19524966]] Loss_Validation:  [[ 11.05116752]]\n",
      "Loop 9520 Loss_Train:  [[ 13.19524965]] Loss_Validation:  [[ 11.05116834]]\n",
      "Loop 9521 Loss_Train:  [[ 13.19524965]] Loss_Validation:  [[ 11.05116915]]\n",
      "Loop 9522 Loss_Train:  [[ 13.19524965]] Loss_Validation:  [[ 11.05116996]]\n",
      "Loop 9523 Loss_Train:  [[ 13.19524965]] Loss_Validation:  [[ 11.05117078]]\n",
      "Loop 9524 Loss_Train:  [[ 13.19524965]] Loss_Validation:  [[ 11.05117159]]\n",
      "Loop 9525 Loss_Train:  [[ 13.19524965]] Loss_Validation:  [[ 11.0511724]]\n",
      "Loop 9526 Loss_Train:  [[ 13.19524965]] Loss_Validation:  [[ 11.05117321]]\n",
      "Loop 9527 Loss_Train:  [[ 13.19524964]] Loss_Validation:  [[ 11.05117402]]\n",
      "Loop 9528 Loss_Train:  [[ 13.19524964]] Loss_Validation:  [[ 11.05117483]]\n",
      "Loop 9529 Loss_Train:  [[ 13.19524964]] Loss_Validation:  [[ 11.05117564]]\n",
      "Loop 9530 Loss_Train:  [[ 13.19524964]] Loss_Validation:  [[ 11.05117645]]\n",
      "Loop 9531 Loss_Train:  [[ 13.19524964]] Loss_Validation:  [[ 11.05117726]]\n",
      "Loop 9532 Loss_Train:  [[ 13.19524964]] Loss_Validation:  [[ 11.05117806]]\n",
      "Loop 9533 Loss_Train:  [[ 13.19524963]] Loss_Validation:  [[ 11.05117887]]\n",
      "Loop 9534 Loss_Train:  [[ 13.19524963]] Loss_Validation:  [[ 11.05117968]]\n",
      "Loop 9535 Loss_Train:  [[ 13.19524963]] Loss_Validation:  [[ 11.05118048]]\n",
      "Loop 9536 Loss_Train:  [[ 13.19524963]] Loss_Validation:  [[ 11.05118129]]\n",
      "Loop 9537 Loss_Train:  [[ 13.19524963]] Loss_Validation:  [[ 11.05118209]]\n",
      "Loop 9538 Loss_Train:  [[ 13.19524963]] Loss_Validation:  [[ 11.0511829]]\n",
      "Loop 9539 Loss_Train:  [[ 13.19524962]] Loss_Validation:  [[ 11.0511837]]\n",
      "Loop 9540 Loss_Train:  [[ 13.19524962]] Loss_Validation:  [[ 11.0511845]]\n",
      "Loop 9541 Loss_Train:  [[ 13.19524962]] Loss_Validation:  [[ 11.05118531]]\n",
      "Loop 9542 Loss_Train:  [[ 13.19524962]] Loss_Validation:  [[ 11.05118611]]\n",
      "Loop 9543 Loss_Train:  [[ 13.19524962]] Loss_Validation:  [[ 11.05118691]]\n",
      "Loop 9544 Loss_Train:  [[ 13.19524962]] Loss_Validation:  [[ 11.05118771]]\n",
      "Loop 9545 Loss_Train:  [[ 13.19524961]] Loss_Validation:  [[ 11.05118851]]\n",
      "Loop 9546 Loss_Train:  [[ 13.19524961]] Loss_Validation:  [[ 11.05118931]]\n",
      "Loop 9547 Loss_Train:  [[ 13.19524961]] Loss_Validation:  [[ 11.05119011]]\n",
      "Loop 9548 Loss_Train:  [[ 13.19524961]] Loss_Validation:  [[ 11.05119091]]\n",
      "Loop 9549 Loss_Train:  [[ 13.19524961]] Loss_Validation:  [[ 11.05119171]]\n",
      "Loop 9550 Loss_Train:  [[ 13.19524961]] Loss_Validation:  [[ 11.0511925]]\n",
      "Loop 9551 Loss_Train:  [[ 13.19524961]] Loss_Validation:  [[ 11.0511933]]\n",
      "Loop 9552 Loss_Train:  [[ 13.1952496]] Loss_Validation:  [[ 11.0511941]]\n",
      "Loop 9553 Loss_Train:  [[ 13.1952496]] Loss_Validation:  [[ 11.05119489]]\n",
      "Loop 9554 Loss_Train:  [[ 13.1952496]] Loss_Validation:  [[ 11.05119569]]\n",
      "Loop 9555 Loss_Train:  [[ 13.1952496]] Loss_Validation:  [[ 11.05119648]]\n",
      "Loop 9556 Loss_Train:  [[ 13.1952496]] Loss_Validation:  [[ 11.05119728]]\n",
      "Loop 9557 Loss_Train:  [[ 13.1952496]] Loss_Validation:  [[ 11.05119807]]\n",
      "Loop 9558 Loss_Train:  [[ 13.19524959]] Loss_Validation:  [[ 11.05119886]]\n",
      "Loop 9559 Loss_Train:  [[ 13.19524959]] Loss_Validation:  [[ 11.05119966]]\n",
      "Loop 9560 Loss_Train:  [[ 13.19524959]] Loss_Validation:  [[ 11.05120045]]\n",
      "Loop 9561 Loss_Train:  [[ 13.19524959]] Loss_Validation:  [[ 11.05120124]]\n",
      "Loop 9562 Loss_Train:  [[ 13.19524959]] Loss_Validation:  [[ 11.05120203]]\n",
      "Loop 9563 Loss_Train:  [[ 13.19524959]] Loss_Validation:  [[ 11.05120282]]\n",
      "Loop 9564 Loss_Train:  [[ 13.19524959]] Loss_Validation:  [[ 11.05120361]]\n",
      "Loop 9565 Loss_Train:  [[ 13.19524958]] Loss_Validation:  [[ 11.0512044]]\n",
      "Loop 9566 Loss_Train:  [[ 13.19524958]] Loss_Validation:  [[ 11.05120519]]\n",
      "Loop 9567 Loss_Train:  [[ 13.19524958]] Loss_Validation:  [[ 11.05120598]]\n",
      "Loop 9568 Loss_Train:  [[ 13.19524958]] Loss_Validation:  [[ 11.05120676]]\n",
      "Loop 9569 Loss_Train:  [[ 13.19524958]] Loss_Validation:  [[ 11.05120755]]\n",
      "Loop 9570 Loss_Train:  [[ 13.19524958]] Loss_Validation:  [[ 11.05120834]]\n",
      "Loop 9571 Loss_Train:  [[ 13.19524957]] Loss_Validation:  [[ 11.05120912]]\n",
      "Loop 9572 Loss_Train:  [[ 13.19524957]] Loss_Validation:  [[ 11.05120991]]\n",
      "Loop 9573 Loss_Train:  [[ 13.19524957]] Loss_Validation:  [[ 11.05121069]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 9574 Loss_Train:  [[ 13.19524957]] Loss_Validation:  [[ 11.05121148]]\n",
      "Loop 9575 Loss_Train:  [[ 13.19524957]] Loss_Validation:  [[ 11.05121226]]\n",
      "Loop 9576 Loss_Train:  [[ 13.19524957]] Loss_Validation:  [[ 11.05121304]]\n",
      "Loop 9577 Loss_Train:  [[ 13.19524957]] Loss_Validation:  [[ 11.05121383]]\n",
      "Loop 9578 Loss_Train:  [[ 13.19524956]] Loss_Validation:  [[ 11.05121461]]\n",
      "Loop 9579 Loss_Train:  [[ 13.19524956]] Loss_Validation:  [[ 11.05121539]]\n",
      "Loop 9580 Loss_Train:  [[ 13.19524956]] Loss_Validation:  [[ 11.05121617]]\n",
      "Loop 9581 Loss_Train:  [[ 13.19524956]] Loss_Validation:  [[ 11.05121695]]\n",
      "Loop 9582 Loss_Train:  [[ 13.19524956]] Loss_Validation:  [[ 11.05121773]]\n",
      "Loop 9583 Loss_Train:  [[ 13.19524956]] Loss_Validation:  [[ 11.05121851]]\n",
      "Loop 9584 Loss_Train:  [[ 13.19524956]] Loss_Validation:  [[ 11.05121929]]\n",
      "Loop 9585 Loss_Train:  [[ 13.19524955]] Loss_Validation:  [[ 11.05122007]]\n",
      "Loop 9586 Loss_Train:  [[ 13.19524955]] Loss_Validation:  [[ 11.05122085]]\n",
      "Loop 9587 Loss_Train:  [[ 13.19524955]] Loss_Validation:  [[ 11.05122162]]\n",
      "Loop 9588 Loss_Train:  [[ 13.19524955]] Loss_Validation:  [[ 11.0512224]]\n",
      "Loop 9589 Loss_Train:  [[ 13.19524955]] Loss_Validation:  [[ 11.05122318]]\n",
      "Loop 9590 Loss_Train:  [[ 13.19524955]] Loss_Validation:  [[ 11.05122395]]\n",
      "Loop 9591 Loss_Train:  [[ 13.19524954]] Loss_Validation:  [[ 11.05122473]]\n",
      "Loop 9592 Loss_Train:  [[ 13.19524954]] Loss_Validation:  [[ 11.0512255]]\n",
      "Loop 9593 Loss_Train:  [[ 13.19524954]] Loss_Validation:  [[ 11.05122628]]\n",
      "Loop 9594 Loss_Train:  [[ 13.19524954]] Loss_Validation:  [[ 11.05122705]]\n",
      "Loop 9595 Loss_Train:  [[ 13.19524954]] Loss_Validation:  [[ 11.05122782]]\n",
      "Loop 9596 Loss_Train:  [[ 13.19524954]] Loss_Validation:  [[ 11.05122859]]\n",
      "Loop 9597 Loss_Train:  [[ 13.19524954]] Loss_Validation:  [[ 11.05122937]]\n",
      "Loop 9598 Loss_Train:  [[ 13.19524953]] Loss_Validation:  [[ 11.05123014]]\n",
      "Loop 9599 Loss_Train:  [[ 13.19524953]] Loss_Validation:  [[ 11.05123091]]\n",
      "Loop 9600 Loss_Train:  [[ 13.19524953]] Loss_Validation:  [[ 11.05123168]]\n",
      "Loop 9601 Loss_Train:  [[ 13.19524953]] Loss_Validation:  [[ 11.05123245]]\n",
      "Loop 9602 Loss_Train:  [[ 13.19524953]] Loss_Validation:  [[ 11.05123322]]\n",
      "Loop 9603 Loss_Train:  [[ 13.19524953]] Loss_Validation:  [[ 11.05123399]]\n",
      "Loop 9604 Loss_Train:  [[ 13.19524953]] Loss_Validation:  [[ 11.05123475]]\n",
      "Loop 9605 Loss_Train:  [[ 13.19524952]] Loss_Validation:  [[ 11.05123552]]\n",
      "Loop 9606 Loss_Train:  [[ 13.19524952]] Loss_Validation:  [[ 11.05123629]]\n",
      "Loop 9607 Loss_Train:  [[ 13.19524952]] Loss_Validation:  [[ 11.05123705]]\n",
      "Loop 9608 Loss_Train:  [[ 13.19524952]] Loss_Validation:  [[ 11.05123782]]\n",
      "Loop 9609 Loss_Train:  [[ 13.19524952]] Loss_Validation:  [[ 11.05123859]]\n",
      "Loop 9610 Loss_Train:  [[ 13.19524952]] Loss_Validation:  [[ 11.05123935]]\n",
      "Loop 9611 Loss_Train:  [[ 13.19524952]] Loss_Validation:  [[ 11.05124011]]\n",
      "Loop 9612 Loss_Train:  [[ 13.19524951]] Loss_Validation:  [[ 11.05124088]]\n",
      "Loop 9613 Loss_Train:  [[ 13.19524951]] Loss_Validation:  [[ 11.05124164]]\n",
      "Loop 9614 Loss_Train:  [[ 13.19524951]] Loss_Validation:  [[ 11.0512424]]\n",
      "Loop 9615 Loss_Train:  [[ 13.19524951]] Loss_Validation:  [[ 11.05124317]]\n",
      "Loop 9616 Loss_Train:  [[ 13.19524951]] Loss_Validation:  [[ 11.05124393]]\n",
      "Loop 9617 Loss_Train:  [[ 13.19524951]] Loss_Validation:  [[ 11.05124469]]\n",
      "Loop 9618 Loss_Train:  [[ 13.19524951]] Loss_Validation:  [[ 11.05124545]]\n",
      "Loop 9619 Loss_Train:  [[ 13.1952495]] Loss_Validation:  [[ 11.05124621]]\n",
      "Loop 9620 Loss_Train:  [[ 13.1952495]] Loss_Validation:  [[ 11.05124697]]\n",
      "Loop 9621 Loss_Train:  [[ 13.1952495]] Loss_Validation:  [[ 11.05124773]]\n",
      "Loop 9622 Loss_Train:  [[ 13.1952495]] Loss_Validation:  [[ 11.05124849]]\n",
      "Loop 9623 Loss_Train:  [[ 13.1952495]] Loss_Validation:  [[ 11.05124925]]\n",
      "Loop 9624 Loss_Train:  [[ 13.1952495]] Loss_Validation:  [[ 11.05125]]\n",
      "Loop 9625 Loss_Train:  [[ 13.1952495]] Loss_Validation:  [[ 11.05125076]]\n",
      "Loop 9626 Loss_Train:  [[ 13.19524949]] Loss_Validation:  [[ 11.05125152]]\n",
      "Loop 9627 Loss_Train:  [[ 13.19524949]] Loss_Validation:  [[ 11.05125227]]\n",
      "Loop 9628 Loss_Train:  [[ 13.19524949]] Loss_Validation:  [[ 11.05125303]]\n",
      "Loop 9629 Loss_Train:  [[ 13.19524949]] Loss_Validation:  [[ 11.05125378]]\n",
      "Loop 9630 Loss_Train:  [[ 13.19524949]] Loss_Validation:  [[ 11.05125454]]\n",
      "Loop 9631 Loss_Train:  [[ 13.19524949]] Loss_Validation:  [[ 11.05125529]]\n",
      "Loop 9632 Loss_Train:  [[ 13.19524949]] Loss_Validation:  [[ 11.05125604]]\n",
      "Loop 9633 Loss_Train:  [[ 13.19524948]] Loss_Validation:  [[ 11.0512568]]\n",
      "Loop 9634 Loss_Train:  [[ 13.19524948]] Loss_Validation:  [[ 11.05125755]]\n",
      "Loop 9635 Loss_Train:  [[ 13.19524948]] Loss_Validation:  [[ 11.0512583]]\n",
      "Loop 9636 Loss_Train:  [[ 13.19524948]] Loss_Validation:  [[ 11.05125905]]\n",
      "Loop 9637 Loss_Train:  [[ 13.19524948]] Loss_Validation:  [[ 11.0512598]]\n",
      "Loop 9638 Loss_Train:  [[ 13.19524948]] Loss_Validation:  [[ 11.05126055]]\n",
      "Loop 9639 Loss_Train:  [[ 13.19524948]] Loss_Validation:  [[ 11.0512613]]\n",
      "Loop 9640 Loss_Train:  [[ 13.19524948]] Loss_Validation:  [[ 11.05126205]]\n",
      "Loop 9641 Loss_Train:  [[ 13.19524947]] Loss_Validation:  [[ 11.0512628]]\n",
      "Loop 9642 Loss_Train:  [[ 13.19524947]] Loss_Validation:  [[ 11.05126355]]\n",
      "Loop 9643 Loss_Train:  [[ 13.19524947]] Loss_Validation:  [[ 11.0512643]]\n",
      "Loop 9644 Loss_Train:  [[ 13.19524947]] Loss_Validation:  [[ 11.05126504]]\n",
      "Loop 9645 Loss_Train:  [[ 13.19524947]] Loss_Validation:  [[ 11.05126579]]\n",
      "Loop 9646 Loss_Train:  [[ 13.19524947]] Loss_Validation:  [[ 11.05126654]]\n",
      "Loop 9647 Loss_Train:  [[ 13.19524947]] Loss_Validation:  [[ 11.05126728]]\n",
      "Loop 9648 Loss_Train:  [[ 13.19524946]] Loss_Validation:  [[ 11.05126803]]\n",
      "Loop 9649 Loss_Train:  [[ 13.19524946]] Loss_Validation:  [[ 11.05126877]]\n",
      "Loop 9650 Loss_Train:  [[ 13.19524946]] Loss_Validation:  [[ 11.05126951]]\n",
      "Loop 9651 Loss_Train:  [[ 13.19524946]] Loss_Validation:  [[ 11.05127026]]\n",
      "Loop 9652 Loss_Train:  [[ 13.19524946]] Loss_Validation:  [[ 11.051271]]\n",
      "Loop 9653 Loss_Train:  [[ 13.19524946]] Loss_Validation:  [[ 11.05127174]]\n",
      "Loop 9654 Loss_Train:  [[ 13.19524946]] Loss_Validation:  [[ 11.05127248]]\n",
      "Loop 9655 Loss_Train:  [[ 13.19524945]] Loss_Validation:  [[ 11.05127323]]\n",
      "Loop 9656 Loss_Train:  [[ 13.19524945]] Loss_Validation:  [[ 11.05127397]]\n",
      "Loop 9657 Loss_Train:  [[ 13.19524945]] Loss_Validation:  [[ 11.05127471]]\n",
      "Loop 9658 Loss_Train:  [[ 13.19524945]] Loss_Validation:  [[ 11.05127545]]\n",
      "Loop 9659 Loss_Train:  [[ 13.19524945]] Loss_Validation:  [[ 11.05127619]]\n",
      "Loop 9660 Loss_Train:  [[ 13.19524945]] Loss_Validation:  [[ 11.05127692]]\n",
      "Loop 9661 Loss_Train:  [[ 13.19524945]] Loss_Validation:  [[ 11.05127766]]\n",
      "Loop 9662 Loss_Train:  [[ 13.19524945]] Loss_Validation:  [[ 11.0512784]]\n",
      "Loop 9663 Loss_Train:  [[ 13.19524944]] Loss_Validation:  [[ 11.05127914]]\n",
      "Loop 9664 Loss_Train:  [[ 13.19524944]] Loss_Validation:  [[ 11.05127987]]\n",
      "Loop 9665 Loss_Train:  [[ 13.19524944]] Loss_Validation:  [[ 11.05128061]]\n",
      "Loop 9666 Loss_Train:  [[ 13.19524944]] Loss_Validation:  [[ 11.05128135]]\n",
      "Loop 9667 Loss_Train:  [[ 13.19524944]] Loss_Validation:  [[ 11.05128208]]\n",
      "Loop 9668 Loss_Train:  [[ 13.19524944]] Loss_Validation:  [[ 11.05128282]]\n",
      "Loop 9669 Loss_Train:  [[ 13.19524944]] Loss_Validation:  [[ 11.05128355]]\n",
      "Loop 9670 Loss_Train:  [[ 13.19524943]] Loss_Validation:  [[ 11.05128428]]\n",
      "Loop 9671 Loss_Train:  [[ 13.19524943]] Loss_Validation:  [[ 11.05128502]]\n",
      "Loop 9672 Loss_Train:  [[ 13.19524943]] Loss_Validation:  [[ 11.05128575]]\n",
      "Loop 9673 Loss_Train:  [[ 13.19524943]] Loss_Validation:  [[ 11.05128648]]\n",
      "Loop 9674 Loss_Train:  [[ 13.19524943]] Loss_Validation:  [[ 11.05128721]]\n",
      "Loop 9675 Loss_Train:  [[ 13.19524943]] Loss_Validation:  [[ 11.05128794]]\n",
      "Loop 9676 Loss_Train:  [[ 13.19524943]] Loss_Validation:  [[ 11.05128868]]\n",
      "Loop 9677 Loss_Train:  [[ 13.19524943]] Loss_Validation:  [[ 11.05128941]]\n",
      "Loop 9678 Loss_Train:  [[ 13.19524942]] Loss_Validation:  [[ 11.05129013]]\n",
      "Loop 9679 Loss_Train:  [[ 13.19524942]] Loss_Validation:  [[ 11.05129086]]\n",
      "Loop 9680 Loss_Train:  [[ 13.19524942]] Loss_Validation:  [[ 11.05129159]]\n",
      "Loop 9681 Loss_Train:  [[ 13.19524942]] Loss_Validation:  [[ 11.05129232]]\n",
      "Loop 9682 Loss_Train:  [[ 13.19524942]] Loss_Validation:  [[ 11.05129305]]\n",
      "Loop 9683 Loss_Train:  [[ 13.19524942]] Loss_Validation:  [[ 11.05129377]]\n",
      "Loop 9684 Loss_Train:  [[ 13.19524942]] Loss_Validation:  [[ 11.0512945]]\n",
      "Loop 9685 Loss_Train:  [[ 13.19524942]] Loss_Validation:  [[ 11.05129523]]\n",
      "Loop 9686 Loss_Train:  [[ 13.19524941]] Loss_Validation:  [[ 11.05129595]]\n",
      "Loop 9687 Loss_Train:  [[ 13.19524941]] Loss_Validation:  [[ 11.05129668]]\n",
      "Loop 9688 Loss_Train:  [[ 13.19524941]] Loss_Validation:  [[ 11.0512974]]\n",
      "Loop 9689 Loss_Train:  [[ 13.19524941]] Loss_Validation:  [[ 11.05129813]]\n",
      "Loop 9690 Loss_Train:  [[ 13.19524941]] Loss_Validation:  [[ 11.05129885]]\n",
      "Loop 9691 Loss_Train:  [[ 13.19524941]] Loss_Validation:  [[ 11.05129957]]\n",
      "Loop 9692 Loss_Train:  [[ 13.19524941]] Loss_Validation:  [[ 11.0513003]]\n",
      "Loop 9693 Loss_Train:  [[ 13.19524941]] Loss_Validation:  [[ 11.05130102]]\n",
      "Loop 9694 Loss_Train:  [[ 13.1952494]] Loss_Validation:  [[ 11.05130174]]\n",
      "Loop 9695 Loss_Train:  [[ 13.1952494]] Loss_Validation:  [[ 11.05130246]]\n",
      "Loop 9696 Loss_Train:  [[ 13.1952494]] Loss_Validation:  [[ 11.05130318]]\n",
      "Loop 9697 Loss_Train:  [[ 13.1952494]] Loss_Validation:  [[ 11.0513039]]\n",
      "Loop 9698 Loss_Train:  [[ 13.1952494]] Loss_Validation:  [[ 11.05130462]]\n",
      "Loop 9699 Loss_Train:  [[ 13.1952494]] Loss_Validation:  [[ 11.05130534]]\n",
      "Loop 9700 Loss_Train:  [[ 13.1952494]] Loss_Validation:  [[ 11.05130606]]\n",
      "Loop 9701 Loss_Train:  [[ 13.19524939]] Loss_Validation:  [[ 11.05130678]]\n",
      "Loop 9702 Loss_Train:  [[ 13.19524939]] Loss_Validation:  [[ 11.05130749]]\n",
      "Loop 9703 Loss_Train:  [[ 13.19524939]] Loss_Validation:  [[ 11.05130821]]\n",
      "Loop 9704 Loss_Train:  [[ 13.19524939]] Loss_Validation:  [[ 11.05130893]]\n",
      "Loop 9705 Loss_Train:  [[ 13.19524939]] Loss_Validation:  [[ 11.05130964]]\n",
      "Loop 9706 Loss_Train:  [[ 13.19524939]] Loss_Validation:  [[ 11.05131036]]\n",
      "Loop 9707 Loss_Train:  [[ 13.19524939]] Loss_Validation:  [[ 11.05131107]]\n",
      "Loop 9708 Loss_Train:  [[ 13.19524939]] Loss_Validation:  [[ 11.05131179]]\n",
      "Loop 9709 Loss_Train:  [[ 13.19524938]] Loss_Validation:  [[ 11.0513125]]\n",
      "Loop 9710 Loss_Train:  [[ 13.19524938]] Loss_Validation:  [[ 11.05131321]]\n",
      "Loop 9711 Loss_Train:  [[ 13.19524938]] Loss_Validation:  [[ 11.05131393]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 9712 Loss_Train:  [[ 13.19524938]] Loss_Validation:  [[ 11.05131464]]\n",
      "Loop 9713 Loss_Train:  [[ 13.19524938]] Loss_Validation:  [[ 11.05131535]]\n",
      "Loop 9714 Loss_Train:  [[ 13.19524938]] Loss_Validation:  [[ 11.05131606]]\n",
      "Loop 9715 Loss_Train:  [[ 13.19524938]] Loss_Validation:  [[ 11.05131678]]\n",
      "Loop 9716 Loss_Train:  [[ 13.19524938]] Loss_Validation:  [[ 11.05131749]]\n",
      "Loop 9717 Loss_Train:  [[ 13.19524938]] Loss_Validation:  [[ 11.0513182]]\n",
      "Loop 9718 Loss_Train:  [[ 13.19524937]] Loss_Validation:  [[ 11.05131891]]\n",
      "Loop 9719 Loss_Train:  [[ 13.19524937]] Loss_Validation:  [[ 11.05131961]]\n",
      "Loop 9720 Loss_Train:  [[ 13.19524937]] Loss_Validation:  [[ 11.05132032]]\n",
      "Loop 9721 Loss_Train:  [[ 13.19524937]] Loss_Validation:  [[ 11.05132103]]\n",
      "Loop 9722 Loss_Train:  [[ 13.19524937]] Loss_Validation:  [[ 11.05132174]]\n",
      "Loop 9723 Loss_Train:  [[ 13.19524937]] Loss_Validation:  [[ 11.05132245]]\n",
      "Loop 9724 Loss_Train:  [[ 13.19524937]] Loss_Validation:  [[ 11.05132315]]\n",
      "Loop 9725 Loss_Train:  [[ 13.19524937]] Loss_Validation:  [[ 11.05132386]]\n",
      "Loop 9726 Loss_Train:  [[ 13.19524936]] Loss_Validation:  [[ 11.05132456]]\n",
      "Loop 9727 Loss_Train:  [[ 13.19524936]] Loss_Validation:  [[ 11.05132527]]\n",
      "Loop 9728 Loss_Train:  [[ 13.19524936]] Loss_Validation:  [[ 11.05132597]]\n",
      "Loop 9729 Loss_Train:  [[ 13.19524936]] Loss_Validation:  [[ 11.05132668]]\n",
      "Loop 9730 Loss_Train:  [[ 13.19524936]] Loss_Validation:  [[ 11.05132738]]\n",
      "Loop 9731 Loss_Train:  [[ 13.19524936]] Loss_Validation:  [[ 11.05132808]]\n",
      "Loop 9732 Loss_Train:  [[ 13.19524936]] Loss_Validation:  [[ 11.05132879]]\n",
      "Loop 9733 Loss_Train:  [[ 13.19524936]] Loss_Validation:  [[ 11.05132949]]\n",
      "Loop 9734 Loss_Train:  [[ 13.19524935]] Loss_Validation:  [[ 11.05133019]]\n",
      "Loop 9735 Loss_Train:  [[ 13.19524935]] Loss_Validation:  [[ 11.05133089]]\n",
      "Loop 9736 Loss_Train:  [[ 13.19524935]] Loss_Validation:  [[ 11.05133159]]\n",
      "Loop 9737 Loss_Train:  [[ 13.19524935]] Loss_Validation:  [[ 11.05133229]]\n",
      "Loop 9738 Loss_Train:  [[ 13.19524935]] Loss_Validation:  [[ 11.05133299]]\n",
      "Loop 9739 Loss_Train:  [[ 13.19524935]] Loss_Validation:  [[ 11.05133369]]\n",
      "Loop 9740 Loss_Train:  [[ 13.19524935]] Loss_Validation:  [[ 11.05133439]]\n",
      "Loop 9741 Loss_Train:  [[ 13.19524935]] Loss_Validation:  [[ 11.05133509]]\n",
      "Loop 9742 Loss_Train:  [[ 13.19524934]] Loss_Validation:  [[ 11.05133579]]\n",
      "Loop 9743 Loss_Train:  [[ 13.19524934]] Loss_Validation:  [[ 11.05133648]]\n",
      "Loop 9744 Loss_Train:  [[ 13.19524934]] Loss_Validation:  [[ 11.05133718]]\n",
      "Loop 9745 Loss_Train:  [[ 13.19524934]] Loss_Validation:  [[ 11.05133788]]\n",
      "Loop 9746 Loss_Train:  [[ 13.19524934]] Loss_Validation:  [[ 11.05133857]]\n",
      "Loop 9747 Loss_Train:  [[ 13.19524934]] Loss_Validation:  [[ 11.05133927]]\n",
      "Loop 9748 Loss_Train:  [[ 13.19524934]] Loss_Validation:  [[ 11.05133996]]\n",
      "Loop 9749 Loss_Train:  [[ 13.19524934]] Loss_Validation:  [[ 11.05134066]]\n",
      "Loop 9750 Loss_Train:  [[ 13.19524934]] Loss_Validation:  [[ 11.05134135]]\n",
      "Loop 9751 Loss_Train:  [[ 13.19524933]] Loss_Validation:  [[ 11.05134205]]\n",
      "Loop 9752 Loss_Train:  [[ 13.19524933]] Loss_Validation:  [[ 11.05134274]]\n",
      "Loop 9753 Loss_Train:  [[ 13.19524933]] Loss_Validation:  [[ 11.05134343]]\n",
      "Loop 9754 Loss_Train:  [[ 13.19524933]] Loss_Validation:  [[ 11.05134412]]\n",
      "Loop 9755 Loss_Train:  [[ 13.19524933]] Loss_Validation:  [[ 11.05134481]]\n",
      "Loop 9756 Loss_Train:  [[ 13.19524933]] Loss_Validation:  [[ 11.05134551]]\n",
      "Loop 9757 Loss_Train:  [[ 13.19524933]] Loss_Validation:  [[ 11.0513462]]\n",
      "Loop 9758 Loss_Train:  [[ 13.19524933]] Loss_Validation:  [[ 11.05134689]]\n",
      "Loop 9759 Loss_Train:  [[ 13.19524932]] Loss_Validation:  [[ 11.05134758]]\n",
      "Loop 9760 Loss_Train:  [[ 13.19524932]] Loss_Validation:  [[ 11.05134827]]\n",
      "Loop 9761 Loss_Train:  [[ 13.19524932]] Loss_Validation:  [[ 11.05134895]]\n",
      "Loop 9762 Loss_Train:  [[ 13.19524932]] Loss_Validation:  [[ 11.05134964]]\n",
      "Loop 9763 Loss_Train:  [[ 13.19524932]] Loss_Validation:  [[ 11.05135033]]\n",
      "Loop 9764 Loss_Train:  [[ 13.19524932]] Loss_Validation:  [[ 11.05135102]]\n",
      "Loop 9765 Loss_Train:  [[ 13.19524932]] Loss_Validation:  [[ 11.0513517]]\n",
      "Loop 9766 Loss_Train:  [[ 13.19524932]] Loss_Validation:  [[ 11.05135239]]\n",
      "Loop 9767 Loss_Train:  [[ 13.19524932]] Loss_Validation:  [[ 11.05135308]]\n",
      "Loop 9768 Loss_Train:  [[ 13.19524931]] Loss_Validation:  [[ 11.05135376]]\n",
      "Loop 9769 Loss_Train:  [[ 13.19524931]] Loss_Validation:  [[ 11.05135445]]\n",
      "Loop 9770 Loss_Train:  [[ 13.19524931]] Loss_Validation:  [[ 11.05135513]]\n",
      "Loop 9771 Loss_Train:  [[ 13.19524931]] Loss_Validation:  [[ 11.05135581]]\n",
      "Loop 9772 Loss_Train:  [[ 13.19524931]] Loss_Validation:  [[ 11.0513565]]\n",
      "Loop 9773 Loss_Train:  [[ 13.19524931]] Loss_Validation:  [[ 11.05135718]]\n",
      "Loop 9774 Loss_Train:  [[ 13.19524931]] Loss_Validation:  [[ 11.05135786]]\n",
      "Loop 9775 Loss_Train:  [[ 13.19524931]] Loss_Validation:  [[ 11.05135854]]\n",
      "Loop 9776 Loss_Train:  [[ 13.19524931]] Loss_Validation:  [[ 11.05135923]]\n",
      "Loop 9777 Loss_Train:  [[ 13.1952493]] Loss_Validation:  [[ 11.05135991]]\n",
      "Loop 9778 Loss_Train:  [[ 13.1952493]] Loss_Validation:  [[ 11.05136059]]\n",
      "Loop 9779 Loss_Train:  [[ 13.1952493]] Loss_Validation:  [[ 11.05136127]]\n",
      "Loop 9780 Loss_Train:  [[ 13.1952493]] Loss_Validation:  [[ 11.05136195]]\n",
      "Loop 9781 Loss_Train:  [[ 13.1952493]] Loss_Validation:  [[ 11.05136263]]\n",
      "Loop 9782 Loss_Train:  [[ 13.1952493]] Loss_Validation:  [[ 11.05136331]]\n",
      "Loop 9783 Loss_Train:  [[ 13.1952493]] Loss_Validation:  [[ 11.05136398]]\n",
      "Loop 9784 Loss_Train:  [[ 13.1952493]] Loss_Validation:  [[ 11.05136466]]\n",
      "Loop 9785 Loss_Train:  [[ 13.1952493]] Loss_Validation:  [[ 11.05136534]]\n",
      "Loop 9786 Loss_Train:  [[ 13.19524929]] Loss_Validation:  [[ 11.05136602]]\n",
      "Loop 9787 Loss_Train:  [[ 13.19524929]] Loss_Validation:  [[ 11.05136669]]\n",
      "Loop 9788 Loss_Train:  [[ 13.19524929]] Loss_Validation:  [[ 11.05136737]]\n",
      "Loop 9789 Loss_Train:  [[ 13.19524929]] Loss_Validation:  [[ 11.05136804]]\n",
      "Loop 9790 Loss_Train:  [[ 13.19524929]] Loss_Validation:  [[ 11.05136872]]\n",
      "Loop 9791 Loss_Train:  [[ 13.19524929]] Loss_Validation:  [[ 11.05136939]]\n",
      "Loop 9792 Loss_Train:  [[ 13.19524929]] Loss_Validation:  [[ 11.05137007]]\n",
      "Loop 9793 Loss_Train:  [[ 13.19524929]] Loss_Validation:  [[ 11.05137074]]\n",
      "Loop 9794 Loss_Train:  [[ 13.19524929]] Loss_Validation:  [[ 11.05137141]]\n",
      "Loop 9795 Loss_Train:  [[ 13.19524928]] Loss_Validation:  [[ 11.05137208]]\n",
      "Loop 9796 Loss_Train:  [[ 13.19524928]] Loss_Validation:  [[ 11.05137276]]\n",
      "Loop 9797 Loss_Train:  [[ 13.19524928]] Loss_Validation:  [[ 11.05137343]]\n",
      "Loop 9798 Loss_Train:  [[ 13.19524928]] Loss_Validation:  [[ 11.0513741]]\n",
      "Loop 9799 Loss_Train:  [[ 13.19524928]] Loss_Validation:  [[ 11.05137477]]\n",
      "Loop 9800 Loss_Train:  [[ 13.19524928]] Loss_Validation:  [[ 11.05137544]]\n",
      "Loop 9801 Loss_Train:  [[ 13.19524928]] Loss_Validation:  [[ 11.05137611]]\n",
      "Loop 9802 Loss_Train:  [[ 13.19524928]] Loss_Validation:  [[ 11.05137678]]\n",
      "Loop 9803 Loss_Train:  [[ 13.19524928]] Loss_Validation:  [[ 11.05137745]]\n",
      "Loop 9804 Loss_Train:  [[ 13.19524927]] Loss_Validation:  [[ 11.05137812]]\n",
      "Loop 9805 Loss_Train:  [[ 13.19524927]] Loss_Validation:  [[ 11.05137878]]\n",
      "Loop 9806 Loss_Train:  [[ 13.19524927]] Loss_Validation:  [[ 11.05137945]]\n",
      "Loop 9807 Loss_Train:  [[ 13.19524927]] Loss_Validation:  [[ 11.05138012]]\n",
      "Loop 9808 Loss_Train:  [[ 13.19524927]] Loss_Validation:  [[ 11.05138079]]\n",
      "Loop 9809 Loss_Train:  [[ 13.19524927]] Loss_Validation:  [[ 11.05138145]]\n",
      "Loop 9810 Loss_Train:  [[ 13.19524927]] Loss_Validation:  [[ 11.05138212]]\n",
      "Loop 9811 Loss_Train:  [[ 13.19524927]] Loss_Validation:  [[ 11.05138278]]\n",
      "Loop 9812 Loss_Train:  [[ 13.19524927]] Loss_Validation:  [[ 11.05138345]]\n",
      "Loop 9813 Loss_Train:  [[ 13.19524926]] Loss_Validation:  [[ 11.05138411]]\n",
      "Loop 9814 Loss_Train:  [[ 13.19524926]] Loss_Validation:  [[ 11.05138477]]\n",
      "Loop 9815 Loss_Train:  [[ 13.19524926]] Loss_Validation:  [[ 11.05138544]]\n",
      "Loop 9816 Loss_Train:  [[ 13.19524926]] Loss_Validation:  [[ 11.0513861]]\n",
      "Loop 9817 Loss_Train:  [[ 13.19524926]] Loss_Validation:  [[ 11.05138676]]\n",
      "Loop 9818 Loss_Train:  [[ 13.19524926]] Loss_Validation:  [[ 11.05138743]]\n",
      "Loop 9819 Loss_Train:  [[ 13.19524926]] Loss_Validation:  [[ 11.05138809]]\n",
      "Loop 9820 Loss_Train:  [[ 13.19524926]] Loss_Validation:  [[ 11.05138875]]\n",
      "Loop 9821 Loss_Train:  [[ 13.19524926]] Loss_Validation:  [[ 11.05138941]]\n",
      "Loop 9822 Loss_Train:  [[ 13.19524926]] Loss_Validation:  [[ 11.05139007]]\n",
      "Loop 9823 Loss_Train:  [[ 13.19524925]] Loss_Validation:  [[ 11.05139073]]\n",
      "Loop 9824 Loss_Train:  [[ 13.19524925]] Loss_Validation:  [[ 11.05139139]]\n",
      "Loop 9825 Loss_Train:  [[ 13.19524925]] Loss_Validation:  [[ 11.05139205]]\n",
      "Loop 9826 Loss_Train:  [[ 13.19524925]] Loss_Validation:  [[ 11.0513927]]\n",
      "Loop 9827 Loss_Train:  [[ 13.19524925]] Loss_Validation:  [[ 11.05139336]]\n",
      "Loop 9828 Loss_Train:  [[ 13.19524925]] Loss_Validation:  [[ 11.05139402]]\n",
      "Loop 9829 Loss_Train:  [[ 13.19524925]] Loss_Validation:  [[ 11.05139468]]\n",
      "Loop 9830 Loss_Train:  [[ 13.19524925]] Loss_Validation:  [[ 11.05139533]]\n",
      "Loop 9831 Loss_Train:  [[ 13.19524925]] Loss_Validation:  [[ 11.05139599]]\n",
      "Loop 9832 Loss_Train:  [[ 13.19524924]] Loss_Validation:  [[ 11.05139664]]\n",
      "Loop 9833 Loss_Train:  [[ 13.19524924]] Loss_Validation:  [[ 11.0513973]]\n",
      "Loop 9834 Loss_Train:  [[ 13.19524924]] Loss_Validation:  [[ 11.05139795]]\n",
      "Loop 9835 Loss_Train:  [[ 13.19524924]] Loss_Validation:  [[ 11.05139861]]\n",
      "Loop 9836 Loss_Train:  [[ 13.19524924]] Loss_Validation:  [[ 11.05139926]]\n",
      "Loop 9837 Loss_Train:  [[ 13.19524924]] Loss_Validation:  [[ 11.05139991]]\n",
      "Loop 9838 Loss_Train:  [[ 13.19524924]] Loss_Validation:  [[ 11.05140057]]\n",
      "Loop 9839 Loss_Train:  [[ 13.19524924]] Loss_Validation:  [[ 11.05140122]]\n",
      "Loop 9840 Loss_Train:  [[ 13.19524924]] Loss_Validation:  [[ 11.05140187]]\n",
      "Loop 9841 Loss_Train:  [[ 13.19524924]] Loss_Validation:  [[ 11.05140252]]\n",
      "Loop 9842 Loss_Train:  [[ 13.19524923]] Loss_Validation:  [[ 11.05140317]]\n",
      "Loop 9843 Loss_Train:  [[ 13.19524923]] Loss_Validation:  [[ 11.05140382]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 9844 Loss_Train:  [[ 13.19524923]] Loss_Validation:  [[ 11.05140447]]\n",
      "Loop 9845 Loss_Train:  [[ 13.19524923]] Loss_Validation:  [[ 11.05140512]]\n",
      "Loop 9846 Loss_Train:  [[ 13.19524923]] Loss_Validation:  [[ 11.05140577]]\n",
      "Loop 9847 Loss_Train:  [[ 13.19524923]] Loss_Validation:  [[ 11.05140642]]\n",
      "Loop 9848 Loss_Train:  [[ 13.19524923]] Loss_Validation:  [[ 11.05140707]]\n",
      "Loop 9849 Loss_Train:  [[ 13.19524923]] Loss_Validation:  [[ 11.05140772]]\n",
      "Loop 9850 Loss_Train:  [[ 13.19524923]] Loss_Validation:  [[ 11.05140836]]\n",
      "Loop 9851 Loss_Train:  [[ 13.19524923]] Loss_Validation:  [[ 11.05140901]]\n",
      "Loop 9852 Loss_Train:  [[ 13.19524922]] Loss_Validation:  [[ 11.05140966]]\n",
      "Loop 9853 Loss_Train:  [[ 13.19524922]] Loss_Validation:  [[ 11.0514103]]\n",
      "Loop 9854 Loss_Train:  [[ 13.19524922]] Loss_Validation:  [[ 11.05141095]]\n",
      "Loop 9855 Loss_Train:  [[ 13.19524922]] Loss_Validation:  [[ 11.05141159]]\n",
      "Loop 9856 Loss_Train:  [[ 13.19524922]] Loss_Validation:  [[ 11.05141224]]\n",
      "Loop 9857 Loss_Train:  [[ 13.19524922]] Loss_Validation:  [[ 11.05141288]]\n",
      "Loop 9858 Loss_Train:  [[ 13.19524922]] Loss_Validation:  [[ 11.05141353]]\n",
      "Loop 9859 Loss_Train:  [[ 13.19524922]] Loss_Validation:  [[ 11.05141417]]\n",
      "Loop 9860 Loss_Train:  [[ 13.19524922]] Loss_Validation:  [[ 11.05141481]]\n",
      "Loop 9861 Loss_Train:  [[ 13.19524922]] Loss_Validation:  [[ 11.05141545]]\n",
      "Loop 9862 Loss_Train:  [[ 13.19524921]] Loss_Validation:  [[ 11.0514161]]\n",
      "Loop 9863 Loss_Train:  [[ 13.19524921]] Loss_Validation:  [[ 11.05141674]]\n",
      "Loop 9864 Loss_Train:  [[ 13.19524921]] Loss_Validation:  [[ 11.05141738]]\n",
      "Loop 9865 Loss_Train:  [[ 13.19524921]] Loss_Validation:  [[ 11.05141802]]\n",
      "Loop 9866 Loss_Train:  [[ 13.19524921]] Loss_Validation:  [[ 11.05141866]]\n",
      "Loop 9867 Loss_Train:  [[ 13.19524921]] Loss_Validation:  [[ 11.0514193]]\n",
      "Loop 9868 Loss_Train:  [[ 13.19524921]] Loss_Validation:  [[ 11.05141994]]\n",
      "Loop 9869 Loss_Train:  [[ 13.19524921]] Loss_Validation:  [[ 11.05142058]]\n",
      "Loop 9870 Loss_Train:  [[ 13.19524921]] Loss_Validation:  [[ 11.05142122]]\n",
      "Loop 9871 Loss_Train:  [[ 13.19524921]] Loss_Validation:  [[ 11.05142185]]\n",
      "Loop 9872 Loss_Train:  [[ 13.1952492]] Loss_Validation:  [[ 11.05142249]]\n",
      "Loop 9873 Loss_Train:  [[ 13.1952492]] Loss_Validation:  [[ 11.05142313]]\n",
      "Loop 9874 Loss_Train:  [[ 13.1952492]] Loss_Validation:  [[ 11.05142376]]\n",
      "Loop 9875 Loss_Train:  [[ 13.1952492]] Loss_Validation:  [[ 11.0514244]]\n",
      "Loop 9876 Loss_Train:  [[ 13.1952492]] Loss_Validation:  [[ 11.05142504]]\n",
      "Loop 9877 Loss_Train:  [[ 13.1952492]] Loss_Validation:  [[ 11.05142567]]\n",
      "Loop 9878 Loss_Train:  [[ 13.1952492]] Loss_Validation:  [[ 11.05142631]]\n",
      "Loop 9879 Loss_Train:  [[ 13.1952492]] Loss_Validation:  [[ 11.05142694]]\n",
      "Loop 9880 Loss_Train:  [[ 13.1952492]] Loss_Validation:  [[ 11.05142758]]\n",
      "Loop 9881 Loss_Train:  [[ 13.1952492]] Loss_Validation:  [[ 11.05142821]]\n",
      "Loop 9882 Loss_Train:  [[ 13.19524919]] Loss_Validation:  [[ 11.05142884]]\n",
      "Loop 9883 Loss_Train:  [[ 13.19524919]] Loss_Validation:  [[ 11.05142947]]\n",
      "Loop 9884 Loss_Train:  [[ 13.19524919]] Loss_Validation:  [[ 11.05143011]]\n",
      "Loop 9885 Loss_Train:  [[ 13.19524919]] Loss_Validation:  [[ 11.05143074]]\n",
      "Loop 9886 Loss_Train:  [[ 13.19524919]] Loss_Validation:  [[ 11.05143137]]\n",
      "Loop 9887 Loss_Train:  [[ 13.19524919]] Loss_Validation:  [[ 11.051432]]\n",
      "Loop 9888 Loss_Train:  [[ 13.19524919]] Loss_Validation:  [[ 11.05143263]]\n",
      "Loop 9889 Loss_Train:  [[ 13.19524919]] Loss_Validation:  [[ 11.05143326]]\n",
      "Loop 9890 Loss_Train:  [[ 13.19524919]] Loss_Validation:  [[ 11.05143389]]\n",
      "Loop 9891 Loss_Train:  [[ 13.19524919]] Loss_Validation:  [[ 11.05143452]]\n",
      "Loop 9892 Loss_Train:  [[ 13.19524918]] Loss_Validation:  [[ 11.05143515]]\n",
      "Loop 9893 Loss_Train:  [[ 13.19524918]] Loss_Validation:  [[ 11.05143578]]\n",
      "Loop 9894 Loss_Train:  [[ 13.19524918]] Loss_Validation:  [[ 11.0514364]]\n",
      "Loop 9895 Loss_Train:  [[ 13.19524918]] Loss_Validation:  [[ 11.05143703]]\n",
      "Loop 9896 Loss_Train:  [[ 13.19524918]] Loss_Validation:  [[ 11.05143766]]\n",
      "Loop 9897 Loss_Train:  [[ 13.19524918]] Loss_Validation:  [[ 11.05143828]]\n",
      "Loop 9898 Loss_Train:  [[ 13.19524918]] Loss_Validation:  [[ 11.05143891]]\n",
      "Loop 9899 Loss_Train:  [[ 13.19524918]] Loss_Validation:  [[ 11.05143954]]\n",
      "Loop 9900 Loss_Train:  [[ 13.19524918]] Loss_Validation:  [[ 11.05144016]]\n",
      "Loop 9901 Loss_Train:  [[ 13.19524918]] Loss_Validation:  [[ 11.05144079]]\n",
      "Loop 9902 Loss_Train:  [[ 13.19524918]] Loss_Validation:  [[ 11.05144141]]\n",
      "Loop 9903 Loss_Train:  [[ 13.19524917]] Loss_Validation:  [[ 11.05144203]]\n",
      "Loop 9904 Loss_Train:  [[ 13.19524917]] Loss_Validation:  [[ 11.05144266]]\n",
      "Loop 9905 Loss_Train:  [[ 13.19524917]] Loss_Validation:  [[ 11.05144328]]\n",
      "Loop 9906 Loss_Train:  [[ 13.19524917]] Loss_Validation:  [[ 11.0514439]]\n",
      "Loop 9907 Loss_Train:  [[ 13.19524917]] Loss_Validation:  [[ 11.05144453]]\n",
      "Loop 9908 Loss_Train:  [[ 13.19524917]] Loss_Validation:  [[ 11.05144515]]\n",
      "Loop 9909 Loss_Train:  [[ 13.19524917]] Loss_Validation:  [[ 11.05144577]]\n",
      "Loop 9910 Loss_Train:  [[ 13.19524917]] Loss_Validation:  [[ 11.05144639]]\n",
      "Loop 9911 Loss_Train:  [[ 13.19524917]] Loss_Validation:  [[ 11.05144701]]\n",
      "Loop 9912 Loss_Train:  [[ 13.19524917]] Loss_Validation:  [[ 11.05144763]]\n",
      "Loop 9913 Loss_Train:  [[ 13.19524916]] Loss_Validation:  [[ 11.05144825]]\n",
      "Loop 9914 Loss_Train:  [[ 13.19524916]] Loss_Validation:  [[ 11.05144887]]\n",
      "Loop 9915 Loss_Train:  [[ 13.19524916]] Loss_Validation:  [[ 11.05144949]]\n",
      "Loop 9916 Loss_Train:  [[ 13.19524916]] Loss_Validation:  [[ 11.05145011]]\n",
      "Loop 9917 Loss_Train:  [[ 13.19524916]] Loss_Validation:  [[ 11.05145072]]\n",
      "Loop 9918 Loss_Train:  [[ 13.19524916]] Loss_Validation:  [[ 11.05145134]]\n",
      "Loop 9919 Loss_Train:  [[ 13.19524916]] Loss_Validation:  [[ 11.05145196]]\n",
      "Loop 9920 Loss_Train:  [[ 13.19524916]] Loss_Validation:  [[ 11.05145257]]\n",
      "Loop 9921 Loss_Train:  [[ 13.19524916]] Loss_Validation:  [[ 11.05145319]]\n",
      "Loop 9922 Loss_Train:  [[ 13.19524916]] Loss_Validation:  [[ 11.05145381]]\n",
      "Loop 9923 Loss_Train:  [[ 13.19524916]] Loss_Validation:  [[ 11.05145442]]\n",
      "Loop 9924 Loss_Train:  [[ 13.19524915]] Loss_Validation:  [[ 11.05145504]]\n",
      "Loop 9925 Loss_Train:  [[ 13.19524915]] Loss_Validation:  [[ 11.05145565]]\n",
      "Loop 9926 Loss_Train:  [[ 13.19524915]] Loss_Validation:  [[ 11.05145626]]\n",
      "Loop 9927 Loss_Train:  [[ 13.19524915]] Loss_Validation:  [[ 11.05145688]]\n",
      "Loop 9928 Loss_Train:  [[ 13.19524915]] Loss_Validation:  [[ 11.05145749]]\n",
      "Loop 9929 Loss_Train:  [[ 13.19524915]] Loss_Validation:  [[ 11.0514581]]\n",
      "Loop 9930 Loss_Train:  [[ 13.19524915]] Loss_Validation:  [[ 11.05145872]]\n",
      "Loop 9931 Loss_Train:  [[ 13.19524915]] Loss_Validation:  [[ 11.05145933]]\n",
      "Loop 9932 Loss_Train:  [[ 13.19524915]] Loss_Validation:  [[ 11.05145994]]\n",
      "Loop 9933 Loss_Train:  [[ 13.19524915]] Loss_Validation:  [[ 11.05146055]]\n",
      "Loop 9934 Loss_Train:  [[ 13.19524915]] Loss_Validation:  [[ 11.05146116]]\n",
      "Loop 9935 Loss_Train:  [[ 13.19524914]] Loss_Validation:  [[ 11.05146177]]\n",
      "Loop 9936 Loss_Train:  [[ 13.19524914]] Loss_Validation:  [[ 11.05146238]]\n",
      "Loop 9937 Loss_Train:  [[ 13.19524914]] Loss_Validation:  [[ 11.05146299]]\n",
      "Loop 9938 Loss_Train:  [[ 13.19524914]] Loss_Validation:  [[ 11.0514636]]\n",
      "Loop 9939 Loss_Train:  [[ 13.19524914]] Loss_Validation:  [[ 11.05146421]]\n",
      "Loop 9940 Loss_Train:  [[ 13.19524914]] Loss_Validation:  [[ 11.05146481]]\n",
      "Loop 9941 Loss_Train:  [[ 13.19524914]] Loss_Validation:  [[ 11.05146542]]\n",
      "Loop 9942 Loss_Train:  [[ 13.19524914]] Loss_Validation:  [[ 11.05146603]]\n",
      "Loop 9943 Loss_Train:  [[ 13.19524914]] Loss_Validation:  [[ 11.05146664]]\n",
      "Loop 9944 Loss_Train:  [[ 13.19524914]] Loss_Validation:  [[ 11.05146724]]\n",
      "Loop 9945 Loss_Train:  [[ 13.19524914]] Loss_Validation:  [[ 11.05146785]]\n",
      "Loop 9946 Loss_Train:  [[ 13.19524914]] Loss_Validation:  [[ 11.05146845]]\n",
      "Loop 9947 Loss_Train:  [[ 13.19524913]] Loss_Validation:  [[ 11.05146906]]\n",
      "Loop 9948 Loss_Train:  [[ 13.19524913]] Loss_Validation:  [[ 11.05146966]]\n",
      "Loop 9949 Loss_Train:  [[ 13.19524913]] Loss_Validation:  [[ 11.05147027]]\n",
      "Loop 9950 Loss_Train:  [[ 13.19524913]] Loss_Validation:  [[ 11.05147087]]\n",
      "Loop 9951 Loss_Train:  [[ 13.19524913]] Loss_Validation:  [[ 11.05147147]]\n",
      "Loop 9952 Loss_Train:  [[ 13.19524913]] Loss_Validation:  [[ 11.05147208]]\n",
      "Loop 9953 Loss_Train:  [[ 13.19524913]] Loss_Validation:  [[ 11.05147268]]\n",
      "Loop 9954 Loss_Train:  [[ 13.19524913]] Loss_Validation:  [[ 11.05147328]]\n",
      "Loop 9955 Loss_Train:  [[ 13.19524913]] Loss_Validation:  [[ 11.05147388]]\n",
      "Loop 9956 Loss_Train:  [[ 13.19524913]] Loss_Validation:  [[ 11.05147449]]\n",
      "Loop 9957 Loss_Train:  [[ 13.19524913]] Loss_Validation:  [[ 11.05147509]]\n",
      "Loop 9958 Loss_Train:  [[ 13.19524912]] Loss_Validation:  [[ 11.05147569]]\n",
      "Loop 9959 Loss_Train:  [[ 13.19524912]] Loss_Validation:  [[ 11.05147629]]\n",
      "Loop 9960 Loss_Train:  [[ 13.19524912]] Loss_Validation:  [[ 11.05147689]]\n",
      "Loop 9961 Loss_Train:  [[ 13.19524912]] Loss_Validation:  [[ 11.05147749]]\n",
      "Loop 9962 Loss_Train:  [[ 13.19524912]] Loss_Validation:  [[ 11.05147808]]\n",
      "Loop 9963 Loss_Train:  [[ 13.19524912]] Loss_Validation:  [[ 11.05147868]]\n",
      "Loop 9964 Loss_Train:  [[ 13.19524912]] Loss_Validation:  [[ 11.05147928]]\n",
      "Loop 9965 Loss_Train:  [[ 13.19524912]] Loss_Validation:  [[ 11.05147988]]\n",
      "Loop 9966 Loss_Train:  [[ 13.19524912]] Loss_Validation:  [[ 11.05148048]]\n",
      "Loop 9967 Loss_Train:  [[ 13.19524912]] Loss_Validation:  [[ 11.05148107]]\n",
      "Loop 9968 Loss_Train:  [[ 13.19524912]] Loss_Validation:  [[ 11.05148167]]\n",
      "Loop 9969 Loss_Train:  [[ 13.19524911]] Loss_Validation:  [[ 11.05148226]]\n",
      "Loop 9970 Loss_Train:  [[ 13.19524911]] Loss_Validation:  [[ 11.05148286]]\n",
      "Loop 9971 Loss_Train:  [[ 13.19524911]] Loss_Validation:  [[ 11.05148345]]\n",
      "Loop 9972 Loss_Train:  [[ 13.19524911]] Loss_Validation:  [[ 11.05148405]]\n",
      "Loop 9973 Loss_Train:  [[ 13.19524911]] Loss_Validation:  [[ 11.05148464]]\n",
      "Loop 9974 Loss_Train:  [[ 13.19524911]] Loss_Validation:  [[ 11.05148524]]\n",
      "Loop 9975 Loss_Train:  [[ 13.19524911]] Loss_Validation:  [[ 11.05148583]]\n",
      "Loop 9976 Loss_Train:  [[ 13.19524911]] Loss_Validation:  [[ 11.05148642]]\n",
      "Loop 9977 Loss_Train:  [[ 13.19524911]] Loss_Validation:  [[ 11.05148702]]\n",
      "Loop 9978 Loss_Train:  [[ 13.19524911]] Loss_Validation:  [[ 11.05148761]]\n",
      "Loop 9979 Loss_Train:  [[ 13.19524911]] Loss_Validation:  [[ 11.0514882]]\n",
      "Loop 9980 Loss_Train:  [[ 13.19524911]] Loss_Validation:  [[ 11.05148879]]\n",
      "Loop 9981 Loss_Train:  [[ 13.1952491]] Loss_Validation:  [[ 11.05148938]]\n",
      "Loop 9982 Loss_Train:  [[ 13.1952491]] Loss_Validation:  [[ 11.05148997]]\n",
      "Loop 9983 Loss_Train:  [[ 13.1952491]] Loss_Validation:  [[ 11.05149056]]\n",
      "Loop 9984 Loss_Train:  [[ 13.1952491]] Loss_Validation:  [[ 11.05149115]]\n",
      "Loop 9985 Loss_Train:  [[ 13.1952491]] Loss_Validation:  [[ 11.05149174]]\n",
      "Loop 9986 Loss_Train:  [[ 13.1952491]] Loss_Validation:  [[ 11.05149233]]\n",
      "Loop 9987 Loss_Train:  [[ 13.1952491]] Loss_Validation:  [[ 11.05149292]]\n",
      "Loop 9988 Loss_Train:  [[ 13.1952491]] Loss_Validation:  [[ 11.05149351]]\n",
      "Loop 9989 Loss_Train:  [[ 13.1952491]] Loss_Validation:  [[ 11.05149409]]\n",
      "Loop 9990 Loss_Train:  [[ 13.1952491]] Loss_Validation:  [[ 11.05149468]]\n",
      "Loop 9991 Loss_Train:  [[ 13.1952491]] Loss_Validation:  [[ 11.05149527]]\n",
      "Loop 9992 Loss_Train:  [[ 13.1952491]] Loss_Validation:  [[ 11.05149585]]\n",
      "Loop 9993 Loss_Train:  [[ 13.19524909]] Loss_Validation:  [[ 11.05149644]]\n",
      "Loop 9994 Loss_Train:  [[ 13.19524909]] Loss_Validation:  [[ 11.05149703]]\n",
      "Loop 9995 Loss_Train:  [[ 13.19524909]] Loss_Validation:  [[ 11.05149761]]\n",
      "Loop 9996 Loss_Train:  [[ 13.19524909]] Loss_Validation:  [[ 11.0514982]]\n",
      "Loop 9997 Loss_Train:  [[ 13.19524909]] Loss_Validation:  [[ 11.05149878]]\n",
      "Loop 9998 Loss_Train:  [[ 13.19524909]] Loss_Validation:  [[ 11.05149936]]\n",
      "Loop 9999 Loss_Train:  [[ 13.19524909]] Loss_Validation:  [[ 11.05149995]]\n",
      "Loop 10000 Loss_Train:  [[ 13.19524909]] Loss_Validation:  [[ 11.05150053]]\n",
      "Loop 10001 Loss_Train:  [[ 13.19524909]] Loss_Validation:  [[ 11.05150111]]\n",
      "Loop 10002 Loss_Train:  [[ 13.19524909]] Loss_Validation:  [[ 11.0515017]]\n",
      "Loop 10003 Loss_Train:  [[ 13.19524909]] Loss_Validation:  [[ 11.05150228]]\n",
      "Loop 10004 Loss_Train:  [[ 13.19524909]] Loss_Validation:  [[ 11.05150286]]\n",
      "Loop 10005 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.05150344]]\n",
      "Loop 10006 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.05150402]]\n",
      "Loop 10007 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.0515046]]\n",
      "Loop 10008 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.05150518]]\n",
      "Loop 10009 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.05150576]]\n",
      "Loop 10010 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.05150634]]\n",
      "Loop 10011 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.05150692]]\n",
      "Loop 10012 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.0515075]]\n",
      "Loop 10013 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.05150807]]\n",
      "Loop 10014 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.05150865]]\n",
      "Loop 10015 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.05150923]]\n",
      "Loop 10016 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.05150981]]\n",
      "Loop 10017 Loss_Train:  [[ 13.19524908]] Loss_Validation:  [[ 11.05151038]]\n",
      "Loop 10018 Loss_Train:  [[ 13.19524907]] Loss_Validation:  [[ 11.05151096]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 10019 Loss_Train:  [[ 13.19524907]] Loss_Validation:  [[ 11.05151153]]\n",
      "Loop 10020 Loss_Train:  [[ 13.19524907]] Loss_Validation:  [[ 11.05151211]]\n",
      "Loop 10021 Loss_Train:  [[ 13.19524907]] Loss_Validation:  [[ 11.05151268]]\n",
      "Loop 10022 Loss_Train:  [[ 13.19524907]] Loss_Validation:  [[ 11.05151326]]\n",
      "Loop 10023 Loss_Train:  [[ 13.19524907]] Loss_Validation:  [[ 11.05151383]]\n",
      "Loop 10024 Loss_Train:  [[ 13.19524907]] Loss_Validation:  [[ 11.0515144]]\n",
      "Loop 10025 Loss_Train:  [[ 13.19524907]] Loss_Validation:  [[ 11.05151498]]\n",
      "Loop 10026 Loss_Train:  [[ 13.19524907]] Loss_Validation:  [[ 11.05151555]]\n",
      "Loop 10027 Loss_Train:  [[ 13.19524907]] Loss_Validation:  [[ 11.05151612]]\n",
      "Loop 10028 Loss_Train:  [[ 13.19524907]] Loss_Validation:  [[ 11.05151669]]\n",
      "Loop 10029 Loss_Train:  [[ 13.19524907]] Loss_Validation:  [[ 11.05151727]]\n",
      "Loop 10030 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05151784]]\n",
      "Loop 10031 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05151841]]\n",
      "Loop 10032 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05151898]]\n",
      "Loop 10033 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05151955]]\n",
      "Loop 10034 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05152012]]\n",
      "Loop 10035 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05152069]]\n",
      "Loop 10036 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05152126]]\n",
      "Loop 10037 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05152182]]\n",
      "Loop 10038 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05152239]]\n",
      "Loop 10039 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05152296]]\n",
      "Loop 10040 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05152353]]\n",
      "Loop 10041 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05152409]]\n",
      "Loop 10042 Loss_Train:  [[ 13.19524906]] Loss_Validation:  [[ 11.05152466]]\n",
      "Loop 10043 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.05152523]]\n",
      "Loop 10044 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.05152579]]\n",
      "Loop 10045 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.05152636]]\n",
      "Loop 10046 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.05152692]]\n",
      "Loop 10047 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.05152749]]\n",
      "Loop 10048 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.05152805]]\n",
      "Loop 10049 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.05152861]]\n",
      "Loop 10050 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.05152918]]\n",
      "Loop 10051 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.05152974]]\n",
      "Loop 10052 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.0515303]]\n",
      "Loop 10053 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.05153086]]\n",
      "Loop 10054 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.05153142]]\n",
      "Loop 10055 Loss_Train:  [[ 13.19524905]] Loss_Validation:  [[ 11.05153199]]\n",
      "Loop 10056 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.05153255]]\n",
      "Loop 10057 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.05153311]]\n",
      "Loop 10058 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.05153367]]\n",
      "Loop 10059 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.05153423]]\n",
      "Loop 10060 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.05153479]]\n",
      "Loop 10061 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.05153534]]\n",
      "Loop 10062 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.0515359]]\n",
      "Loop 10063 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.05153646]]\n",
      "Loop 10064 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.05153702]]\n",
      "Loop 10065 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.05153758]]\n",
      "Loop 10066 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.05153813]]\n",
      "Loop 10067 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.05153869]]\n",
      "Loop 10068 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.05153925]]\n",
      "Loop 10069 Loss_Train:  [[ 13.19524904]] Loss_Validation:  [[ 11.0515398]]\n",
      "Loop 10070 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154036]]\n",
      "Loop 10071 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154091]]\n",
      "Loop 10072 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154147]]\n",
      "Loop 10073 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154202]]\n",
      "Loop 10074 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154258]]\n",
      "Loop 10075 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154313]]\n",
      "Loop 10076 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154368]]\n",
      "Loop 10077 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154423]]\n",
      "Loop 10078 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154479]]\n",
      "Loop 10079 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154534]]\n",
      "Loop 10080 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154589]]\n",
      "Loop 10081 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154644]]\n",
      "Loop 10082 Loss_Train:  [[ 13.19524903]] Loss_Validation:  [[ 11.05154699]]\n",
      "Loop 10083 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05154754]]\n",
      "Loop 10084 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05154809]]\n",
      "Loop 10085 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05154864]]\n",
      "Loop 10086 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05154919]]\n",
      "Loop 10087 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05154974]]\n",
      "Loop 10088 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05155029]]\n",
      "Loop 10089 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05155084]]\n",
      "Loop 10090 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05155138]]\n",
      "Loop 10091 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05155193]]\n",
      "Loop 10092 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05155248]]\n",
      "Loop 10093 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05155303]]\n",
      "Loop 10094 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05155357]]\n",
      "Loop 10095 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05155412]]\n",
      "Loop 10096 Loss_Train:  [[ 13.19524902]] Loss_Validation:  [[ 11.05155466]]\n",
      "Loop 10097 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.05155521]]\n",
      "Loop 10098 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.05155575]]\n",
      "Loop 10099 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.0515563]]\n",
      "Loop 10100 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.05155684]]\n",
      "Loop 10101 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.05155738]]\n",
      "Loop 10102 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.05155793]]\n",
      "Loop 10103 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.05155847]]\n",
      "Loop 10104 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.05155901]]\n",
      "Loop 10105 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.05155955]]\n",
      "Loop 10106 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.0515601]]\n",
      "Loop 10107 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.05156064]]\n",
      "Loop 10108 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.05156118]]\n",
      "Loop 10109 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.05156172]]\n",
      "Loop 10110 Loss_Train:  [[ 13.19524901]] Loss_Validation:  [[ 11.05156226]]\n",
      "Loop 10111 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.0515628]]\n",
      "Loop 10112 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05156334]]\n",
      "Loop 10113 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05156388]]\n",
      "Loop 10114 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05156442]]\n",
      "Loop 10115 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05156495]]\n",
      "Loop 10116 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05156549]]\n",
      "Loop 10117 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05156603]]\n",
      "Loop 10118 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05156657]]\n",
      "Loop 10119 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.0515671]]\n",
      "Loop 10120 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05156764]]\n",
      "Loop 10121 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05156818]]\n",
      "Loop 10122 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05156871]]\n",
      "Loop 10123 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05156925]]\n",
      "Loop 10124 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05156978]]\n",
      "Loop 10125 Loss_Train:  [[ 13.195249]] Loss_Validation:  [[ 11.05157032]]\n",
      "Loop 10126 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157085]]\n",
      "Loop 10127 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157138]]\n",
      "Loop 10128 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157192]]\n",
      "Loop 10129 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157245]]\n",
      "Loop 10130 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157298]]\n",
      "Loop 10131 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157351]]\n",
      "Loop 10132 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157405]]\n",
      "Loop 10133 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157458]]\n",
      "Loop 10134 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157511]]\n",
      "Loop 10135 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157564]]\n",
      "Loop 10136 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157617]]\n",
      "Loop 10137 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.0515767]]\n",
      "Loop 10138 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157723]]\n",
      "Loop 10139 Loss_Train:  [[ 13.19524899]] Loss_Validation:  [[ 11.05157776]]\n",
      "Loop 10140 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05157829]]\n",
      "Loop 10141 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05157882]]\n",
      "Loop 10142 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05157935]]\n",
      "Loop 10143 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05157987]]\n",
      "Loop 10144 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.0515804]]\n",
      "Loop 10145 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05158093]]\n",
      "Loop 10146 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05158145]]\n",
      "Loop 10147 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05158198]]\n",
      "Loop 10148 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05158251]]\n",
      "Loop 10149 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05158303]]\n",
      "Loop 10150 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05158356]]\n",
      "Loop 10151 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05158408]]\n",
      "Loop 10152 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05158461]]\n",
      "Loop 10153 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05158513]]\n",
      "Loop 10154 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05158566]]\n",
      "Loop 10155 Loss_Train:  [[ 13.19524898]] Loss_Validation:  [[ 11.05158618]]\n",
      "Loop 10156 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.0515867]]\n",
      "Loop 10157 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05158722]]\n",
      "Loop 10158 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05158775]]\n",
      "Loop 10159 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05158827]]\n",
      "Loop 10160 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05158879]]\n",
      "Loop 10161 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05158931]]\n",
      "Loop 10162 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05158983]]\n",
      "Loop 10163 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05159035]]\n",
      "Loop 10164 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05159087]]\n",
      "Loop 10165 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05159139]]\n",
      "Loop 10166 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05159191]]\n",
      "Loop 10167 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05159243]]\n",
      "Loop 10168 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05159295]]\n",
      "Loop 10169 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05159347]]\n",
      "Loop 10170 Loss_Train:  [[ 13.19524897]] Loss_Validation:  [[ 11.05159399]]\n",
      "Loop 10171 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.0515945]]\n",
      "Loop 10172 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05159502]]\n",
      "Loop 10173 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05159554]]\n",
      "Loop 10174 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05159606]]\n",
      "Loop 10175 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05159657]]\n",
      "Loop 10176 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05159709]]\n",
      "Loop 10177 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.0515976]]\n",
      "Loop 10178 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05159812]]\n",
      "Loop 10179 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05159863]]\n",
      "Loop 10180 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05159915]]\n",
      "Loop 10181 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05159966]]\n",
      "Loop 10182 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05160018]]\n",
      "Loop 10183 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05160069]]\n",
      "Loop 10184 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.0516012]]\n",
      "Loop 10185 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05160171]]\n",
      "Loop 10186 Loss_Train:  [[ 13.19524896]] Loss_Validation:  [[ 11.05160223]]\n",
      "Loop 10187 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160274]]\n",
      "Loop 10188 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160325]]\n",
      "Loop 10189 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160376]]\n",
      "Loop 10190 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160427]]\n",
      "Loop 10191 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160478]]\n",
      "Loop 10192 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160529]]\n",
      "Loop 10193 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.0516058]]\n",
      "Loop 10194 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160631]]\n",
      "Loop 10195 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160682]]\n",
      "Loop 10196 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160733]]\n",
      "Loop 10197 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160784]]\n",
      "Loop 10198 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160835]]\n",
      "Loop 10199 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160885]]\n",
      "Loop 10200 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160936]]\n",
      "Loop 10201 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05160987]]\n",
      "Loop 10202 Loss_Train:  [[ 13.19524895]] Loss_Validation:  [[ 11.05161037]]\n",
      "Loop 10203 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161088]]\n",
      "Loop 10204 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161139]]\n",
      "Loop 10205 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161189]]\n",
      "Loop 10206 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.0516124]]\n",
      "Loop 10207 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.0516129]]\n",
      "Loop 10208 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161341]]\n",
      "Loop 10209 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161391]]\n",
      "Loop 10210 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161441]]\n",
      "Loop 10211 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161492]]\n",
      "Loop 10212 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161542]]\n",
      "Loop 10213 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161592]]\n",
      "Loop 10214 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161643]]\n",
      "Loop 10215 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161693]]\n",
      "Loop 10216 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161743]]\n",
      "Loop 10217 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161793]]\n",
      "Loop 10218 Loss_Train:  [[ 13.19524894]] Loss_Validation:  [[ 11.05161843]]\n",
      "Loop 10219 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05161893]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 10220 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05161943]]\n",
      "Loop 10221 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05161993]]\n",
      "Loop 10222 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05162043]]\n",
      "Loop 10223 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05162093]]\n",
      "Loop 10224 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05162143]]\n",
      "Loop 10225 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05162193]]\n",
      "Loop 10226 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05162243]]\n",
      "Loop 10227 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05162293]]\n",
      "Loop 10228 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05162342]]\n",
      "Loop 10229 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05162392]]\n",
      "Loop 10230 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05162442]]\n",
      "Loop 10231 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05162491]]\n",
      "Loop 10232 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05162541]]\n",
      "Loop 10233 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.05162591]]\n",
      "Loop 10234 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.0516264]]\n",
      "Loop 10235 Loss_Train:  [[ 13.19524893]] Loss_Validation:  [[ 11.0516269]]\n",
      "Loop 10236 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05162739]]\n",
      "Loop 10237 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05162788]]\n",
      "Loop 10238 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05162838]]\n",
      "Loop 10239 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05162887]]\n",
      "Loop 10240 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05162937]]\n",
      "Loop 10241 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05162986]]\n",
      "Loop 10242 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05163035]]\n",
      "Loop 10243 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05163084]]\n",
      "Loop 10244 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05163134]]\n",
      "Loop 10245 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05163183]]\n",
      "Loop 10246 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05163232]]\n",
      "Loop 10247 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05163281]]\n",
      "Loop 10248 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.0516333]]\n",
      "Loop 10249 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05163379]]\n",
      "Loop 10250 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05163428]]\n",
      "Loop 10251 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05163477]]\n",
      "Loop 10252 Loss_Train:  [[ 13.19524892]] Loss_Validation:  [[ 11.05163526]]\n",
      "Loop 10253 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05163575]]\n",
      "Loop 10254 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05163624]]\n",
      "Loop 10255 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05163673]]\n",
      "Loop 10256 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05163721]]\n",
      "Loop 10257 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.0516377]]\n",
      "Loop 10258 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05163819]]\n",
      "Loop 10259 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05163867]]\n",
      "Loop 10260 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05163916]]\n",
      "Loop 10261 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05163965]]\n",
      "Loop 10262 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05164013]]\n",
      "Loop 10263 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05164062]]\n",
      "Loop 10264 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.0516411]]\n",
      "Loop 10265 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05164159]]\n",
      "Loop 10266 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05164207]]\n",
      "Loop 10267 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05164256]]\n",
      "Loop 10268 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05164304]]\n",
      "Loop 10269 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05164352]]\n",
      "Loop 10270 Loss_Train:  [[ 13.19524891]] Loss_Validation:  [[ 11.05164401]]\n",
      "Loop 10271 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05164449]]\n",
      "Loop 10272 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05164497]]\n",
      "Loop 10273 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05164546]]\n",
      "Loop 10274 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05164594]]\n",
      "Loop 10275 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05164642]]\n",
      "Loop 10276 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.0516469]]\n",
      "Loop 10277 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05164738]]\n",
      "Loop 10278 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05164786]]\n",
      "Loop 10279 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05164834]]\n",
      "Loop 10280 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05164882]]\n",
      "Loop 10281 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.0516493]]\n",
      "Loop 10282 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05164978]]\n",
      "Loop 10283 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05165026]]\n",
      "Loop 10284 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05165074]]\n",
      "Loop 10285 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05165121]]\n",
      "Loop 10286 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05165169]]\n",
      "Loop 10287 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05165217]]\n",
      "Loop 10288 Loss_Train:  [[ 13.1952489]] Loss_Validation:  [[ 11.05165265]]\n",
      "Loop 10289 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05165312]]\n",
      "Loop 10290 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.0516536]]\n",
      "Loop 10291 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05165408]]\n",
      "Loop 10292 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05165455]]\n",
      "Loop 10293 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05165503]]\n",
      "Loop 10294 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.0516555]]\n",
      "Loop 10295 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05165598]]\n",
      "Loop 10296 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05165645]]\n",
      "Loop 10297 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05165693]]\n",
      "Loop 10298 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.0516574]]\n",
      "Loop 10299 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05165787]]\n",
      "Loop 10300 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05165835]]\n",
      "Loop 10301 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05165882]]\n",
      "Loop 10302 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05165929]]\n",
      "Loop 10303 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05165976]]\n",
      "Loop 10304 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05166024]]\n",
      "Loop 10305 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05166071]]\n",
      "Loop 10306 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05166118]]\n",
      "Loop 10307 Loss_Train:  [[ 13.19524889]] Loss_Validation:  [[ 11.05166165]]\n",
      "Loop 10308 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166212]]\n",
      "Loop 10309 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166259]]\n",
      "Loop 10310 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166306]]\n",
      "Loop 10311 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166353]]\n",
      "Loop 10312 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.051664]]\n",
      "Loop 10313 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166447]]\n",
      "Loop 10314 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166494]]\n",
      "Loop 10315 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.0516654]]\n",
      "Loop 10316 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166587]]\n",
      "Loop 10317 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166634]]\n",
      "Loop 10318 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166681]]\n",
      "Loop 10319 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166727]]\n",
      "Loop 10320 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166774]]\n",
      "Loop 10321 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166821]]\n",
      "Loop 10322 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166867]]\n",
      "Loop 10323 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05166914]]\n",
      "Loop 10324 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.0516696]]\n",
      "Loop 10325 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05167007]]\n",
      "Loop 10326 Loss_Train:  [[ 13.19524888]] Loss_Validation:  [[ 11.05167053]]\n",
      "Loop 10327 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.051671]]\n",
      "Loop 10328 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167146]]\n",
      "Loop 10329 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167193]]\n",
      "Loop 10330 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167239]]\n",
      "Loop 10331 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167285]]\n",
      "Loop 10332 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167331]]\n",
      "Loop 10333 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167378]]\n",
      "Loop 10334 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167424]]\n",
      "Loop 10335 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.0516747]]\n",
      "Loop 10336 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167516]]\n",
      "Loop 10337 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167562]]\n",
      "Loop 10338 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167608]]\n",
      "Loop 10339 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167654]]\n",
      "Loop 10340 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.051677]]\n",
      "Loop 10341 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167746]]\n",
      "Loop 10342 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167792]]\n",
      "Loop 10343 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167838]]\n",
      "Loop 10344 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167884]]\n",
      "Loop 10345 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.0516793]]\n",
      "Loop 10346 Loss_Train:  [[ 13.19524887]] Loss_Validation:  [[ 11.05167976]]\n",
      "Loop 10347 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168022]]\n",
      "Loop 10348 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168067]]\n",
      "Loop 10349 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168113]]\n",
      "Loop 10350 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168159]]\n",
      "Loop 10351 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168204]]\n",
      "Loop 10352 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.0516825]]\n",
      "Loop 10353 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168296]]\n",
      "Loop 10354 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168341]]\n",
      "Loop 10355 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168387]]\n",
      "Loop 10356 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168432]]\n",
      "Loop 10357 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168478]]\n",
      "Loop 10358 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168523]]\n",
      "Loop 10359 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168569]]\n",
      "Loop 10360 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168614]]\n",
      "Loop 10361 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168659]]\n",
      "Loop 10362 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168705]]\n",
      "Loop 10363 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.0516875]]\n",
      "Loop 10364 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168795]]\n",
      "Loop 10365 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.0516884]]\n",
      "Loop 10366 Loss_Train:  [[ 13.19524886]] Loss_Validation:  [[ 11.05168886]]\n",
      "Loop 10367 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05168931]]\n",
      "Loop 10368 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05168976]]\n",
      "Loop 10369 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169021]]\n",
      "Loop 10370 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169066]]\n",
      "Loop 10371 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169111]]\n",
      "Loop 10372 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169156]]\n",
      "Loop 10373 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169201]]\n",
      "Loop 10374 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169246]]\n",
      "Loop 10375 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169291]]\n",
      "Loop 10376 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169336]]\n",
      "Loop 10377 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169381]]\n",
      "Loop 10378 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169425]]\n",
      "Loop 10379 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.0516947]]\n",
      "Loop 10380 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169515]]\n",
      "Loop 10381 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.0516956]]\n",
      "Loop 10382 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169604]]\n",
      "Loop 10383 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169649]]\n",
      "Loop 10384 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169694]]\n",
      "Loop 10385 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169738]]\n",
      "Loop 10386 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169783]]\n",
      "Loop 10387 Loss_Train:  [[ 13.19524885]] Loss_Validation:  [[ 11.05169827]]\n",
      "Loop 10388 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05169872]]\n",
      "Loop 10389 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05169916]]\n",
      "Loop 10390 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05169961]]\n",
      "Loop 10391 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170005]]\n",
      "Loop 10392 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170049]]\n",
      "Loop 10393 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170094]]\n",
      "Loop 10394 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170138]]\n",
      "Loop 10395 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170182]]\n",
      "Loop 10396 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170227]]\n",
      "Loop 10397 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170271]]\n",
      "Loop 10398 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170315]]\n",
      "Loop 10399 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170359]]\n",
      "Loop 10400 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170403]]\n",
      "Loop 10401 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170447]]\n",
      "Loop 10402 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170492]]\n",
      "Loop 10403 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170536]]\n",
      "Loop 10404 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.0517058]]\n",
      "Loop 10405 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170624]]\n",
      "Loop 10406 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170667]]\n",
      "Loop 10407 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170711]]\n",
      "Loop 10408 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170755]]\n",
      "Loop 10409 Loss_Train:  [[ 13.19524884]] Loss_Validation:  [[ 11.05170799]]\n",
      "Loop 10410 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05170843]]\n",
      "Loop 10411 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05170887]]\n",
      "Loop 10412 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05170931]]\n",
      "Loop 10413 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05170974]]\n",
      "Loop 10414 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171018]]\n",
      "Loop 10415 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171062]]\n",
      "Loop 10416 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171105]]\n",
      "Loop 10417 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171149]]\n",
      "Loop 10418 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171192]]\n",
      "Loop 10419 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171236]]\n",
      "Loop 10420 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.0517128]]\n",
      "Loop 10421 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171323]]\n",
      "Loop 10422 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171366]]\n",
      "Loop 10423 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.0517141]]\n",
      "Loop 10424 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171453]]\n",
      "Loop 10425 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171497]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 10426 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.0517154]]\n",
      "Loop 10427 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171583]]\n",
      "Loop 10428 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171627]]\n",
      "Loop 10429 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.0517167]]\n",
      "Loop 10430 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171713]]\n",
      "Loop 10431 Loss_Train:  [[ 13.19524883]] Loss_Validation:  [[ 11.05171756]]\n",
      "Loop 10432 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05171799]]\n",
      "Loop 10433 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05171842]]\n",
      "Loop 10434 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05171886]]\n",
      "Loop 10435 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05171929]]\n",
      "Loop 10436 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05171972]]\n",
      "Loop 10437 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172015]]\n",
      "Loop 10438 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172058]]\n",
      "Loop 10439 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172101]]\n",
      "Loop 10440 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172143]]\n",
      "Loop 10441 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172186]]\n",
      "Loop 10442 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172229]]\n",
      "Loop 10443 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172272]]\n",
      "Loop 10444 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172315]]\n",
      "Loop 10445 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172358]]\n",
      "Loop 10446 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.051724]]\n",
      "Loop 10447 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172443]]\n",
      "Loop 10448 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172486]]\n",
      "Loop 10449 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172528]]\n",
      "Loop 10450 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172571]]\n",
      "Loop 10451 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172614]]\n",
      "Loop 10452 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172656]]\n",
      "Loop 10453 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172699]]\n",
      "Loop 10454 Loss_Train:  [[ 13.19524882]] Loss_Validation:  [[ 11.05172741]]\n",
      "Loop 10455 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05172784]]\n",
      "Loop 10456 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05172826]]\n",
      "Loop 10457 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05172868]]\n",
      "Loop 10458 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05172911]]\n",
      "Loop 10459 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05172953]]\n",
      "Loop 10460 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05172996]]\n",
      "Loop 10461 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173038]]\n",
      "Loop 10462 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.0517308]]\n",
      "Loop 10463 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173122]]\n",
      "Loop 10464 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173165]]\n",
      "Loop 10465 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173207]]\n",
      "Loop 10466 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173249]]\n",
      "Loop 10467 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173291]]\n",
      "Loop 10468 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173333]]\n",
      "Loop 10469 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173375]]\n",
      "Loop 10470 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173417]]\n",
      "Loop 10471 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173459]]\n",
      "Loop 10472 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173501]]\n",
      "Loop 10473 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173543]]\n",
      "Loop 10474 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173585]]\n",
      "Loop 10475 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173627]]\n",
      "Loop 10476 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173669]]\n",
      "Loop 10477 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.0517371]]\n",
      "Loop 10478 Loss_Train:  [[ 13.19524881]] Loss_Validation:  [[ 11.05173752]]\n",
      "Loop 10479 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05173794]]\n",
      "Loop 10480 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05173836]]\n",
      "Loop 10481 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05173877]]\n",
      "Loop 10482 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05173919]]\n",
      "Loop 10483 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05173961]]\n",
      "Loop 10484 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174002]]\n",
      "Loop 10485 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174044]]\n",
      "Loop 10486 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174086]]\n",
      "Loop 10487 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174127]]\n",
      "Loop 10488 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174169]]\n",
      "Loop 10489 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.0517421]]\n",
      "Loop 10490 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174251]]\n",
      "Loop 10491 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174293]]\n",
      "Loop 10492 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174334]]\n",
      "Loop 10493 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174376]]\n",
      "Loop 10494 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174417]]\n",
      "Loop 10495 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174458]]\n",
      "Loop 10496 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.051745]]\n",
      "Loop 10497 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174541]]\n",
      "Loop 10498 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174582]]\n",
      "Loop 10499 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174623]]\n",
      "Loop 10500 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174664]]\n",
      "Loop 10501 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174705]]\n",
      "Loop 10502 Loss_Train:  [[ 13.1952488]] Loss_Validation:  [[ 11.05174747]]\n",
      "Loop 10503 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05174788]]\n",
      "Loop 10504 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05174829]]\n",
      "Loop 10505 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.0517487]]\n",
      "Loop 10506 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05174911]]\n",
      "Loop 10507 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05174952]]\n",
      "Loop 10508 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05174993]]\n",
      "Loop 10509 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175033]]\n",
      "Loop 10510 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175074]]\n",
      "Loop 10511 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175115]]\n",
      "Loop 10512 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175156]]\n",
      "Loop 10513 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175197]]\n",
      "Loop 10514 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175237]]\n",
      "Loop 10515 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175278]]\n",
      "Loop 10516 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175319]]\n",
      "Loop 10517 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.0517536]]\n",
      "Loop 10518 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.051754]]\n",
      "Loop 10519 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175441]]\n",
      "Loop 10520 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175481]]\n",
      "Loop 10521 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175522]]\n",
      "Loop 10522 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175563]]\n",
      "Loop 10523 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175603]]\n",
      "Loop 10524 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175643]]\n",
      "Loop 10525 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175684]]\n",
      "Loop 10526 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175724]]\n",
      "Loop 10527 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175765]]\n",
      "Loop 10528 Loss_Train:  [[ 13.19524879]] Loss_Validation:  [[ 11.05175805]]\n",
      "Loop 10529 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05175845]]\n",
      "Loop 10530 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05175886]]\n",
      "Loop 10531 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05175926]]\n",
      "Loop 10532 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05175966]]\n",
      "Loop 10533 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176006]]\n",
      "Loop 10534 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176047]]\n",
      "Loop 10535 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176087]]\n",
      "Loop 10536 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176127]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 10537 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176167]]\n",
      "Loop 10538 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176207]]\n",
      "Loop 10539 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176247]]\n",
      "Loop 10540 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176287]]\n",
      "Loop 10541 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176327]]\n",
      "Loop 10542 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176367]]\n",
      "Loop 10543 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176407]]\n",
      "Loop 10544 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176447]]\n",
      "Loop 10545 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176487]]\n",
      "Loop 10546 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176527]]\n",
      "Loop 10547 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176567]]\n",
      "Loop 10548 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176606]]\n",
      "Loop 10549 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176646]]\n",
      "Loop 10550 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176686]]\n",
      "Loop 10551 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176726]]\n",
      "Loop 10552 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176765]]\n",
      "Loop 10553 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176805]]\n",
      "Loop 10554 Loss_Train:  [[ 13.19524878]] Loss_Validation:  [[ 11.05176845]]\n",
      "Loop 10555 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05176884]]\n",
      "Loop 10556 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05176924]]\n",
      "Loop 10557 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05176963]]\n",
      "Loop 10558 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177003]]\n",
      "Loop 10559 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177042]]\n",
      "Loop 10560 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177082]]\n",
      "Loop 10561 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177121]]\n",
      "Loop 10562 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177161]]\n",
      "Loop 10563 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.051772]]\n",
      "Loop 10564 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177239]]\n",
      "Loop 10565 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177279]]\n",
      "Loop 10566 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177318]]\n",
      "Loop 10567 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177357]]\n",
      "Loop 10568 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177397]]\n",
      "Loop 10569 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177436]]\n",
      "Loop 10570 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177475]]\n",
      "Loop 10571 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177514]]\n",
      "Loop 10572 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177553]]\n",
      "Loop 10573 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177592]]\n",
      "Loop 10574 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177631]]\n",
      "Loop 10575 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177671]]\n",
      "Loop 10576 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.0517771]]\n",
      "Loop 10577 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177749]]\n",
      "Loop 10578 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177788]]\n",
      "Loop 10579 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177827]]\n",
      "Loop 10580 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177865]]\n",
      "Loop 10581 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177904]]\n",
      "Loop 10582 Loss_Train:  [[ 13.19524877]] Loss_Validation:  [[ 11.05177943]]\n",
      "Loop 10583 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05177982]]\n",
      "Loop 10584 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178021]]\n",
      "Loop 10585 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.0517806]]\n",
      "Loop 10586 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178098]]\n",
      "Loop 10587 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178137]]\n",
      "Loop 10588 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178176]]\n",
      "Loop 10589 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178214]]\n",
      "Loop 10590 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178253]]\n",
      "Loop 10591 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178292]]\n",
      "Loop 10592 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.0517833]]\n",
      "Loop 10593 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178369]]\n",
      "Loop 10594 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178407]]\n",
      "Loop 10595 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178446]]\n",
      "Loop 10596 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178484]]\n",
      "Loop 10597 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178523]]\n",
      "Loop 10598 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178561]]\n",
      "Loop 10599 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.051786]]\n",
      "Loop 10600 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178638]]\n",
      "Loop 10601 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178677]]\n",
      "Loop 10602 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178715]]\n",
      "Loop 10603 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178753]]\n",
      "Loop 10604 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178791]]\n",
      "Loop 10605 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.0517883]]\n",
      "Loop 10606 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178868]]\n",
      "Loop 10607 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178906]]\n",
      "Loop 10608 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178944]]\n",
      "Loop 10609 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05178982]]\n",
      "Loop 10610 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05179021]]\n",
      "Loop 10611 Loss_Train:  [[ 13.19524876]] Loss_Validation:  [[ 11.05179059]]\n",
      "Loop 10612 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179097]]\n",
      "Loop 10613 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179135]]\n",
      "Loop 10614 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179173]]\n",
      "Loop 10615 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179211]]\n",
      "Loop 10616 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179249]]\n",
      "Loop 10617 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179287]]\n",
      "Loop 10618 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179324]]\n",
      "Loop 10619 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179362]]\n",
      "Loop 10620 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.051794]]\n",
      "Loop 10621 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179438]]\n",
      "Loop 10622 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179476]]\n",
      "Loop 10623 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179514]]\n",
      "Loop 10624 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179551]]\n",
      "Loop 10625 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179589]]\n",
      "Loop 10626 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179627]]\n",
      "Loop 10627 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179664]]\n",
      "Loop 10628 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179702]]\n",
      "Loop 10629 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.0517974]]\n",
      "Loop 10630 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179777]]\n",
      "Loop 10631 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179815]]\n",
      "Loop 10632 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179852]]\n",
      "Loop 10633 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.0517989]]\n",
      "Loop 10634 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179927]]\n",
      "Loop 10635 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05179965]]\n",
      "Loop 10636 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05180002]]\n",
      "Loop 10637 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.0518004]]\n",
      "Loop 10638 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05180077]]\n",
      "Loop 10639 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05180114]]\n",
      "Loop 10640 Loss_Train:  [[ 13.19524875]] Loss_Validation:  [[ 11.05180152]]\n",
      "Loop 10641 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180189]]\n",
      "Loop 10642 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180226]]\n",
      "Loop 10643 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180263]]\n",
      "Loop 10644 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180301]]\n",
      "Loop 10645 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180338]]\n",
      "Loop 10646 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180375]]\n",
      "Loop 10647 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180412]]\n",
      "Loop 10648 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180449]]\n",
      "Loop 10649 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180486]]\n",
      "Loop 10650 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180523]]\n",
      "Loop 10651 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180561]]\n",
      "Loop 10652 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180598]]\n",
      "Loop 10653 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180635]]\n",
      "Loop 10654 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180671]]\n",
      "Loop 10655 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180708]]\n",
      "Loop 10656 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180745]]\n",
      "Loop 10657 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180782]]\n",
      "Loop 10658 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180819]]\n",
      "Loop 10659 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180856]]\n",
      "Loop 10660 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180893]]\n",
      "Loop 10661 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180929]]\n",
      "Loop 10662 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05180966]]\n",
      "Loop 10663 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05181003]]\n",
      "Loop 10664 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.0518104]]\n",
      "Loop 10665 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05181076]]\n",
      "Loop 10666 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05181113]]\n",
      "Loop 10667 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.0518115]]\n",
      "Loop 10668 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05181186]]\n",
      "Loop 10669 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05181223]]\n",
      "Loop 10670 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05181259]]\n",
      "Loop 10671 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05181296]]\n",
      "Loop 10672 Loss_Train:  [[ 13.19524874]] Loss_Validation:  [[ 11.05181332]]\n",
      "Loop 10673 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181369]]\n",
      "Loop 10674 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181405]]\n",
      "Loop 10675 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181442]]\n",
      "Loop 10676 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181478]]\n",
      "Loop 10677 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181515]]\n",
      "Loop 10678 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181551]]\n",
      "Loop 10679 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181587]]\n",
      "Loop 10680 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181623]]\n",
      "Loop 10681 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.0518166]]\n",
      "Loop 10682 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181696]]\n",
      "Loop 10683 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181732]]\n",
      "Loop 10684 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181768]]\n",
      "Loop 10685 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181805]]\n",
      "Loop 10686 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181841]]\n",
      "Loop 10687 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181877]]\n",
      "Loop 10688 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181913]]\n",
      "Loop 10689 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181949]]\n",
      "Loop 10690 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05181985]]\n",
      "Loop 10691 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182021]]\n",
      "Loop 10692 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182057]]\n",
      "Loop 10693 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182093]]\n",
      "Loop 10694 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182129]]\n",
      "Loop 10695 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182165]]\n",
      "Loop 10696 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182201]]\n",
      "Loop 10697 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182237]]\n",
      "Loop 10698 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182273]]\n",
      "Loop 10699 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182308]]\n",
      "Loop 10700 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182344]]\n",
      "Loop 10701 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.0518238]]\n",
      "Loop 10702 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182416]]\n",
      "Loop 10703 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182451]]\n",
      "Loop 10704 Loss_Train:  [[ 13.19524873]] Loss_Validation:  [[ 11.05182487]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 10705 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182523]]\n",
      "Loop 10706 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182558]]\n",
      "Loop 10707 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182594]]\n",
      "Loop 10708 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.0518263]]\n",
      "Loop 10709 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182665]]\n",
      "Loop 10710 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182701]]\n",
      "Loop 10711 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182736]]\n",
      "Loop 10712 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182772]]\n",
      "Loop 10713 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182807]]\n",
      "Loop 10714 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182843]]\n",
      "Loop 10715 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182878]]\n",
      "Loop 10716 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182913]]\n",
      "Loop 10717 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182949]]\n",
      "Loop 10718 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05182984]]\n",
      "Loop 10719 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183019]]\n",
      "Loop 10720 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183055]]\n",
      "Loop 10721 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.0518309]]\n",
      "Loop 10722 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183125]]\n",
      "Loop 10723 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183161]]\n",
      "Loop 10724 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183196]]\n",
      "Loop 10725 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183231]]\n",
      "Loop 10726 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183266]]\n",
      "Loop 10727 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183301]]\n",
      "Loop 10728 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183336]]\n",
      "Loop 10729 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183371]]\n",
      "Loop 10730 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183406]]\n",
      "Loop 10731 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183441]]\n",
      "Loop 10732 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183476]]\n",
      "Loop 10733 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183511]]\n",
      "Loop 10734 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183546]]\n",
      "Loop 10735 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183581]]\n",
      "Loop 10736 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183616]]\n",
      "Loop 10737 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183651]]\n",
      "Loop 10738 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183686]]\n",
      "Loop 10739 Loss_Train:  [[ 13.19524872]] Loss_Validation:  [[ 11.05183721]]\n",
      "Loop 10740 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05183756]]\n",
      "Loop 10741 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.0518379]]\n",
      "Loop 10742 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05183825]]\n",
      "Loop 10743 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.0518386]]\n",
      "Loop 10744 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05183895]]\n",
      "Loop 10745 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05183929]]\n",
      "Loop 10746 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05183964]]\n",
      "Loop 10747 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05183999]]\n",
      "Loop 10748 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184033]]\n",
      "Loop 10749 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184068]]\n",
      "Loop 10750 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184102]]\n",
      "Loop 10751 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184137]]\n",
      "Loop 10752 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184171]]\n",
      "Loop 10753 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184206]]\n",
      "Loop 10754 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.0518424]]\n",
      "Loop 10755 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184275]]\n",
      "Loop 10756 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184309]]\n",
      "Loop 10757 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184344]]\n",
      "Loop 10758 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184378]]\n",
      "Loop 10759 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184412]]\n",
      "Loop 10760 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184447]]\n",
      "Loop 10761 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184481]]\n",
      "Loop 10762 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184515]]\n",
      "Loop 10763 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184549]]\n",
      "Loop 10764 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184584]]\n",
      "Loop 10765 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184618]]\n",
      "Loop 10766 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184652]]\n",
      "Loop 10767 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184686]]\n",
      "Loop 10768 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.0518472]]\n",
      "Loop 10769 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184754]]\n",
      "Loop 10770 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184789]]\n",
      "Loop 10771 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184823]]\n",
      "Loop 10772 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184857]]\n",
      "Loop 10773 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184891]]\n",
      "Loop 10774 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184925]]\n",
      "Loop 10775 Loss_Train:  [[ 13.19524871]] Loss_Validation:  [[ 11.05184959]]\n",
      "Loop 10776 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05184993]]\n",
      "Loop 10777 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185027]]\n",
      "Loop 10778 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.0518506]]\n",
      "Loop 10779 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185094]]\n",
      "Loop 10780 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185128]]\n",
      "Loop 10781 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185162]]\n",
      "Loop 10782 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185196]]\n",
      "Loop 10783 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.0518523]]\n",
      "Loop 10784 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185263]]\n",
      "Loop 10785 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185297]]\n",
      "Loop 10786 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185331]]\n",
      "Loop 10787 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185364]]\n",
      "Loop 10788 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185398]]\n",
      "Loop 10789 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185432]]\n",
      "Loop 10790 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185465]]\n",
      "Loop 10791 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185499]]\n",
      "Loop 10792 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185532]]\n",
      "Loop 10793 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185566]]\n",
      "Loop 10794 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.051856]]\n",
      "Loop 10795 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185633]]\n",
      "Loop 10796 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185667]]\n",
      "Loop 10797 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.051857]]\n",
      "Loop 10798 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185733]]\n",
      "Loop 10799 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185767]]\n",
      "Loop 10800 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.051858]]\n",
      "Loop 10801 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185834]]\n",
      "Loop 10802 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185867]]\n",
      "Loop 10803 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.051859]]\n",
      "Loop 10804 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185933]]\n",
      "Loop 10805 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05185967]]\n",
      "Loop 10806 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05186]]\n",
      "Loop 10807 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05186033]]\n",
      "Loop 10808 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05186066]]\n",
      "Loop 10809 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.051861]]\n",
      "Loop 10810 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05186133]]\n",
      "Loop 10811 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05186166]]\n",
      "Loop 10812 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05186199]]\n",
      "Loop 10813 Loss_Train:  [[ 13.1952487]] Loss_Validation:  [[ 11.05186232]]\n",
      "Loop 10814 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186265]]\n",
      "Loop 10815 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186298]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 10816 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186331]]\n",
      "Loop 10817 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186364]]\n",
      "Loop 10818 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186397]]\n",
      "Loop 10819 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.0518643]]\n",
      "Loop 10820 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186463]]\n",
      "Loop 10821 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186496]]\n",
      "Loop 10822 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186529]]\n",
      "Loop 10823 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186562]]\n",
      "Loop 10824 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186594]]\n",
      "Loop 10825 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186627]]\n",
      "Loop 10826 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.0518666]]\n",
      "Loop 10827 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186693]]\n",
      "Loop 10828 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186725]]\n",
      "Loop 10829 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186758]]\n",
      "Loop 10830 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186791]]\n",
      "Loop 10831 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186823]]\n",
      "Loop 10832 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186856]]\n",
      "Loop 10833 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186889]]\n",
      "Loop 10834 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186921]]\n",
      "Loop 10835 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186954]]\n",
      "Loop 10836 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05186986]]\n",
      "Loop 10837 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187019]]\n",
      "Loop 10838 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187051]]\n",
      "Loop 10839 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187084]]\n",
      "Loop 10840 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187116]]\n",
      "Loop 10841 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187149]]\n",
      "Loop 10842 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187181]]\n",
      "Loop 10843 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187214]]\n",
      "Loop 10844 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187246]]\n",
      "Loop 10845 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187278]]\n",
      "Loop 10846 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187311]]\n",
      "Loop 10847 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187343]]\n",
      "Loop 10848 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187375]]\n",
      "Loop 10849 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187408]]\n",
      "Loop 10850 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.0518744]]\n",
      "Loop 10851 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187472]]\n",
      "Loop 10852 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187504]]\n",
      "Loop 10853 Loss_Train:  [[ 13.19524869]] Loss_Validation:  [[ 11.05187536]]\n",
      "Loop 10854 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187568]]\n",
      "Loop 10855 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187601]]\n",
      "Loop 10856 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187633]]\n",
      "Loop 10857 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187665]]\n",
      "Loop 10858 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187697]]\n",
      "Loop 10859 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187729]]\n",
      "Loop 10860 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187761]]\n",
      "Loop 10861 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187793]]\n",
      "Loop 10862 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187825]]\n",
      "Loop 10863 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187857]]\n",
      "Loop 10864 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187889]]\n",
      "Loop 10865 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187921]]\n",
      "Loop 10866 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187952]]\n",
      "Loop 10867 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05187984]]\n",
      "Loop 10868 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188016]]\n",
      "Loop 10869 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188048]]\n",
      "Loop 10870 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.0518808]]\n",
      "Loop 10871 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188112]]\n",
      "Loop 10872 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188143]]\n",
      "Loop 10873 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188175]]\n",
      "Loop 10874 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188207]]\n",
      "Loop 10875 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188238]]\n",
      "Loop 10876 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.0518827]]\n",
      "Loop 10877 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188302]]\n",
      "Loop 10878 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188333]]\n",
      "Loop 10879 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188365]]\n",
      "Loop 10880 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188396]]\n",
      "Loop 10881 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188428]]\n",
      "Loop 10882 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188459]]\n",
      "Loop 10883 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188491]]\n",
      "Loop 10884 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188522]]\n",
      "Loop 10885 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188554]]\n",
      "Loop 10886 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188585]]\n",
      "Loop 10887 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188617]]\n",
      "Loop 10888 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188648]]\n",
      "Loop 10889 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.0518868]]\n",
      "Loop 10890 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188711]]\n",
      "Loop 10891 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188742]]\n",
      "Loop 10892 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188773]]\n",
      "Loop 10893 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188805]]\n",
      "Loop 10894 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188836]]\n",
      "Loop 10895 Loss_Train:  [[ 13.19524868]] Loss_Validation:  [[ 11.05188867]]\n",
      "Loop 10896 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05188898]]\n",
      "Loop 10897 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.0518893]]\n",
      "Loop 10898 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05188961]]\n",
      "Loop 10899 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05188992]]\n",
      "Loop 10900 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189023]]\n",
      "Loop 10901 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189054]]\n",
      "Loop 10902 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189085]]\n",
      "Loop 10903 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189116]]\n",
      "Loop 10904 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189147]]\n",
      "Loop 10905 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189178]]\n",
      "Loop 10906 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189209]]\n",
      "Loop 10907 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.0518924]]\n",
      "Loop 10908 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189271]]\n",
      "Loop 10909 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189302]]\n",
      "Loop 10910 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189333]]\n",
      "Loop 10911 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189364]]\n",
      "Loop 10912 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189395]]\n",
      "Loop 10913 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189426]]\n",
      "Loop 10914 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189457]]\n",
      "Loop 10915 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189487]]\n",
      "Loop 10916 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189518]]\n",
      "Loop 10917 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189549]]\n",
      "Loop 10918 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.0518958]]\n",
      "Loop 10919 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.0518961]]\n",
      "Loop 10920 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189641]]\n",
      "Loop 10921 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189672]]\n",
      "Loop 10922 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189702]]\n",
      "Loop 10923 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189733]]\n",
      "Loop 10924 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189764]]\n",
      "Loop 10925 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189794]]\n",
      "Loop 10926 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189825]]\n",
      "Loop 10927 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189855]]\n",
      "Loop 10928 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189886]]\n",
      "Loop 10929 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189916]]\n",
      "Loop 10930 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189947]]\n",
      "Loop 10931 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05189977]]\n",
      "Loop 10932 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05190008]]\n",
      "Loop 10933 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05190038]]\n",
      "Loop 10934 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05190069]]\n",
      "Loop 10935 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05190099]]\n",
      "Loop 10936 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05190129]]\n",
      "Loop 10937 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.0519016]]\n",
      "Loop 10938 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.0519019]]\n",
      "Loop 10939 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.0519022]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 10940 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05190251]]\n",
      "Loop 10941 Loss_Train:  [[ 13.19524867]] Loss_Validation:  [[ 11.05190281]]\n",
      "Loop 10942 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190311]]\n",
      "Loop 10943 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190341]]\n",
      "Loop 10944 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190371]]\n",
      "Loop 10945 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190402]]\n",
      "Loop 10946 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190432]]\n",
      "Loop 10947 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190462]]\n",
      "Loop 10948 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190492]]\n",
      "Loop 10949 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190522]]\n",
      "Loop 10950 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190552]]\n",
      "Loop 10951 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190582]]\n",
      "Loop 10952 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190612]]\n",
      "Loop 10953 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190642]]\n",
      "Loop 10954 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190672]]\n",
      "Loop 10955 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190702]]\n",
      "Loop 10956 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190732]]\n",
      "Loop 10957 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190762]]\n",
      "Loop 10958 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190792]]\n",
      "Loop 10959 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190822]]\n",
      "Loop 10960 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190852]]\n",
      "Loop 10961 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190881]]\n",
      "Loop 10962 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190911]]\n",
      "Loop 10963 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190941]]\n",
      "Loop 10964 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05190971]]\n",
      "Loop 10965 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191]]\n",
      "Loop 10966 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.0519103]]\n",
      "Loop 10967 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.0519106]]\n",
      "Loop 10968 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.0519109]]\n",
      "Loop 10969 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191119]]\n",
      "Loop 10970 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191149]]\n",
      "Loop 10971 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191178]]\n",
      "Loop 10972 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191208]]\n",
      "Loop 10973 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191238]]\n",
      "Loop 10974 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191267]]\n",
      "Loop 10975 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191297]]\n",
      "Loop 10976 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191326]]\n",
      "Loop 10977 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191356]]\n",
      "Loop 10978 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191385]]\n",
      "Loop 10979 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191415]]\n",
      "Loop 10980 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191444]]\n",
      "Loop 10981 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191474]]\n",
      "Loop 10982 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191503]]\n",
      "Loop 10983 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191532]]\n",
      "Loop 10984 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191562]]\n",
      "Loop 10985 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191591]]\n",
      "Loop 10986 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.0519162]]\n",
      "Loop 10987 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.0519165]]\n",
      "Loop 10988 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191679]]\n",
      "Loop 10989 Loss_Train:  [[ 13.19524866]] Loss_Validation:  [[ 11.05191708]]\n",
      "Loop 10990 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05191737]]\n",
      "Loop 10991 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05191767]]\n",
      "Loop 10992 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05191796]]\n",
      "Loop 10993 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05191825]]\n",
      "Loop 10994 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05191854]]\n",
      "Loop 10995 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05191883]]\n",
      "Loop 10996 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05191912]]\n",
      "Loop 10997 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05191941]]\n",
      "Loop 10998 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.0519197]]\n",
      "Loop 10999 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192]]\n",
      "Loop 11000 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192029]]\n",
      "Loop 11001 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192058]]\n",
      "Loop 11002 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192087]]\n",
      "Loop 11003 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192116]]\n",
      "Loop 11004 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192144]]\n",
      "Loop 11005 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192173]]\n",
      "Loop 11006 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192202]]\n",
      "Loop 11007 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192231]]\n",
      "Loop 11008 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.0519226]]\n",
      "Loop 11009 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192289]]\n",
      "Loop 11010 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192318]]\n",
      "Loop 11011 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192347]]\n",
      "Loop 11012 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192375]]\n",
      "Loop 11013 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192404]]\n",
      "Loop 11014 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192433]]\n",
      "Loop 11015 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192462]]\n",
      "Loop 11016 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.0519249]]\n",
      "Loop 11017 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192519]]\n",
      "Loop 11018 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192548]]\n",
      "Loop 11019 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192576]]\n",
      "Loop 11020 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192605]]\n",
      "Loop 11021 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192633]]\n",
      "Loop 11022 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192662]]\n",
      "Loop 11023 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192691]]\n",
      "Loop 11024 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192719]]\n",
      "Loop 11025 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192748]]\n",
      "Loop 11026 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192776]]\n",
      "Loop 11027 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192805]]\n",
      "Loop 11028 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192833]]\n",
      "Loop 11029 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192862]]\n",
      "Loop 11030 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.0519289]]\n",
      "Loop 11031 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192918]]\n",
      "Loop 11032 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192947]]\n",
      "Loop 11033 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05192975]]\n",
      "Loop 11034 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05193003]]\n",
      "Loop 11035 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05193032]]\n",
      "Loop 11036 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.0519306]]\n",
      "Loop 11037 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05193088]]\n",
      "Loop 11038 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05193117]]\n",
      "Loop 11039 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05193145]]\n",
      "Loop 11040 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05193173]]\n",
      "Loop 11041 Loss_Train:  [[ 13.19524865]] Loss_Validation:  [[ 11.05193201]]\n",
      "Loop 11042 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.0519323]]\n",
      "Loop 11043 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193258]]\n",
      "Loop 11044 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193286]]\n",
      "Loop 11045 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193314]]\n",
      "Loop 11046 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193342]]\n",
      "Loop 11047 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.0519337]]\n",
      "Loop 11048 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193398]]\n",
      "Loop 11049 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193426]]\n",
      "Loop 11050 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193454]]\n",
      "Loop 11051 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193482]]\n",
      "Loop 11052 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.0519351]]\n",
      "Loop 11053 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193538]]\n",
      "Loop 11054 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193566]]\n",
      "Loop 11055 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193594]]\n",
      "Loop 11056 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193622]]\n",
      "Loop 11057 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.0519365]]\n",
      "Loop 11058 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193678]]\n",
      "Loop 11059 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193706]]\n",
      "Loop 11060 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193734]]\n",
      "Loop 11061 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193761]]\n",
      "Loop 11062 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193789]]\n",
      "Loop 11063 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193817]]\n",
      "Loop 11064 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193845]]\n",
      "Loop 11065 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193872]]\n",
      "Loop 11066 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.051939]]\n",
      "Loop 11067 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193928]]\n",
      "Loop 11068 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193956]]\n",
      "Loop 11069 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05193983]]\n",
      "Loop 11070 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194011]]\n",
      "Loop 11071 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194038]]\n",
      "Loop 11072 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194066]]\n",
      "Loop 11073 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194094]]\n",
      "Loop 11074 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194121]]\n",
      "Loop 11075 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194149]]\n",
      "Loop 11076 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194176]]\n",
      "Loop 11077 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194204]]\n",
      "Loop 11078 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194231]]\n",
      "Loop 11079 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194259]]\n",
      "Loop 11080 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194286]]\n",
      "Loop 11081 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194314]]\n",
      "Loop 11082 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194341]]\n",
      "Loop 11083 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194368]]\n",
      "Loop 11084 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194396]]\n",
      "Loop 11085 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194423]]\n",
      "Loop 11086 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.0519445]]\n",
      "Loop 11087 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194478]]\n",
      "Loop 11088 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194505]]\n",
      "Loop 11089 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194532]]\n",
      "Loop 11090 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.0519456]]\n",
      "Loop 11091 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194587]]\n",
      "Loop 11092 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194614]]\n",
      "Loop 11093 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194641]]\n",
      "Loop 11094 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194668]]\n",
      "Loop 11095 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194696]]\n",
      "Loop 11096 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194723]]\n",
      "Loop 11097 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.0519475]]\n",
      "Loop 11098 Loss_Train:  [[ 13.19524864]] Loss_Validation:  [[ 11.05194777]]\n",
      "Loop 11099 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05194804]]\n",
      "Loop 11100 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05194831]]\n",
      "Loop 11101 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05194858]]\n",
      "Loop 11102 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05194885]]\n",
      "Loop 11103 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05194912]]\n",
      "Loop 11104 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05194939]]\n",
      "Loop 11105 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05194966]]\n",
      "Loop 11106 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05194993]]\n",
      "Loop 11107 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.0519502]]\n",
      "Loop 11108 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195047]]\n",
      "Loop 11109 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195074]]\n",
      "Loop 11110 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195101]]\n",
      "Loop 11111 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195128]]\n",
      "Loop 11112 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195154]]\n",
      "Loop 11113 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195181]]\n",
      "Loop 11114 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195208]]\n",
      "Loop 11115 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195235]]\n",
      "Loop 11116 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195262]]\n",
      "Loop 11117 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195288]]\n",
      "Loop 11118 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195315]]\n",
      "Loop 11119 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195342]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 11120 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195369]]\n",
      "Loop 11121 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195395]]\n",
      "Loop 11122 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195422]]\n",
      "Loop 11123 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195448]]\n",
      "Loop 11124 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195475]]\n",
      "Loop 11125 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195502]]\n",
      "Loop 11126 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195528]]\n",
      "Loop 11127 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195555]]\n",
      "Loop 11128 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195581]]\n",
      "Loop 11129 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195608]]\n",
      "Loop 11130 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195634]]\n",
      "Loop 11131 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195661]]\n",
      "Loop 11132 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195687]]\n",
      "Loop 11133 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195714]]\n",
      "Loop 11134 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.0519574]]\n",
      "Loop 11135 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195767]]\n",
      "Loop 11136 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195793]]\n",
      "Loop 11137 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195819]]\n",
      "Loop 11138 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195846]]\n",
      "Loop 11139 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195872]]\n",
      "Loop 11140 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195898]]\n",
      "Loop 11141 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195925]]\n",
      "Loop 11142 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195951]]\n",
      "Loop 11143 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05195977]]\n",
      "Loop 11144 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196004]]\n",
      "Loop 11145 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.0519603]]\n",
      "Loop 11146 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196056]]\n",
      "Loop 11147 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196082]]\n",
      "Loop 11148 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196108]]\n",
      "Loop 11149 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196134]]\n",
      "Loop 11150 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196161]]\n",
      "Loop 11151 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196187]]\n",
      "Loop 11152 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196213]]\n",
      "Loop 11153 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196239]]\n",
      "Loop 11154 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196265]]\n",
      "Loop 11155 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196291]]\n",
      "Loop 11156 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196317]]\n",
      "Loop 11157 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196343]]\n",
      "Loop 11158 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196369]]\n",
      "Loop 11159 Loss_Train:  [[ 13.19524863]] Loss_Validation:  [[ 11.05196395]]\n",
      "Loop 11160 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196421]]\n",
      "Loop 11161 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196447]]\n",
      "Loop 11162 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196473]]\n",
      "Loop 11163 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196499]]\n",
      "Loop 11164 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196525]]\n",
      "Loop 11165 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.0519655]]\n",
      "Loop 11166 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196576]]\n",
      "Loop 11167 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196602]]\n",
      "Loop 11168 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196628]]\n",
      "Loop 11169 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196654]]\n",
      "Loop 11170 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.0519668]]\n",
      "Loop 11171 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196705]]\n",
      "Loop 11172 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196731]]\n",
      "Loop 11173 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196757]]\n",
      "Loop 11174 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196782]]\n",
      "Loop 11175 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196808]]\n",
      "Loop 11176 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196834]]\n",
      "Loop 11177 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196859]]\n",
      "Loop 11178 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196885]]\n",
      "Loop 11179 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196911]]\n",
      "Loop 11180 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196936]]\n",
      "Loop 11181 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196962]]\n",
      "Loop 11182 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05196987]]\n",
      "Loop 11183 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197013]]\n",
      "Loop 11184 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197038]]\n",
      "Loop 11185 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197064]]\n",
      "Loop 11186 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197089]]\n",
      "Loop 11187 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197115]]\n",
      "Loop 11188 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.0519714]]\n",
      "Loop 11189 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197166]]\n",
      "Loop 11190 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197191]]\n",
      "Loop 11191 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197217]]\n",
      "Loop 11192 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197242]]\n",
      "Loop 11193 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197267]]\n",
      "Loop 11194 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197293]]\n",
      "Loop 11195 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197318]]\n",
      "Loop 11196 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197343]]\n",
      "Loop 11197 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197369]]\n",
      "Loop 11198 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197394]]\n",
      "Loop 11199 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197419]]\n",
      "Loop 11200 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197444]]\n",
      "Loop 11201 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.0519747]]\n",
      "Loop 11202 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197495]]\n",
      "Loop 11203 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.0519752]]\n",
      "Loop 11204 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197545]]\n",
      "Loop 11205 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.0519757]]\n",
      "Loop 11206 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197596]]\n",
      "Loop 11207 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197621]]\n",
      "Loop 11208 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197646]]\n",
      "Loop 11209 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197671]]\n",
      "Loop 11210 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197696]]\n",
      "Loop 11211 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197721]]\n",
      "Loop 11212 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197746]]\n",
      "Loop 11213 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197771]]\n",
      "Loop 11214 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197796]]\n",
      "Loop 11215 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197821]]\n",
      "Loop 11216 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197846]]\n",
      "Loop 11217 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197871]]\n",
      "Loop 11218 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197896]]\n",
      "Loop 11219 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197921]]\n",
      "Loop 11220 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197946]]\n",
      "Loop 11221 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.0519797]]\n",
      "Loop 11222 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05197995]]\n",
      "Loop 11223 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.0519802]]\n",
      "Loop 11224 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05198045]]\n",
      "Loop 11225 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.0519807]]\n",
      "Loop 11226 Loss_Train:  [[ 13.19524862]] Loss_Validation:  [[ 11.05198095]]\n",
      "Loop 11227 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198119]]\n",
      "Loop 11228 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198144]]\n",
      "Loop 11229 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198169]]\n",
      "Loop 11230 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198193]]\n",
      "Loop 11231 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198218]]\n",
      "Loop 11232 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198243]]\n",
      "Loop 11233 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198268]]\n",
      "Loop 11234 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198292]]\n",
      "Loop 11235 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198317]]\n",
      "Loop 11236 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198341]]\n",
      "Loop 11237 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198366]]\n",
      "Loop 11238 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198391]]\n",
      "Loop 11239 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198415]]\n",
      "Loop 11240 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.0519844]]\n",
      "Loop 11241 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198464]]\n",
      "Loop 11242 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198489]]\n",
      "Loop 11243 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198513]]\n",
      "Loop 11244 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198538]]\n",
      "Loop 11245 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198562]]\n",
      "Loop 11246 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198587]]\n",
      "Loop 11247 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198611]]\n",
      "Loop 11248 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198635]]\n",
      "Loop 11249 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.0519866]]\n",
      "Loop 11250 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198684]]\n",
      "Loop 11251 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198709]]\n",
      "Loop 11252 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198733]]\n",
      "Loop 11253 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198757]]\n",
      "Loop 11254 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198781]]\n",
      "Loop 11255 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198806]]\n",
      "Loop 11256 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.0519883]]\n",
      "Loop 11257 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198854]]\n",
      "Loop 11258 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198879]]\n",
      "Loop 11259 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198903]]\n",
      "Loop 11260 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198927]]\n",
      "Loop 11261 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198951]]\n",
      "Loop 11262 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198975]]\n",
      "Loop 11263 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05198999]]\n",
      "Loop 11264 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199024]]\n",
      "Loop 11265 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199048]]\n",
      "Loop 11266 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199072]]\n",
      "Loop 11267 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199096]]\n",
      "Loop 11268 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.0519912]]\n",
      "Loop 11269 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199144]]\n",
      "Loop 11270 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199168]]\n",
      "Loop 11271 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199192]]\n",
      "Loop 11272 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199216]]\n",
      "Loop 11273 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.0519924]]\n",
      "Loop 11274 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199264]]\n",
      "Loop 11275 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199288]]\n",
      "Loop 11276 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199312]]\n",
      "Loop 11277 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199336]]\n",
      "Loop 11278 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.0519936]]\n",
      "Loop 11279 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199384]]\n",
      "Loop 11280 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199407]]\n",
      "Loop 11281 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199431]]\n",
      "Loop 11282 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199455]]\n",
      "Loop 11283 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199479]]\n",
      "Loop 11284 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199503]]\n",
      "Loop 11285 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199527]]\n",
      "Loop 11286 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.0519955]]\n",
      "Loop 11287 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199574]]\n",
      "Loop 11288 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199598]]\n",
      "Loop 11289 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199621]]\n",
      "Loop 11290 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199645]]\n",
      "Loop 11291 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199669]]\n",
      "Loop 11292 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199693]]\n",
      "Loop 11293 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199716]]\n",
      "Loop 11294 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.0519974]]\n",
      "Loop 11295 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199763]]\n",
      "Loop 11296 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199787]]\n",
      "Loop 11297 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199811]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 11298 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199834]]\n",
      "Loop 11299 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199858]]\n",
      "Loop 11300 Loss_Train:  [[ 13.19524861]] Loss_Validation:  [[ 11.05199881]]\n",
      "Loop 11301 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05199905]]\n",
      "Loop 11302 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05199928]]\n",
      "Loop 11303 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05199952]]\n",
      "Loop 11304 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05199975]]\n",
      "Loop 11305 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05199999]]\n",
      "Loop 11306 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200022]]\n",
      "Loop 11307 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200046]]\n",
      "Loop 11308 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200069]]\n",
      "Loop 11309 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200092]]\n",
      "Loop 11310 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200116]]\n",
      "Loop 11311 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200139]]\n",
      "Loop 11312 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200162]]\n",
      "Loop 11313 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200186]]\n",
      "Loop 11314 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200209]]\n",
      "Loop 11315 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200232]]\n",
      "Loop 11316 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200256]]\n",
      "Loop 11317 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200279]]\n",
      "Loop 11318 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200302]]\n",
      "Loop 11319 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200325]]\n",
      "Loop 11320 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200348]]\n",
      "Loop 11321 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200372]]\n",
      "Loop 11322 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200395]]\n",
      "Loop 11323 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200418]]\n",
      "Loop 11324 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200441]]\n",
      "Loop 11325 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200464]]\n",
      "Loop 11326 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200487]]\n",
      "Loop 11327 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.0520051]]\n",
      "Loop 11328 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200534]]\n",
      "Loop 11329 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200557]]\n",
      "Loop 11330 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.0520058]]\n",
      "Loop 11331 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200603]]\n",
      "Loop 11332 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200626]]\n",
      "Loop 11333 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200649]]\n",
      "Loop 11334 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200672]]\n",
      "Loop 11335 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200695]]\n",
      "Loop 11336 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200718]]\n",
      "Loop 11337 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200741]]\n",
      "Loop 11338 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200763]]\n",
      "Loop 11339 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200786]]\n",
      "Loop 11340 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200809]]\n",
      "Loop 11341 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200832]]\n",
      "Loop 11342 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200855]]\n",
      "Loop 11343 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200878]]\n",
      "Loop 11344 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200901]]\n",
      "Loop 11345 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200923]]\n",
      "Loop 11346 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200946]]\n",
      "Loop 11347 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200969]]\n",
      "Loop 11348 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05200992]]\n",
      "Loop 11349 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201014]]\n",
      "Loop 11350 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201037]]\n",
      "Loop 11351 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.0520106]]\n",
      "Loop 11352 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201083]]\n",
      "Loop 11353 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201105]]\n",
      "Loop 11354 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201128]]\n",
      "Loop 11355 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201151]]\n",
      "Loop 11356 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201173]]\n",
      "Loop 11357 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201196]]\n",
      "Loop 11358 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201218]]\n",
      "Loop 11359 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201241]]\n",
      "Loop 11360 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201264]]\n",
      "Loop 11361 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201286]]\n",
      "Loop 11362 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201309]]\n",
      "Loop 11363 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201331]]\n",
      "Loop 11364 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201354]]\n",
      "Loop 11365 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201376]]\n",
      "Loop 11366 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201399]]\n",
      "Loop 11367 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201421]]\n",
      "Loop 11368 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201444]]\n",
      "Loop 11369 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201466]]\n",
      "Loop 11370 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201488]]\n",
      "Loop 11371 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201511]]\n",
      "Loop 11372 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201533]]\n",
      "Loop 11373 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201556]]\n",
      "Loop 11374 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201578]]\n",
      "Loop 11375 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.052016]]\n",
      "Loop 11376 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201623]]\n",
      "Loop 11377 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201645]]\n",
      "Loop 11378 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201667]]\n",
      "Loop 11379 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201689]]\n",
      "Loop 11380 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201712]]\n",
      "Loop 11381 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201734]]\n",
      "Loop 11382 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201756]]\n",
      "Loop 11383 Loss_Train:  [[ 13.1952486]] Loss_Validation:  [[ 11.05201778]]\n",
      "Loop 11384 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.052018]]\n",
      "Loop 11385 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05201823]]\n",
      "Loop 11386 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05201845]]\n",
      "Loop 11387 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05201867]]\n",
      "Loop 11388 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05201889]]\n",
      "Loop 11389 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05201911]]\n",
      "Loop 11390 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05201933]]\n",
      "Loop 11391 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05201955]]\n",
      "Loop 11392 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05201977]]\n",
      "Loop 11393 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05201999]]\n",
      "Loop 11394 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202022]]\n",
      "Loop 11395 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202044]]\n",
      "Loop 11396 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202066]]\n",
      "Loop 11397 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202088]]\n",
      "Loop 11398 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.0520211]]\n",
      "Loop 11399 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202131]]\n",
      "Loop 11400 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202153]]\n",
      "Loop 11401 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202175]]\n",
      "Loop 11402 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202197]]\n",
      "Loop 11403 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202219]]\n",
      "Loop 11404 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202241]]\n",
      "Loop 11405 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202263]]\n",
      "Loop 11406 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202285]]\n",
      "Loop 11407 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202307]]\n",
      "Loop 11408 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202328]]\n",
      "Loop 11409 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.0520235]]\n",
      "Loop 11410 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202372]]\n",
      "Loop 11411 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202394]]\n",
      "Loop 11412 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202416]]\n",
      "Loop 11413 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202437]]\n",
      "Loop 11414 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202459]]\n",
      "Loop 11415 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202481]]\n",
      "Loop 11416 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202502]]\n",
      "Loop 11417 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202524]]\n",
      "Loop 11418 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202546]]\n",
      "Loop 11419 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202567]]\n",
      "Loop 11420 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202589]]\n",
      "Loop 11421 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202611]]\n",
      "Loop 11422 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202632]]\n",
      "Loop 11423 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202654]]\n",
      "Loop 11424 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202675]]\n",
      "Loop 11425 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202697]]\n",
      "Loop 11426 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202719]]\n",
      "Loop 11427 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.0520274]]\n",
      "Loop 11428 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202762]]\n",
      "Loop 11429 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202783]]\n",
      "Loop 11430 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202805]]\n",
      "Loop 11431 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202826]]\n",
      "Loop 11432 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202848]]\n",
      "Loop 11433 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202869]]\n",
      "Loop 11434 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.0520289]]\n",
      "Loop 11435 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202912]]\n",
      "Loop 11436 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202933]]\n",
      "Loop 11437 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202955]]\n",
      "Loop 11438 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202976]]\n",
      "Loop 11439 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05202997]]\n",
      "Loop 11440 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203019]]\n",
      "Loop 11441 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.0520304]]\n",
      "Loop 11442 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203061]]\n",
      "Loop 11443 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203083]]\n",
      "Loop 11444 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203104]]\n",
      "Loop 11445 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203125]]\n",
      "Loop 11446 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203146]]\n",
      "Loop 11447 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203168]]\n",
      "Loop 11448 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203189]]\n",
      "Loop 11449 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.0520321]]\n",
      "Loop 11450 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203231]]\n",
      "Loop 11451 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203252]]\n",
      "Loop 11452 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203274]]\n",
      "Loop 11453 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203295]]\n",
      "Loop 11454 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203316]]\n",
      "Loop 11455 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203337]]\n",
      "Loop 11456 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203358]]\n",
      "Loop 11457 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203379]]\n",
      "Loop 11458 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.052034]]\n",
      "Loop 11459 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203421]]\n",
      "Loop 11460 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203442]]\n",
      "Loop 11461 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203463]]\n",
      "Loop 11462 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203484]]\n",
      "Loop 11463 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203505]]\n",
      "Loop 11464 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203526]]\n",
      "Loop 11465 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203547]]\n",
      "Loop 11466 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203568]]\n",
      "Loop 11467 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203589]]\n",
      "Loop 11468 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.0520361]]\n",
      "Loop 11469 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203631]]\n",
      "Loop 11470 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203652]]\n",
      "Loop 11471 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203673]]\n",
      "Loop 11472 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203694]]\n",
      "Loop 11473 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203715]]\n",
      "Loop 11474 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203735]]\n",
      "Loop 11475 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203756]]\n",
      "Loop 11476 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203777]]\n",
      "Loop 11477 Loss_Train:  [[ 13.19524859]] Loss_Validation:  [[ 11.05203798]]\n",
      "Loop 11478 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05203819]]\n",
      "Loop 11479 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05203839]]\n",
      "Loop 11480 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.0520386]]\n",
      "Loop 11481 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05203881]]\n",
      "Loop 11482 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05203902]]\n",
      "Loop 11483 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05203922]]\n",
      "Loop 11484 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05203943]]\n",
      "Loop 11485 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05203964]]\n",
      "Loop 11486 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05203984]]\n",
      "Loop 11487 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204005]]\n",
      "Loop 11488 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204026]]\n",
      "Loop 11489 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204046]]\n",
      "Loop 11490 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204067]]\n",
      "Loop 11491 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204087]]\n",
      "Loop 11492 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204108]]\n",
      "Loop 11493 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204128]]\n",
      "Loop 11494 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204149]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 11495 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.0520417]]\n",
      "Loop 11496 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.0520419]]\n",
      "Loop 11497 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204211]]\n",
      "Loop 11498 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204231]]\n",
      "Loop 11499 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204252]]\n",
      "Loop 11500 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204272]]\n",
      "Loop 11501 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204292]]\n",
      "Loop 11502 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204313]]\n",
      "Loop 11503 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204333]]\n",
      "Loop 11504 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204354]]\n",
      "Loop 11505 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204374]]\n",
      "Loop 11506 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204394]]\n",
      "Loop 11507 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204415]]\n",
      "Loop 11508 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204435]]\n",
      "Loop 11509 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204456]]\n",
      "Loop 11510 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204476]]\n",
      "Loop 11511 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204496]]\n",
      "Loop 11512 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204516]]\n",
      "Loop 11513 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204537]]\n",
      "Loop 11514 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204557]]\n",
      "Loop 11515 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204577]]\n",
      "Loop 11516 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204597]]\n",
      "Loop 11517 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204618]]\n",
      "Loop 11518 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204638]]\n",
      "Loop 11519 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204658]]\n",
      "Loop 11520 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204678]]\n",
      "Loop 11521 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204698]]\n",
      "Loop 11522 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204719]]\n",
      "Loop 11523 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204739]]\n",
      "Loop 11524 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204759]]\n",
      "Loop 11525 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204779]]\n",
      "Loop 11526 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204799]]\n",
      "Loop 11527 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204819]]\n",
      "Loop 11528 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204839]]\n",
      "Loop 11529 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204859]]\n",
      "Loop 11530 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204879]]\n",
      "Loop 11531 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204899]]\n",
      "Loop 11532 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204919]]\n",
      "Loop 11533 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204939]]\n",
      "Loop 11534 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204959]]\n",
      "Loop 11535 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204979]]\n",
      "Loop 11536 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05204999]]\n",
      "Loop 11537 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205019]]\n",
      "Loop 11538 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205039]]\n",
      "Loop 11539 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205059]]\n",
      "Loop 11540 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205079]]\n",
      "Loop 11541 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205099]]\n",
      "Loop 11542 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205119]]\n",
      "Loop 11543 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205138]]\n",
      "Loop 11544 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205158]]\n",
      "Loop 11545 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205178]]\n",
      "Loop 11546 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205198]]\n",
      "Loop 11547 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205218]]\n",
      "Loop 11548 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205237]]\n",
      "Loop 11549 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205257]]\n",
      "Loop 11550 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205277]]\n",
      "Loop 11551 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205297]]\n",
      "Loop 11552 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205316]]\n",
      "Loop 11553 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205336]]\n",
      "Loop 11554 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205356]]\n",
      "Loop 11555 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205376]]\n",
      "Loop 11556 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205395]]\n",
      "Loop 11557 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205415]]\n",
      "Loop 11558 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205435]]\n",
      "Loop 11559 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205454]]\n",
      "Loop 11560 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205474]]\n",
      "Loop 11561 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205493]]\n",
      "Loop 11562 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205513]]\n",
      "Loop 11563 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205533]]\n",
      "Loop 11564 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205552]]\n",
      "Loop 11565 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205572]]\n",
      "Loop 11566 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205591]]\n",
      "Loop 11567 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205611]]\n",
      "Loop 11568 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.0520563]]\n",
      "Loop 11569 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.0520565]]\n",
      "Loop 11570 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205669]]\n",
      "Loop 11571 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205689]]\n",
      "Loop 11572 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205708]]\n",
      "Loop 11573 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205728]]\n",
      "Loop 11574 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205747]]\n",
      "Loop 11575 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205766]]\n",
      "Loop 11576 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205786]]\n",
      "Loop 11577 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205805]]\n",
      "Loop 11578 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205825]]\n",
      "Loop 11579 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205844]]\n",
      "Loop 11580 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205863]]\n",
      "Loop 11581 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205883]]\n",
      "Loop 11582 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205902]]\n",
      "Loop 11583 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205921]]\n",
      "Loop 11584 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205941]]\n",
      "Loop 11585 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.0520596]]\n",
      "Loop 11586 Loss_Train:  [[ 13.19524858]] Loss_Validation:  [[ 11.05205979]]\n",
      "Loop 11587 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05205998]]\n",
      "Loop 11588 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206018]]\n",
      "Loop 11589 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206037]]\n",
      "Loop 11590 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206056]]\n",
      "Loop 11591 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206075]]\n",
      "Loop 11592 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206094]]\n",
      "Loop 11593 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206114]]\n",
      "Loop 11594 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206133]]\n",
      "Loop 11595 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206152]]\n",
      "Loop 11596 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206171]]\n",
      "Loop 11597 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.0520619]]\n",
      "Loop 11598 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206209]]\n",
      "Loop 11599 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206228]]\n",
      "Loop 11600 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206247]]\n",
      "Loop 11601 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206266]]\n",
      "Loop 11602 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206285]]\n",
      "Loop 11603 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206305]]\n",
      "Loop 11604 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206324]]\n",
      "Loop 11605 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206343]]\n",
      "Loop 11606 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206362]]\n",
      "Loop 11607 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206381]]\n",
      "Loop 11608 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.052064]]\n",
      "Loop 11609 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206418]]\n",
      "Loop 11610 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206437]]\n",
      "Loop 11611 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206456]]\n",
      "Loop 11612 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206475]]\n",
      "Loop 11613 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206494]]\n",
      "Loop 11614 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206513]]\n",
      "Loop 11615 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206532]]\n",
      "Loop 11616 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206551]]\n",
      "Loop 11617 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.0520657]]\n",
      "Loop 11618 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206588]]\n",
      "Loop 11619 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206607]]\n",
      "Loop 11620 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206626]]\n",
      "Loop 11621 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206645]]\n",
      "Loop 11622 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206664]]\n",
      "Loop 11623 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206682]]\n",
      "Loop 11624 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206701]]\n",
      "Loop 11625 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.0520672]]\n",
      "Loop 11626 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206739]]\n",
      "Loop 11627 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206757]]\n",
      "Loop 11628 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206776]]\n",
      "Loop 11629 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206795]]\n",
      "Loop 11630 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206814]]\n",
      "Loop 11631 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206832]]\n",
      "Loop 11632 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206851]]\n",
      "Loop 11633 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206869]]\n",
      "Loop 11634 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206888]]\n",
      "Loop 11635 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206907]]\n",
      "Loop 11636 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206925]]\n",
      "Loop 11637 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206944]]\n",
      "Loop 11638 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206962]]\n",
      "Loop 11639 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05206981]]\n",
      "Loop 11640 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207]]\n",
      "Loop 11641 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207018]]\n",
      "Loop 11642 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207037]]\n",
      "Loop 11643 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207055]]\n",
      "Loop 11644 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207074]]\n",
      "Loop 11645 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207092]]\n",
      "Loop 11646 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207111]]\n",
      "Loop 11647 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207129]]\n",
      "Loop 11648 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207148]]\n",
      "Loop 11649 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207166]]\n",
      "Loop 11650 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207184]]\n",
      "Loop 11651 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207203]]\n",
      "Loop 11652 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207221]]\n",
      "Loop 11653 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.0520724]]\n",
      "Loop 11654 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207258]]\n",
      "Loop 11655 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207276]]\n",
      "Loop 11656 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207295]]\n",
      "Loop 11657 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207313]]\n",
      "Loop 11658 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207331]]\n",
      "Loop 11659 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.0520735]]\n",
      "Loop 11660 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207368]]\n",
      "Loop 11661 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207386]]\n",
      "Loop 11662 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207404]]\n",
      "Loop 11663 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207423]]\n",
      "Loop 11664 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207441]]\n",
      "Loop 11665 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207459]]\n",
      "Loop 11666 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207477]]\n",
      "Loop 11667 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207496]]\n",
      "Loop 11668 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207514]]\n",
      "Loop 11669 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207532]]\n",
      "Loop 11670 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.0520755]]\n",
      "Loop 11671 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207568]]\n",
      "Loop 11672 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207586]]\n",
      "Loop 11673 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207605]]\n",
      "Loop 11674 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207623]]\n",
      "Loop 11675 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207641]]\n",
      "Loop 11676 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207659]]\n",
      "Loop 11677 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207677]]\n",
      "Loop 11678 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207695]]\n",
      "Loop 11679 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207713]]\n",
      "Loop 11680 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207731]]\n",
      "Loop 11681 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207749]]\n",
      "Loop 11682 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207767]]\n",
      "Loop 11683 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207785]]\n",
      "Loop 11684 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207803]]\n",
      "Loop 11685 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207821]]\n",
      "Loop 11686 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207839]]\n",
      "Loop 11687 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207857]]\n",
      "Loop 11688 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207875]]\n",
      "Loop 11689 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207893]]\n",
      "Loop 11690 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207911]]\n",
      "Loop 11691 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207929]]\n",
      "Loop 11692 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207947]]\n",
      "Loop 11693 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207964]]\n",
      "Loop 11694 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05207982]]\n",
      "Loop 11695 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208]]\n",
      "Loop 11696 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208018]]\n",
      "Loop 11697 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208036]]\n",
      "Loop 11698 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208054]]\n",
      "Loop 11699 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208071]]\n",
      "Loop 11700 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208089]]\n",
      "Loop 11701 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208107]]\n",
      "Loop 11702 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208125]]\n",
      "Loop 11703 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208142]]\n",
      "Loop 11704 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.0520816]]\n",
      "Loop 11705 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208178]]\n",
      "Loop 11706 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208196]]\n",
      "Loop 11707 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208213]]\n",
      "Loop 11708 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208231]]\n",
      "Loop 11709 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208249]]\n",
      "Loop 11710 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208266]]\n",
      "Loop 11711 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208284]]\n",
      "Loop 11712 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208302]]\n",
      "Loop 11713 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208319]]\n",
      "Loop 11714 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208337]]\n",
      "Loop 11715 Loss_Train:  [[ 13.19524857]] Loss_Validation:  [[ 11.05208354]]\n",
      "Loop 11716 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208372]]\n",
      "Loop 11717 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0520839]]\n",
      "Loop 11718 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208407]]\n",
      "Loop 11719 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208425]]\n",
      "Loop 11720 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208442]]\n",
      "Loop 11721 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0520846]]\n",
      "Loop 11722 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208477]]\n",
      "Loop 11723 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208495]]\n",
      "Loop 11724 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208512]]\n",
      "Loop 11725 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0520853]]\n",
      "Loop 11726 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208547]]\n",
      "Loop 11727 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208565]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 11728 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208582]]\n",
      "Loop 11729 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.052086]]\n",
      "Loop 11730 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208617]]\n",
      "Loop 11731 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208634]]\n",
      "Loop 11732 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208652]]\n",
      "Loop 11733 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208669]]\n",
      "Loop 11734 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208687]]\n",
      "Loop 11735 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208704]]\n",
      "Loop 11736 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208721]]\n",
      "Loop 11737 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208739]]\n",
      "Loop 11738 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208756]]\n",
      "Loop 11739 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208773]]\n",
      "Loop 11740 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208791]]\n",
      "Loop 11741 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208808]]\n",
      "Loop 11742 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208825]]\n",
      "Loop 11743 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208842]]\n",
      "Loop 11744 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0520886]]\n",
      "Loop 11745 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208877]]\n",
      "Loop 11746 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208894]]\n",
      "Loop 11747 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208911]]\n",
      "Loop 11748 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208928]]\n",
      "Loop 11749 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208946]]\n",
      "Loop 11750 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208963]]\n",
      "Loop 11751 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0520898]]\n",
      "Loop 11752 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05208997]]\n",
      "Loop 11753 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209014]]\n",
      "Loop 11754 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209031]]\n",
      "Loop 11755 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209048]]\n",
      "Loop 11756 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209066]]\n",
      "Loop 11757 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209083]]\n",
      "Loop 11758 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.052091]]\n",
      "Loop 11759 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209117]]\n",
      "Loop 11760 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209134]]\n",
      "Loop 11761 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209151]]\n",
      "Loop 11762 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209168]]\n",
      "Loop 11763 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209185]]\n",
      "Loop 11764 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209202]]\n",
      "Loop 11765 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209219]]\n",
      "Loop 11766 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209236]]\n",
      "Loop 11767 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209253]]\n",
      "Loop 11768 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0520927]]\n",
      "Loop 11769 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209287]]\n",
      "Loop 11770 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209304]]\n",
      "Loop 11771 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209321]]\n",
      "Loop 11772 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209338]]\n",
      "Loop 11773 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209355]]\n",
      "Loop 11774 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209371]]\n",
      "Loop 11775 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209388]]\n",
      "Loop 11776 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209405]]\n",
      "Loop 11777 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209422]]\n",
      "Loop 11778 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209439]]\n",
      "Loop 11779 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209456]]\n",
      "Loop 11780 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209472]]\n",
      "Loop 11781 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209489]]\n",
      "Loop 11782 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209506]]\n",
      "Loop 11783 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209523]]\n",
      "Loop 11784 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0520954]]\n",
      "Loop 11785 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209556]]\n",
      "Loop 11786 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209573]]\n",
      "Loop 11787 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0520959]]\n",
      "Loop 11788 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209607]]\n",
      "Loop 11789 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209623]]\n",
      "Loop 11790 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0520964]]\n",
      "Loop 11791 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209657]]\n",
      "Loop 11792 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209673]]\n",
      "Loop 11793 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0520969]]\n",
      "Loop 11794 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209707]]\n",
      "Loop 11795 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209723]]\n",
      "Loop 11796 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0520974]]\n",
      "Loop 11797 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209757]]\n",
      "Loop 11798 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209773]]\n",
      "Loop 11799 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0520979]]\n",
      "Loop 11800 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209806]]\n",
      "Loop 11801 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209823]]\n",
      "Loop 11802 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209839]]\n",
      "Loop 11803 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209856]]\n",
      "Loop 11804 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209873]]\n",
      "Loop 11805 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209889]]\n",
      "Loop 11806 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209906]]\n",
      "Loop 11807 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209922]]\n",
      "Loop 11808 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209939]]\n",
      "Loop 11809 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209955]]\n",
      "Loop 11810 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209972]]\n",
      "Loop 11811 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05209988]]\n",
      "Loop 11812 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210004]]\n",
      "Loop 11813 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210021]]\n",
      "Loop 11814 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210037]]\n",
      "Loop 11815 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210054]]\n",
      "Loop 11816 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0521007]]\n",
      "Loop 11817 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210086]]\n",
      "Loop 11818 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210103]]\n",
      "Loop 11819 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210119]]\n",
      "Loop 11820 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210136]]\n",
      "Loop 11821 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210152]]\n",
      "Loop 11822 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210168]]\n",
      "Loop 11823 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210185]]\n",
      "Loop 11824 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210201]]\n",
      "Loop 11825 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210217]]\n",
      "Loop 11826 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210233]]\n",
      "Loop 11827 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0521025]]\n",
      "Loop 11828 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210266]]\n",
      "Loop 11829 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210282]]\n",
      "Loop 11830 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210298]]\n",
      "Loop 11831 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210315]]\n",
      "Loop 11832 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210331]]\n",
      "Loop 11833 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210347]]\n",
      "Loop 11834 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210363]]\n",
      "Loop 11835 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0521038]]\n",
      "Loop 11836 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210396]]\n",
      "Loop 11837 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210412]]\n",
      "Loop 11838 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210428]]\n",
      "Loop 11839 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210444]]\n",
      "Loop 11840 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0521046]]\n",
      "Loop 11841 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210476]]\n",
      "Loop 11842 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210492]]\n",
      "Loop 11843 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210509]]\n",
      "Loop 11844 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210525]]\n",
      "Loop 11845 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210541]]\n",
      "Loop 11846 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210557]]\n",
      "Loop 11847 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210573]]\n",
      "Loop 11848 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210589]]\n",
      "Loop 11849 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210605]]\n",
      "Loop 11850 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210621]]\n",
      "Loop 11851 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210637]]\n",
      "Loop 11852 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210653]]\n",
      "Loop 11853 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210669]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 11854 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210685]]\n",
      "Loop 11855 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210701]]\n",
      "Loop 11856 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210717]]\n",
      "Loop 11857 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210733]]\n",
      "Loop 11858 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210749]]\n",
      "Loop 11859 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210764]]\n",
      "Loop 11860 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0521078]]\n",
      "Loop 11861 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210796]]\n",
      "Loop 11862 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210812]]\n",
      "Loop 11863 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210828]]\n",
      "Loop 11864 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210844]]\n",
      "Loop 11865 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0521086]]\n",
      "Loop 11866 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210876]]\n",
      "Loop 11867 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210891]]\n",
      "Loop 11868 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210907]]\n",
      "Loop 11869 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210923]]\n",
      "Loop 11870 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210939]]\n",
      "Loop 11871 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210955]]\n",
      "Loop 11872 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.0521097]]\n",
      "Loop 11873 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05210986]]\n",
      "Loop 11874 Loss_Train:  [[ 13.19524856]] Loss_Validation:  [[ 11.05211002]]\n",
      "Loop 11875 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211018]]\n",
      "Loop 11876 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211033]]\n",
      "Loop 11877 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211049]]\n",
      "Loop 11878 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211065]]\n",
      "Loop 11879 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521108]]\n",
      "Loop 11880 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211096]]\n",
      "Loop 11881 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211112]]\n",
      "Loop 11882 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211127]]\n",
      "Loop 11883 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211143]]\n",
      "Loop 11884 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211159]]\n",
      "Loop 11885 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211174]]\n",
      "Loop 11886 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521119]]\n",
      "Loop 11887 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211206]]\n",
      "Loop 11888 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211221]]\n",
      "Loop 11889 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211237]]\n",
      "Loop 11890 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211252]]\n",
      "Loop 11891 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211268]]\n",
      "Loop 11892 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211283]]\n",
      "Loop 11893 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211299]]\n",
      "Loop 11894 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211314]]\n",
      "Loop 11895 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521133]]\n",
      "Loop 11896 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211345]]\n",
      "Loop 11897 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211361]]\n",
      "Loop 11898 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211376]]\n",
      "Loop 11899 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211392]]\n",
      "Loop 11900 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211407]]\n",
      "Loop 11901 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211423]]\n",
      "Loop 11902 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211438]]\n",
      "Loop 11903 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211454]]\n",
      "Loop 11904 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211469]]\n",
      "Loop 11905 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211484]]\n",
      "Loop 11906 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.052115]]\n",
      "Loop 11907 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211515]]\n",
      "Loop 11908 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211531]]\n",
      "Loop 11909 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211546]]\n",
      "Loop 11910 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211561]]\n",
      "Loop 11911 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211577]]\n",
      "Loop 11912 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211592]]\n",
      "Loop 11913 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211607]]\n",
      "Loop 11914 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211623]]\n",
      "Loop 11915 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211638]]\n",
      "Loop 11916 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211653]]\n",
      "Loop 11917 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211669]]\n",
      "Loop 11918 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211684]]\n",
      "Loop 11919 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211699]]\n",
      "Loop 11920 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211714]]\n",
      "Loop 11921 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521173]]\n",
      "Loop 11922 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211745]]\n",
      "Loop 11923 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521176]]\n",
      "Loop 11924 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211775]]\n",
      "Loop 11925 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521179]]\n",
      "Loop 11926 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211806]]\n",
      "Loop 11927 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211821]]\n",
      "Loop 11928 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211836]]\n",
      "Loop 11929 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211851]]\n",
      "Loop 11930 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211866]]\n",
      "Loop 11931 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211881]]\n",
      "Loop 11932 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211896]]\n",
      "Loop 11933 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211912]]\n",
      "Loop 11934 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211927]]\n",
      "Loop 11935 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211942]]\n",
      "Loop 11936 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211957]]\n",
      "Loop 11937 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211972]]\n",
      "Loop 11938 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05211987]]\n",
      "Loop 11939 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212002]]\n",
      "Loop 11940 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212017]]\n",
      "Loop 11941 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212032]]\n",
      "Loop 11942 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212047]]\n",
      "Loop 11943 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212062]]\n",
      "Loop 11944 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212077]]\n",
      "Loop 11945 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212092]]\n",
      "Loop 11946 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212107]]\n",
      "Loop 11947 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212122]]\n",
      "Loop 11948 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212137]]\n",
      "Loop 11949 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212152]]\n",
      "Loop 11950 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212167]]\n",
      "Loop 11951 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212182]]\n",
      "Loop 11952 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212197]]\n",
      "Loop 11953 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212211]]\n",
      "Loop 11954 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212226]]\n",
      "Loop 11955 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212241]]\n",
      "Loop 11956 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212256]]\n",
      "Loop 11957 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212271]]\n",
      "Loop 11958 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212286]]\n",
      "Loop 11959 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212301]]\n",
      "Loop 11960 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212315]]\n",
      "Loop 11961 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521233]]\n",
      "Loop 11962 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212345]]\n",
      "Loop 11963 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521236]]\n",
      "Loop 11964 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212375]]\n",
      "Loop 11965 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212389]]\n",
      "Loop 11966 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212404]]\n",
      "Loop 11967 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212419]]\n",
      "Loop 11968 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212434]]\n",
      "Loop 11969 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212448]]\n",
      "Loop 11970 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212463]]\n",
      "Loop 11971 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212478]]\n",
      "Loop 11972 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212493]]\n",
      "Loop 11973 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212507]]\n",
      "Loop 11974 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212522]]\n",
      "Loop 11975 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212537]]\n",
      "Loop 11976 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212551]]\n",
      "Loop 11977 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212566]]\n",
      "Loop 11978 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212581]]\n",
      "Loop 11979 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212595]]\n",
      "Loop 11980 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521261]]\n",
      "Loop 11981 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212624]]\n",
      "Loop 11982 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212639]]\n",
      "Loop 11983 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212654]]\n",
      "Loop 11984 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212668]]\n",
      "Loop 11985 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212683]]\n",
      "Loop 11986 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212697]]\n",
      "Loop 11987 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212712]]\n",
      "Loop 11988 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212726]]\n",
      "Loop 11989 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212741]]\n",
      "Loop 11990 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212755]]\n",
      "Loop 11991 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521277]]\n",
      "Loop 11992 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212784]]\n",
      "Loop 11993 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212799]]\n",
      "Loop 11994 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212813]]\n",
      "Loop 11995 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212828]]\n",
      "Loop 11996 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212842]]\n",
      "Loop 11997 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212857]]\n",
      "Loop 11998 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212871]]\n",
      "Loop 11999 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212886]]\n",
      "Loop 12000 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.052129]]\n",
      "Loop 12001 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212914]]\n",
      "Loop 12002 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212929]]\n",
      "Loop 12003 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212943]]\n",
      "Loop 12004 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212958]]\n",
      "Loop 12005 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212972]]\n",
      "Loop 12006 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05212986]]\n",
      "Loop 12007 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213001]]\n",
      "Loop 12008 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213015]]\n",
      "Loop 12009 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213029]]\n",
      "Loop 12010 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213044]]\n",
      "Loop 12011 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213058]]\n",
      "Loop 12012 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213072]]\n",
      "Loop 12013 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213086]]\n",
      "Loop 12014 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213101]]\n",
      "Loop 12015 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213115]]\n",
      "Loop 12016 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213129]]\n",
      "Loop 12017 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213143]]\n",
      "Loop 12018 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213158]]\n",
      "Loop 12019 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213172]]\n",
      "Loop 12020 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213186]]\n",
      "Loop 12021 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.052132]]\n",
      "Loop 12022 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213215]]\n",
      "Loop 12023 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213229]]\n",
      "Loop 12024 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213243]]\n",
      "Loop 12025 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213257]]\n",
      "Loop 12026 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213271]]\n",
      "Loop 12027 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213285]]\n",
      "Loop 12028 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.052133]]\n",
      "Loop 12029 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213314]]\n",
      "Loop 12030 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213328]]\n",
      "Loop 12031 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213342]]\n",
      "Loop 12032 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213356]]\n",
      "Loop 12033 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521337]]\n",
      "Loop 12034 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213384]]\n",
      "Loop 12035 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213398]]\n",
      "Loop 12036 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213412]]\n",
      "Loop 12037 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213426]]\n",
      "Loop 12038 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521344]]\n",
      "Loop 12039 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213454]]\n",
      "Loop 12040 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213468]]\n",
      "Loop 12041 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213482]]\n",
      "Loop 12042 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213496]]\n",
      "Loop 12043 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521351]]\n",
      "Loop 12044 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213524]]\n",
      "Loop 12045 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213538]]\n",
      "Loop 12046 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213552]]\n",
      "Loop 12047 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213566]]\n",
      "Loop 12048 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521358]]\n",
      "Loop 12049 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213594]]\n",
      "Loop 12050 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213608]]\n",
      "Loop 12051 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213622]]\n",
      "Loop 12052 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213636]]\n",
      "Loop 12053 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521365]]\n",
      "Loop 12054 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213664]]\n",
      "Loop 12055 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213677]]\n",
      "Loop 12056 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213691]]\n",
      "Loop 12057 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213705]]\n",
      "Loop 12058 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213719]]\n",
      "Loop 12059 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213733]]\n",
      "Loop 12060 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213747]]\n",
      "Loop 12061 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521376]]\n",
      "Loop 12062 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213774]]\n",
      "Loop 12063 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213788]]\n",
      "Loop 12064 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213802]]\n",
      "Loop 12065 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213816]]\n",
      "Loop 12066 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213829]]\n",
      "Loop 12067 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213843]]\n",
      "Loop 12068 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213857]]\n",
      "Loop 12069 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213871]]\n",
      "Loop 12070 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213884]]\n",
      "Loop 12071 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213898]]\n",
      "Loop 12072 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213912]]\n",
      "Loop 12073 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213925]]\n",
      "Loop 12074 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213939]]\n",
      "Loop 12075 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213953]]\n",
      "Loop 12076 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213966]]\n",
      "Loop 12077 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.0521398]]\n",
      "Loop 12078 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05213994]]\n",
      "Loop 12079 Loss_Train:  [[ 13.19524855]] Loss_Validation:  [[ 11.05214007]]\n",
      "Loop 12080 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214021]]\n",
      "Loop 12081 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214035]]\n",
      "Loop 12082 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214048]]\n",
      "Loop 12083 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214062]]\n",
      "Loop 12084 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214075]]\n",
      "Loop 12085 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214089]]\n",
      "Loop 12086 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214103]]\n",
      "Loop 12087 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214116]]\n",
      "Loop 12088 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.0521413]]\n",
      "Loop 12089 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214143]]\n",
      "Loop 12090 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214157]]\n",
      "Loop 12091 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.0521417]]\n",
      "Loop 12092 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214184]]\n",
      "Loop 12093 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214197]]\n",
      "Loop 12094 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214211]]\n",
      "Loop 12095 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214224]]\n",
      "Loop 12096 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214238]]\n",
      "Loop 12097 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214251]]\n",
      "Loop 12098 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214265]]\n",
      "Loop 12099 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214278]]\n",
      "Loop 12100 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214292]]\n",
      "Loop 12101 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214305]]\n",
      "Loop 12102 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214318]]\n",
      "Loop 12103 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214332]]\n",
      "Loop 12104 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214345]]\n",
      "Loop 12105 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214359]]\n",
      "Loop 12106 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214372]]\n",
      "Loop 12107 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214385]]\n",
      "Loop 12108 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214399]]\n",
      "Loop 12109 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214412]]\n",
      "Loop 12110 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214425]]\n",
      "Loop 12111 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214439]]\n",
      "Loop 12112 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214452]]\n",
      "Loop 12113 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214465]]\n",
      "Loop 12114 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214479]]\n",
      "Loop 12115 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214492]]\n",
      "Loop 12116 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214505]]\n",
      "Loop 12117 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214519]]\n",
      "Loop 12118 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214532]]\n",
      "Loop 12119 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214545]]\n",
      "Loop 12120 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214558]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 12121 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214572]]\n",
      "Loop 12122 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214585]]\n",
      "Loop 12123 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214598]]\n",
      "Loop 12124 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214611]]\n",
      "Loop 12125 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214624]]\n",
      "Loop 12126 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214638]]\n",
      "Loop 12127 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214651]]\n",
      "Loop 12128 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214664]]\n",
      "Loop 12129 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214677]]\n",
      "Loop 12130 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.0521469]]\n",
      "Loop 12131 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214704]]\n",
      "Loop 12132 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214717]]\n",
      "Loop 12133 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.0521473]]\n",
      "Loop 12134 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214743]]\n",
      "Loop 12135 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214756]]\n",
      "Loop 12136 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214769]]\n",
      "Loop 12137 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214782]]\n",
      "Loop 12138 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214795]]\n",
      "Loop 12139 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214808]]\n",
      "Loop 12140 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214821]]\n",
      "Loop 12141 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214834]]\n",
      "Loop 12142 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214848]]\n",
      "Loop 12143 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214861]]\n",
      "Loop 12144 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214874]]\n",
      "Loop 12145 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214887]]\n",
      "Loop 12146 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.052149]]\n",
      "Loop 12147 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214913]]\n",
      "Loop 12148 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214926]]\n",
      "Loop 12149 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214939]]\n",
      "Loop 12150 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214952]]\n",
      "Loop 12151 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214965]]\n",
      "Loop 12152 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05214978]]\n",
      "Loop 12153 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.0521499]]\n",
      "Loop 12154 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215003]]\n",
      "Loop 12155 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215016]]\n",
      "Loop 12156 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215029]]\n",
      "Loop 12157 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215042]]\n",
      "Loop 12158 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215055]]\n",
      "Loop 12159 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215068]]\n",
      "Loop 12160 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215081]]\n",
      "Loop 12161 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215094]]\n",
      "Loop 12162 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215107]]\n",
      "Loop 12163 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215119]]\n",
      "Loop 12164 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215132]]\n",
      "Loop 12165 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215145]]\n",
      "Loop 12166 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215158]]\n",
      "Loop 12167 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215171]]\n",
      "Loop 12168 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215184]]\n",
      "Loop 12169 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215196]]\n",
      "Loop 12170 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215209]]\n",
      "Loop 12171 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215222]]\n",
      "Loop 12172 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215235]]\n",
      "Loop 12173 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215248]]\n",
      "Loop 12174 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.0521526]]\n",
      "Loop 12175 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215273]]\n",
      "Loop 12176 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215286]]\n",
      "Loop 12177 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215299]]\n",
      "Loop 12178 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215311]]\n",
      "Loop 12179 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215324]]\n",
      "Loop 12180 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215337]]\n",
      "Loop 12181 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215349]]\n",
      "Loop 12182 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215362]]\n",
      "Loop 12183 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215375]]\n",
      "Loop 12184 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215387]]\n",
      "Loop 12185 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.052154]]\n",
      "Loop 12186 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215413]]\n",
      "Loop 12187 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215425]]\n",
      "Loop 12188 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215438]]\n",
      "Loop 12189 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215451]]\n",
      "Loop 12190 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215463]]\n",
      "Loop 12191 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215476]]\n",
      "Loop 12192 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215488]]\n",
      "Loop 12193 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215501]]\n",
      "Loop 12194 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215514]]\n",
      "Loop 12195 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215526]]\n",
      "Loop 12196 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215539]]\n",
      "Loop 12197 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215551]]\n",
      "Loop 12198 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215564]]\n",
      "Loop 12199 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215576]]\n",
      "Loop 12200 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215589]]\n",
      "Loop 12201 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215601]]\n",
      "Loop 12202 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215614]]\n",
      "Loop 12203 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215626]]\n",
      "Loop 12204 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215639]]\n",
      "Loop 12205 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215651]]\n",
      "Loop 12206 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215664]]\n",
      "Loop 12207 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215676]]\n",
      "Loop 12208 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215689]]\n",
      "Loop 12209 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215701]]\n",
      "Loop 12210 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215714]]\n",
      "Loop 12211 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215726]]\n",
      "Loop 12212 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215739]]\n",
      "Loop 12213 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215751]]\n",
      "Loop 12214 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215763]]\n",
      "Loop 12215 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215776]]\n",
      "Loop 12216 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215788]]\n",
      "Loop 12217 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215801]]\n",
      "Loop 12218 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215813]]\n",
      "Loop 12219 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215825]]\n",
      "Loop 12220 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215838]]\n",
      "Loop 12221 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.0521585]]\n",
      "Loop 12222 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215862]]\n",
      "Loop 12223 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215875]]\n",
      "Loop 12224 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215887]]\n",
      "Loop 12225 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215899]]\n",
      "Loop 12226 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215912]]\n",
      "Loop 12227 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215924]]\n",
      "Loop 12228 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215936]]\n",
      "Loop 12229 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215948]]\n",
      "Loop 12230 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215961]]\n",
      "Loop 12231 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215973]]\n",
      "Loop 12232 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215985]]\n",
      "Loop 12233 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05215997]]\n",
      "Loop 12234 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.0521601]]\n",
      "Loop 12235 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05216022]]\n",
      "Loop 12236 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05216034]]\n",
      "Loop 12237 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05216046]]\n",
      "Loop 12238 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05216059]]\n",
      "Loop 12239 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05216071]]\n",
      "Loop 12240 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05216083]]\n",
      "Loop 12241 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05216095]]\n",
      "Loop 12242 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05216107]]\n",
      "Loop 12243 Loss_Train:  [[ 13.19524854]] Loss_Validation:  [[ 11.05216119]]\n",
      "BGD Completed Successfully. Time Used:17.917592763900757s\n",
      "Drawing...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3X18XHWd//3XZ+4yuU+aptAboAVh\noS1tqQVxQW5dFBSriAKKAup2VbxWl2WX4s2KPPB64M0CsuviDwVE7VK8BIRVFF3sWrkuBdsulJYC\nrdBCaGnTmyTN/Uzyuf44J+kknaRJ2plJOu/n4zGPc8733H16ks4733NmzjF3R0REZLBIoQsQEZHx\nSQEhIiJZKSBERCQrBYSIiGSlgBARkawUECIikpUCQsYdM7vJzH6Sh/2sN7Nzcr2fXDMzN7O3FLoO\nOfwoICTvzKw149VrZh0Z0x89xPv6oZl1D9rnZQDuPsfd/2cM25wZvinHhlnmKjNbbWYtZtZgZt/M\nXN7MJpnZI2bWZmZbzOwjg9b/SNjeZmY/N7NJo61T5GApICTv3L2i7wW8Blyc0bYsB7v8ZuY+3f3B\nA60w3Jv/CJUBXwAmA28Dzgeuz5j/XaAbOAL4KHCXmc0J9z0H+D/Ax8L57cB/HGQ9IqOmgJDxKmFm\nPzKzveGpoEV9M8xsmpk9ZGaNZvaqmf39WHZgZpvN7J3h+E1m9jMz+4mZtQBXm9lpZrYq7AVsN7Pb\nwlVXhsOmsEfy9sHbdve73P0P7t7t7m8Ay4Azwn2VAx8EvuLure7+FPAYQSBAEBj/5e4r3b0V+Apw\niZlVjuDfVB0et8awB/JlM4uE8yLh9BYz2xEuVx3O6+sVLTGzrWa2zcz+MWO7Qx0LOYwpIGS8eh+w\nHKghePP8dwje5ID/Ap4DphP8Zf4FM3vXIdjnYuBn4T6XAd8BvuPuVcBxwE/D5c4KhzVhj+SPI9j2\nWcD6cPwEoMfdX86Y/xwwJxyfE04D4O5/IehtnDCC/fwbUA0cC5wNfBy4Jpx3dfg6N5xfQXhcM5wL\nHA9cACztC1CGPhZyGFNAyHj1lLs/7u49wI+B+WH7qUC9u98c/nX+CvB94PJhtnW9mTWFr53DLPdH\nd/+5u/e6eweQAt5iZpPDv/T/NJZ/iJldAywCvh02VQDNgxZrBipHOH+o/USBy4Ab3X2vu28G/pWB\nPZPb3P2VsGdyI3D5oNNpX3P3Nnd/HrgPuCJsPyTHQiYWBYSMV29mjLcDyfCN7BhgWsYbfhPwRYJz\n9UP5trvXhK/Jwyz3+qDpTxL81f6imf3ZzN472n+Emb0fuBW40N37wqkVqBq0aBWwd4TzhzIZSABb\nMtq2EPS0AKZlmRdj4LF7fdD8aeH4QR8LmXgO9kKcSL69Drzq7sfnYNsDbm3s7huBK8LTWpcAPzOz\nusHLDcXM3k3Qu3lP+Bd5n5eBmJkdH+4Dgh5S3ymo9ezrMWFmxwIl4XrD2Unwl/4xwAth29HAG+H4\n1nAeGfPSwHZgRth2FPBixvytMPSxcPe2A9QkE5h6EDLRPAO0mNkNZlZqZlEzm2tmpx7qHZnZlWZW\n7+69QFPY3AM0Ar0E5/GHWvc8gusYH3T3ZzLnhW+qDwM3m1m5mZ1BcP3jx+Eiy4CLzewd4QXtm4GH\n3X3YHkR4Ou6nwNfNrNLMjgGuA/q+U/IA8A9mNsvMKoD/G3jQ3dMZm/mKmZWFn6S6BnjwAMdCDmMK\nCJlQwjfBi4EFwKsEfzX/gODC7KH2bmC9mbUSXKS93N073b0d+Drw/4anuU7Psu5Xwpoez/j+xa8y\n5n8WKAV2ELxxf8bd14f/xvXApwmCYgfBtYfPjrDm/wtoA14BngL+E7g3nHcvQQitJDh2neHymX4P\nbAKeJDg195vhjsUIa5IJyvTAIBExs5kEoREf1KOQIqYehIiIZKWAEBGRrHSKSUREslIPQkREsprQ\n34OYPHmyz5w5s9BliIhMKKtXr97p7vUHWm5CB8TMmTNZtWpVocsQEZlQzGzLgZfSKSYRERmCAkJE\nRLJSQIiISFYT+hqEiORHKpWioaGBzk7dXWMiSSaTzJgxg3g8Pqb1FRAickANDQ1UVlYyc+ZMzKzQ\n5cgIuDu7du2ioaGBWbNmjWkbOTvFZGZJM3vGzJ4LHxn5tbB9lpk9bWYbzexBM0uE7SXh9KZw/sxc\n1SYio9PZ2UldXZ3CYQIxM+rq6g6q15fLaxBdwHnuPp/gzpvvDu96+Q3g9vB+/nsIHkRCONzj7m8B\nbg+XE5FxQuEw8RzszyxnAeGB1nAyHr4cOI/gub8A9wPvD8cXh9OE88+3XP1Gbn8BfncLtO3KyeZF\nRA4HOf0UU/gwl2cJ7mn/W+AvQFPG7YQb2Pc4xOmEjzsM5zcDdVm2ucTMVpnZqsbGxrEVtmsjrPwW\ntL554GVFpKB27drFggULWLBgAUceeSTTp0/vn+7u7h7RNq655hpeeumlEe/zBz/4AV/4whfGWvJh\nI6cXqcOHuywwsxrgEeCkbIuFw2y9hf3uJOjudwN3AyxatGhsdxqMlwfDVMeYVheR/Kmrq+PZZ58F\n4KabbqKiooLrr79+wDLujrsTiWT/m/e+++7LeZ2Ho7x8D8Ldm4D/AU4HasKHz0PwHNyt4XgDwfNw\nCedXA7tzUlC8NBh263G6IhPVpk2bmDt3Lp/+9KdZuHAh27ZtY8mSJSxatIg5c+Zw88039y975pln\n8uyzz5JOp6mpqWHp0qXMnz+ft7/97ezYsWPE+/zJT37CySefzNy5c/niF78IQDqd5mMf+1h/+513\n3gnA7bffzuzZs5k/fz5XXnnlof3H50nOehBmVg+k3L3JzEqBdxJceF4BXAosB64CHg1XeSyc/mM4\n/3eeq3uR9wWEehAio/a1/1rPC1tbDuk2Z0+r4qsXzxn1ei+88AL33Xcf3/ve9wC49dZbmTRpEul0\nmnPPPZdLL72U2bNnD1inubmZs88+m1tvvZXrrruOe++9l6VLlx5wXw0NDXz5y19m1apVVFdX8853\nvpNf/OIX1NfXs3PnTp5//nkAmpqCR3Z/85vfZMuWLSQSif62iSaXPYipwAozWwv8Gfitu/8CuAG4\nzsw2EVxjuCdc/h6gLmy/DjjwT2ys4mXBMNWes12ISO4dd9xxnHrqqf3TDzzwAAsXLmThwoVs2LCB\nF154Yb91SktLufDCCwF461vfyubNm0e0r6effprzzjuPyZMnE4/H+chHPsLKlSt5y1vewksvvcTn\nP/95nnjiCaqrg8ejz5kzhyuvvJJly5aN+YtqhZazHoS7rwVOydL+CnBalvZO4EO5qmcA9SBExmws\nf+nnSnl5ef/4xo0b+c53vsMzzzxDTU0NV155ZdbvACQSif7xaDRKOj2yR3APdUKjrq6OtWvX8qtf\n/Yo777yThx56iLvvvpsnnniC3//+9zz66KPccsstrFu3jmg0Osp/YWEV572YEn0XqdWDEDlctLS0\nUFlZSVVVFdu2beOJJ544pNs//fTTWbFiBbt27SKdTrN8+XLOPvtsGhsbcXc+9KEP8bWvfY01a9bQ\n09NDQ0MD5513Ht/61rdobGykvX3ivd8U5602+nsQE+8HJiLZLVy4kNmzZzN37lyOPfZYzjjjjIPa\n3j333MPPfvaz/ulVq1Zx8803c8455+DuXHzxxbznPe9hzZo1fPKTn8TdMTO+8Y1vkE6n+chHPsLe\nvXvp7e3lhhtuoLKy8mD/iXk3oZ9JvWjRIh/TA4N6e+HmWjjnRjgnd5c6RA4XGzZs4KSTsn1KXca7\nbD87M1vt7osOtG5xnmKKRCCWVA9CRGQYxRkQEJxm0kVqEZEhFXFAlEO3ehAiIkMp4oAo1SkmEZFh\nFGVA/HnzbrbsdTo7Wg+8sIhIkSrKj7nuau2Gzgh1XboXk4jIUIqyB1GWiNLhJdCti9QiE8E555yz\n3xff7rjjDj772c8Ou15FRQUAW7du5dJLLx1y2wf6uPwdd9wx4ItuF1100SG5v9JNN93Et7/97YPe\nTq4Ub0BQomsQIhPEFVdcwfLlywe0LV++nCuuuGJE60+bNm3Al95Ga3BAPP7449TU1Ix5exNFUQZE\naSJKBwksrR6EyERw6aWX8otf/IKuri4ANm/ezNatWznzzDNpbW3l/PPPZ+HChZx88sk8+uij+62/\nefNm5s6dC0BHRweXX3458+bN47LLLqOjY9/7wGc+85n+24V/9atfBeDOO+9k69atnHvuuZx77rkA\nzJw5k507dwJw2223MXfuXObOncsdd9zRv7+TTjqJv/3bv2XOnDlccMEFA/ZzINm22dbWxnve8x7m\nz5/P3LlzefDBBwFYunQps2fPZt68efs9J+NgFeU1iLJEjA4vIaKAEBm9Xy2FN58/tNs88mS48NYh\nZ9fV1XHaaafx61//msWLF7N8+XIuu+wyzIxkMskjjzxCVVUVO3fu5PTTT+d973vfkM9jvuuuuygr\nK2Pt2rWsXbuWhQsX9s/7+te/zqRJk+jp6eH8889n7dq1/P3f/z233XYbK1asYPLkyQO2tXr1au67\n7z6efvpp3J23ve1tnH322dTW1rJx40YeeOABvv/97/PhD3+Yhx56aETPhRhqm6+88grTpk3jl7/8\nJRDctnz37t088sgjvPjii5jZIb+teFH2IMoTUTpJKCBEJpDM00yZp5fcnS9+8YvMmzePd77znbzx\nxhts3759yO2sXLmy/4163rx5zJs3r3/eT3/6UxYuXMgpp5zC+vXrs94uPNNTTz3FBz7wAcrLy6mo\nqOCSSy7hD3/4AwCzZs1iwYIFwOhuKz7UNk8++WT++7//mxtuuIE//OEPVFdXU1VVRTKZ5FOf+hQP\nP/wwZWVlI9rHSBVlD6I0EaWdEmI9+98KWEQOYJi/9HPp/e9/P9dddx1r1qyho6Oj/y//ZcuW0djY\nyOrVq4nH48ycOTPrbb4zZetdvPrqq3z729/mz3/+M7W1tVx99dUH3M5w97IrKSnpH49GoyM+xTTU\nNk844QRWr17N448/zo033sgFF1zAv/zLv/DMM8/w5JNPsnz5cv793/+d3/3udyPaz0gUZQ+i7xRT\n1FPQM7J7wYtIYVVUVHDOOefwiU98YsDF6ebmZqZMmUI8HmfFihVs2bJl2O2cddZZLFu2DIB169ax\ndu1aILhdeHl5OdXV1Wzfvp1f/epX/etUVlayd+/erNv6+c9/Tnt7O21tbTzyyCO84x3vOKh/51Db\n3Lp1K2VlZVx55ZVcf/31rFmzhtbWVpqbm7nooou44447+p/dfagUZQ8iGjFSkWQwkWqHaFVhCxKR\nEbniiiu45JJLBnyi6aMf/SgXX3wxixYtYsGCBZx44onDbuMzn/kM11xzDfPmzWPBggWcdlrw/LL5\n8+dzyimnMGfOnP1uF75kyRIuvPBCpk6dyooVK/rbFy5cyNVXX92/jU996lOccsopIz6dBHDLLbf0\nX4iG4NGm2bb5xBNP8E//9E9EIhHi8Th33XUXe/fuZfHixXR2duLu3H777SPe70gU5+2+gVu+dj1f\n9u/DP74MlUcc4spEDi+63ffEpdt9j0FvNKMHISIi+ynegIiFV/t1y28RkayKNiCI9wWEehAiIzGR\nT0cXq4P9mRVxQOi51CIjlUwm2bVrl0JiAnF3du3aRTKZHPM2ivJTTACRhE4xiYzUjBkzaGhooLGx\nsdClyCgkk0lmzJgx5vUVEOpBiBxQPB5n1qxZhS5D8qxoTzFZSXkwoseOiohkVbQBEesLCPUgRESy\nyllAmNlRZrbCzDaY2Xoz+3zYfpOZvWFmz4avizLWudHMNpnZS2b2rlzVBhBN6hqEiMhwcnkNIg38\no7uvMbNKYLWZ/Tacd7u7D3iMkpnNBi4H5gDTgP82sxPcvScXxSXCHkRPdzvRXOxARGSCy1kPwt23\nufuacHwvsAGYPswqi4Hl7t7l7q8Cm4DTclVfaUmCLo+T1nOpRUSyyss1CDObCZwCPB02fc7M1prZ\nvWZWG7ZNB17PWK2BLIFiZkvMbJWZrTqYj9yVlQS3/O7pbB3zNkREDmc5DwgzqwAeAr7g7i3AXcBx\nwAJgG/CvfYtmWX2/b+W4+93uvsjdF9XX14+5rrLwsaM9XbpILSKSTU4DwsziBOGwzN0fBnD37e7e\n4+69wPfZdxqpATgqY/UZwNZc1VYaD54J0auPuYqIZJXLTzEZcA+wwd1vy2ifmrHYB4B14fhjwOVm\nVmJms4DjgWdyVV9Z+NhR79Y1CBGRbHL5KaYzgI8Bz5tZ32OOvghcYWYLCE4fbQb+DsDd15vZT4EX\nCD4BdW2uPsEEQUC0UgpdugYhIpJNzgLC3Z8i+3WFx4dZ5+vA13NVU6bSRJTtnsRS6kGIiGRTtN+k\nLkvEaCdJRAEhIpJVEQdElFZPElVAiIhkVdQB0UYpsbQCQkQkmyIOiBitJIn3tIMegiIisp+iDYho\nxOi0MgwHfdRVRGQ/RRsQAKlYeEfXbn3UVURksKIOiHQ0DAh9F0JEZD/FHRDxvqfK7S1sISIi41BR\nB4THK4IR9SBERPZT1AFhycpgRNcgRET2U9QBESkJA0I9CBGR/RR1QESTVcGIrkGIiOynqAMiXqYe\nhIjIUIo6IBKlQUB4l3oQIiKDFXVAVJQmaPUk6U4FhIjIYMUdECUx2kiSbm8pdCkiIuNOUQdEZTJG\nq5eqByEikkXRB0Q7JbgCQkRkP0UdEBUlcdooxfVFORGR/RR5QMRo9SSmgBAR2U9RB0RlMkYbpUQU\nECIi+ynqgKgoidHmSaJ67KiIyH6KOyCSMVr1XGoRkayKOiDi0QhdkVLivV3Qky50OSIi40pRBwRA\nOtb30CBdhxARyZSzgDCzo8xshZltMLP1Zvb5sH2Smf3WzDaGw9qw3czsTjPbZGZrzWxhrmrL1NP3\n0CAFhIjIALnsQaSBf3T3k4DTgWvNbDawFHjS3Y8HngynAS4Ejg9fS4C7clhbv96+x47qjq4iIgPk\nLCDcfZu7rwnH9wIbgOnAYuD+cLH7gfeH44uBH3ngT0CNmU3NVX39EupBiIhkk5drEGY2EzgFeBo4\nwt23QRAiwJRwsenA6xmrNYRtOeV9Dw3qbM71rkREJpScB4SZVQAPAV9w9+Fum2pZ2jzL9paY2Soz\nW9XY2HjwBSZrgmFn08FvS0TkMJLTgDCzOEE4LHP3h8Pm7X2njsLhjrC9ATgqY/UZwNbB23T3u919\nkbsvqq+vP+gao6V9AaEehIhIplx+ismAe4AN7n5bxqzHgKvC8auARzPaPx5+mul0oLnvVFQuRctr\nAfAOBYSISKZYDrd9BvAx4HkzezZs+yJwK/BTM/sk8BrwoXDe48BFwCagHbgmh7X1S5ZW0O1RIu17\ncnowREQmmpy9J7r7U2S/rgBwfpblHbg2V/UMpaI0TjPlVLQpIEREMhX9N6krS2K0eDk97XsKXYqI\nyLhS9AFRURJjL2W6BiEiMkjRB0R1WZxmL9fHXEVEBlFAlMZpoQzrUg9CRCRT0QdETWnQg4h1D/cd\nPhGR4lP0AVFVGqeFcuKpFvD9vrgtIlK0ij4gkvEo7ZEKot4DqfZClyMiMm4UfUAApBPhDfs6dKFa\nRKSPAgLoSVQHI7ofk4hIPwUEQFIBISIymAICiJTqlt8iIoMpIIBYeEdX9SBERPZRQADxir5bfut+\nTCIifRQQQLJiEgDpNp1iEhHpoztcA9UVpbR6Elp3Ey90MSIi44R6EIS326CcdJtOMYmI9FFAENzR\ntcXL6NUtv0VE+ikg6Lujazl07C50KSIi48aIAsLMPm9mVRa4x8zWmNkFuS4uX2rKEuzxSqL6HoSI\nSL+R9iA+4e4twAVAPXANcGvOqsqzmtI4u72SeJd6ECIifUYaEBYOLwLuc/fnMtomvLJElCarIplq\nht7eQpcjIjIujDQgVpvZbwgC4gkzqwQOm3dSM6M9XkuEHt1uQ0QkNNLvQXwSWAC84u7tZjaJ4DTT\nYaO7ZBJ0AG07oWxSocsRESm4kfYg3g685O5NZnYl8GXgsPpMaLokDIX2XYUtRERknBhpQNwFtJvZ\nfOCfgS3Aj3JWVQFYeV0w0r6zsIWIiIwTIw2ItLs7sBj4jrt/B6jMXVn5F6+aEoy0KSBERGDkAbHX\nzG4EPgb80syiMPxti8zsXjPbYWbrMtpuMrM3zOzZ8HVRxrwbzWyTmb1kZu8ayz/mYJTWHAFAT2tj\nvnctIjIujTQgLgO6CL4P8SYwHfjWAdb5IfDuLO23u/uC8PU4gJnNBi4H5oTr/EcYQnlTW1XBXi+l\nq2VHPncrIjJujSggwlBYBlSb2XuBTncf9hqEu68ERvrNs8XAcnfvcvdXgU3AaSNc95CYXFHCbq+k\nu0WnmEREYOS32vgw8AzwIeDDwNNmdukY9/k5M1sbnoIKH+XGdOD1jGUawrZstSwxs1Vmtqqx8dCd\nDppcUcIeKvE2nWISEYGRn2L6EnCqu1/l7h8n+Ov+K2PY313AcQTfqdgG/GvYnu1b2Z5tA+5+t7sv\ncvdF9fX1Yyghu8kVCXZ5FaaPuYqIACMPiIi7Z56c3zWKdfu5+3Z373H3XuD77DuN1AAclbHoDGDr\naLd/MCZXBqeYYp26H5OICIz8Tf7XZvaEmV1tZlcDvwQeH+3OzGxqxuQHgL5POD0GXG5mJWY2Czie\n4JRW3lSWxGiyapLde8Czdl5ERIrKiG614e7/ZGYfBM4gOB10t7s/Mtw6ZvYAcA4w2cwagK8C55jZ\nAoLTR5uBvwu3v97Mfgq8AKSBa929Z0z/ojEyM7oStcR6uqG7DUoq8rl7EZFxZ8TPpHb3h4CHRrH8\nFVma7xlm+a8DXx/p9nMhXToJWgm+Ta2AEJEiN2xAmNlesl8sNsDdvSonVRWIlU0OAqJtF9TOLHQ5\nIiIFNWxAuPthdTuNA4lUTIYdgD7qKiKiZ1JnilZPA6C3ZVuBKxERKTwFRIZk7VR63eje80ahSxER\nKTgFRIa6qnJ2UUXXnoZClyIiUnAKiAz1FSW86bU6xSQiggJigClVSbZ7Ldb6ZqFLEREpOAVEhmk1\nSXZ4LYn27YUuRUSk4BQQGcoSMZpikylL7YF0d6HLEREpKAXEIN2l4aNHdZpJRIqcAmIQrzwyGNmr\ngBCR4qaAGCRaEz6naK8+ySQixU0BMUjZpBkApJr0ZTkRKW4KiEFqJx9Jt0dp26kvy4lIcVNADDK1\ntowd1Op2GyJS9BQQg0yrLmW71+oahIgUPQXEIEdWJ9nmk4i3KSBEpLgpIAZJxqPsih1JZec26O0t\ndDkiIgWjgMiitWw6MU/pNJOIFDUFRBapyqODkaYthS1ERKSAFBBZlNTPAqB39+bCFiIiUkAKiCyq\npx5Hrxttb24qdCkiIgWjgMjimCm1bKeWjsZXCl2KiEjBKCCymDm5nNd8CuzRNQgRKV4KiCymViXZ\nyhSSbbrdhogULwVEFpGIsTc5jYruRkh3FbocEZGCyFlAmNm9ZrbDzNZltE0ys9+a2cZwWBu2m5nd\naWabzGytmS3MVV0jla4+mggOTa8XuhQRkYLIZQ/ih8C7B7UtBZ509+OBJ8NpgAuB48PXEuCuHNY1\nIrE6fdRVRIpbzgLC3VcCuwc1LwbuD8fvB96f0f4jD/wJqDGzqbmqbSTKp54AQMvWFwtZhohIweT7\nGsQR7r4NIByGD4BmOpB5LqchbNuPmS0xs1VmtqqxsTFnhU6ddgzNXkbn1hdytg8RkfFsvFyktixt\nnm1Bd7/b3Re5+6L6+vqcFXTslEo2+gxofCln+xARGc/yHRDb+04dhcMdYXsDcFTGcjOArXmubYAj\nqkp4LXIUFS36NrWIFKd8B8RjwFXh+FXAoxntHw8/zXQ60Nx3KqpQzIzWquOo6GmCtp2FLEVEpCBy\n+THXB4A/An9lZg1m9kngVuBvzGwj8DfhNMDjwCvAJuD7wGdzVddoRKacCEDv9g0FrkREJP9iudqw\nu18xxKzzsyzrwLW5qmWsqo8+GTbBni3PU3fsOwpdjohIXo2Xi9Tj0jGzjqfVk+xtWHfghUVEDjMK\niGGccGQVm3w6kZ36JJOIFB8FxDCS8SjbEjOp3bsRPOunbkVEDlsKiAPYO2kOlb3N0Kx7MolIcVFA\nHEDJ0acC0LzpmQJXIiKSXwqIAzhmzml0e5SdL/+p0KWIiOSVAuIAZh81hZc5hsi2NYUuRUQkrxQQ\nB5CIRdhadhJTWjdAb2+hyxERyRsFxAikj1xAubfTtePlQpciIpI3CogRqD3+dAAa1j1V4EpERPJH\nATECJ558Ks1eRsfGlYUuRUQkbxQQI1BbWcqGkvlMbny60KWIiOSNAmKEOmacyZG9b9L0xsZClyIi\nkhcKiBGaesq7AHj1z48XuBIRkfxQQIzQCbPfSiO19L7y+0KXIiKSFwqIEYpEI7xWvYiZLavo7k4V\nuhwRkZxTQIxCYvZF1NHM2j8+UehSRERyTgExCie+44N0Eaflfx8udCkiIjmngBiFeFk1r1a/jZP2\nrKC5vavQ5YiI5JQCYpTK5l/CVNvNn/7w20KXIiKSUwqIUTrq7ZeQIkbHqmX09uopcyJy+FJAjJKV\n1vLmjHdxXvcKVr6wudDliIjkjAJiDKaefy1V1sGLv/1hoUsREckZBcQYxGb+NXvKj+Ov9zzKypd2\nFLocEZGcUECMhRkVZ32WeZFXefzR/yTdowcJicjhpyABYWabzex5M3vWzFaFbZPM7LdmtjEc1hai\ntpGKv/VjdJRO5cOtP+Ynf9xc6HJERA65QvYgznX3Be6+KJxeCjzp7scDT4bT41eshOT5N7Awsok/\nPvEAm3a0FroiEZFDajydYloM3B+O3w+8v4C1jIgt+Cjpmll8Kfoj/nn5n+hM9RS6JBGRQ6ZQAeHA\nb8xstZktCduOcPdtAOFwSoFqG7lYgtjFt3M0b3Lujh/zDw8+q+9GiMhho1ABcYa7LwQuBK41s7NG\nuqKZLTGzVWa2qrGxMXcVjtRx58L8K7g2/gu2r1/Jlx9dp5AQkcNCQQLC3beGwx3AI8BpwHYzmwoQ\nDrN+ftTd73b3Re6+qL6+Pl8lD+/dt2I1M7i/4rv85unn+fyDz+p0k4hMeHkPCDMrN7PKvnHgAmAd\n8BhwVbjYVcCj+a5tzEprsMtYFgqrAAAQ3UlEQVR+QqW38nj9v7HiuU1c8h//H6/ubCt0ZSIiY1aI\nHsQRwFNm9hzwDPBLd/81cCvwN2a2EfibcHriOPJk+NAPmdL2Mk/NuIvmPTt59x0r+e6KTepNiMiE\nZO4T93z5okWLfNWqVYUuY6D1P4eHPkm69ji+VvkVfvxihCOrkiw561g+uHAG1WXxQlcoIkXOzFZn\nfMVg6OUUEDnw6kp48EpwZ+Oim7hx44mseq2JZDzCe+dN49K3zmDRMbXEouPpU8YiUiwUEIW2ZzM8\n/Hfw+p9g1llsWrCUe1+p4tH/fYO27h6qS+Oc81f1nHV8PYtm1nL0pDLMrNBVi0gRUECMB709sOpe\n+N0t0NkEs86m49RrWZE+mSdfbGTFSzvY3dYNQH1lCQuOquGkqVWceGQlJx5ZyTF15UQjCg0RObQU\nEONJxx5Y/UN4+v/A3m1QOwtmL6bnpMW8HDmO1a81sXrLHtY2NPHqzjb6vkaRjEeYWVfOzLpyjplc\nFgzrguERVUmFh4iMiQJiPEp3w/qHYe2D8MrvwXugchrMPBNmngFHv53Oqlls2tnBhm0tvPjmXjbv\nbGPzrjZe391Bd8ZdY2MR44iqJNNqkkytLmVqTZJp1aVMrU4yrSYYTipP6LSViOxHATHete+Glx6H\nv/wONj8FrduD9ngZHDEn+NjskSfD5BNg0nH0lB/BtpZOXtvVzuZd7bzR1M62pk62NnewtamTN5s7\nBwQIQCIaob6yhMmVJUypLKF+wDDZPz25ooRETBfMRYqFAmIicYedG+GNVfDm87BtbTDsat63TLws\nODVVdyxMOhZqjoaq6VA1Daqm05ucxK72FNvCwNja1MH2vZ007u3qf+3Y29V/zWOw2rJ4f3DUVSSY\nVJ6grjzBpPISJpUnmNzfVkJVaUw9E5EJbKQBEctHMXIAZlB/QvDq4w5Nr8GuTbD7Fdj9Kuz+CzS+\nBC8/AT0D3+gj0RLqq6ZRXzWdedVhcEyaCkfVQ8UUKD8SKqaQileys62bHS37QiMYdvZPb9ndxu7W\nbtq6s3/BLxYxavsDZF+Y1FWU9I/XlCWoKYsHr9IEyXhEoSIywSggxiszqD0meHH+wHm9PdDWCM1v\nQEvma2vQtuWPsHcr9Kb322w8mmBq+RSmVtRD+ZQgPCqmwNQpcHzYVj4VyurojFWxu9PZ3dbNrrZu\ndrd1sau1O5hu3de27o1mdrV1s7dz//31ScQi1IZhUV0Wp6Y0DI++ICntG8aD+WUJasvilMajChaR\nAlFATESRKFQeGbx4a/ZlenuC6xxtO6B1RxAorTv2TbfuCEJk23PBPN+/t5AEppVUM61sEpRNgrI6\nKA2HU2qDYX/bEXQnathDBbs6oKmjm+b2FE0dKZraUzS1dwfDjmD42u521jak2NPeTVd66Ee2JqIR\nqkrjVJXGqErGqUwGw6rSGJXJOFXJcFgao7IknF+6b1iRiBHRp71ExkQBcbiKRKGiPngdMWf4ZXt7\ng4/i9oVH+67g1bFn33j77mBe44vBePf+T9BLENxo64hEZRAopbVQWgPJmmBYXQNHVA9sS06hK1ZF\nk5ezp7eUps5emtpTNIdBsiccb+lM09KRYm9nmq1NHbR0ptnbmaIzNfzzwM2gIpERGmHIVCZjVCRj\nlJfEqEiEw5JgWF4S7R/PbCuJRcf+8xCZgBQQApEIlNcFryknjWyddFcQFO27oGN3RpDsyWjbHXxB\nsPkN6GwOxnv2v0heQhgsACVVkKzOCJBwvC4jVEoqg+VKKknFKmi1Ulq8jJbeElpS0f4gaelM9QdJ\nS0c47EzxZksnL+9I0dbVQ2tXmu5hejCZ4lELwiLRFxzRASFSURKjLDGwrSwRpTQRpSweDhNRShOx\n/umSmK7NyPilgJCxiZVA1dTgNVLukOoIgqKzGTqagvGOpn0B0tfWN3/3K/vmp/a/fXocqA1fAERL\nwgAJX8nqfeN1VRntVRkhU0VnpIxWK6PNk7T0ltCajtHWHQRIW1d6wHh/W1cPezvTvNncua+9u4ee\nUTwwKmJQGg9CozQRoSwe6w+SskSUZLxvPGgvjUf3hU44XZqIkYxFSMajlMQjJGPBesl42KYQkjFS\nQEj+mEGiLHhVTRv9+unuICi6WqBrb8YwfHU2Z0xnzGt6feA6gy7ex8NX5YBaI5CogER5xitjumrQ\ndDjuiQpS0VLaSdJOkg5L0ubBq7U3QUfa6ehO097dQ3t3D52pnkHjwbyO7h6aO1J0dPfNT9OZ6t3v\nuy4jlYhF+kOkLzxKYpkhsn9bMgybkr7pjPGSWIRELEJJLFgnEYuQiAZt/a9o8NI1oIlLASETRyyx\n77rKWLlDunPoUOluy3i1hq+MtrbG4EaMffO7Wgdc4DeCazEJoCbb/uNhoMRLg++2xEszpkuhomzg\nvAHjZfREk3RaCd2U0EEJ7Z6ggwQdnqCdBO29CTrTTmeql650D52pXjpTPXSme+gKx7vSYVsqmN/a\nlWZnazddg+ele0fVGxpKPGrZwyMMlpLo4PZ9r/4g2m+ZaP90PGLEoxFi4X5i0QjxaNCW2d43Hs+Y\nH4uYelfDUEBIcTHLeDOecvDbcw+uq/QHSlsQGgOCZfB4K6Q6IdUenHJLdUDbznA6oy3VDj6wxxAF\nysNXbbZ6AGKDgyV8xZLBK56EsmRwmrCvLZYxHd/Xlo4k6LYEKRJ0EaeTOJ2eoIsYnZ6g04O2rt4o\n3T1Odzro5XSne+lK9w6Y7h403dU/3kNbd5o97dmX7wqncyUeNWKRgaESjxnxyBChEo2Q6FsnFrZH\ngnVikSC0YhEjFgZQNGLEo0Y03Ec0EiwfjRixcDvBcN86sYx50TAA920nmO671pVLCgiRg2EWvrGW\nBJ/cOpT6wmdwaPQNu7MEyoBh5nhb0HPqbAo+YJDuDEIq3blvmv17CzFG+iZh+0ImXpoRPiVBYPUd\no2gieJUmgh5hNGyLJfbNy1wunPZIjHQkQdripIiRIk63x0hZjG7ipInTRYyUB9NdxEj1GqkeJ90b\nBEy610n19JLqCYbpnl66e5x0T++A9mCe0x0OUz29pHqdVDqY19bdQyrdS7p3+HXSh6D3NZxPn30c\nSy88Maf7UECIjFeZ4VM6ZH/h0HCHnhSkO/YFRrorCJfM6XTnoNcQYZNtfldLuI+uIPh6usPxFPR0\nZf2EW/+hYN+1otKR/pssMiiASiAaDwMovm86EgunE/vGY3EoiYfz40Mv1zcvy3IeidNrMXosRtpi\n9BIEWo9FSROlJ5xOe4w0UVIeJUWUFDF63Ej1Oj1hCPWE4dbT66R7nHSvc+LUygMfg4OkgBCRMIzC\nN9JC6Qupnq6MIOkaPlQGB0y6e5TrpIIPLaQ6oDcVtqfC8XSwbt943/wsXyrNxghOCUYJrkmNikUG\nBk5/IGWML7wKjv7caLc8KgoIERkfxkNIjURv776wGC5I+ucfaLnuIKQyl89cpzeVMb9n3/ShuIZ2\nAAoIEZHRiEQgEp76O8zpIQAiIpKVAkJERLJSQIiISFYKCBERyUoBISIiWY27gDCzd5vZS2a2ycyW\nFroeEZFiNa4CwsyiwHeBC4HZwBVmNruwVYmIFKdxFRDAacAmd3/F3buB5cDiAtckIlKUxtsX5aYD\nr2dMNwBvy1zAzJYAS8LJVjN7aYz7mgzsHOO6uTZea1NdozNe64LxW5vqGp2x1nXMSBYabwGR7cbs\nA26J6O53A3cf9I7MVrn7ooPdTi6M19pU1+iM17pg/NamukYn13WNt1NMDcBRGdMzgK0FqkVEpKiN\nt4D4M3C8mc0yswRwOfBYgWsSESlK4+oUk7unzexzwBMEd8m9193X52h3B32aKofGa22qa3TGa10w\nfmtTXaOT07rMPbdPPRIRkYlpvJ1iEhGRcUIBISIiWRVlQIyX23mY2VFmtsLMNpjZejP7fNh+k5m9\nYWbPhq+LClDbZjN7Ptz/qrBtkpn91sw2hsMcPyg5a11/lXFcnjWzFjP7QiGOmZnda2Y7zGxdRlvW\nY2SBO8PfubVmtjDPdX3LzF4M9/2ImdWE7TPNrCPjuH0vz3UN+XMzsxvD4/WSmb0rV3UNU9uDGXVt\nNrNnw/Z8HrOh3iPy83vm7kX1Irj4/RfgWIJHxT4HzC5QLVOBheF4JfAywS1GbgKuL/Bx2gxMHtT2\nTWBpOL4U+MY4+Fm+SfCln7wfM+AsYCGw7kDHCLgI+BXBd31OB57Oc10XALFw/BsZdc3MXK4Axyvr\nzy38f/AcUALMCv/PRvNZ26D5/wr8SwGO2VDvEXn5PSvGHsS4uZ2Hu29z9zXh+F5gA8G3ycerxcD9\n4fj9wPsLWAvA+cBf3H1LIXbu7iuB3YOahzpGi4EfeeBPQI2ZTc1XXe7+G3dPh5N/IviOUV4NcbyG\nshhY7u5d7v4qsIng/27eazMzAz4MPJCr/Q9lmPeIvPyeFWNAZLudR8HflM1sJnAK8HTY9Lmwi3hv\nIU7lEHyD/TdmttqC25sAHOHu2yD4xQVy/9T04V3OwP+0hT5mMPQxGk+/d58g+Cuzzywz+18z+72Z\nvaMA9WT7uY2n4/UOYLu7b8xoy/sxG/QekZffs2IMiAPeziPfzKwCeAj4gru3AHcBxwELgG0E3dt8\nO8PdFxLcWfdaMzurADUMyYIvUr4P+H/CpvFwzIYzLn7vzOxLQBpYFjZtA45291OA64D/NLOqPJY0\n1M9tXByv0BUM/EMk78csy3vEkItmaRvzcSvGgBhXt/MwszjBD36Zuz8M4O7b3b3H3XuB75PDrvVQ\n3H1rONwBPBLWsL2vuxoOd+S7rgwXAmvcfTuMj2MWGuoYFfz3zsyuAt4LfNTDE9bhKZxd4fhqgnP9\nJ+SrpmF+bgU/XgBmFgMuAR7sa8v3Mcv2HkGefs+KMSDGze08wnOb9wAb3P22jPbMc4YfANYNXjfH\ndZWbWWXfOMEFznUEx+mqcLGrgEfzWdcgA/6qK/QxyzDUMXoM+Hj4KZPTgea+UwT5YGbvBm4A3ufu\n7Rnt9RY8hwUzOxY4Hnglj3UN9XN7DLjczErMbFZY1zP5qivDO4EX3b2hryGfx2yo9wjy9XuWjyvx\n4+1FcKX/ZYLk/1IB6ziToPu3Fng2fF0E/Bh4Pmx/DJia57qOJfgEyXPA+r5jBNQBTwIbw+GkAh23\nMmAXUJ3RlvdjRhBQ24AUwV9unxzqGBF0/b8b/s49DyzKc12bCM5N9/2efS9c9oPhz/g5YA1wcZ7r\nGvLnBnwpPF4vARfm+2cZtv8Q+PSgZfN5zIZ6j8jL75lutSEiIlkV4ykmEREZAQWEiIhkpYAQEZGs\nFBAiIpKVAkJERLJSQIiMgJm1FroGkXxTQIiISFYKCJFRCL+h+i0zW2fB8zIuO0D7OWa20oJnMLxg\nZt8zs4iZRc3shxnL/0Nh/2Ui+4sVugCRCeYSghvLzQcmA382s5XAXw/RDsH9hWYDW4Bfh9t4FZju\n7nMBLHyAj8h4oh6EyOicCTzgwQ3mtgO/B04dph3gGQ+eP9JDcEuHMwnu3XOsmf1beJ+k4e7QKVIQ\nCgiR0cl2O+Xh2mH/2y27u+8h6G38D3At8IODL03k0FJAiIzOSuCy8BpCPcGjKp8Zph3gtPDuwRHg\nMuApM5sMRNz9IeArBI+7FBlXdA1CZHQeAd5OcCdPB/7Z3d80s6HaTwT+CNwKnEwQJI+E4/eFoQFw\nY37/GSIHpru5iuSQmZ0DXO/u7y10LSKjpVNMIiKSlXoQIiKSlXoQIiKSlQJCRESyUkCIiEhWCggR\nEclKASEiIln9/4rFMlM2BY/WAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d90326f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3qkWW3ucAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d53e7b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draw Completed\n",
      "Maching Learning Lab-1:linear regression Completed Successfully. Time Used:18.15487790107727s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    # Cost Function:0.5*lambda*W'*W+0.5*(Y-X*W)'*(Y-X*W)\n",
    "\n",
    "    # Read Data\n",
    "    tic0=time.time()\n",
    "    Data_Path='/home/lucas/Codes/GitHub/ML_Assignment1/ML_Assignment1/DataSet/housing.txt'\n",
    "    Data_Parameter,Data_Value=load_svmlight_file(Data_Path)\n",
    "    Data_Parameter=Data_Parameter.toarray()\n",
    "    train_X, val_X,train_Y,val_Y = train_test_split(Data_Parameter,Data_Value,test_size=0.3, random_state=1)\n",
    "    t_row=train_X.shape[0]#Row Size\n",
    "    col=train_X.shape[1]#Column Size\n",
    "    v_row=val_X.shape[0]\n",
    "    train_Y=train_Y.reshape(t_row, 1)\n",
    "    val_Y=val_Y.reshape(v_row, 1)\n",
    "\n",
    "    W = np.random.random(size=(col, 1))\n",
    "    Paramaters={\n",
    "        'Weights': W,\n",
    "        'train_X':train_X,\n",
    "        'train_Y':train_Y,\n",
    "        'val_X':val_X,\n",
    "        'val_Y':val_Y,\n",
    "        'max_loops':100000,  # in case it won't converage\n",
    "        'epsilon':0.000001,  # if Wt+1-Wt<epsilon then stop BGD\n",
    "        'lambda':0.1,  # regularize\n",
    "        'learning_rate':0.000085,  #learning rate\n",
    "    }\n",
    "    loops,train_loss,val_loss=BGD(Paramaters)\n",
    "    Draw(loops,train_loss,val_loss)\n",
    "    print('Maching Learning Lab-1:linear regression Completed Successfully. Time Used:{}s'.format(time.time()-tic0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
